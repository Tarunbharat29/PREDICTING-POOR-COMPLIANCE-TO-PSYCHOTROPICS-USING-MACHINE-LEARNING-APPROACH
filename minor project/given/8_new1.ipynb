{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7504bc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster_1_date</th>\n",
       "      <th>Date of screening</th>\n",
       "      <th>UHID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>...</th>\n",
       "      <th>No of relapses/exacerbations</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio &lt; 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio &lt; 0.95}</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>frequency of follow up at lgb (to write down follow-up dates)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Final (ignore for now)</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.06.2020</td>\n",
       "      <td>2015-02-28 00:00:00</td>\n",
       "      <td>20190021678</td>\n",
       "      <td>Akhiar Ahmed</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "      <td>180</td>\n",
       "      <td>212</td>\n",
       "      <td>07-12-2019, 21-12-2019, 17-01-2020, 11-04-2020...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.06.2020</td>\n",
       "      <td>2019-05-20 00:00:00</td>\n",
       "      <td>20190008847</td>\n",
       "      <td>Mampi Shill</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.06.2020</td>\n",
       "      <td>2019-09-24 00:00:00</td>\n",
       "      <td>20190016882</td>\n",
       "      <td>Salema Khatoon</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.06.2020</td>\n",
       "      <td>2014-03-03 00:00:00</td>\n",
       "      <td>20170010718</td>\n",
       "      <td>Jiarur Rahman</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.06.2020</td>\n",
       "      <td>2020-06-18 00:00:00</td>\n",
       "      <td>20200006501</td>\n",
       "      <td>Debashis Nath</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>22-06-2020,30-09-2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cluster_1_date    Date of screening         UHID            Name  \\\n",
       "0     22.06.2020  2015-02-28 00:00:00  20190021678    Akhiar Ahmed   \n",
       "1     22.06.2020  2019-05-20 00:00:00  20190008847     Mampi Shill   \n",
       "2     22.06.2020  2019-09-24 00:00:00  20190016882  Salema Khatoon   \n",
       "3     22.06.2020  2014-03-03 00:00:00  20170010718   Jiarur Rahman   \n",
       "4     22.06.2020  2020-06-18 00:00:00  20200006501   Debashis Nath   \n",
       "\n",
       "   Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "0                          10.0                   16.0      male     Islam   \n",
       "1                           8.0                   10.0    female     Islam   \n",
       "2                          17.0                   18.0    female     Islam   \n",
       "3                           7.0                   17.0      male     Islam   \n",
       "4                          10.0                   10.0      male  Hinduism   \n",
       "\n",
       "  Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "0                                            Primary                                         \n",
       "1                                                NaN                                         \n",
       "2                                            Primary                                         \n",
       "3                                                NaN                                         \n",
       "4                                            primary                                         \n",
       "\n",
       "  Max education attained  ... No of relapses/exacerbations  \\\n",
       "0                    NaN  ...                          0.0   \n",
       "1                    NaN  ...                          6.0   \n",
       "2                Primary  ...                          0.0   \n",
       "3                    NaN  ...                          6.0   \n",
       "4                Primary  ...                          1.0   \n",
       "\n",
       "  Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "0                                               1649                            \n",
       "1                                                 22                            \n",
       "2                                                 30                            \n",
       "3                                                 58                            \n",
       "4                                                 20                            \n",
       "\n",
       "  Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}  \\\n",
       "0                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "1                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "2                                               Poor                                                                                                                                                                                                                                                                                              \n",
       "3                                               Good                                                                                                                                                                                                                                                                                              \n",
       "4                                               Good                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "   mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "0                                               12.4                                     \n",
       "1                                               1.66                                     \n",
       "2                                               1.78                                     \n",
       "3                                                NaN                                     \n",
       "4                                                  1                                     \n",
       "\n",
       "  maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "0                                                180                                  \n",
       "1                                                395                                  \n",
       "2                                                240                                  \n",
       "3                                                NaN                                  \n",
       "4                                                 90                                  \n",
       "\n",
       "  total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "0                                                212                                                   \n",
       "1                                                626                                                   \n",
       "2                                                330                                                   \n",
       "3                                               1320                                                   \n",
       "4                                                 90                                                   \n",
       "\n",
       "  frequency of follow up at lgb (to write down follow-up dates)  \\\n",
       "0  07-12-2019, 21-12-2019, 17-01-2020, 11-04-2020...              \n",
       "1  24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...              \n",
       "2     19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020              \n",
       "3  31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...              \n",
       "4                              22-06-2020,30-09-2020              \n",
       "\n",
       "  total number of follow up at LGBRIMH Final (ignore for now)  \\\n",
       "0                                  6.0                    NaN   \n",
       "1                                 12.0                    NaN   \n",
       "2                                  4.0                    NaN   \n",
       "3                                 69.0                    NaN   \n",
       "4                                  2.0                    NaN   \n",
       "\n",
       "  Number of In patient cares  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        0.0  \n",
       "3                        0.0  \n",
       "4                        1.0  \n",
       "\n",
       "[5 rows x 274 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "xlsx_file_path = 'Pilot_Variable_list_cluster 1to 8.xlsx'\n",
    "df2 = pd.read_excel(xlsx_file_path)\n",
    "csv_file_path = '8originaldata.csv'\n",
    "df2.to_csv(csv_file_path, index=False)\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a147fcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster_1_date\n",
      "\n",
      "Date of screening\n",
      "\n",
      "UHID\n",
      "\n",
      "Name\n",
      "\n",
      "Age at presentation (in yrs)\n",
      "\n",
      "Age at last follow up\n",
      "\n",
      "Sex (m/f)\n",
      "\n",
      "Religion\n",
      "\n",
      "Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)\n",
      "\n",
      "Max education attained\n",
      "\n",
      "Address in detail\n",
      "\n",
      "Post Office\n",
      "\n",
      "Rural/Urban\n",
      "\n",
      "Distance from LGBRIMH (in KM)\n",
      "\n",
      "District\n",
      "\n",
      "State\n",
      "\n",
      "Occupation of parents\n",
      "\n",
      "Socioeconomic status\n",
      "\n",
      "Referral\n",
      "\n",
      "Brought by\n",
      "\n",
      "Age at onset(in years)\n",
      "\n",
      "Chief complaint 1\n",
      "\n",
      "Chief complaint 2\n",
      "\n",
      "Chief complaint 3\n",
      "\n",
      "Time period between onset to first consultation at LGBRIMH (DUI) (in days)\n",
      "\n",
      "Type of Family (Nuclear/Joint/single parent/orphan/ foster family\n",
      "\n",
      "Family environment\n",
      "\n",
      "Details of family abnormality (describe)\n",
      "\n",
      "Family h/o stillbirth/abortion\n",
      "\n",
      "Family history(general medical)\n",
      "\n",
      "Family history (psychiatric/neurological)\n",
      "\n",
      "Faith healer visited before consultation or not(yes/no)\n",
      "\n",
      "Antenatal risk factor\n",
      "\n",
      "Place of delivery (Home/hospital)\n",
      "\n",
      "Birth weight(in kg)\n",
      "\n",
      "Neonatal complication\n",
      "\n",
      "Postnatal complication\n",
      "\n",
      "Developmental history\n",
      "\n",
      "Age of school entry(in years)\n",
      "\n",
      "Type of school\n",
      "\n",
      "School adjustment\n",
      "\n",
      "Academic performance\n",
      "\n",
      "School dropout present (yes/no)\n",
      "\n",
      "Detail of past psychiatric history 1\n",
      "\n",
      "Past treatment 1\n",
      "\n",
      "Past treatment medication 1\n",
      "\n",
      "Starting dose past medication 1\n",
      "\n",
      "Age of starting of past medication 1(in years)\n",
      "\n",
      "Past maintenance dose1 (in mg)\n",
      "\n",
      "Side effects of past medication 1\n",
      "\n",
      "Age of occurance past side effects 1(in years)\n",
      "\n",
      "Duration of past side effect 1(in months)\n",
      "\n",
      "Response to past medication 1\n",
      "\n",
      "Detail of past history 2\n",
      "\n",
      "Past treatment 2\n",
      "\n",
      "Past treatment medication 2\n",
      "\n",
      "Starting dose past medication 2\n",
      "\n",
      "Age of starting of past medication 2(in years)\n",
      "\n",
      "Past maintenance dose2\n",
      "\n",
      "Side effects of past medication 2\n",
      "\n",
      "Age of occurance past side effects 2(in years)\n",
      "\n",
      "Duration of past side effect 2(in months)\n",
      "\n",
      "Response to past medication 2\n",
      "\n",
      "Detail of past history 3\n",
      "\n",
      "Past treatment  3\n",
      "\n",
      "Past treatment medication 3\n",
      "\n",
      "Starting dose past medication 3 \n",
      "\n",
      "Age of starting past medication 3 (in years)\n",
      "\n",
      "Past maintenance dose 3\n",
      "\n",
      "Side effects past medication 3\n",
      "\n",
      "Age of occurance of past side effects 3 (in years)\n",
      "\n",
      "Duration of past side effects 3 (in months)\n",
      "\n",
      "Response to past medication 3\n",
      "\n",
      "Change in doctor\n",
      "\n",
      "Past/Current medical conditions\n",
      "\n",
      "Age of onset of medical conditions (in years)\n",
      "\n",
      "Details of medical conditions\n",
      "\n",
      "Treatments for medical conditions\n",
      "\n",
      "Severity of medical conditions\n",
      "\n",
      "weight (in Kg)\n",
      "\n",
      "weight z score\n",
      "\n",
      "height (in cm)\n",
      "\n",
      "height z score\n",
      "\n",
      "head circumference (in cm)\n",
      "\n",
      "head circumference z score\n",
      "\n",
      "systemic examination(abnormal/normal)\n",
      "\n",
      "systemic examination details (main finding only)\n",
      "\n",
      "Mental status examination/Behavioral Observation details (abnormal/normal)\n",
      "\n",
      "Mental status examination/Behavioral observation details (main finding only in description)\n",
      "\n",
      "Screening diagnosis \n",
      "\n",
      "detailed workup diagnosis\n",
      "\n",
      "Follow up diagnosis changed or not (yes/no)\n",
      "\n",
      "If yes, changed once or multiple times (once/multiple)\n",
      "\n",
      "If yes, after how many days from first presentation diagnosis changed (in days)\n",
      "\n",
      "If yes, diagnosis changed to what\n",
      "\n",
      "Axis 1_1\n",
      "\n",
      "Axis 1_2\n",
      "\n",
      "Axis 1_3\n",
      "\n",
      "Axis 1_4\n",
      "\n",
      "Axis 2\n",
      "\n",
      "Axis 3\n",
      "\n",
      "Axis 4_1\n",
      "\n",
      "Axis 4_2\n",
      "\n",
      "Axis 4_3\n",
      "\n",
      "Axis 5\n",
      "\n",
      "significant psychosocial stressor\n",
      "\n",
      "name of Medication 1\n",
      "\n",
      "medication 1 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 1 (Mode value of medication) (in mg)\n",
      "\n",
      "Maximum dose of medication 1 (in mg)\n",
      "\n",
      "Total duration of medication 1 (in days) \n",
      "\n",
      "Continued medication 1/stopped/changed\n",
      "\n",
      "Response to medication 1 (Good/partial/no)\n",
      "\n",
      "Side effect of medication 1\n",
      "\n",
      "onset of side effect post starting med 1 ( in days)\n",
      "\n",
      "total duration of side effect of medication 1 (in days)\n",
      "\n",
      "Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) \n",
      "\n",
      "name of Medication 2\n",
      "\n",
      "Medication 2 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 2 (in mg)\n",
      "\n",
      "Maximum dose of medication 2 (in mg)\n",
      "\n",
      "Total duration of medication 2(in days) \n",
      "\n",
      "Continued medication 2/stopped/changed\n",
      "\n",
      "Response to medication 2 (Good/partial/no)\n",
      "\n",
      "Side effect of medication 2\n",
      "\n",
      "onset of side effect post starting med 2 ( in days)\n",
      "\n",
      "total duration of side effect of medication 2 (in days)\n",
      "\n",
      "Medication possession ratios 2(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 3\n",
      "\n",
      "Medication 3 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 3 (in mg)\n",
      "\n",
      "Maximum dose of medication 3 (in mg)\n",
      "\n",
      "Total duration of medication 3 (in days\n",
      "\n",
      "continued medication 3/stopped/changed\n",
      "\n",
      "Response to medication 3 (Good/partial/no)\n",
      "\n",
      "Side effect of medication 3\n",
      "\n",
      "onset of side effect post starting med 3 ( in days)\n",
      "\n",
      "total duration of side effect of medication 3 (in days)\n",
      "\n",
      "Medication possession ratios 3(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 4\n",
      "\n",
      "Medication 4 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 4 (in mg)\n",
      "\n",
      "Maximum dose of medication 4 (in mg)\n",
      "\n",
      "Total duration of medication 4 (in days)\n",
      "\n",
      "continued medication 4/stopped/changed\n",
      "\n",
      "Response to medication 4(Good/partial/no)\n",
      "\n",
      "Side effect of medication 4\n",
      "\n",
      "onset of side effect post starting med 4 ( in days)\n",
      "\n",
      "total duration of side effect of medication 4 (in days)\n",
      "\n",
      "Medication possession ratios 4(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 5\n",
      "\n",
      "Medication 5 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 5 (in mg)\n",
      "\n",
      "Maximum dose of medication 5(in mg)\n",
      "\n",
      "Total duration of medication 5 (in days)\n",
      "\n",
      "continued medication 5/stopped/changed\n",
      "\n",
      "Response to medication 5(Good/partial/no)\n",
      "\n",
      "Side effect of medication 5\n",
      "\n",
      "onset of side effect post starting med 5 ( in days)\n",
      "\n",
      "total duration of side effect of medication 5 (in days)\n",
      "\n",
      "Medication possession ratios 5(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 6\n",
      "\n",
      "Medication 6 starting dose\n",
      "\n",
      "Avg dose of medication 6\n",
      "\n",
      "Maximum dose of medication 6\n",
      "\n",
      "Total duration of medication 6\n",
      "\n",
      "continued medication 6/stopped/changed\n",
      "\n",
      "Response to medication 6(Good/partial/no)\n",
      "\n",
      "Side effect of medication 6\n",
      "\n",
      "onset of side effect post starting med 6 ( in days)\n",
      "\n",
      "total duration of side effect of medication 6 (in days)\n",
      "\n",
      "Medication possession ratios 6(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 7\n",
      "\n",
      "Medication 7 starting dose\n",
      "\n",
      "Avg dose of medication 7\n",
      "\n",
      "Maximum dose of medication 7\n",
      "\n",
      "Total duration of medication 7\n",
      "\n",
      "continued medication 7/stopped/changed\n",
      "\n",
      "Response to medication 7(Good/partial/no)\n",
      "\n",
      "Side effect of medication 7\n",
      "\n",
      "onset of side effect post starting med 7 ( in days)\n",
      "\n",
      "total duration of side effect of medication 7 (in days)\n",
      "\n",
      "Medication possession ratios 7(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 8\n",
      "\n",
      "Medication 8 starting dose\n",
      "\n",
      "Avg dose of medication 8\n",
      "\n",
      "Maximum dose of medication 8\n",
      "\n",
      "Total duration of medication 8\n",
      "\n",
      "Continued medication 8/stopped/changed\n",
      "\n",
      "Response to medication 8(Good/partial/no)\n",
      "\n",
      "Side effect of medication 8\n",
      "\n",
      "onset of side effect post starting med 8 ( in days)\n",
      "\n",
      "total duration of side effect of medication 8 (in days)\n",
      "\n",
      "Medication possession ratios 8(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 9\n",
      "\n",
      "Medication 9 starting dose\n",
      "\n",
      "Avg dose of medication 9\n",
      "\n",
      "Maximum dose of medication 9\n",
      "\n",
      "Total duration of medication 9\n",
      "\n",
      "continued medication 9/stopped/changed\n",
      "\n",
      "Response to medication 9(Good/partial/no)\n",
      "\n",
      "Side effect of medication 9\n",
      "\n",
      "onset of side effect post starting med 9 ( in days)\n",
      "\n",
      "total duration of side effect of medication 9 (in days)\n",
      "\n",
      "Medication possession ratios 9(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 10\n",
      "\n",
      "Medication 10 starting dose\n",
      "\n",
      "Avg dose of medication 10\n",
      "\n",
      "Maximum dose of medication 10\n",
      "\n",
      "Total duration of medication 10\n",
      "\n",
      "continued medication 10/stopped/changed\n",
      "\n",
      "Response to medication 10(Good/partial/no)\n",
      "\n",
      "Side effect of medication 10\n",
      "\n",
      "onset of side effect post starting med 10 ( in days)\n",
      "\n",
      "total duration of side effect of medication 10 (in days)\n",
      "\n",
      "Medication possession ratios 10(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 11\n",
      "\n",
      "Medication 11 starting dose\n",
      "\n",
      "Avg dose of medication 11\n",
      "\n",
      "Maximum dose of medication 11\n",
      "\n",
      "Total duration of medication 11\n",
      "\n",
      "continued medication 11/stopped/changed\n",
      "\n",
      "Response to medication 11(Good/partial/no)\n",
      "\n",
      "Side effect of medication 11\n",
      "\n",
      "onset of side effect post starting med 11 ( in days)\n",
      "\n",
      "total duration of side effect of medication 11 (in days)\n",
      "\n",
      "Medication possession ratios 11(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 12\n",
      "\n",
      "Medication 12 starting dose\n",
      "\n",
      "Avg dose of medication 12\n",
      "\n",
      "Maximum dose of medication 12\n",
      "\n",
      "Total duration of medication 12\n",
      "\n",
      "continued medication 12/stopped/changed\n",
      "\n",
      "Response to medication 12(Good/partial/no)\n",
      "\n",
      "Side effect of medication 12\n",
      "\n",
      "onset of side effect post starting med 12 ( in days)\n",
      "\n",
      "total duration of side effect of medication 12 (in days)\n",
      "\n",
      "Medication possession ratios 12(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 13\n",
      "\n",
      "Medication 13 starting dose\n",
      "\n",
      "Avg dose of medication 13\n",
      "\n",
      "Maximum dose of medication 13\n",
      "\n",
      "Total duration of medication 13\n",
      "\n",
      "continued medication 13/stopped/changed\n",
      "\n",
      "Response to medication 13(Good/partial/no)\n",
      "\n",
      "Side effect of medication 13\n",
      "\n",
      "onset of side effect post starting med 13 ( in days)\n",
      "\n",
      "total duration of side effect of medication 13 (in days)\n",
      "\n",
      "Medication possession ratios 13(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 14\n",
      "\n",
      "Medication 14 starting dose\n",
      "\n",
      "Avg dose of medication 14\n",
      "\n",
      "Maximum dose of medication 14\n",
      "\n",
      "Total duration of medication 14\n",
      "\n",
      "continued medication 14/stopped/changed\n",
      "\n",
      "Response to medication 14(Good/partial/no)\n",
      "\n",
      "Side effect of medication 14\n",
      "\n",
      "onset of side effect post starting med 14 ( in days)\n",
      "\n",
      "total duration of side effect of medication 14 (in days)\n",
      "\n",
      "Medication possession ratios 14(MPRs) in lgb;x-syrup\n",
      "\n",
      "cost of medication\n",
      "\n",
      "Other treatments(rehabilitative intervention/IT/CBT/ipt/FT/PMT/BEHAVIOURAL INTERVENTIONS FOR DEVELOPMENTAL DISORDERS, Combination therapy)\n",
      "\n",
      "Maximum duration of symptom free period (in days)\n",
      "\n",
      "Max Duration of resolution of symptoms before recurrence/relapse (in days)\n",
      "\n",
      "No of relapses/exacerbations\n",
      "\n",
      "Off-medications duration (to add all such durations over follow-up in days)\n",
      "\n",
      "Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}\n",
      "\n",
      "mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)\n",
      "\n",
      "maximum period of compliance at lgb (in days) (longest streak of good compliance)\n",
      "\n",
      "total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)\n",
      "\n",
      "frequency of follow up at lgb (to write down follow-up dates)\n",
      "\n",
      "total number of follow up at LGBRIMH\n",
      "\n",
      "Final (ignore for now)\n",
      "\n",
      "Number of In patient cares\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = df2.columns\n",
    "for i in a:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "275daefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = df2.drop(['Cluster_1_date', 'Date of screening', 'UHID', 'Name'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b41b7e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Address in detail</th>\n",
       "      <th>Post Office</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>...</th>\n",
       "      <th>No of relapses/exacerbations</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio &lt; 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio &lt; 0.95}</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>frequency of follow up at lgb (to write down follow-up dates)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Final (ignore for now)</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>koloni jala</td>\n",
       "      <td>Juria</td>\n",
       "      <td>Rural</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "      <td>180</td>\n",
       "      <td>212</td>\n",
       "      <td>07-12-2019, 21-12-2019, 17-01-2020, 11-04-2020...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>momosing gaon</td>\n",
       "      <td>Dhansiri bazar</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rampur satra padumoni</td>\n",
       "      <td>Borduwa</td>\n",
       "      <td>Rural</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samaka</td>\n",
       "      <td>Tuktuki</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>No.Borphukhuri P.o,Jahamari P.S,Thelamara,Soni...</td>\n",
       "      <td>Borphukuri</td>\n",
       "      <td>Rural</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>22-06-2020,30-09-2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Nangaldua</td>\n",
       "      <td>Saidoria</td>\n",
       "      <td>Rural</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>No 2 Panigaon Kechali</td>\n",
       "      <td>Itachali</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "0                            10.0                   16.0      male     Islam   \n",
       "1                             8.0                   10.0    female     Islam   \n",
       "2                            17.0                   18.0    female     Islam   \n",
       "3                             7.0                   17.0      male     Islam   \n",
       "4                            10.0                   10.0      male  Hinduism   \n",
       "..                            ...                    ...       ...       ...   \n",
       "187                          15.0                   17.0      male     Islam   \n",
       "188                           NaN                    NaN       NaN       NaN   \n",
       "189                           NaN                    NaN       NaN       NaN   \n",
       "190                           NaN                    NaN       NaN       NaN   \n",
       "191                           5.0                    8.0      male  Hinduism   \n",
       "\n",
       "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "0                                              Primary                                         \n",
       "1                                                  NaN                                         \n",
       "2                                              Primary                                         \n",
       "3                                                  NaN                                         \n",
       "4                                              primary                                         \n",
       "..                                                 ...                                         \n",
       "187                                        high school                                         \n",
       "188                                                NaN                                         \n",
       "189                                                NaN                                         \n",
       "190                                                NaN                                         \n",
       "191                                            primary                                         \n",
       "\n",
       "    Max education attained                                  Address in detail  \\\n",
       "0                      NaN                                        koloni jala   \n",
       "1                      NaN                                      momosing gaon   \n",
       "2                  Primary                              Rampur satra padumoni   \n",
       "3                      NaN                                             Samaka   \n",
       "4                  Primary  No.Borphukhuri P.o,Jahamari P.S,Thelamara,Soni...   \n",
       "..                     ...                                                ...   \n",
       "187            high school                                          Nangaldua   \n",
       "188                    NaN                                                NaN   \n",
       "189                    NaN                                                NaN   \n",
       "190                    NaN                                                NaN   \n",
       "191                primary                              No 2 Panigaon Kechali   \n",
       "\n",
       "        Post Office Rural/Urban  Distance from LGBRIMH (in KM)  ...  \\\n",
       "0             Juria       Rural                           53.0  ...   \n",
       "1    Dhansiri bazar       Rural                           62.0  ...   \n",
       "2           Borduwa       Rural                           55.0  ...   \n",
       "3           Tuktuki       Rural                          102.0  ...   \n",
       "4        Borphukuri       Rural                           29.0  ...   \n",
       "..              ...         ...                            ...  ...   \n",
       "187        Saidoria       Rural                           37.0  ...   \n",
       "188             NaN         NaN                            NaN  ...   \n",
       "189             NaN         NaN                            NaN  ...   \n",
       "190             NaN         NaN                            NaN  ...   \n",
       "191        Itachali       Rural                           63.0  ...   \n",
       "\n",
       "    No of relapses/exacerbations  \\\n",
       "0                            0.0   \n",
       "1                            6.0   \n",
       "2                            0.0   \n",
       "3                            6.0   \n",
       "4                            1.0   \n",
       "..                           ...   \n",
       "187                          0.0   \n",
       "188                          NaN   \n",
       "189                          NaN   \n",
       "190                          NaN   \n",
       "191                          0.0   \n",
       "\n",
       "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "0                                                 1649                            \n",
       "1                                                   22                            \n",
       "2                                                   30                            \n",
       "3                                                   58                            \n",
       "4                                                   20                            \n",
       "..                                                 ...                            \n",
       "187                                                120                            \n",
       "188                                                NaN                            \n",
       "189                                                NaN                            \n",
       "190                                                NaN                            \n",
       "191                                                  0                            \n",
       "\n",
       "    Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}  \\\n",
       "0                                                  NaN                                                                                                                                                                                                                                                                                              \n",
       "1                                         Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "2                                                 Poor                                                                                                                                                                                                                                                                                              \n",
       "3                                                 Good                                                                                                                                                                                                                                                                                              \n",
       "4                                                 Good                                                                                                                                                                                                                                                                                              \n",
       "..                                                 ...                                                                                                                                                                                                                                                                                              \n",
       "187                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "188                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "189                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "190                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "191                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "0                                                 12.4                                    \n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "..                                                 ...                                    \n",
       "187                                               1.21                                    \n",
       "188                                                NaN                                    \n",
       "189                                                NaN                                    \n",
       "190                                                NaN                                    \n",
       "191                                               2.15                                    \n",
       "\n",
       "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "0                                                  180                                  \n",
       "1                                                  395                                  \n",
       "2                                                  240                                  \n",
       "3                                                  NaN                                  \n",
       "4                                                   90                                  \n",
       "..                                                 ...                                  \n",
       "187                                                390                                  \n",
       "188                                                NaN                                  \n",
       "189                                                NaN                                  \n",
       "190                                                NaN                                  \n",
       "191                                               1619                                  \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "0                                                  212                                                   \n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "..                                                 ...                                                   \n",
       "187                                                875                                                   \n",
       "188                                                NaN                                                   \n",
       "189                                                NaN                                                   \n",
       "190                                                NaN                                                   \n",
       "191                                               1619                                                   \n",
       "\n",
       "     frequency of follow up at lgb (to write down follow-up dates)  \\\n",
       "0    07-12-2019, 21-12-2019, 17-01-2020, 11-04-2020...               \n",
       "1    24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...               \n",
       "2       19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020               \n",
       "3    31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...               \n",
       "4                                22-06-2020,30-09-2020               \n",
       "..                                                 ...               \n",
       "187  29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...               \n",
       "188                                                NaN               \n",
       "189                                                NaN               \n",
       "190                                                NaN               \n",
       "191  16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...               \n",
       "\n",
       "    total number of follow up at LGBRIMH Final (ignore for now)  \\\n",
       "0                                    6.0                    NaN   \n",
       "1                                   12.0                    NaN   \n",
       "2                                    4.0                    NaN   \n",
       "3                                   69.0                    NaN   \n",
       "4                                    2.0                    NaN   \n",
       "..                                   ...                    ...   \n",
       "187                                 24.0                    NaN   \n",
       "188                                  NaN                    NaN   \n",
       "189                                  NaN                    NaN   \n",
       "190                                  NaN                    NaN   \n",
       "191                                 25.0                    NaN   \n",
       "\n",
       "    Number of In patient cares  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          1.0  \n",
       "..                         ...  \n",
       "187                        0.0  \n",
       "188                        NaN  \n",
       "189                        NaN  \n",
       "190                        NaN  \n",
       "191                        0.0  \n",
       "\n",
       "[192 rows x 270 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df070ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)\n",
      "\n",
      "Age at last follow up\n",
      "\n",
      "Sex (m/f)\n",
      "\n",
      "Religion\n",
      "\n",
      "Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)\n",
      "\n",
      "Max education attained\n",
      "\n",
      "Address in detail\n",
      "\n",
      "Post Office\n",
      "\n",
      "Rural/Urban\n",
      "\n",
      "Distance from LGBRIMH (in KM)\n",
      "\n",
      "District\n",
      "\n",
      "State\n",
      "\n",
      "Occupation of parents\n",
      "\n",
      "Socioeconomic status\n",
      "\n",
      "Referral\n",
      "\n",
      "Brought by\n",
      "\n",
      "Age at onset(in years)\n",
      "\n",
      "Chief complaint 1\n",
      "\n",
      "Chief complaint 2\n",
      "\n",
      "Chief complaint 3\n",
      "\n",
      "Time period between onset to first consultation at LGBRIMH (DUI) (in days)\n",
      "\n",
      "Type of Family (Nuclear/Joint/single parent/orphan/ foster family\n",
      "\n",
      "Family environment\n",
      "\n",
      "Details of family abnormality (describe)\n",
      "\n",
      "Family h/o stillbirth/abortion\n",
      "\n",
      "Family history(general medical)\n",
      "\n",
      "Family history (psychiatric/neurological)\n",
      "\n",
      "Faith healer visited before consultation or not(yes/no)\n",
      "\n",
      "Antenatal risk factor\n",
      "\n",
      "Place of delivery (Home/hospital)\n",
      "\n",
      "Birth weight(in kg)\n",
      "\n",
      "Neonatal complication\n",
      "\n",
      "Postnatal complication\n",
      "\n",
      "Developmental history\n",
      "\n",
      "Age of school entry(in years)\n",
      "\n",
      "Type of school\n",
      "\n",
      "School adjustment\n",
      "\n",
      "Academic performance\n",
      "\n",
      "School dropout present (yes/no)\n",
      "\n",
      "Detail of past psychiatric history 1\n",
      "\n",
      "Past treatment 1\n",
      "\n",
      "Past treatment medication 1\n",
      "\n",
      "Starting dose past medication 1\n",
      "\n",
      "Age of starting of past medication 1(in years)\n",
      "\n",
      "Past maintenance dose1 (in mg)\n",
      "\n",
      "Side effects of past medication 1\n",
      "\n",
      "Age of occurance past side effects 1(in years)\n",
      "\n",
      "Duration of past side effect 1(in months)\n",
      "\n",
      "Response to past medication 1\n",
      "\n",
      "Detail of past history 2\n",
      "\n",
      "Past treatment 2\n",
      "\n",
      "Past treatment medication 2\n",
      "\n",
      "Starting dose past medication 2\n",
      "\n",
      "Age of starting of past medication 2(in years)\n",
      "\n",
      "Past maintenance dose2\n",
      "\n",
      "Side effects of past medication 2\n",
      "\n",
      "Age of occurance past side effects 2(in years)\n",
      "\n",
      "Duration of past side effect 2(in months)\n",
      "\n",
      "Response to past medication 2\n",
      "\n",
      "Detail of past history 3\n",
      "\n",
      "Past treatment  3\n",
      "\n",
      "Past treatment medication 3\n",
      "\n",
      "Starting dose past medication 3 \n",
      "\n",
      "Age of starting past medication 3 (in years)\n",
      "\n",
      "Past maintenance dose 3\n",
      "\n",
      "Side effects past medication 3\n",
      "\n",
      "Age of occurance of past side effects 3 (in years)\n",
      "\n",
      "Duration of past side effects 3 (in months)\n",
      "\n",
      "Response to past medication 3\n",
      "\n",
      "Change in doctor\n",
      "\n",
      "Past/Current medical conditions\n",
      "\n",
      "Age of onset of medical conditions (in years)\n",
      "\n",
      "Details of medical conditions\n",
      "\n",
      "Treatments for medical conditions\n",
      "\n",
      "Severity of medical conditions\n",
      "\n",
      "weight (in Kg)\n",
      "\n",
      "weight z score\n",
      "\n",
      "height (in cm)\n",
      "\n",
      "height z score\n",
      "\n",
      "head circumference (in cm)\n",
      "\n",
      "head circumference z score\n",
      "\n",
      "systemic examination(abnormal/normal)\n",
      "\n",
      "systemic examination details (main finding only)\n",
      "\n",
      "Mental status examination/Behavioral Observation details (abnormal/normal)\n",
      "\n",
      "Mental status examination/Behavioral observation details (main finding only in description)\n",
      "\n",
      "Screening diagnosis \n",
      "\n",
      "detailed workup diagnosis\n",
      "\n",
      "Follow up diagnosis changed or not (yes/no)\n",
      "\n",
      "If yes, changed once or multiple times (once/multiple)\n",
      "\n",
      "If yes, after how many days from first presentation diagnosis changed (in days)\n",
      "\n",
      "If yes, diagnosis changed to what\n",
      "\n",
      "Axis 1_1\n",
      "\n",
      "Axis 1_2\n",
      "\n",
      "Axis 1_3\n",
      "\n",
      "Axis 1_4\n",
      "\n",
      "Axis 2\n",
      "\n",
      "Axis 3\n",
      "\n",
      "Axis 4_1\n",
      "\n",
      "Axis 4_2\n",
      "\n",
      "Axis 4_3\n",
      "\n",
      "Axis 5\n",
      "\n",
      "significant psychosocial stressor\n",
      "\n",
      "name of Medication 1\n",
      "\n",
      "medication 1 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 1 (Mode value of medication) (in mg)\n",
      "\n",
      "Maximum dose of medication 1 (in mg)\n",
      "\n",
      "Total duration of medication 1 (in days) \n",
      "\n",
      "Continued medication 1/stopped/changed\n",
      "\n",
      "Response to medication 1 (Good/partial/no)\n",
      "\n",
      "Side effect of medication 1\n",
      "\n",
      "onset of side effect post starting med 1 ( in days)\n",
      "\n",
      "total duration of side effect of medication 1 (in days)\n",
      "\n",
      "Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) \n",
      "\n",
      "name of Medication 2\n",
      "\n",
      "Medication 2 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 2 (in mg)\n",
      "\n",
      "Maximum dose of medication 2 (in mg)\n",
      "\n",
      "Total duration of medication 2(in days) \n",
      "\n",
      "Continued medication 2/stopped/changed\n",
      "\n",
      "Response to medication 2 (Good/partial/no)\n",
      "\n",
      "Side effect of medication 2\n",
      "\n",
      "onset of side effect post starting med 2 ( in days)\n",
      "\n",
      "total duration of side effect of medication 2 (in days)\n",
      "\n",
      "Medication possession ratios 2(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 3\n",
      "\n",
      "Medication 3 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 3 (in mg)\n",
      "\n",
      "Maximum dose of medication 3 (in mg)\n",
      "\n",
      "Total duration of medication 3 (in days\n",
      "\n",
      "continued medication 3/stopped/changed\n",
      "\n",
      "Response to medication 3 (Good/partial/no)\n",
      "\n",
      "Side effect of medication 3\n",
      "\n",
      "onset of side effect post starting med 3 ( in days)\n",
      "\n",
      "total duration of side effect of medication 3 (in days)\n",
      "\n",
      "Medication possession ratios 3(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 4\n",
      "\n",
      "Medication 4 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 4 (in mg)\n",
      "\n",
      "Maximum dose of medication 4 (in mg)\n",
      "\n",
      "Total duration of medication 4 (in days)\n",
      "\n",
      "continued medication 4/stopped/changed\n",
      "\n",
      "Response to medication 4(Good/partial/no)\n",
      "\n",
      "Side effect of medication 4\n",
      "\n",
      "onset of side effect post starting med 4 ( in days)\n",
      "\n",
      "total duration of side effect of medication 4 (in days)\n",
      "\n",
      "Medication possession ratios 4(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 5\n",
      "\n",
      "Medication 5 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 5 (in mg)\n",
      "\n",
      "Maximum dose of medication 5(in mg)\n",
      "\n",
      "Total duration of medication 5 (in days)\n",
      "\n",
      "continued medication 5/stopped/changed\n",
      "\n",
      "Response to medication 5(Good/partial/no)\n",
      "\n",
      "Side effect of medication 5\n",
      "\n",
      "onset of side effect post starting med 5 ( in days)\n",
      "\n",
      "total duration of side effect of medication 5 (in days)\n",
      "\n",
      "Medication possession ratios 5(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 6\n",
      "\n",
      "Medication 6 starting dose\n",
      "\n",
      "Avg dose of medication 6\n",
      "\n",
      "Maximum dose of medication 6\n",
      "\n",
      "Total duration of medication 6\n",
      "\n",
      "continued medication 6/stopped/changed\n",
      "\n",
      "Response to medication 6(Good/partial/no)\n",
      "\n",
      "Side effect of medication 6\n",
      "\n",
      "onset of side effect post starting med 6 ( in days)\n",
      "\n",
      "total duration of side effect of medication 6 (in days)\n",
      "\n",
      "Medication possession ratios 6(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 7\n",
      "\n",
      "Medication 7 starting dose\n",
      "\n",
      "Avg dose of medication 7\n",
      "\n",
      "Maximum dose of medication 7\n",
      "\n",
      "Total duration of medication 7\n",
      "\n",
      "continued medication 7/stopped/changed\n",
      "\n",
      "Response to medication 7(Good/partial/no)\n",
      "\n",
      "Side effect of medication 7\n",
      "\n",
      "onset of side effect post starting med 7 ( in days)\n",
      "\n",
      "total duration of side effect of medication 7 (in days)\n",
      "\n",
      "Medication possession ratios 7(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 8\n",
      "\n",
      "Medication 8 starting dose\n",
      "\n",
      "Avg dose of medication 8\n",
      "\n",
      "Maximum dose of medication 8\n",
      "\n",
      "Total duration of medication 8\n",
      "\n",
      "Continued medication 8/stopped/changed\n",
      "\n",
      "Response to medication 8(Good/partial/no)\n",
      "\n",
      "Side effect of medication 8\n",
      "\n",
      "onset of side effect post starting med 8 ( in days)\n",
      "\n",
      "total duration of side effect of medication 8 (in days)\n",
      "\n",
      "Medication possession ratios 8(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 9\n",
      "\n",
      "Medication 9 starting dose\n",
      "\n",
      "Avg dose of medication 9\n",
      "\n",
      "Maximum dose of medication 9\n",
      "\n",
      "Total duration of medication 9\n",
      "\n",
      "continued medication 9/stopped/changed\n",
      "\n",
      "Response to medication 9(Good/partial/no)\n",
      "\n",
      "Side effect of medication 9\n",
      "\n",
      "onset of side effect post starting med 9 ( in days)\n",
      "\n",
      "total duration of side effect of medication 9 (in days)\n",
      "\n",
      "Medication possession ratios 9(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 10\n",
      "\n",
      "Medication 10 starting dose\n",
      "\n",
      "Avg dose of medication 10\n",
      "\n",
      "Maximum dose of medication 10\n",
      "\n",
      "Total duration of medication 10\n",
      "\n",
      "continued medication 10/stopped/changed\n",
      "\n",
      "Response to medication 10(Good/partial/no)\n",
      "\n",
      "Side effect of medication 10\n",
      "\n",
      "onset of side effect post starting med 10 ( in days)\n",
      "\n",
      "total duration of side effect of medication 10 (in days)\n",
      "\n",
      "Medication possession ratios 10(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 11\n",
      "\n",
      "Medication 11 starting dose\n",
      "\n",
      "Avg dose of medication 11\n",
      "\n",
      "Maximum dose of medication 11\n",
      "\n",
      "Total duration of medication 11\n",
      "\n",
      "continued medication 11/stopped/changed\n",
      "\n",
      "Response to medication 11(Good/partial/no)\n",
      "\n",
      "Side effect of medication 11\n",
      "\n",
      "onset of side effect post starting med 11 ( in days)\n",
      "\n",
      "total duration of side effect of medication 11 (in days)\n",
      "\n",
      "Medication possession ratios 11(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 12\n",
      "\n",
      "Medication 12 starting dose\n",
      "\n",
      "Avg dose of medication 12\n",
      "\n",
      "Maximum dose of medication 12\n",
      "\n",
      "Total duration of medication 12\n",
      "\n",
      "continued medication 12/stopped/changed\n",
      "\n",
      "Response to medication 12(Good/partial/no)\n",
      "\n",
      "Side effect of medication 12\n",
      "\n",
      "onset of side effect post starting med 12 ( in days)\n",
      "\n",
      "total duration of side effect of medication 12 (in days)\n",
      "\n",
      "Medication possession ratios 12(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 13\n",
      "\n",
      "Medication 13 starting dose\n",
      "\n",
      "Avg dose of medication 13\n",
      "\n",
      "Maximum dose of medication 13\n",
      "\n",
      "Total duration of medication 13\n",
      "\n",
      "continued medication 13/stopped/changed\n",
      "\n",
      "Response to medication 13(Good/partial/no)\n",
      "\n",
      "Side effect of medication 13\n",
      "\n",
      "onset of side effect post starting med 13 ( in days)\n",
      "\n",
      "total duration of side effect of medication 13 (in days)\n",
      "\n",
      "Medication possession ratios 13(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 14\n",
      "\n",
      "Medication 14 starting dose\n",
      "\n",
      "Avg dose of medication 14\n",
      "\n",
      "Maximum dose of medication 14\n",
      "\n",
      "Total duration of medication 14\n",
      "\n",
      "continued medication 14/stopped/changed\n",
      "\n",
      "Response to medication 14(Good/partial/no)\n",
      "\n",
      "Side effect of medication 14\n",
      "\n",
      "onset of side effect post starting med 14 ( in days)\n",
      "\n",
      "total duration of side effect of medication 14 (in days)\n",
      "\n",
      "Medication possession ratios 14(MPRs) in lgb;x-syrup\n",
      "\n",
      "cost of medication\n",
      "\n",
      "Other treatments(rehabilitative intervention/IT/CBT/ipt/FT/PMT/BEHAVIOURAL INTERVENTIONS FOR DEVELOPMENTAL DISORDERS, Combination therapy)\n",
      "\n",
      "Maximum duration of symptom free period (in days)\n",
      "\n",
      "Max Duration of resolution of symptoms before recurrence/relapse (in days)\n",
      "\n",
      "No of relapses/exacerbations\n",
      "\n",
      "Off-medications duration (to add all such durations over follow-up in days)\n",
      "\n",
      "Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}\n",
      "\n",
      "mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)\n",
      "\n",
      "maximum period of compliance at lgb (in days) (longest streak of good compliance)\n",
      "\n",
      "total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)\n",
      "\n",
      "frequency of follow up at lgb (to write down follow-up dates)\n",
      "\n",
      "total number of follow up at LGBRIMH\n",
      "\n",
      "Final (ignore for now)\n",
      "\n",
      "Number of In patient cares\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = df2.columns\n",
    "for i in a:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d71dd9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(['Address in detail', 'Post Office'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3a4d4355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)\n",
      "\n",
      "Age at last follow up\n",
      "\n",
      "Sex (m/f)\n",
      "\n",
      "Religion\n",
      "\n",
      "Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)\n",
      "\n",
      "Max education attained\n",
      "\n",
      "Rural/Urban\n",
      "\n",
      "Distance from LGBRIMH (in KM)\n",
      "\n",
      "District\n",
      "\n",
      "State\n",
      "\n",
      "Occupation of parents\n",
      "\n",
      "Socioeconomic status\n",
      "\n",
      "Referral\n",
      "\n",
      "Brought by\n",
      "\n",
      "Age at onset(in years)\n",
      "\n",
      "Chief complaint 1\n",
      "\n",
      "Chief complaint 2\n",
      "\n",
      "Chief complaint 3\n",
      "\n",
      "Time period between onset to first consultation at LGBRIMH (DUI) (in days)\n",
      "\n",
      "Type of Family (Nuclear/Joint/single parent/orphan/ foster family\n",
      "\n",
      "Family environment\n",
      "\n",
      "Details of family abnormality (describe)\n",
      "\n",
      "Family h/o stillbirth/abortion\n",
      "\n",
      "Family history(general medical)\n",
      "\n",
      "Family history (psychiatric/neurological)\n",
      "\n",
      "Faith healer visited before consultation or not(yes/no)\n",
      "\n",
      "Antenatal risk factor\n",
      "\n",
      "Place of delivery (Home/hospital)\n",
      "\n",
      "Birth weight(in kg)\n",
      "\n",
      "Neonatal complication\n",
      "\n",
      "Postnatal complication\n",
      "\n",
      "Developmental history\n",
      "\n",
      "Age of school entry(in years)\n",
      "\n",
      "Type of school\n",
      "\n",
      "School adjustment\n",
      "\n",
      "Academic performance\n",
      "\n",
      "School dropout present (yes/no)\n",
      "\n",
      "Detail of past psychiatric history 1\n",
      "\n",
      "Past treatment 1\n",
      "\n",
      "Past treatment medication 1\n",
      "\n",
      "Starting dose past medication 1\n",
      "\n",
      "Age of starting of past medication 1(in years)\n",
      "\n",
      "Past maintenance dose1 (in mg)\n",
      "\n",
      "Side effects of past medication 1\n",
      "\n",
      "Age of occurance past side effects 1(in years)\n",
      "\n",
      "Duration of past side effect 1(in months)\n",
      "\n",
      "Response to past medication 1\n",
      "\n",
      "Detail of past history 2\n",
      "\n",
      "Past treatment 2\n",
      "\n",
      "Past treatment medication 2\n",
      "\n",
      "Starting dose past medication 2\n",
      "\n",
      "Age of starting of past medication 2(in years)\n",
      "\n",
      "Past maintenance dose2\n",
      "\n",
      "Side effects of past medication 2\n",
      "\n",
      "Age of occurance past side effects 2(in years)\n",
      "\n",
      "Duration of past side effect 2(in months)\n",
      "\n",
      "Response to past medication 2\n",
      "\n",
      "Detail of past history 3\n",
      "\n",
      "Past treatment  3\n",
      "\n",
      "Past treatment medication 3\n",
      "\n",
      "Starting dose past medication 3 \n",
      "\n",
      "Age of starting past medication 3 (in years)\n",
      "\n",
      "Past maintenance dose 3\n",
      "\n",
      "Side effects past medication 3\n",
      "\n",
      "Age of occurance of past side effects 3 (in years)\n",
      "\n",
      "Duration of past side effects 3 (in months)\n",
      "\n",
      "Response to past medication 3\n",
      "\n",
      "Change in doctor\n",
      "\n",
      "Past/Current medical conditions\n",
      "\n",
      "Age of onset of medical conditions (in years)\n",
      "\n",
      "Details of medical conditions\n",
      "\n",
      "Treatments for medical conditions\n",
      "\n",
      "Severity of medical conditions\n",
      "\n",
      "weight (in Kg)\n",
      "\n",
      "weight z score\n",
      "\n",
      "height (in cm)\n",
      "\n",
      "height z score\n",
      "\n",
      "head circumference (in cm)\n",
      "\n",
      "head circumference z score\n",
      "\n",
      "systemic examination(abnormal/normal)\n",
      "\n",
      "systemic examination details (main finding only)\n",
      "\n",
      "Mental status examination/Behavioral Observation details (abnormal/normal)\n",
      "\n",
      "Mental status examination/Behavioral observation details (main finding only in description)\n",
      "\n",
      "Screening diagnosis \n",
      "\n",
      "detailed workup diagnosis\n",
      "\n",
      "Follow up diagnosis changed or not (yes/no)\n",
      "\n",
      "If yes, changed once or multiple times (once/multiple)\n",
      "\n",
      "If yes, after how many days from first presentation diagnosis changed (in days)\n",
      "\n",
      "If yes, diagnosis changed to what\n",
      "\n",
      "Axis 1_1\n",
      "\n",
      "Axis 1_2\n",
      "\n",
      "Axis 1_3\n",
      "\n",
      "Axis 1_4\n",
      "\n",
      "Axis 2\n",
      "\n",
      "Axis 3\n",
      "\n",
      "Axis 4_1\n",
      "\n",
      "Axis 4_2\n",
      "\n",
      "Axis 4_3\n",
      "\n",
      "Axis 5\n",
      "\n",
      "significant psychosocial stressor\n",
      "\n",
      "name of Medication 1\n",
      "\n",
      "medication 1 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 1 (Mode value of medication) (in mg)\n",
      "\n",
      "Maximum dose of medication 1 (in mg)\n",
      "\n",
      "Total duration of medication 1 (in days) \n",
      "\n",
      "Continued medication 1/stopped/changed\n",
      "\n",
      "Response to medication 1 (Good/partial/no)\n",
      "\n",
      "Side effect of medication 1\n",
      "\n",
      "onset of side effect post starting med 1 ( in days)\n",
      "\n",
      "total duration of side effect of medication 1 (in days)\n",
      "\n",
      "Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) \n",
      "\n",
      "name of Medication 2\n",
      "\n",
      "Medication 2 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 2 (in mg)\n",
      "\n",
      "Maximum dose of medication 2 (in mg)\n",
      "\n",
      "Total duration of medication 2(in days) \n",
      "\n",
      "Continued medication 2/stopped/changed\n",
      "\n",
      "Response to medication 2 (Good/partial/no)\n",
      "\n",
      "Side effect of medication 2\n",
      "\n",
      "onset of side effect post starting med 2 ( in days)\n",
      "\n",
      "total duration of side effect of medication 2 (in days)\n",
      "\n",
      "Medication possession ratios 2(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 3\n",
      "\n",
      "Medication 3 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 3 (in mg)\n",
      "\n",
      "Maximum dose of medication 3 (in mg)\n",
      "\n",
      "Total duration of medication 3 (in days\n",
      "\n",
      "continued medication 3/stopped/changed\n",
      "\n",
      "Response to medication 3 (Good/partial/no)\n",
      "\n",
      "Side effect of medication 3\n",
      "\n",
      "onset of side effect post starting med 3 ( in days)\n",
      "\n",
      "total duration of side effect of medication 3 (in days)\n",
      "\n",
      "Medication possession ratios 3(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 4\n",
      "\n",
      "Medication 4 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 4 (in mg)\n",
      "\n",
      "Maximum dose of medication 4 (in mg)\n",
      "\n",
      "Total duration of medication 4 (in days)\n",
      "\n",
      "continued medication 4/stopped/changed\n",
      "\n",
      "Response to medication 4(Good/partial/no)\n",
      "\n",
      "Side effect of medication 4\n",
      "\n",
      "onset of side effect post starting med 4 ( in days)\n",
      "\n",
      "total duration of side effect of medication 4 (in days)\n",
      "\n",
      "Medication possession ratios 4(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 5\n",
      "\n",
      "Medication 5 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 5 (in mg)\n",
      "\n",
      "Maximum dose of medication 5(in mg)\n",
      "\n",
      "Total duration of medication 5 (in days)\n",
      "\n",
      "continued medication 5/stopped/changed\n",
      "\n",
      "Response to medication 5(Good/partial/no)\n",
      "\n",
      "Side effect of medication 5\n",
      "\n",
      "onset of side effect post starting med 5 ( in days)\n",
      "\n",
      "total duration of side effect of medication 5 (in days)\n",
      "\n",
      "Medication possession ratios 5(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 6\n",
      "\n",
      "Medication 6 starting dose\n",
      "\n",
      "Avg dose of medication 6\n",
      "\n",
      "Maximum dose of medication 6\n",
      "\n",
      "Total duration of medication 6\n",
      "\n",
      "continued medication 6/stopped/changed\n",
      "\n",
      "Response to medication 6(Good/partial/no)\n",
      "\n",
      "Side effect of medication 6\n",
      "\n",
      "onset of side effect post starting med 6 ( in days)\n",
      "\n",
      "total duration of side effect of medication 6 (in days)\n",
      "\n",
      "Medication possession ratios 6(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 7\n",
      "\n",
      "Medication 7 starting dose\n",
      "\n",
      "Avg dose of medication 7\n",
      "\n",
      "Maximum dose of medication 7\n",
      "\n",
      "Total duration of medication 7\n",
      "\n",
      "continued medication 7/stopped/changed\n",
      "\n",
      "Response to medication 7(Good/partial/no)\n",
      "\n",
      "Side effect of medication 7\n",
      "\n",
      "onset of side effect post starting med 7 ( in days)\n",
      "\n",
      "total duration of side effect of medication 7 (in days)\n",
      "\n",
      "Medication possession ratios 7(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 8\n",
      "\n",
      "Medication 8 starting dose\n",
      "\n",
      "Avg dose of medication 8\n",
      "\n",
      "Maximum dose of medication 8\n",
      "\n",
      "Total duration of medication 8\n",
      "\n",
      "Continued medication 8/stopped/changed\n",
      "\n",
      "Response to medication 8(Good/partial/no)\n",
      "\n",
      "Side effect of medication 8\n",
      "\n",
      "onset of side effect post starting med 8 ( in days)\n",
      "\n",
      "total duration of side effect of medication 8 (in days)\n",
      "\n",
      "Medication possession ratios 8(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 9\n",
      "\n",
      "Medication 9 starting dose\n",
      "\n",
      "Avg dose of medication 9\n",
      "\n",
      "Maximum dose of medication 9\n",
      "\n",
      "Total duration of medication 9\n",
      "\n",
      "continued medication 9/stopped/changed\n",
      "\n",
      "Response to medication 9(Good/partial/no)\n",
      "\n",
      "Side effect of medication 9\n",
      "\n",
      "onset of side effect post starting med 9 ( in days)\n",
      "\n",
      "total duration of side effect of medication 9 (in days)\n",
      "\n",
      "Medication possession ratios 9(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 10\n",
      "\n",
      "Medication 10 starting dose\n",
      "\n",
      "Avg dose of medication 10\n",
      "\n",
      "Maximum dose of medication 10\n",
      "\n",
      "Total duration of medication 10\n",
      "\n",
      "continued medication 10/stopped/changed\n",
      "\n",
      "Response to medication 10(Good/partial/no)\n",
      "\n",
      "Side effect of medication 10\n",
      "\n",
      "onset of side effect post starting med 10 ( in days)\n",
      "\n",
      "total duration of side effect of medication 10 (in days)\n",
      "\n",
      "Medication possession ratios 10(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 11\n",
      "\n",
      "Medication 11 starting dose\n",
      "\n",
      "Avg dose of medication 11\n",
      "\n",
      "Maximum dose of medication 11\n",
      "\n",
      "Total duration of medication 11\n",
      "\n",
      "continued medication 11/stopped/changed\n",
      "\n",
      "Response to medication 11(Good/partial/no)\n",
      "\n",
      "Side effect of medication 11\n",
      "\n",
      "onset of side effect post starting med 11 ( in days)\n",
      "\n",
      "total duration of side effect of medication 11 (in days)\n",
      "\n",
      "Medication possession ratios 11(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 12\n",
      "\n",
      "Medication 12 starting dose\n",
      "\n",
      "Avg dose of medication 12\n",
      "\n",
      "Maximum dose of medication 12\n",
      "\n",
      "Total duration of medication 12\n",
      "\n",
      "continued medication 12/stopped/changed\n",
      "\n",
      "Response to medication 12(Good/partial/no)\n",
      "\n",
      "Side effect of medication 12\n",
      "\n",
      "onset of side effect post starting med 12 ( in days)\n",
      "\n",
      "total duration of side effect of medication 12 (in days)\n",
      "\n",
      "Medication possession ratios 12(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 13\n",
      "\n",
      "Medication 13 starting dose\n",
      "\n",
      "Avg dose of medication 13\n",
      "\n",
      "Maximum dose of medication 13\n",
      "\n",
      "Total duration of medication 13\n",
      "\n",
      "continued medication 13/stopped/changed\n",
      "\n",
      "Response to medication 13(Good/partial/no)\n",
      "\n",
      "Side effect of medication 13\n",
      "\n",
      "onset of side effect post starting med 13 ( in days)\n",
      "\n",
      "total duration of side effect of medication 13 (in days)\n",
      "\n",
      "Medication possession ratios 13(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 14\n",
      "\n",
      "Medication 14 starting dose\n",
      "\n",
      "Avg dose of medication 14\n",
      "\n",
      "Maximum dose of medication 14\n",
      "\n",
      "Total duration of medication 14\n",
      "\n",
      "continued medication 14/stopped/changed\n",
      "\n",
      "Response to medication 14(Good/partial/no)\n",
      "\n",
      "Side effect of medication 14\n",
      "\n",
      "onset of side effect post starting med 14 ( in days)\n",
      "\n",
      "total duration of side effect of medication 14 (in days)\n",
      "\n",
      "Medication possession ratios 14(MPRs) in lgb;x-syrup\n",
      "\n",
      "cost of medication\n",
      "\n",
      "Other treatments(rehabilitative intervention/IT/CBT/ipt/FT/PMT/BEHAVIOURAL INTERVENTIONS FOR DEVELOPMENTAL DISORDERS, Combination therapy)\n",
      "\n",
      "Maximum duration of symptom free period (in days)\n",
      "\n",
      "Max Duration of resolution of symptoms before recurrence/relapse (in days)\n",
      "\n",
      "No of relapses/exacerbations\n",
      "\n",
      "Off-medications duration (to add all such durations over follow-up in days)\n",
      "\n",
      "Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}\n",
      "\n",
      "mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)\n",
      "\n",
      "maximum period of compliance at lgb (in days) (longest streak of good compliance)\n",
      "\n",
      "total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)\n",
      "\n",
      "frequency of follow up at lgb (to write down follow-up dates)\n",
      "\n",
      "total number of follow up at LGBRIMH\n",
      "\n",
      "Final (ignore for now)\n",
      "\n",
      "Number of In patient cares\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = df2.columns\n",
    "for i in a:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fb85c798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>District</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>No of relapses/exacerbations</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio &lt; 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio &lt; 0.95}</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>frequency of follow up at lgb (to write down follow-up dates)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Final (ignore for now)</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "      <td>180</td>\n",
       "      <td>212</td>\n",
       "      <td>07-12-2019, 21-12-2019, 17-01-2020, 11-04-2020...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>22-06-2020,30-09-2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "0                            10.0                   16.0      male     Islam   \n",
       "1                             8.0                   10.0    female     Islam   \n",
       "2                            17.0                   18.0    female     Islam   \n",
       "3                             7.0                   17.0      male     Islam   \n",
       "4                            10.0                   10.0      male  Hinduism   \n",
       "..                            ...                    ...       ...       ...   \n",
       "187                          15.0                   17.0      male     Islam   \n",
       "188                           NaN                    NaN       NaN       NaN   \n",
       "189                           NaN                    NaN       NaN       NaN   \n",
       "190                           NaN                    NaN       NaN       NaN   \n",
       "191                           5.0                    8.0      male  Hinduism   \n",
       "\n",
       "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "0                                              Primary                                         \n",
       "1                                                  NaN                                         \n",
       "2                                              Primary                                         \n",
       "3                                                  NaN                                         \n",
       "4                                              primary                                         \n",
       "..                                                 ...                                         \n",
       "187                                        high school                                         \n",
       "188                                                NaN                                         \n",
       "189                                                NaN                                         \n",
       "190                                                NaN                                         \n",
       "191                                            primary                                         \n",
       "\n",
       "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "0                      NaN       Rural                           53.0   \n",
       "1                      NaN       Rural                           62.0   \n",
       "2                  Primary       Rural                           55.0   \n",
       "3                      NaN       Rural                          102.0   \n",
       "4                  Primary       Rural                           29.0   \n",
       "..                     ...         ...                            ...   \n",
       "187            high school       Rural                           37.0   \n",
       "188                    NaN         NaN                            NaN   \n",
       "189                    NaN         NaN                            NaN   \n",
       "190                    NaN         NaN                            NaN   \n",
       "191                primary       Rural                           63.0   \n",
       "\n",
       "     District  State  ... No of relapses/exacerbations  \\\n",
       "0      Nagaon  Assam  ...                          0.0   \n",
       "1    Udalguri  Assam  ...                          6.0   \n",
       "2      Nagaon  Assam  ...                          0.0   \n",
       "3      Nagaon  Assam  ...                          6.0   \n",
       "4    Sonitpur  Assam  ...                          1.0   \n",
       "..        ...    ...  ...                          ...   \n",
       "187    Nagaon  Assam  ...                          0.0   \n",
       "188       NaN    NaN  ...                          NaN   \n",
       "189       NaN    NaN  ...                          NaN   \n",
       "190       NaN    NaN  ...                          NaN   \n",
       "191    Nagaon  Assam  ...                          0.0   \n",
       "\n",
       "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "0                                                 1649                            \n",
       "1                                                   22                            \n",
       "2                                                   30                            \n",
       "3                                                   58                            \n",
       "4                                                   20                            \n",
       "..                                                 ...                            \n",
       "187                                                120                            \n",
       "188                                                NaN                            \n",
       "189                                                NaN                            \n",
       "190                                                NaN                            \n",
       "191                                                  0                            \n",
       "\n",
       "    Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}  \\\n",
       "0                                                  NaN                                                                                                                                                                                                                                                                                              \n",
       "1                                         Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "2                                                 Poor                                                                                                                                                                                                                                                                                              \n",
       "3                                                 Good                                                                                                                                                                                                                                                                                              \n",
       "4                                                 Good                                                                                                                                                                                                                                                                                              \n",
       "..                                                 ...                                                                                                                                                                                                                                                                                              \n",
       "187                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "188                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "189                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "190                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "191                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "0                                                 12.4                                    \n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "..                                                 ...                                    \n",
       "187                                               1.21                                    \n",
       "188                                                NaN                                    \n",
       "189                                                NaN                                    \n",
       "190                                                NaN                                    \n",
       "191                                               2.15                                    \n",
       "\n",
       "     maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "0                                                  180                                   \n",
       "1                                                  395                                   \n",
       "2                                                  240                                   \n",
       "3                                                  NaN                                   \n",
       "4                                                   90                                   \n",
       "..                                                 ...                                   \n",
       "187                                                390                                   \n",
       "188                                                NaN                                   \n",
       "189                                                NaN                                   \n",
       "190                                                NaN                                   \n",
       "191                                               1619                                   \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "0                                                  212                                                   \n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "..                                                 ...                                                   \n",
       "187                                                875                                                   \n",
       "188                                                NaN                                                   \n",
       "189                                                NaN                                                   \n",
       "190                                                NaN                                                   \n",
       "191                                               1619                                                   \n",
       "\n",
       "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
       "0    07-12-2019, 21-12-2019, 17-01-2020, 11-04-2020...              \n",
       "1    24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...              \n",
       "2       19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020              \n",
       "3    31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...              \n",
       "4                                22-06-2020,30-09-2020              \n",
       "..                                                 ...              \n",
       "187  29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...              \n",
       "188                                                NaN              \n",
       "189                                                NaN              \n",
       "190                                                NaN              \n",
       "191  16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...              \n",
       "\n",
       "    total number of follow up at LGBRIMH Final (ignore for now)  \\\n",
       "0                                    6.0                    NaN   \n",
       "1                                   12.0                    NaN   \n",
       "2                                    4.0                    NaN   \n",
       "3                                   69.0                    NaN   \n",
       "4                                    2.0                    NaN   \n",
       "..                                   ...                    ...   \n",
       "187                                 24.0                    NaN   \n",
       "188                                  NaN                    NaN   \n",
       "189                                  NaN                    NaN   \n",
       "190                                  NaN                    NaN   \n",
       "191                                 25.0                    NaN   \n",
       "\n",
       "    Number of In patient cares  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          1.0  \n",
       "..                         ...  \n",
       "187                        0.0  \n",
       "188                        NaN  \n",
       "189                        NaN  \n",
       "190                        NaN  \n",
       "191                        0.0  \n",
       "\n",
       "[192 rows x 268 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f920de1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               NaN\n",
       "1               NaN\n",
       "2               NaN\n",
       "3               NaN\n",
       "4      Tempo Driver\n",
       "           ...     \n",
       "187             NaN\n",
       "188             NaN\n",
       "189             NaN\n",
       "190             NaN\n",
       "191             NaN\n",
       "Name: Occupation of parents, Length: 192, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Occupation of parents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "66ed9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(['Occupation of parents', 'Referral', 'Brought by'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a734ba60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>District</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>No of relapses/exacerbations</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio &lt; 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio &lt; 0.95}</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>frequency of follow up at lgb (to write down follow-up dates)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Final (ignore for now)</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "      <td>180</td>\n",
       "      <td>212</td>\n",
       "      <td>07-12-2019, 21-12-2019, 17-01-2020, 11-04-2020...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>22-06-2020,30-09-2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "0                            10.0                   16.0      male     Islam   \n",
       "1                             8.0                   10.0    female     Islam   \n",
       "2                            17.0                   18.0    female     Islam   \n",
       "3                             7.0                   17.0      male     Islam   \n",
       "4                            10.0                   10.0      male  Hinduism   \n",
       "..                            ...                    ...       ...       ...   \n",
       "187                          15.0                   17.0      male     Islam   \n",
       "188                           NaN                    NaN       NaN       NaN   \n",
       "189                           NaN                    NaN       NaN       NaN   \n",
       "190                           NaN                    NaN       NaN       NaN   \n",
       "191                           5.0                    8.0      male  Hinduism   \n",
       "\n",
       "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "0                                              Primary                                         \n",
       "1                                                  NaN                                         \n",
       "2                                              Primary                                         \n",
       "3                                                  NaN                                         \n",
       "4                                              primary                                         \n",
       "..                                                 ...                                         \n",
       "187                                        high school                                         \n",
       "188                                                NaN                                         \n",
       "189                                                NaN                                         \n",
       "190                                                NaN                                         \n",
       "191                                            primary                                         \n",
       "\n",
       "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "0                      NaN       Rural                           53.0   \n",
       "1                      NaN       Rural                           62.0   \n",
       "2                  Primary       Rural                           55.0   \n",
       "3                      NaN       Rural                          102.0   \n",
       "4                  Primary       Rural                           29.0   \n",
       "..                     ...         ...                            ...   \n",
       "187            high school       Rural                           37.0   \n",
       "188                    NaN         NaN                            NaN   \n",
       "189                    NaN         NaN                            NaN   \n",
       "190                    NaN         NaN                            NaN   \n",
       "191                primary       Rural                           63.0   \n",
       "\n",
       "     District  State  ... No of relapses/exacerbations  \\\n",
       "0      Nagaon  Assam  ...                          0.0   \n",
       "1    Udalguri  Assam  ...                          6.0   \n",
       "2      Nagaon  Assam  ...                          0.0   \n",
       "3      Nagaon  Assam  ...                          6.0   \n",
       "4    Sonitpur  Assam  ...                          1.0   \n",
       "..        ...    ...  ...                          ...   \n",
       "187    Nagaon  Assam  ...                          0.0   \n",
       "188       NaN    NaN  ...                          NaN   \n",
       "189       NaN    NaN  ...                          NaN   \n",
       "190       NaN    NaN  ...                          NaN   \n",
       "191    Nagaon  Assam  ...                          0.0   \n",
       "\n",
       "     Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "0                                                 1649                             \n",
       "1                                                   22                             \n",
       "2                                                   30                             \n",
       "3                                                   58                             \n",
       "4                                                   20                             \n",
       "..                                                 ...                             \n",
       "187                                                120                             \n",
       "188                                                NaN                             \n",
       "189                                                NaN                             \n",
       "190                                                NaN                             \n",
       "191                                                  0                             \n",
       "\n",
       "    Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}  \\\n",
       "0                                                  NaN                                                                                                                                                                                                                                                                                              \n",
       "1                                         Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "2                                                 Poor                                                                                                                                                                                                                                                                                              \n",
       "3                                                 Good                                                                                                                                                                                                                                                                                              \n",
       "4                                                 Good                                                                                                                                                                                                                                                                                              \n",
       "..                                                 ...                                                                                                                                                                                                                                                                                              \n",
       "187                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "188                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "189                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "190                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "191                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "0                                                 12.4                                    \n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "..                                                 ...                                    \n",
       "187                                               1.21                                    \n",
       "188                                                NaN                                    \n",
       "189                                                NaN                                    \n",
       "190                                                NaN                                    \n",
       "191                                               2.15                                    \n",
       "\n",
       "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "0                                                  180                                  \n",
       "1                                                  395                                  \n",
       "2                                                  240                                  \n",
       "3                                                  NaN                                  \n",
       "4                                                   90                                  \n",
       "..                                                 ...                                  \n",
       "187                                                390                                  \n",
       "188                                                NaN                                  \n",
       "189                                                NaN                                  \n",
       "190                                                NaN                                  \n",
       "191                                               1619                                  \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "0                                                  212                                                   \n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "..                                                 ...                                                   \n",
       "187                                                875                                                   \n",
       "188                                                NaN                                                   \n",
       "189                                                NaN                                                   \n",
       "190                                                NaN                                                   \n",
       "191                                               1619                                                   \n",
       "\n",
       "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
       "0    07-12-2019, 21-12-2019, 17-01-2020, 11-04-2020...              \n",
       "1    24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...              \n",
       "2       19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020              \n",
       "3    31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...              \n",
       "4                                22-06-2020,30-09-2020              \n",
       "..                                                 ...              \n",
       "187  29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...              \n",
       "188                                                NaN              \n",
       "189                                                NaN              \n",
       "190                                                NaN              \n",
       "191  16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...              \n",
       "\n",
       "    total number of follow up at LGBRIMH Final (ignore for now)  \\\n",
       "0                                    6.0                    NaN   \n",
       "1                                   12.0                    NaN   \n",
       "2                                    4.0                    NaN   \n",
       "3                                   69.0                    NaN   \n",
       "4                                    2.0                    NaN   \n",
       "..                                   ...                    ...   \n",
       "187                                 24.0                    NaN   \n",
       "188                                  NaN                    NaN   \n",
       "189                                  NaN                    NaN   \n",
       "190                                  NaN                    NaN   \n",
       "191                                 25.0                    NaN   \n",
       "\n",
       "    Number of In patient cares  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          1.0  \n",
       "..                         ...  \n",
       "187                        0.0  \n",
       "188                        NaN  \n",
       "189                        NaN  \n",
       "190                        NaN  \n",
       "191                        0.0  \n",
       "\n",
       "[192 rows x 265 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8a5d20a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)\n",
      "\n",
      "Age at last follow up\n",
      "\n",
      "Sex (m/f)\n",
      "\n",
      "Religion\n",
      "\n",
      "Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)\n",
      "\n",
      "Max education attained\n",
      "\n",
      "Rural/Urban\n",
      "\n",
      "Distance from LGBRIMH (in KM)\n",
      "\n",
      "District\n",
      "\n",
      "State\n",
      "\n",
      "Socioeconomic status\n",
      "\n",
      "Age at onset(in years)\n",
      "\n",
      "Chief complaint 1\n",
      "\n",
      "Chief complaint 2\n",
      "\n",
      "Chief complaint 3\n",
      "\n",
      "Time period between onset to first consultation at LGBRIMH (DUI) (in days)\n",
      "\n",
      "Type of Family (Nuclear/Joint/single parent/orphan/ foster family\n",
      "\n",
      "Family environment\n",
      "\n",
      "Details of family abnormality (describe)\n",
      "\n",
      "Family h/o stillbirth/abortion\n",
      "\n",
      "Family history(general medical)\n",
      "\n",
      "Family history (psychiatric/neurological)\n",
      "\n",
      "Faith healer visited before consultation or not(yes/no)\n",
      "\n",
      "Antenatal risk factor\n",
      "\n",
      "Place of delivery (Home/hospital)\n",
      "\n",
      "Birth weight(in kg)\n",
      "\n",
      "Neonatal complication\n",
      "\n",
      "Postnatal complication\n",
      "\n",
      "Developmental history\n",
      "\n",
      "Age of school entry(in years)\n",
      "\n",
      "Type of school\n",
      "\n",
      "School adjustment\n",
      "\n",
      "Academic performance\n",
      "\n",
      "School dropout present (yes/no)\n",
      "\n",
      "Detail of past psychiatric history 1\n",
      "\n",
      "Past treatment 1\n",
      "\n",
      "Past treatment medication 1\n",
      "\n",
      "Starting dose past medication 1\n",
      "\n",
      "Age of starting of past medication 1(in years)\n",
      "\n",
      "Past maintenance dose1 (in mg)\n",
      "\n",
      "Side effects of past medication 1\n",
      "\n",
      "Age of occurance past side effects 1(in years)\n",
      "\n",
      "Duration of past side effect 1(in months)\n",
      "\n",
      "Response to past medication 1\n",
      "\n",
      "Detail of past history 2\n",
      "\n",
      "Past treatment 2\n",
      "\n",
      "Past treatment medication 2\n",
      "\n",
      "Starting dose past medication 2\n",
      "\n",
      "Age of starting of past medication 2(in years)\n",
      "\n",
      "Past maintenance dose2\n",
      "\n",
      "Side effects of past medication 2\n",
      "\n",
      "Age of occurance past side effects 2(in years)\n",
      "\n",
      "Duration of past side effect 2(in months)\n",
      "\n",
      "Response to past medication 2\n",
      "\n",
      "Detail of past history 3\n",
      "\n",
      "Past treatment  3\n",
      "\n",
      "Past treatment medication 3\n",
      "\n",
      "Starting dose past medication 3 \n",
      "\n",
      "Age of starting past medication 3 (in years)\n",
      "\n",
      "Past maintenance dose 3\n",
      "\n",
      "Side effects past medication 3\n",
      "\n",
      "Age of occurance of past side effects 3 (in years)\n",
      "\n",
      "Duration of past side effects 3 (in months)\n",
      "\n",
      "Response to past medication 3\n",
      "\n",
      "Change in doctor\n",
      "\n",
      "Past/Current medical conditions\n",
      "\n",
      "Age of onset of medical conditions (in years)\n",
      "\n",
      "Details of medical conditions\n",
      "\n",
      "Treatments for medical conditions\n",
      "\n",
      "Severity of medical conditions\n",
      "\n",
      "weight (in Kg)\n",
      "\n",
      "weight z score\n",
      "\n",
      "height (in cm)\n",
      "\n",
      "height z score\n",
      "\n",
      "head circumference (in cm)\n",
      "\n",
      "head circumference z score\n",
      "\n",
      "systemic examination(abnormal/normal)\n",
      "\n",
      "systemic examination details (main finding only)\n",
      "\n",
      "Mental status examination/Behavioral Observation details (abnormal/normal)\n",
      "\n",
      "Mental status examination/Behavioral observation details (main finding only in description)\n",
      "\n",
      "Screening diagnosis \n",
      "\n",
      "detailed workup diagnosis\n",
      "\n",
      "Follow up diagnosis changed or not (yes/no)\n",
      "\n",
      "If yes, changed once or multiple times (once/multiple)\n",
      "\n",
      "If yes, after how many days from first presentation diagnosis changed (in days)\n",
      "\n",
      "If yes, diagnosis changed to what\n",
      "\n",
      "Axis 1_1\n",
      "\n",
      "Axis 1_2\n",
      "\n",
      "Axis 1_3\n",
      "\n",
      "Axis 1_4\n",
      "\n",
      "Axis 2\n",
      "\n",
      "Axis 3\n",
      "\n",
      "Axis 4_1\n",
      "\n",
      "Axis 4_2\n",
      "\n",
      "Axis 4_3\n",
      "\n",
      "Axis 5\n",
      "\n",
      "significant psychosocial stressor\n",
      "\n",
      "name of Medication 1\n",
      "\n",
      "medication 1 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 1 (Mode value of medication) (in mg)\n",
      "\n",
      "Maximum dose of medication 1 (in mg)\n",
      "\n",
      "Total duration of medication 1 (in days) \n",
      "\n",
      "Continued medication 1/stopped/changed\n",
      "\n",
      "Response to medication 1 (Good/partial/no)\n",
      "\n",
      "Side effect of medication 1\n",
      "\n",
      "onset of side effect post starting med 1 ( in days)\n",
      "\n",
      "total duration of side effect of medication 1 (in days)\n",
      "\n",
      "Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) \n",
      "\n",
      "name of Medication 2\n",
      "\n",
      "Medication 2 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 2 (in mg)\n",
      "\n",
      "Maximum dose of medication 2 (in mg)\n",
      "\n",
      "Total duration of medication 2(in days) \n",
      "\n",
      "Continued medication 2/stopped/changed\n",
      "\n",
      "Response to medication 2 (Good/partial/no)\n",
      "\n",
      "Side effect of medication 2\n",
      "\n",
      "onset of side effect post starting med 2 ( in days)\n",
      "\n",
      "total duration of side effect of medication 2 (in days)\n",
      "\n",
      "Medication possession ratios 2(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 3\n",
      "\n",
      "Medication 3 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 3 (in mg)\n",
      "\n",
      "Maximum dose of medication 3 (in mg)\n",
      "\n",
      "Total duration of medication 3 (in days\n",
      "\n",
      "continued medication 3/stopped/changed\n",
      "\n",
      "Response to medication 3 (Good/partial/no)\n",
      "\n",
      "Side effect of medication 3\n",
      "\n",
      "onset of side effect post starting med 3 ( in days)\n",
      "\n",
      "total duration of side effect of medication 3 (in days)\n",
      "\n",
      "Medication possession ratios 3(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 4\n",
      "\n",
      "Medication 4 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 4 (in mg)\n",
      "\n",
      "Maximum dose of medication 4 (in mg)\n",
      "\n",
      "Total duration of medication 4 (in days)\n",
      "\n",
      "continued medication 4/stopped/changed\n",
      "\n",
      "Response to medication 4(Good/partial/no)\n",
      "\n",
      "Side effect of medication 4\n",
      "\n",
      "onset of side effect post starting med 4 ( in days)\n",
      "\n",
      "total duration of side effect of medication 4 (in days)\n",
      "\n",
      "Medication possession ratios 4(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 5\n",
      "\n",
      "Medication 5 starting dose (in mg)\n",
      "\n",
      "Avg dose of medication 5 (in mg)\n",
      "\n",
      "Maximum dose of medication 5(in mg)\n",
      "\n",
      "Total duration of medication 5 (in days)\n",
      "\n",
      "continued medication 5/stopped/changed\n",
      "\n",
      "Response to medication 5(Good/partial/no)\n",
      "\n",
      "Side effect of medication 5\n",
      "\n",
      "onset of side effect post starting med 5 ( in days)\n",
      "\n",
      "total duration of side effect of medication 5 (in days)\n",
      "\n",
      "Medication possession ratios 5(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 6\n",
      "\n",
      "Medication 6 starting dose\n",
      "\n",
      "Avg dose of medication 6\n",
      "\n",
      "Maximum dose of medication 6\n",
      "\n",
      "Total duration of medication 6\n",
      "\n",
      "continued medication 6/stopped/changed\n",
      "\n",
      "Response to medication 6(Good/partial/no)\n",
      "\n",
      "Side effect of medication 6\n",
      "\n",
      "onset of side effect post starting med 6 ( in days)\n",
      "\n",
      "total duration of side effect of medication 6 (in days)\n",
      "\n",
      "Medication possession ratios 6(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 7\n",
      "\n",
      "Medication 7 starting dose\n",
      "\n",
      "Avg dose of medication 7\n",
      "\n",
      "Maximum dose of medication 7\n",
      "\n",
      "Total duration of medication 7\n",
      "\n",
      "continued medication 7/stopped/changed\n",
      "\n",
      "Response to medication 7(Good/partial/no)\n",
      "\n",
      "Side effect of medication 7\n",
      "\n",
      "onset of side effect post starting med 7 ( in days)\n",
      "\n",
      "total duration of side effect of medication 7 (in days)\n",
      "\n",
      "Medication possession ratios 7(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 8\n",
      "\n",
      "Medication 8 starting dose\n",
      "\n",
      "Avg dose of medication 8\n",
      "\n",
      "Maximum dose of medication 8\n",
      "\n",
      "Total duration of medication 8\n",
      "\n",
      "Continued medication 8/stopped/changed\n",
      "\n",
      "Response to medication 8(Good/partial/no)\n",
      "\n",
      "Side effect of medication 8\n",
      "\n",
      "onset of side effect post starting med 8 ( in days)\n",
      "\n",
      "total duration of side effect of medication 8 (in days)\n",
      "\n",
      "Medication possession ratios 8(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 9\n",
      "\n",
      "Medication 9 starting dose\n",
      "\n",
      "Avg dose of medication 9\n",
      "\n",
      "Maximum dose of medication 9\n",
      "\n",
      "Total duration of medication 9\n",
      "\n",
      "continued medication 9/stopped/changed\n",
      "\n",
      "Response to medication 9(Good/partial/no)\n",
      "\n",
      "Side effect of medication 9\n",
      "\n",
      "onset of side effect post starting med 9 ( in days)\n",
      "\n",
      "total duration of side effect of medication 9 (in days)\n",
      "\n",
      "Medication possession ratios 9(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 10\n",
      "\n",
      "Medication 10 starting dose\n",
      "\n",
      "Avg dose of medication 10\n",
      "\n",
      "Maximum dose of medication 10\n",
      "\n",
      "Total duration of medication 10\n",
      "\n",
      "continued medication 10/stopped/changed\n",
      "\n",
      "Response to medication 10(Good/partial/no)\n",
      "\n",
      "Side effect of medication 10\n",
      "\n",
      "onset of side effect post starting med 10 ( in days)\n",
      "\n",
      "total duration of side effect of medication 10 (in days)\n",
      "\n",
      "Medication possession ratios 10(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 11\n",
      "\n",
      "Medication 11 starting dose\n",
      "\n",
      "Avg dose of medication 11\n",
      "\n",
      "Maximum dose of medication 11\n",
      "\n",
      "Total duration of medication 11\n",
      "\n",
      "continued medication 11/stopped/changed\n",
      "\n",
      "Response to medication 11(Good/partial/no)\n",
      "\n",
      "Side effect of medication 11\n",
      "\n",
      "onset of side effect post starting med 11 ( in days)\n",
      "\n",
      "total duration of side effect of medication 11 (in days)\n",
      "\n",
      "Medication possession ratios 11(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 12\n",
      "\n",
      "Medication 12 starting dose\n",
      "\n",
      "Avg dose of medication 12\n",
      "\n",
      "Maximum dose of medication 12\n",
      "\n",
      "Total duration of medication 12\n",
      "\n",
      "continued medication 12/stopped/changed\n",
      "\n",
      "Response to medication 12(Good/partial/no)\n",
      "\n",
      "Side effect of medication 12\n",
      "\n",
      "onset of side effect post starting med 12 ( in days)\n",
      "\n",
      "total duration of side effect of medication 12 (in days)\n",
      "\n",
      "Medication possession ratios 12(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 13\n",
      "\n",
      "Medication 13 starting dose\n",
      "\n",
      "Avg dose of medication 13\n",
      "\n",
      "Maximum dose of medication 13\n",
      "\n",
      "Total duration of medication 13\n",
      "\n",
      "continued medication 13/stopped/changed\n",
      "\n",
      "Response to medication 13(Good/partial/no)\n",
      "\n",
      "Side effect of medication 13\n",
      "\n",
      "onset of side effect post starting med 13 ( in days)\n",
      "\n",
      "total duration of side effect of medication 13 (in days)\n",
      "\n",
      "Medication possession ratios 13(MPRs) in lgb;x-syrup\n",
      "\n",
      "name of Medication 14\n",
      "\n",
      "Medication 14 starting dose\n",
      "\n",
      "Avg dose of medication 14\n",
      "\n",
      "Maximum dose of medication 14\n",
      "\n",
      "Total duration of medication 14\n",
      "\n",
      "continued medication 14/stopped/changed\n",
      "\n",
      "Response to medication 14(Good/partial/no)\n",
      "\n",
      "Side effect of medication 14\n",
      "\n",
      "onset of side effect post starting med 14 ( in days)\n",
      "\n",
      "total duration of side effect of medication 14 (in days)\n",
      "\n",
      "Medication possession ratios 14(MPRs) in lgb;x-syrup\n",
      "\n",
      "cost of medication\n",
      "\n",
      "Other treatments(rehabilitative intervention/IT/CBT/ipt/FT/PMT/BEHAVIOURAL INTERVENTIONS FOR DEVELOPMENTAL DISORDERS, Combination therapy)\n",
      "\n",
      "Maximum duration of symptom free period (in days)\n",
      "\n",
      "Max Duration of resolution of symptoms before recurrence/relapse (in days)\n",
      "\n",
      "No of relapses/exacerbations\n",
      "\n",
      "Off-medications duration (to add all such durations over follow-up in days)\n",
      "\n",
      "Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}\n",
      "\n",
      "mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)\n",
      "\n",
      "maximum period of compliance at lgb (in days) (longest streak of good compliance)\n",
      "\n",
      "total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)\n",
      "\n",
      "frequency of follow up at lgb (to write down follow-up dates)\n",
      "\n",
      "total number of follow up at LGBRIMH\n",
      "\n",
      "Final (ignore for now)\n",
      "\n",
      "Number of In patient cares\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = df2.columns\n",
    "for i in a:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f4f80d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               NaN\n",
       "1      Satisfactory\n",
       "2              Poor\n",
       "3              Good\n",
       "4              Good\n",
       "           ...     \n",
       "187    Satisfactory\n",
       "188             NaN\n",
       "189             NaN\n",
       "190             NaN\n",
       "191    Satisfactory\n",
       "Name: Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}, Length: 192, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bd219d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(['Final (ignore for now)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fa409808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>District</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>Max Duration of resolution of symptoms before recurrence/relapse (in days)</th>\n",
       "      <th>No of relapses/exacerbations</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio &lt; 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio &lt; 0.95}</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>frequency of follow up at lgb (to write down follow-up dates)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "      <td>180</td>\n",
       "      <td>212</td>\n",
       "      <td>07-12-2019, 21-12-2019, 17-01-2020, 11-04-2020...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>22-06-2020,30-09-2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "0                            10.0                   16.0      male     Islam   \n",
       "1                             8.0                   10.0    female     Islam   \n",
       "2                            17.0                   18.0    female     Islam   \n",
       "3                             7.0                   17.0      male     Islam   \n",
       "4                            10.0                   10.0      male  Hinduism   \n",
       "..                            ...                    ...       ...       ...   \n",
       "187                          15.0                   17.0      male     Islam   \n",
       "188                           NaN                    NaN       NaN       NaN   \n",
       "189                           NaN                    NaN       NaN       NaN   \n",
       "190                           NaN                    NaN       NaN       NaN   \n",
       "191                           5.0                    8.0      male  Hinduism   \n",
       "\n",
       "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "0                                              Primary                                         \n",
       "1                                                  NaN                                         \n",
       "2                                              Primary                                         \n",
       "3                                                  NaN                                         \n",
       "4                                              primary                                         \n",
       "..                                                 ...                                         \n",
       "187                                        high school                                         \n",
       "188                                                NaN                                         \n",
       "189                                                NaN                                         \n",
       "190                                                NaN                                         \n",
       "191                                            primary                                         \n",
       "\n",
       "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "0                      NaN       Rural                           53.0   \n",
       "1                      NaN       Rural                           62.0   \n",
       "2                  Primary       Rural                           55.0   \n",
       "3                      NaN       Rural                          102.0   \n",
       "4                  Primary       Rural                           29.0   \n",
       "..                     ...         ...                            ...   \n",
       "187            high school       Rural                           37.0   \n",
       "188                    NaN         NaN                            NaN   \n",
       "189                    NaN         NaN                            NaN   \n",
       "190                    NaN         NaN                            NaN   \n",
       "191                primary       Rural                           63.0   \n",
       "\n",
       "     District  State  ...  \\\n",
       "0      Nagaon  Assam  ...   \n",
       "1    Udalguri  Assam  ...   \n",
       "2      Nagaon  Assam  ...   \n",
       "3      Nagaon  Assam  ...   \n",
       "4    Sonitpur  Assam  ...   \n",
       "..        ...    ...  ...   \n",
       "187    Nagaon  Assam  ...   \n",
       "188       NaN    NaN  ...   \n",
       "189       NaN    NaN  ...   \n",
       "190       NaN    NaN  ...   \n",
       "191    Nagaon  Assam  ...   \n",
       "\n",
       "    Max Duration of resolution of symptoms before recurrence/relapse (in days)  \\\n",
       "0                                                  Nil                           \n",
       "1                                                   13                           \n",
       "2                                                  Nil                           \n",
       "3                                                   19                           \n",
       "4                                                   60                           \n",
       "..                                                 ...                           \n",
       "187                                                  0                           \n",
       "188                                                NaN                           \n",
       "189                                                NaN                           \n",
       "190                                                NaN                           \n",
       "191                                                205                           \n",
       "\n",
       "     No of relapses/exacerbations  \\\n",
       "0                             0.0   \n",
       "1                             6.0   \n",
       "2                             0.0   \n",
       "3                             6.0   \n",
       "4                             1.0   \n",
       "..                            ...   \n",
       "187                           0.0   \n",
       "188                           NaN   \n",
       "189                           NaN   \n",
       "190                           NaN   \n",
       "191                           0.0   \n",
       "\n",
       "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "0                                                 1649                            \n",
       "1                                                   22                            \n",
       "2                                                   30                            \n",
       "3                                                   58                            \n",
       "4                                                   20                            \n",
       "..                                                 ...                            \n",
       "187                                                120                            \n",
       "188                                                NaN                            \n",
       "189                                                NaN                            \n",
       "190                                                NaN                            \n",
       "191                                                  0                            \n",
       "\n",
       "    Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}  \\\n",
       "0                                                  NaN                                                                                                                                                                                                                                                                                              \n",
       "1                                         Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "2                                                 Poor                                                                                                                                                                                                                                                                                              \n",
       "3                                                 Good                                                                                                                                                                                                                                                                                              \n",
       "4                                                 Good                                                                                                                                                                                                                                                                                              \n",
       "..                                                 ...                                                                                                                                                                                                                                                                                              \n",
       "187                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "188                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "189                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "190                                                NaN                                                                                                                                                                                                                                                                                              \n",
       "191                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "0                                                 12.4                                    \n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "..                                                 ...                                    \n",
       "187                                               1.21                                    \n",
       "188                                                NaN                                    \n",
       "189                                                NaN                                    \n",
       "190                                                NaN                                    \n",
       "191                                               2.15                                    \n",
       "\n",
       "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "0                                                  180                                  \n",
       "1                                                  395                                  \n",
       "2                                                  240                                  \n",
       "3                                                  NaN                                  \n",
       "4                                                   90                                  \n",
       "..                                                 ...                                  \n",
       "187                                                390                                  \n",
       "188                                                NaN                                  \n",
       "189                                                NaN                                  \n",
       "190                                                NaN                                  \n",
       "191                                               1619                                  \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "0                                                  212                                                   \n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "..                                                 ...                                                   \n",
       "187                                                875                                                   \n",
       "188                                                NaN                                                   \n",
       "189                                                NaN                                                   \n",
       "190                                                NaN                                                   \n",
       "191                                               1619                                                   \n",
       "\n",
       "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
       "0    07-12-2019, 21-12-2019, 17-01-2020, 11-04-2020...              \n",
       "1    24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...              \n",
       "2       19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020              \n",
       "3    31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...              \n",
       "4                                22-06-2020,30-09-2020              \n",
       "..                                                 ...              \n",
       "187  29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...              \n",
       "188                                                NaN              \n",
       "189                                                NaN              \n",
       "190                                                NaN              \n",
       "191  16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...              \n",
       "\n",
       "    total number of follow up at LGBRIMH Number of In patient cares  \n",
       "0                                    6.0                        0.0  \n",
       "1                                   12.0                        0.0  \n",
       "2                                    4.0                        0.0  \n",
       "3                                   69.0                        0.0  \n",
       "4                                    2.0                        1.0  \n",
       "..                                   ...                        ...  \n",
       "187                                 24.0                        0.0  \n",
       "188                                  NaN                        NaN  \n",
       "189                                  NaN                        NaN  \n",
       "190                                  NaN                        NaN  \n",
       "191                                 25.0                        0.0  \n",
       "\n",
       "[192 rows x 264 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "14a7c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.rename(columns={'Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}': 'Final'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ec268bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Final'] = df2['Final'].replace({'Yes': 'Good', 'No': 'Poor'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "90cce714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Satisfactory', 'Poor', 'Good'], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Final'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "723ec4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in 'Final' column: 44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nan_count = df2['Final'].isna().sum()\n",
    "print(f\"Number of NaN values in 'Final' column: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "408ed8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>District</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>Max Duration of resolution of symptoms before recurrence/relapse (in days)</th>\n",
       "      <th>No of relapses/exacerbations</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Final</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>frequency of follow up at lgb (to write down follow-up dates)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "      <td>180</td>\n",
       "      <td>212</td>\n",
       "      <td>07-12-2019, 21-12-2019, 17-01-2020, 11-04-2020...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>22-06-2020,30-09-2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "0                            10.0                   16.0      male     Islam   \n",
       "1                             8.0                   10.0    female     Islam   \n",
       "2                            17.0                   18.0    female     Islam   \n",
       "3                             7.0                   17.0      male     Islam   \n",
       "4                            10.0                   10.0      male  Hinduism   \n",
       "..                            ...                    ...       ...       ...   \n",
       "187                          15.0                   17.0      male     Islam   \n",
       "188                           NaN                    NaN       NaN       NaN   \n",
       "189                           NaN                    NaN       NaN       NaN   \n",
       "190                           NaN                    NaN       NaN       NaN   \n",
       "191                           5.0                    8.0      male  Hinduism   \n",
       "\n",
       "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "0                                              Primary                                         \n",
       "1                                                  NaN                                         \n",
       "2                                              Primary                                         \n",
       "3                                                  NaN                                         \n",
       "4                                              primary                                         \n",
       "..                                                 ...                                         \n",
       "187                                        high school                                         \n",
       "188                                                NaN                                         \n",
       "189                                                NaN                                         \n",
       "190                                                NaN                                         \n",
       "191                                            primary                                         \n",
       "\n",
       "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "0                      NaN       Rural                           53.0   \n",
       "1                      NaN       Rural                           62.0   \n",
       "2                  Primary       Rural                           55.0   \n",
       "3                      NaN       Rural                          102.0   \n",
       "4                  Primary       Rural                           29.0   \n",
       "..                     ...         ...                            ...   \n",
       "187            high school       Rural                           37.0   \n",
       "188                    NaN         NaN                            NaN   \n",
       "189                    NaN         NaN                            NaN   \n",
       "190                    NaN         NaN                            NaN   \n",
       "191                primary       Rural                           63.0   \n",
       "\n",
       "     District  State  ...  \\\n",
       "0      Nagaon  Assam  ...   \n",
       "1    Udalguri  Assam  ...   \n",
       "2      Nagaon  Assam  ...   \n",
       "3      Nagaon  Assam  ...   \n",
       "4    Sonitpur  Assam  ...   \n",
       "..        ...    ...  ...   \n",
       "187    Nagaon  Assam  ...   \n",
       "188       NaN    NaN  ...   \n",
       "189       NaN    NaN  ...   \n",
       "190       NaN    NaN  ...   \n",
       "191    Nagaon  Assam  ...   \n",
       "\n",
       "    Max Duration of resolution of symptoms before recurrence/relapse (in days)  \\\n",
       "0                                                  Nil                           \n",
       "1                                                   13                           \n",
       "2                                                  Nil                           \n",
       "3                                                   19                           \n",
       "4                                                   60                           \n",
       "..                                                 ...                           \n",
       "187                                                  0                           \n",
       "188                                                NaN                           \n",
       "189                                                NaN                           \n",
       "190                                                NaN                           \n",
       "191                                                205                           \n",
       "\n",
       "     No of relapses/exacerbations  \\\n",
       "0                             0.0   \n",
       "1                             6.0   \n",
       "2                             0.0   \n",
       "3                             6.0   \n",
       "4                             1.0   \n",
       "..                            ...   \n",
       "187                           0.0   \n",
       "188                           NaN   \n",
       "189                           NaN   \n",
       "190                           NaN   \n",
       "191                           0.0   \n",
       "\n",
       "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "0                                                 1649                            \n",
       "1                                                   22                            \n",
       "2                                                   30                            \n",
       "3                                                   58                            \n",
       "4                                                   20                            \n",
       "..                                                 ...                            \n",
       "187                                                120                            \n",
       "188                                                NaN                            \n",
       "189                                                NaN                            \n",
       "190                                                NaN                            \n",
       "191                                                  0                            \n",
       "\n",
       "            Final  \\\n",
       "0             NaN   \n",
       "1    Satisfactory   \n",
       "2            Poor   \n",
       "3            Good   \n",
       "4            Good   \n",
       "..            ...   \n",
       "187  Satisfactory   \n",
       "188           NaN   \n",
       "189           NaN   \n",
       "190           NaN   \n",
       "191  Satisfactory   \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "0                                                 12.4                                    \n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "..                                                 ...                                    \n",
       "187                                               1.21                                    \n",
       "188                                                NaN                                    \n",
       "189                                                NaN                                    \n",
       "190                                                NaN                                    \n",
       "191                                               2.15                                    \n",
       "\n",
       "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "0                                                  180                                  \n",
       "1                                                  395                                  \n",
       "2                                                  240                                  \n",
       "3                                                  NaN                                  \n",
       "4                                                   90                                  \n",
       "..                                                 ...                                  \n",
       "187                                                390                                  \n",
       "188                                                NaN                                  \n",
       "189                                                NaN                                  \n",
       "190                                                NaN                                  \n",
       "191                                               1619                                  \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "0                                                  212                                                   \n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "..                                                 ...                                                   \n",
       "187                                                875                                                   \n",
       "188                                                NaN                                                   \n",
       "189                                                NaN                                                   \n",
       "190                                                NaN                                                   \n",
       "191                                               1619                                                   \n",
       "\n",
       "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
       "0    07-12-2019, 21-12-2019, 17-01-2020, 11-04-2020...              \n",
       "1    24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...              \n",
       "2       19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020              \n",
       "3    31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...              \n",
       "4                                22-06-2020,30-09-2020              \n",
       "..                                                 ...              \n",
       "187  29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...              \n",
       "188                                                NaN              \n",
       "189                                                NaN              \n",
       "190                                                NaN              \n",
       "191  16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...              \n",
       "\n",
       "    total number of follow up at LGBRIMH Number of In patient cares  \n",
       "0                                    6.0                        0.0  \n",
       "1                                   12.0                        0.0  \n",
       "2                                    4.0                        0.0  \n",
       "3                                   69.0                        0.0  \n",
       "4                                    2.0                        1.0  \n",
       "..                                   ...                        ...  \n",
       "187                                 24.0                        0.0  \n",
       "188                                  NaN                        NaN  \n",
       "189                                  NaN                        NaN  \n",
       "190                                  NaN                        NaN  \n",
       "191                                 25.0                        0.0  \n",
       "\n",
       "[192 rows x 264 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "53b6da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(subset=['Final'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7e9a5c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in 'Final' column: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nan_count = df2['Final'].isna().sum()\n",
    "print(f\"Number of NaN values in 'Final' column: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f7e00ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>District</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>Max Duration of resolution of symptoms before recurrence/relapse (in days)</th>\n",
       "      <th>No of relapses/exacerbations</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Final</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>frequency of follow up at lgb (to write down follow-up dates)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>22-06-2020,30-09-2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>6.6</td>\n",
       "      <td>480</td>\n",
       "      <td>3495</td>\n",
       "      <td>29-04-2014, 29-05-2014, 04-07-2014, 25-08-14, ...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>Rural</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>2.1</td>\n",
       "      <td>648</td>\n",
       "      <td>648</td>\n",
       "      <td>28-03-22, 13-07-22, 26-08-22, 11-10-22, 15-05-...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>110.0</td>\n",
       "      <td>morigaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>228</td>\n",
       "      <td>2.0</td>\n",
       "      <td>330</td>\n",
       "      <td>Poor</td>\n",
       "      <td>3.8</td>\n",
       "      <td>113</td>\n",
       "      <td>576</td>\n",
       "      <td>08-06-22, 26-08-22, 19-12-22, 23-01-23, 02-11-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>326.0</td>\n",
       "      <td>Dhubri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180</td>\n",
       "      <td>Poor</td>\n",
       "      <td>4.3</td>\n",
       "      <td>170</td>\n",
       "      <td>384</td>\n",
       "      <td>28-08-2021, 15-07-2022, 17-08-2022</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "1                             8.0                   10.0    female     Islam   \n",
       "2                            17.0                   18.0    female     Islam   \n",
       "3                             7.0                   17.0      male     Islam   \n",
       "4                            10.0                   10.0      male  Hinduism   \n",
       "5                             8.0                   15.0    female     Islam   \n",
       "..                            ...                    ...       ...       ...   \n",
       "163                           7.0                    9.0      male  Hinduism   \n",
       "164                          16.0                   17.0      male     Islam   \n",
       "186                          15.0                   15.0      male     Islam   \n",
       "187                          15.0                   17.0      male     Islam   \n",
       "191                           5.0                    8.0      male  Hinduism   \n",
       "\n",
       "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "1                                                  NaN                                         \n",
       "2                                              Primary                                         \n",
       "3                                                  NaN                                         \n",
       "4                                              primary                                         \n",
       "5                                  no formal education                                         \n",
       "..                                                 ...                                         \n",
       "163                                no formal education                                         \n",
       "164                                            primary                                         \n",
       "186                                        high school                                         \n",
       "187                                        high school                                         \n",
       "191                                            primary                                         \n",
       "\n",
       "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "1                      NaN       Rural                           62.0   \n",
       "2                  Primary       Rural                           55.0   \n",
       "3                      NaN       Rural                          102.0   \n",
       "4                  Primary       Rural                           29.0   \n",
       "5      no formal education       Rural                          102.0   \n",
       "..                     ...         ...                            ...   \n",
       "163    no formal education       Rural                           57.0   \n",
       "164                primary       Rural                          110.0   \n",
       "186            high school       Rural                          326.0   \n",
       "187            high school       Rural                           37.0   \n",
       "191                primary       Rural                           63.0   \n",
       "\n",
       "     District  State  ...  \\\n",
       "1    Udalguri  Assam  ...   \n",
       "2      Nagaon  Assam  ...   \n",
       "3      Nagaon  Assam  ...   \n",
       "4    Sonitpur  Assam  ...   \n",
       "5      Nagaon  Assam  ...   \n",
       "..        ...    ...  ...   \n",
       "163  Sonitpur  Assam  ...   \n",
       "164  morigaon  Assam  ...   \n",
       "186    Dhubri  Assam  ...   \n",
       "187    Nagaon  Assam  ...   \n",
       "191    Nagaon  Assam  ...   \n",
       "\n",
       "    Max Duration of resolution of symptoms before recurrence/relapse (in days)  \\\n",
       "1                                                   13                           \n",
       "2                                                  Nil                           \n",
       "3                                                   19                           \n",
       "4                                                   60                           \n",
       "5                                                  480                           \n",
       "..                                                 ...                           \n",
       "163                                                594                           \n",
       "164                                                228                           \n",
       "186                                                 30                           \n",
       "187                                                  0                           \n",
       "191                                                205                           \n",
       "\n",
       "     No of relapses/exacerbations  \\\n",
       "1                             6.0   \n",
       "2                             0.0   \n",
       "3                             6.0   \n",
       "4                             1.0   \n",
       "5                            33.0   \n",
       "..                            ...   \n",
       "163                           0.0   \n",
       "164                           2.0   \n",
       "186                           1.0   \n",
       "187                           0.0   \n",
       "191                           0.0   \n",
       "\n",
       "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "1                                                   22                            \n",
       "2                                                   30                            \n",
       "3                                                   58                            \n",
       "4                                                   20                            \n",
       "5                                                   65                            \n",
       "..                                                 ...                            \n",
       "163                                                  0                            \n",
       "164                                                330                            \n",
       "186                                                180                            \n",
       "187                                                120                            \n",
       "191                                                  0                            \n",
       "\n",
       "            Final  \\\n",
       "1    Satisfactory   \n",
       "2            Poor   \n",
       "3            Good   \n",
       "4            Good   \n",
       "5    Satisfactory   \n",
       "..            ...   \n",
       "163          Good   \n",
       "164          Poor   \n",
       "186          Poor   \n",
       "187  Satisfactory   \n",
       "191  Satisfactory   \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "5                                                  6.6                                    \n",
       "..                                                 ...                                    \n",
       "163                                                2.1                                    \n",
       "164                                                3.8                                    \n",
       "186                                                4.3                                    \n",
       "187                                               1.21                                    \n",
       "191                                               2.15                                    \n",
       "\n",
       "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "1                                                  395                                  \n",
       "2                                                  240                                  \n",
       "3                                                  NaN                                  \n",
       "4                                                   90                                  \n",
       "5                                                  480                                  \n",
       "..                                                 ...                                  \n",
       "163                                                648                                  \n",
       "164                                                113                                  \n",
       "186                                                170                                  \n",
       "187                                                390                                  \n",
       "191                                               1619                                  \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "5                                                 3495                                                   \n",
       "..                                                 ...                                                   \n",
       "163                                                648                                                   \n",
       "164                                                576                                                   \n",
       "186                                                384                                                   \n",
       "187                                                875                                                   \n",
       "191                                               1619                                                   \n",
       "\n",
       "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
       "1    24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...              \n",
       "2       19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020              \n",
       "3    31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...              \n",
       "4                                22-06-2020,30-09-2020              \n",
       "5    29-04-2014, 29-05-2014, 04-07-2014, 25-08-14, ...              \n",
       "..                                                 ...              \n",
       "163  28-03-22, 13-07-22, 26-08-22, 11-10-22, 15-05-...              \n",
       "164   08-06-22, 26-08-22, 19-12-22, 23-01-23, 02-11-23              \n",
       "186                 28-08-2021, 15-07-2022, 17-08-2022              \n",
       "187  29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...              \n",
       "191  16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...              \n",
       "\n",
       "    total number of follow up at LGBRIMH Number of In patient cares  \n",
       "1                                   12.0                        0.0  \n",
       "2                                    4.0                        0.0  \n",
       "3                                   69.0                        0.0  \n",
       "4                                    2.0                        1.0  \n",
       "5                                   71.0                        0.0  \n",
       "..                                   ...                        ...  \n",
       "163                                 10.0                        0.0  \n",
       "164                                  5.0                        0.0  \n",
       "186                                  3.0                        0.0  \n",
       "187                                 24.0                        0.0  \n",
       "191                                 25.0                        0.0  \n",
       "\n",
       "[148 rows x 264 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2dd43d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "text_columns = df2.select_dtypes(include=['object']).columns\n",
    "columns_with_null = df2.columns[df2.isnull().any()]\n",
    "text_columns = [col for col in text_columns if col not in columns_with_null]\n",
    "df2['combine'] = df2[text_columns].apply(lambda row: ','.join(row.dropna().astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d1ae04c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      female,Islam,Udalguri,Assam,episodes of unresp...\n",
       "2      female,Islam,Nagaon,Assam,Episodes of abnormal...\n",
       "3      male,Islam,Nagaon,Assam,episode of abnormal je...\n",
       "4      male,Hinduism,Sonitpur,Assam,inattention,nil,N...\n",
       "5      female,Islam,Nagaon,Assam,epileptic fits,Nil,N...\n",
       "                             ...                        \n",
       "163    male,Hinduism,Sonitpur,Assam,delayed developme...\n",
       "164    male,Islam,morigaon,Assam,suspiciousness towar...\n",
       "186    male,Islam,Dhubri,Assam,Irrelevent Talking,Nil...\n",
       "187    male,Islam,Nagaon,Assam,No Memory of events, C...\n",
       "191    male,Hinduism,Nagaon,Assam,unable to speak ,Cu...\n",
       "Name: combine, Length: 148, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['combine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4a7e0745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female,Islam,Udalguri,Assam,episodes of unresponsiveness ,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,sodium valproate,300,clobazam,5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019, 17-12-2019, 18-01-2020, 02-03-2020, 02-05-2020,22-06-2020, 28-08-2020, 17-11-2020, 21-01-2021\n",
      "female,Islam,Nagaon,Assam,Episodes of abnormal jerky movement of body,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,carbamazepine,500,clobazam,5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020\n",
      "male,Islam,Nagaon,Assam,episode of abnormal jerky movement with LOC,Seizure disorder,Nil,Nil,Nil,Nil,Nil,Nil,Nil,carbamazepine,200,phenobarbitone,60,clobazam,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Good,31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014, 25-08-2014, 01-02-2016, 30-03-2016, 29-04-2016, 03-06-2016, 28-08-2016, 08-08-2016, 08-09-2016, 05-10-2016, 09-11-2016, 16-12-2016, 23-01-2017, 22-02-2017, 10-03-2017, 21-04-2017, 25-05-2017, 22-06-2017, 20-07-2017, 03-10-2017, 02-11-2017, 06-01-2018, 05-02-2018, 08-03-2018, 07-04-2018, 05-05-2018, 07-06-2018, 09-08-2018, 12-09-2018, 09-10-2018, 12-11-2018, 19-12-2018, 17-01-2019, 13-06-2019, 13-07-2019, 17-08-2019, 17-08-2019, 20-10-2019, 30-11-2019, 03-01-2020, 06-03-2020, 22-06-2020, 02-04-2021, 10-05-2021, 06-08-2021, 07-09-2021, 13-11-2021, 17-01-2022, 19-03-2022, 30-05-2022, 04-07-2022, 09-08-2022, 13-09-2022, 27-10-2022, 28-11-2022, 10-01-2023, 13-02-2023, 22-03-2023, 26-04-2023, 05-06-2023, 17-07-2023, 24-08-2023, 25-09-2023, 06-11-2023\n",
      "male,Hinduism,Sonitpur,Assam,inattention,nil,Nil,Nil,ADHD,Nil,Nil,Nil,motor coordination disorder,clonidine,0.05,Nil,Nil,nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Purchased,Good,22-06-2020,30-09-2020\n",
      "female,Islam,Nagaon,Assam,epileptic fits,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,sodium valproate,400,clobazam,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,29-04-2014, 29-05-2014, 04-07-2014, 25-08-14, 01-03-16, 30-03-16, 29-04-16, 03-06-16, 28-06-16, 08-08-16, 08-09-16, 05-10-16, 09-11-16, 16-12-16, 23-01-17, 22-02-17, 10-03-17, 21-04-17, 25-05-17, 22-06-17, 20-07-17, 02-11-17, 06-01-18, 05-02-18, 08-03-18, 07-04-18, 05-05-18, 07-06-18, 27-06-18, 09-08-18, 12-09-18, 09-10-18, 12-11-18, 19-12-18, 17-01-19, 20-02-19, 30-03-19, 02-05-19, 13-06-19, 13-07-19, 17-08-19, 17-09-19, 22-10-19, 30-11-19, 03-01-2020, 28-01-2020, 06-03-2020, 22-06-2020, 02-04-21, 10-05-21, 06-08-21, 07-09-21, 13-11-21, 17-01-22, 19-03-22, 30-05-22, 04-07-22, 09-08-22, 13-09-22, 27-10-22, 28-11-22, 10-1-23, 13-02-23, 23-03-23, 26-04-23, 05-06-23, 17-07-23, 24-08-23, 25-09-23, 06-11-23\n",
      "female,Islam,Sonitpur,Assam,abnormal jerky movements with fall,Nil,once,seizure disorder,Nil,Nil,Nil,Nil,Nil,sodium valproate,500,clobazam,10,Carbamazepine,200,1 tbsp,Reduced d/t resolution,risperidone,0.5,0.5,0.5,540,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,10-06-15, 22-06-15, 15-07-15, 29-07-15, 26-05-15, 23-09-15, 21-10-15, 11-11-15, 21-12-15, 25-1-16, 16-3-16, 18-5-16, 20-07-16, 7-9-16, 26-10-16, 28-12-16, 27-1-17, 22-2-17, 17-3-17, 14-4-17, 12-5-17, 26-6-17, 13-9-17, 11-10-17, 15-11-17, 15-12-17, 7-2-18, 2-4-18, 9-5-18, 31-5-18, 27-6-18, 4-8-18, 24-9-18, 5-11-18, 14-12-18, 15-1-19, 12-2-19, 12-4-19, 25-5-19, 16-7-19, 20-8-19, 21-9-19, 21-10-19, 18-11-19, 20-12-19, 25-1-2020, 24-2-2020, 20-03-20, 19-05-20, 22-06-20, 28-07-20, 20-10-20, 0-11-20, 22-12-20, 19-1-21, 19-2-21, 19-03-21, 12-04-21, 08-05-21, 19-07-21, 13-08-21, 11-10-21, 16-11-21, 17-12-21, 11-01-22, 15-03-21, 12-04-22, 13-06-22, 16-07-22, 16-08-22, 14-11-22, 24-01-23, 28-02-23, 1-04-23, 29-05-23, 4-07-23, 18-08-23, 26-09-23, 07-11-23\n",
      "male,Hinduism,Sonitpur,Assam,abnormal movement of body with deviation of face to opposite side,Seizure disorder,Nil,Nil,Nil,Nil,Nil,Nil,Nil,carbamazepine,600,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,8-6-2016, 18-7-2016, 19-8-2016, 14-9-16, 4-10-2016,9-11-2016, 9-1-2017, 10-2-2017, 11-3-2017, 10-4-2017, 11-5-2017, 10-6-2017, 8-7-2017, 5-8-2017, 4-9-2017, 14-10-2017, 4-12-2017, 2-1-2018,2-2-2018, 3-3-2018, 4-4-2018, 2-5-2018, 2-6-2018, 2-7-2018, 31-7-2018, 30-8-2018, 28-9-2018, 29-19-2018, 28-11-2018, 27-12-2018, 25-1-2019, 26-2-2019, 26-3-2019, 24-4-2019, 27-5-2019, 27-6-2019, 27-8-2019, 25-9-2019, 25-10-2019, 25-11-2019, 24-12-2019, 21-1-2020, 22-2-2020, 23-3-2020, 21-4-2020, 22-5-2020, 22-6-2020, 9-1-2021, 3-3-2021, 12-4-2021, 14-6-2021, 8-8-2021,14-9-2021, 16-10-2021, 16-11-2021, 3-1-2022,4-2-2022, 5-3-2022, 5-4-2022, 20-5-2022, 6-7-2022, 3-8-2022, 2-9-2022, 30-9-2022, 2-11-2022, 8-12-2022, 28-12-2023, 4-2-2023, 4-3-2023, 4-5-2023, 27-5-2023, 4-7-2023, 1-8-2023, 2-9-2023, 3-10-2023, 1-11-2023\n",
      "male,Hinduism,Sonitpur,Assam,Delayed speech,Nil,NIL,NIL,At risk ADHD,At risk SLD,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Good,2020-06-22 00:00:00\n",
      "female,Hinduism,Darrang,Assam,Abnormal jerky movements,Nil,once,depressive disorder, seizure disorder,Depressive disorder due to another medical condition,Nil,Nil,Nil,Nil,sodium valproate,400,Fluoxetine,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Poor,27-12-2019, 17-3-2020, 22-06-2020, 14-12-2020, 22-01-2021, 6-11-2023\n",
      "male,Hinduism,Karbianglong,Assam,Delayed speech,Nil,Nil,Nil,ADHD,vocal tics,Nil,Nil,Nil,clonidine,0.05,Risperidone ,0.5,Melatonin,3,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Poor,27-02-2020, 22-06-2020\n",
      "female,Islam,Darrang,Assam,Abnormal jerky movements,NIL,NIL,NIL,NIL,NIL,NIL,NIL,NIL,Sodium Valproate,300,nil,nil,nil,nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,14-02-2020,22-06-2022\n",
      "female,Hinduism,Sonitpur,Assam,Episodes of loss of consciousness,treated for afebrile seizures,NIL,NIL,NIL,NIL,NIL,NIL,NIL,Sodium Valproate,200,nil,nil,nil,nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,08-03-2018,13-06-2019,28-06-2019,22-06-2022,26-11-2020,11-08-2022,06-07-2023\n",
      "female,Hinduism,Sonitpur,Assam,persistent low mood,Nil,Nil,Nil,Depressive disorder due to another medical condition,Nil,Nil,Nil,Nil,escitalopram,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,22.06.2020\n",
      "female,Islam,Sonitpur,Assam,anger outburst,Nil,once,seizure disorder,Nil,Nil,Nil,Nil,Nil,Olanzapine,5,sodum valproate,300,clobazam,5,300,stopped,Levetiracetam,750,1000,1000,90,1,Carbamazepine,400,600,600,30,Skin rashes,12,7,1,Risperidone,1,4,4,1620,Nil,Nil,Nil,0.99,Lorazepam,2,2,2,120,Continued,Good,Nil,Nil,Nil,1,Chlorpromazine,50,50,50,210,Stopped,Good,Nil,Nil,Nil,1,Melatonin,3,3,3,60,Continued,Good,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Satisfactory,15-10-12, 9-1-13, 4-2-13, 7-3-13, 5-4-13, 6-5-13, 5-6-13, 4-7-13, 3-8-13, 2-9-13, 3-10-13, 2-11-13, 21-11-13, 11-3-15, 3-4-15, 22-4-15, 14-5-15, 5-6-15, 13-7-15, 19-8-15, 22-9-15, 21-10-15, 20-11-15, 21-12,15, 19-1-16, 18-2-16, 3-3-16, 2-4-19, 6-5-16, 7-3-17, 13-4-17, 17-5-17, 19-6-17, 20-7-17, 16-8-17, 13-9-17, 14-10-17, 28-10-17, 28-11-17, 30-12-17, 31-1-18, 5-3-18, 4-4-18, 12-4-18, 2-5-18, 28-5-18, 2-7-18, 31-7-18,30-08-18, 29-10-18, 28-11-18, 29-12-18, 29-01-19, 28-2-19, 29-3-19, 27-4-19, 27-5-19, 26-6-19, 25-7-19, 26-8-19, 25-9-19, 26-10-19, 22-11-19, 25-12-19, 20-1-20, 22-2-20, 21-4-20, 22-05-20, 22-6-20, 16-11-20, 11-01-21, 21-03-21, 12-06-23, 30-07-23, 04-08-23, 18-08-23, 19-09-23, 18-10-23\n",
      "male,hinduism,Sonitpur,Assam,episodes of loss of consciousness,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Divalproaex sodium,250,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,07.03.2019, 24.01.2020, 04.02.2020, 03.03.2020, 14.05.2020, 22.06.2020, 28.09.2020, 20.02.2021, 17.05.2021, 19.8.2021, 06.07.2022, 14.08.2023\n",
      "female,Islam,Nagaon,Assam,jerks of hands and legs,Seizure disorder,once,mania with psychotic symptoms, moderate to severe IDD,Mania with psychotic symptoms,Nicotine dependence,Nil,Nil,Nil,Sodium valproate,600,Olanzapine,20,lithium,900,2,Reduced d/t resolution,Lorazepam,2,2,4,1050,0.54,Clonazepam,0.5,0.5,0.5,60,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,30-08-18, 03-10-18, 17-11-18, 20-12-18, 31-01-19, 15-03-19, 1-05-19, 29-06-19, 25-09-19, 21-10-19, 05-12-19, 24-01-2020, 22-06-2020, 06-10-2020, 23-11-2020, 09-03-21, 11-05-21, 28-07-21, 04-10-21, 26-11-21, 29-01-22, 10-03-22, 20-04-22, 26-05-22, 18-07-22, 07-09-22, 10-10-22, 23-11-22, 04-1-23, 02-03-23, 20-04-23, 09-06-23, 04-08-23, 23-09-23, 04-11-23\n",
      "male,Islam,Nagaon,Assam,anger outburst,Nil,Nil,Nil,acute and transient psychotic disorder,Nil,Nil,Nil,Nil,Olanzapine,10,Lorazepam,2,Chlorpromazine,100,5,Stopped,promethazine,25,25,25,1,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,18-02-2020, 21-03-2020, 09-05-2020, 22-06-2020, 03-09-2020\n",
      "male,Islam,Sonitpur,Assam,overactivity,Nil,once,ASD, at risk ADHD with mild IDD,ASD,at risk ADHD,Nil,Nil,Nil,clonidine,0.025,Methylphenidate,2.5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Purchased,Satisfactory,22-06-2020, 31-08-2020, 14-09-2020, 28-10-2020, 20-11-2020, 12-03-2020, 19-03-2021\n",
      "male,Hinduism,Sonitpur,Assam,jerky movement of limbs,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,sodium valproate,200,Clonazepam,0.25,Escitalopram,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,08-12-2020, 16-10-2021, 10-11-2021, 13-12-2021, 17-01-2022, 16-07-2021, 16-08-2021, 13-9-2021, 14-5-2022, 15-6-2022, 15-7-2022, 16-2-2022, 15-3-2022, 18-4-2022, 12-10-2022, 11-11-2022, 13-12-2022, 9-1-2023, 12-8-2022, 12-9-2022, 10-4-2023, 8-5-2023, 10-6-2023, 8-7-2023, 11-2-2023, 4-3-2023, 5-8-2023, 29-8-2023, 7-10-2023, 4-11-2023\n",
      "female,Islam,Sonitpur,Assam,episodes of LOC,seizure disorder,twice,Mild IDD with seizure disorder,Nil,Nil,Nil,Nil,Nil,sodium valproate,100,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,03-07-17, 11-09-17, 19-03-18, 04-05-18, 20-06-18, 03-08-18, 18-09-18, 09-10-18, 28-11-18, 07-02-19, 13-04-19, 23-05-19, 09-07-19, 15-11-19, 04-10-19, 15-11-19, 17-12-19, 23-01-2020, 04-03-2020, 22-04-2020, 22-06-2020, 26-09-2020, 19-11-2020, 29-12-2020, 04-02-21, 06-03-21, 12-04-21, 29-05-21, 09-07-21, 27-08-21, 06-10-21, 17-11-21, 23-12-21, 12-1-22, 05-02-22, 19-02-22, 22-03-22, 02-05-22, 13-06-22, 16-07-22, 23-08-22, 16-08-22, 26-09-22, 05-10-22, 28-10-22, 08-11-22, 07-02-23, 05-04-23, 29-05-23, 04-07-23, 18-07-23, 15-09-23, \n",
      "female,Islam,Sonitpur,Assam,generalised weakness,treated for seizures ,Nil,Nil,Specific learning disorder,Nil,Nil,Nil,Nil,Sodium Valproate,400,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,28-11-2018,03-05-2019,06-06-2019,23-07-2019,14-09-2019,12-10-2019,16-11-2019,21-12-2019,31-01-2020,02-03-2020,22-06-2020,24-03-2021,24-04-2021,06-08-2022,27-08-2022,24-09-2022,05-11-2022,19-11-2022,24-12-2022,28-01-2023,06-03-2023,12-04-2023,12-04-2023,15-06-2023,26-07-2023,04-09-2023,16-09-2023,13-10-2023\n",
      "male,Islam,Nagaon,Assam,involuntary movements of hands and feet,Nil,Nil,Nil,ADHD,Nil,Nil,Nil,Nil,Sodium Valproate,200,clobazam,10,Risperidone,0.5,1,Continued,Clonidine,0.05,0.15,0.15,1004,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,05-06-2014,27-06-2014,30-07-2014,02-09-2014,08-10-2014,14-11-2017,30-12-2014,27-02-2015,03-04-2015,09-05-2015,25-06-2015,31-07-2015,01-10-2015,09-11-2015,01-01-2016,12-02-2016,18-03-2016,19-04-2016,07-05-2016,04-06-2016,11-07-2016,05-08-2016,03-09-2016,13-10-2016,09-11-2016,07-12-2016,02-01-2017,01-02-2017,03-03-2017,31-03-2017,10-05-2017,03-06-2017,04-07-2017,08-09-2017,29-06-2018,09-08-2018,18-09-2018,20-10-2018,23-11-2018,30-11-2018,09-02-2019,02-04-2019,27-05-2019,18-06-2019,19-06-2019,26-07-2019,09-09-2019,10-10-2019,16-11-2019,26-11-2019,24-12-2019,04-02-2020,19-03-2020,18-05-2020,22-06-2020,15-10-2020,16-11-2020,17-12-2020,16-01-2021,25-02-2021,19-05-2021,31-07-2021,13-11-2021,20-12-2021,10-01-2022,09-03-2022,12-04-2022,20-06-2022,25-08-2022,09-11-2022,15-02-2023,03-05-2023,04-07-2023,24-08-2023\n",
      "male,Hinduism,Sonitpur,Assam,irritability,Nil,Nil,Nil,ADHD,Tics, transvestism with fetishism,Nil,Nil,Risperidone,1,Trihexiphenidyl,1,Carbamazepine,200,10,Continued,Fluoxetine,10,20,40,1299,0.99,Aripiprazole,2.5,10,10,1299,Nil,Nil,Nil,0.99,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Satisfactory,23-11-2015,28-12-2015,15-02-2016,11-04-2016,25-05-2016,24-06-2016,06-07-2016,03-08-2016,08-09-2016,13-10-2016,10-11-2016,12-12-2016,18-01-2017,02-03-2017,10-04-2017,03-05-2017,29-05-2017,05-06-2017,03-07-2017,02-08-2017,04-09-2017,06-11-2017,04-12-2017,05-01-2018,14-02-2018,02-04-2018,01-06-2018,02-06-2018,04-07-2018,02-08-2018,06-09-2018,09-10-2018,07-11-2018,10-01-2019,11-02-2019,18-03-2019,26-04-2019,28-05-2019,18-06-2019,28-08-2019,04-10-2019,08-11-2019,11-12-2019,16-01-2020,15-02-2020,29-02-2020,22-04-2020,05-05-2020,22-06-2020,21-07-2020,29-08-2020,21-10-2020,15-11-2020,22-12-2020,22-01-2021,06-03-2021,02-04-2021,08-05-2021,25-01-2022,23-08-2022,19-12-2022,24-07-2023,05-10-2023\n",
      "male,Islam,Dhubri,Assam,aggressiveness,aggression,multiple,bipolar disorder NOS, OCD, polysubstance use,Bipolar disorder NOS,OCD,Polysubstance use,Nil,Nil,oxcarbazepine,450,Fluoxetine,20,Naltrexone,50,20,Changed d/t non response,Pregabalin,75,300,300,750,1,Escitalopram,10,20,20,540,switch to mania,77.1,30,1,Olanzapine,10,10,20,810,weight gain,115.7,139,1,Lurasidone,20,40,80,90,Stopped,Partial,Nil,Nil,Nil,1,Lithium,600,600,600,240,Stopped,Nil,Nil,Nil,Nil,1,Risperidone,4,6,8,720,Continued,Partial,Nil,Nil,Nil,Clomipramine,75,150,150,600,Continued,Good,Nil,Nil,Nil,1,Trihexyphenidyl,2,2,2,600,Continued,Nil,Nil,Nil,1,Clonazepam,0.5,0.5,0.5,510,Continued,Good,Nil,Nil,Nil,1,Melatonin,5,5,5,360,Stopped,Good,Sedation,Nil,Nil,1,Both Free and Purchased,Good,13-06-2018,18-08-2018,23-08-2018,19-09-2018,24-10-2018,20-02-2019,13-03-2019,06-04-2019,25-05-2019,31-07-2019,13-09-2019,08-10-2019,17-12-2019,07-01-2020,13-03-2020,11-05-2020,22-06-2020,11-09-2020,23-01-2021,24-03-2021,14-04-2021,12-06-2021,14-06-2021,20-08-2021,10-09-2021,28-09-2021,16-11-2021,01-12-2021,03-12-2021,17-12-2021,31-12-2021,18-02-2022,22-02-2022,11-03-2022,25-03-2022,23-04-2022,01-07-2022,13-08-2022,31-12-2022,12-05-2023,09-06-2023,27-07-2023\n",
      "male,Hinduism,Sonitpur,Assam,decreased interest in studies and poor academic performance,Nil,Nil,Nil,Moderate depressive disorder without somatic symptoms,Nil,Nil,Nil,Nil,Escitalpram,10,Clonazepam,0.5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,17-03-2020, 15-06-2020, 22-06-2020, 24-06-2020, 01-07-2020, 03-08-2020, 24-08-2020, \n",
      "male,Islam,Barpeta,Assam,Excessive talking with tall talks,Current condition,Nil,Nil,Mania with psychotic symptoms,Nil,Nil,Nil,Nil,Olanzpine,20,Lithium carbonate,900,Chlorpromazine,200,4,Changed d/t non response,Zuclopenthixol acetate,100,100,100,2,1,Clonazepam,0.5,0.5,0.5,7,Nil,Nil,Nil,1,Trihexyphenidyl,2,2,2,446,Nil,Nil,Nil,0.26,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,04-01-2020,06-02-2020,11-03-2020,22-06-2020,27-08-2020,30-10-2020,07-01-2021,24-02-2021,02-02-2022\n",
      "male,Islam,Sonitpur,Assam,decrease talk,Nil,Nil,Nil,Acute and transient psychotic disorder,Nil,Nil,Nil,Nil,Olanzapine,15,Chlorpromazine,50,Amitryptiline,25,2,Stopped,Fluoxetine,20,20,40,1366,0.99,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,21-11-2016, 21-12-2016, 21-1-2017, 28-2-2017, 31-3-2017, 2-5-2017, 1-6-2017, 5-7-2017, 12-8-2017, 8-9-2017, 18-10-2017, 21-11-2017, 28-12-2017, 31-1-2018, 21-3-2018, 23-4-2018, 31-5-2018,6-6-2018, 3-7-2018, 25-9-2018, 5-11-2018, 18-12-2018, 29-1-2019, 6-3-2019, 3-4-2019, 19-4-2019, 25-5-2019, 29-6-2019, 9-8-2019, 24-9-2019, 29-10-2019, 1-12-2019, 6-1-2020,14-2-2020, 12-6-2020, 30-10-2020, 11-12-2020, 18-1-2021,19-3-2021, 13-4-2021, 3-8-2021, 6-11-2021, 11-12-2021, 4-2-2022, 14-6-2022, 20-7-2022, 24-8-2022, 12-11-2022, 4-1-2023,18-5-2023, 21-6-2023-11-10-2023 \n",
      "male,Hinduism,Karbi Anglong,Assam,school refusal,Nil,Once,IDD,ADHD,OCD,ODD,ADHD,OCD,ODD,Nil,Nil,Sodium Valproate,375,Clonidine,0.05,Risperidone,1,20,Continued,Melatonin,3,3,3,81,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Satisfactory,23.09.2017,23.10.2017,24.11.2017,05.10.2018,22.09.2021,28.10.2021,13.01.2022\n",
      "male,Islam,Darrang,Assam,delayed developmental milestones,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Risperidone,0.5,Clonidine,0.25,trihexyphenidyl,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Good,19.07.2017,15.09.2017,13.11.2017,13.06.2019,18.07.2019,21.11.2019,31.12.2019,11.03.2020,23.10.2020,05.04.2021,28.10.2021,11.10.2022,23.06.2023,26.07.2023,28.08.2023,10.10.2023,17.11.2023\n",
      "male,Hinduism,Nagaon,Assam,Episodes ofinvoluntary jerky movements of the body,Current condition,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Carbamazepine,300,Sodium valproate,200,Clobazam,5,60,Changed d/t non response,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Satisfactory,21-11-2014,17-12-2014,15-01-2015,14-02-2015,24-03-2015,13-04-2015,04-05-2015,04-06-2015,23-07-2015,06-08-2015,07-09-2015,03-10-2015,03-11-2015,07-12-2015,24-01-2016,30-01-2016,04-03-2016,05-04-2016,07-05-2016,06-06-2016,30-06-2016,30-07-2016,05-09-2016,23-09-2016,24-10-2016,07-12-2016,30-01-2017,07-03-2017,20-04-2017,17-07-2019,21-09-2019,21-09-2019,19-10-2019,22-11-2019,23-12-2019,22-01-2020,19-02-2020,13-03-2020,23-04-2020,16-06-2020,01-08-2020,02-09-2020,27-11-2020,25-12-2020,04-02-2021,25-02-2021,01-04-2021,22-04-2021,08-05-2021,11-06-2021,19-07-2021,17-08-2021,25-09-2021,28-10-2021,03-12-2021,-4-01-2022,03-02-2022,10-03-2022,14-04-2022,06-05-2022,08-06-2022,09-07-2022,17-08-2022,23-09-2022,02-11-2022,09-12-2022,30-12-2022,15-02,2023,13-03-2023,1-04-2023,04-05-2023,18-05-2023\n",
      "female,Islam,Sonitpur,Assam,Poor self care activity and forgetful after learning,Nil,Nil,Nil,ADHD,conduct disorder,Nil,Nil,Nil,clonidine,0.05,Aripiprazole,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,28-10-21, 03-01-22, 18-05-22, 20-06-22, 25-08-22\n",
      "female,Islam,Nagaon,Assam,Self crying,Nil,Nil,Nil,Psychosis NOS,Nil,Nil,Nil,Nil,Risperidone,2,Sodium valproate,200,trihexyphenidyl,2,10,Stopped,Lithium,600,600,600,60,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,21.04.2016,16.05.2016,23.05.2017,24.07.2017,19.02.2018,26.03.2018,30.11.2018,12.01.2019,02.01.2019,20.02.2020,15.06.2020,11.02.2021,07.10.2021,28.10.2021,03.12.2021,30.12.2021,17.02.2022,24.03.2022,12.05.2022,29.08.2022,06.10.2022,03.05.2023,16.11.2023,27.11.2023\n",
      "male,Hinduism,Udalguri,Assam,abnormal jerky movements with loss of conciousness,Nil,Nil,Nil,Seizure disorder,Nil,Nil,Nil,Nil,Phenytoin,200,Sodium valproate,500,Risperidone,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,25-3-2019, 22-4-2019, 21-5-2019, 28-6-2019, 9-8-2019, 9-9-2019, 11-10-2019, 5-11-2019, 4-12-2019, 6-1-2019, 10-2-2020, 6-7-2020, 24-11-2020, 12-1-2021, 26-4-2021, 30-7-2021, 28-9-2021, 28-10-2021, 28-12-2021, 25-2-2022, 25-4-2022, 25-5-2022, 27-6-2022, 27-7-2022, 26-8-2022, 2-11-2022, 2-1-2023, 27-2-2023, 17-4-2023, 29-5-2023, 27-6-2023, 27-9-2023, 25-10-2023,27-11-2023\n",
      "male,Hinduism,Lakhimpur,Assam,sudden jerky movemnts of body,Current illness,Nil,Nil,depressive disorder,Dissociation,SLD in maths,Nil,Nil,Escitalopram,5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,28-08-21, 28-10-21, 27-12-21, 27-1-22, 25-04-22, 27-06-22, 26-08-22, 26-10-22, 18-11-22, 10-04-23, 19-10-23\n",
      "male,Islam,Sonitpur,Assam,abnormal jerky movements,current illness,Nil,Nil,Depressive disorder,history of ADHD,history of conduct disorder,Nil,Nil,sodium Valproate,400,clobazam,10,Escitalopram,5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,28-10-21, 29-11-21, 05-01-22, 05-09-22, 09-03-22, 09-04-22\n",
      "female,Islam,Nagaon,Assam,does not obey commands, verbally abusive,Nil,once,ADHD with conduct disorder, IDD, seizure disorder,ADHD,conduct disorder,Nil,Nil,Nil,Atomoxetine,10,sodium Valproate,400,clonidine,0.05,2,loss to follow-up,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Good,30-09-21, 28-10-21, 13-12-21, 29-01-21\n",
      "male,Islam,Nagaon,Assam,irrelevant talk,Nil,No,Nil,Acute and transient psychotic disorder,Nil,Nil,Nil,Nil,Olanzapine,10,Lorazepam,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,30-9-2021, 28-10-2021, 6-2-2023\n",
      "male,Islam,Nagaon,Assam,abnormal jerky movements,Nil,Nil,Nil,Dissociative disorder,Psychosis NOS,Nil,Nil,Nil,Aripiprazole,5,Escitalopram,5,Fluoxetine,20,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Poor,8.9.21,20.9.2021,28.10.2021,17.2.2022,4.9.2023,12.9.2023\n",
      "male,Hinduism,Darrang,Assam,intake of cannabis once,Nil,Nil,Nil,Acute and Transient Psychotic disorder,Nil,Nil,Nil,Nil,Olanzapine,10,Trihexyphenidyl,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,05-07-21, 03-09-21, 28-10-21, 02-12-21, 31-01-22, 31-03-22, 31-05-22, 28-06-22, 29-12-22, 13-02-23, 02-06-23, 25-07-23\n",
      "male,Hinduism,Baksa,Assam,tall claim,Nil,Nil,Nil,Cannabis induced psychosis,Nil,Nil,Nil,Nil,Olanzapine,10,Lorazepam,2,trihexyphenidyl,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,3-5-2021, 12-7-2021, 28-10-2021, 24-1-2022, 5-5-2022, 21-7-2022\n",
      "male,Islam,Nagaon,Assam,Tightening of body,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,300,Clobazam,5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Ni,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,12-12-2022, 26-12-2022,16-1-2023, 16-2-2023\n",
      "male,Hinduism,Darrang,Assam,fearfulness,Nil,Once,Psychosis Nos with Anxiety disorder,Psychosis NOS,Anxiety disorder,Nil,Nil,Nil,amisulpride,400,Clonazepam,0.5,olanzapine ,10,4,Stopped,Aripiprazole,20,25,25,124,1,Fluoxetine,10,10,10,28,Nil,Nil,Nil,1,Melatonin,3,3,3,28,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,18-7-2022, 27-7-202217-8-2022, 15-9-2022, 6-10-2022, 14-10-2022, 16-11-2022, 21-11-2022, 17-12-2022, 13-1-2023, 18-1-2023, 16-2-2023, 15-3-2023, 17-4-2023, 7-6-2023, 31-7-2023, 11-8-2023, 19-8-2023, 20-9-2023, 18-10-2023, 4-11-2023, 2-12-2023\n",
      "male,Hinduism,Udalgiri,Assam,delayed developmental milestones,Nil,Nil,Nil,ASD,ADHD,Nil,Nil,Nil,Methylphenidate,2.5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,21-7-2022,16-2-2023, 18-5-2023, 5-10-2023\n",
      "female,Islam,Darrang,Assam,low social interaction,Nil,Nil,Nil,Acute and transient psychotic disorder,Nil,Nil,Nil,Nil,Olanzapine,5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,2023-02-16 00:00:00\n",
      "male,Islam,Nagaon,Assam,irrelevant talk,Nil,Nil,Nil,Acute and transient psychotic disorder,Nil,Nil,Nil,Nil,Olanzapine,10,Lorazepam,2,trihexyphenidyl,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,8-11-2021, 30-11-2021, 30-12-2021,29-1-2022, 1-3-2022, 31-3-2022, 5-5-2022, 11-6-2022, 5-7-2022, 4-8-2022, 5-9-2022, 10-10-2022, 10-11-2022, 5-12-2022, 14-1-2023, 16-2-2023, 27-3-2023,6-5-2023, 10-6-2025\n",
      "male,Islam,Nagaon,Assam,Unable to care for self,Nil,once,ADHD with conduct disorder, IDD, seizure disorder,Oppositional defiant disorder,ADHD,Nil,Nil,Nil,Sodium Valproate,400,Risperidone,1,Lorazepam,2,1,loss to follow-up,Melatonin,3,3,3,30,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,16-1-2023, 16-3-2023\n",
      "male,Islam,Nagaon,Assam,unconscious with abnormal body movement,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,200,clobazam,10,Phenobarbitone,30,1,Stopped,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,2-2-2021, 8-5-2021, 14-9-2021, 5-4-2021, -5-5-2021, 28-6-2022, 24-8-2022, 31-10-2022, 16-2-2023, 8-5-2023, 11-7-2023, 1-11-2023\n",
      "female,Islam,Nagaon,Assam,withdrawan to self,Nil,Nil,Nil,Behavioral abnormalities,Nil,Nil,Nil,Nil,Risperidone,1,Piracetam,400,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,14-3-2019, 23-12-2019, 5-5-2022, 25-6-2022, 29-8-2022, 31-10-2022, 15-12-202216-2-2023\n",
      "male,Hinduism,Sonitpur,Assam,Reduce social interaction,Nil,Once,Psychosis with OCD,Psychosis,OCD,Nil,Nil,Nil,Olanzapine,10,Fluoxetine,10,Lorazepam,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,5-4-2022, 5-5-2022, 2-6-2022, 1-7-2022, 15-7-2022, 26-7-2022, 4-8-2022, 11-8-2022, 18-8-2022, 25-8-2022, 6-9-2022, 13-10-2022, 10-11-2022, 24-12-2022, 16-2-2023, 5-5-2023, 28-7-2023, 18-10-2023\n",
      "male,Hinduism,Sonitpur,Assam,Dizziness,Nil,Nil,Nil,depressive disorder,dissociative disorder,Nil,Nil,Nil,Escitalopram,10,Clonazepam,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,17-1-2023, 16-2-2023, 3-3-2023, 3-4-2023, 19-5-2023, 24-6-2023, 29-7-2023, 7-9-2023\n",
      "female,Islam,Nagaon,Assam,Delay in developmental milestones,jerky movements of whole body,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,100,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,16.02.2023,27.03.2023,15.05.2023\n",
      "male,Islam,Nagaon,Assam,feeling of unreality,Nil,Nil,Nil,Mixed anxiety and depressive disorder,Nil,Nil,Nil,Nil,Fluoxetine,10,Clonazepam,0.25,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,16.02.2023,6.3.2023,22.3.2023,31.3.2023,28.4.2023,16.6.23,1.9.2023,24.10.2023\n",
      "male,Islam,Sonitpur,Assam,headache,Nil,Once,mixed anxiety and depression,Tension headache,anxiety,depression,Nil,Nil,Escitalopram,10,Clonazepam,0.25,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,28-12-2020, 13-4-2021, 25-7-2022, 16-2-2023\n",
      "male,Islam,Nagaon,Assam,decreased interest in studies,Nil,Once,Anxiety disorder,Anxiety disorder,Secondary Enuresis ,Nil,Nil,Nil,Fluoxetine,5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,16.2.2023,10.3.2023,17.4.2023,5.6.2023\n",
      "female,Islam,Sonitpur,Assam,low intelligence,Nil,Nil,Nil,ADHD,ODD,Nil,Nil,Nil,Clonidine,0.025,Risperidone,0.5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,15-9-2022, 17-11-2022, 20-12-2022, 16-2-2023, 18-4-2023, 27-7-2023\n",
      "male,Islam,Nagaon,Assam,tonic clonic movement of the body,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,400,clobazam,10,Ariprazole,5,1,Continued,Phenobarbitone,30,90,150,809,0.98,Lorazepam,2,2,2,100,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,20-5-2017, 21-6-2017, 25-8-2018, 1-9-2018, 12-9-2018, 22-10-2018, 23-11-2018, 31-12-2018, 16-2-2019, 22-3-2019, 3-7-2019, 3-8-2019, 11-9-2019, 15-10-2019, 15-11-2019, 23-12-2019, 31-1-2020, 22-2-2020, 9-3-2020, 23-4-2020, 15-6-2020, 18-8-2020, 17-10-2020, 3-12-2020, 28-12-2020, 25-1-2021, 25-2-2021, 7-4-2021, 19-6-2021, 4-8-2021, 6-9-2021, 13-10-2021, 17-11-2021, 30-12-2021, 19-2-2022, 24-3-2022, 21-4-2022, 26-5-2022, 2-6-2022, 9-8-2022, 22-9-2022, 17-11-2022, 7-1-2023, 16-2-2023, 21-3-2023, 29-4-2023, 26-8-2023, 7-10-2023, 4-12-2023\n",
      "male,Hinduism,Morigaon,Assam,Involuntary jerky movement of whole body,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,200,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,8-7-2022, 8-8-2022, 8-9-2022, 18-10-2022, 14-11-2022, 12-12-2022, 11-1-2023, 16-2-2023, 4-4-2023, 17-6-2023, 7-8-2023, 27-11-2023\n",
      "female,Hinduism,Sonitpur,Assam,Silly talking,Nil,No,Nil,depressive disorder,Nil,Nil ,Nil,Nil,Escitalopram,2.5,Melatonin,3,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,7-2-2023, 21-2-2023\n",
      "male,Hinduism,Sonitpur,Assam,increased anger outbursts,Nil,once,ADHD,Tic disorder,IDD,ADHD,Tic Disorder,Nil,Nil,Nil,Risperidone,1,Trihexyphenidyl,1,Methylphenidate,2.5,0.05,Continued,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Good,21.5.2022,1.6.2022,22.6.2022,21.7.2022,27.8.2022,30.7.2022,30.9.2022,1.11.2022,2.12.2022,6.1.2023,16.2.2023,23.3.2023,29.4.2023,10.6.2023,17.7.2023,28.8.2023,9.10.2023,27.11.2023\n",
      "male,Islam,Darrang,Assam,abnormal jerky movements of right upper and lower limbs,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Levetiracetam,100,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Purchased,Good,16.2.2023,16.3.2023,17.4.2023,15.5.2023\n",
      "male,Hinduism,Sonitpur,Assam,irrelevant talk,Nil,Nil,Nil,Acute and transient psychotic disorder,Nil,Nil,Nil,Nil,Olanzapine,10,Lorazepam,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,2023-02-16 00:00:00\n",
      "male,Islam,Sonitpur,Assam,demand money,Nil,twice,Mild intellectual developemental disorder with behavioral disturbances with seizure disorder with ADHD and ODD,ADHD,ODD,Nil,Nil,Nil,Risperidone,2,Sodium Valproate,500,Clobazam,5,30,Stopped,Clonidine,0.025,0.1,0.1,555,1,Methylphenidate,5,15,20,381,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Good,24-4-2017, 16-5-2017, 8-10-2018, 7-11-2018, 10-12-2018,12-1-2019, 28-3-2019, 30-4-2019, 30-5-2019, 1-7-2019, 5-8-2019, 7-9-2019, 7-10-2019, 11-11-2019,18-12-2019, 20-1-2020, 17-2-2020, 17-3-2020, 18-6-2020, 16-9-2020, 10-11-2020, 28-12-2020, 2-1-2021, 2-2-2021, 22-3-2021, 26-4-2021, 8-6-2022, 8-7-2022, 11-8-2022, 9-9-2022, 30-9-2022, 30-11-2022, 10-1-2023, 16-2-2023, 25-3-2023, 26-4-2023, 30-5-2023,1-7-2023, 5-8-2023, 7-9-2023, 25-10-2023\n",
      "female,Hinduism,Sonitpur,Assam,delayed speech,Nil,Once,ASD,GDD,ASD,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Good,16.2.2023,3.3.2023,13.6.2023\n",
      "male,Hinduism,Sonitpur,Assam,Not able to speak since childhood,Nil,twice,ODD and severe Intellectual developmental disorder,Nil,Nil,Nil,Nil,Nil,Risperidone,0.5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,29-12-2017, 11-1-2022, 12-1-2022, 16-2-2023, 18-2-2023\n",
      "male,Hinduism,Sonitpur,Assam,jerky movement ,Yes,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Carbamazepine,200,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,4-5-2022, 21-6-2022, 21-7-2022, 20-08-2022, 17-10-2022, 16-11-2022, 19-12-2022, 17-1-2-2023, 16-2-2023, 18-3-2023, 18-4-2023, 16-5-2023, 16-6-2023, 13-7-2023, 7-8-2023, 31-8-2023, 1-11-2023, 2-12-2023\n",
      "female,Hinduism,Sonitpur,Assam,Decreased sleep and appetite,Nil,Nil,Nil,Acute and transient psychotic disorder,Nil,Ni,Nil,Nil,Haloperidol,10,Promethazine,50,Risperidone,2,5,Continued,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,22-9-2022, 20-10-2022, 17-11-2022, 21-12-2022, 16-2-2023, 7-4-2023, 18-7-2023, 17-8-2023, 13-10-2023\n",
      "male,Islam,Sonitpur,Assam,complain from school,Nil ,Nil,Nil,ADHD,Nil,Nil,Nil,Nil,Atomoxetine,10,Risperidone,1,clonidine,0.05,5,loss to follow-up,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,11-1-2018, 8-2-2019, 10-3-2019, 6-4-2019, 4-5-2019, 13-7-2019, 11-2-2020, 2-5-2022, 30-8-2022, 29-92022, 16-2-2023, 20-4-2023\n",
      "male,Hinduism,Udalguri,Assam,Not able to speak,Nil,twice,ADHD, IDD with seizure disorder,ADHD ,Nil,Nil,Nil,Nil,Sodium Valproate,600,clobazam,10,Risperidone,0.5,0.025,Changed d/t non response,Methylphenidate,2.5,5,10,145,0.94,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,12-1-2023, 16-2-2023, 30-3-2023, 07-5-2023, 2-6-2023, 13-7-2023, 21-8-2023, 25-9-2023, 3-11-2023\n",
      "female,Hinduism,Sonitpur,Assam,decreased self care,Similar episode,Nil,Nil,Psychosis NOS,Nil,Nil,Nil,Nil,Olanzapine,10,Lorazepam,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,13-5-2022, 11-6-2022, 15-7-2022, 16-8-2022, 17-1-2023, 18-1-2023, 16-2-2023\n",
      "female,Islam,Nagaon,Assam,abnormal movements of all 4 limbs,Similar complaints,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium valproate,300,Clobazam,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,06-07-15, 02-09-15, 16-10-15, 25-12-15, 08-03-16, 13-06-16, 16-08-16, 24-09-16, 10-10-16, 2-11-16, 12-12-16, 18-01-17, 20-02-17, 24-03-17, 05-05-17, 06-06-17, 11-07-17, 14-08-17, 22-09-17, 22-11-17, 02-01-18, 02-02-18, 11-04-18, 31-05-18, 02-07-18, 06-08-18, 18-09-18, 22-10-18, 18-11-18, 01-01-19, 08-02-19, 18-03-19, 23-04-19, 23-05-19, 19-06-19, 29-07-19, 11-09-19, 31-10-19, 25-12-19, 13-02-2020, 04-03-20, 22-04-20, 16-06-20\n",
      "male,Hinduism,Sonitpur,Assam,Decrease sleep,Nil,Once,BPAD,BPAD in Mania,Nil,Nil,Nil, Nil,Fluoxetine,10,Olanzapine,10,Lithium,900,50,Stopped,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,27-11-2019, 24-1-2020, 3-3-2020, 22-4-2020, 16-6-2020, 29-7-2020, 3-11-2020, 17-11-2020, 29-12-2020, 10-2-2021, 16-3-2021, 31-3-2021, 30-3-2022, 27-5-2022, 8-7-2022, 22-8-2022, 27-9-2022, 11-11-2022, 14-12-2022, 18-1-2023, 28-2-2023, 18-4-2023, 20-7-2023, 26-9-2023, 6-12-2023\n",
      "female,Islam,Sonitpur,Assam,headache, dizziness,Nil,twice,Anxiety disorder,Anxiety disorder,exam phobia,Nil,Nil,Nil,Amitriptyline,25,Escitalopram,5,Propranolol,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,04-04-08, 12-05-18, 23-06-18, 28-07-18, 15-09-18, 12-03-2020, 22-04-2020, 07-06-2020 \n",
      "female,Islam,Nagaon,Assam,sudden jerky movemnts of body with loss of consciousness,Current condition,Once,Moderate IDD with seizure disorder,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,600,Clobazam,10`,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,28-1-2019, 2-3-2019, 9-4-2019, 29-5-2019, 2-9-2019, 30-9-2019, 27-11-2019, 24-12-2019, 31-1-2020, 4-2-2020, 22-4-2020, 9-6-2020, 8-10-2020, 27-11-2020, 28-12-2020, 29-1-2021, 27-2-2021, 30-3-2021,4-5-2021, 11-6-2021, 9-8-2021, 7-10-2021, 10-11-2021, 15-12-2021, 4-2-2022, 16-3-2022, 21-4-2022, 3-6-2022, 28-6-2022, 4-8-2022, 29-9-2022, 1-11-2022, 15-12-2022, 14-1-2023, 25-2-2023, 11-4-2023, 25-5-2023, 26-3-2023, 25-7-2023, 8-9-2023, 6-10-2023, 4-11-2023, 14-12-2023\n",
      "female,Hinduism,Sonitpur,Assam,generalized fits,similar complaints,once,IDD with epilepsy,Nil,Nil,Nil,Nil,Nil,Carbamazepine,200,Valproate,400,Clobazam,10,0.25,Continued,trihexyphenidyl,2,2,2,1035,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,17-04-10, 18-09-10, 27-10-10, 27-11-10, 12-09-17, 12-10-17, 27-10-17, 22-12-17, 25-01-18, 10-03-18, 24-04-18, 21-05-18, 04-07-18, 13-08-18, 12-09-18, 06-10-18, 14-11-18, 21-12-18, 28-01-19, 15-03-19, 24-04-19, 31-05-19, 09-07-19, 26-08-19, 15-10-19, 30-12-19, 02-03-20, 22-04-20, 25-05-20, 12-08-20, 08-10-20, 30-10-20, 09-01-21, 08-02-21, 08-03-21, 08-04-21, 05-05-21, 21-06-21, 28-09-21, 03-12-21, 27-01-22, 17-04-22, 09-05-22, 13-07-22, 13-09-22, 14-11-22, 27-01-23, 18-03-23, 29-06-23, 24-07-23, 02-09-23, 29-09-23, 14-11-23, 20-12-23\n",
      "male,Hinduism,Sonitpur,Assam,Poor understanding, Restlessness and inattention,Nil,Twice,ADHD,PTSD,ODD,Mild IDD,ADHD,PTSD,ODD,Nicotine use diorder,Nil,Risperidone,1,Fluoxetine,10,Clonidine,0.05,2.5,Stopped,Propranolol,10,10,10,5,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Poor,6-8-2011,14-8-2019,15-6-2020,18-1-2021,24-2-2021,1-3-2021,8-3-2021,30-4-2021,2-6-2021,3-6-2021,18-6-2021\n",
      "female,Hinduism,Udalguri,Assam,irrelevant talk,Nil,Once,BPAD,BPAD,Nil,Nil,Nil,Nil,Olanzapine,15,Aripiprazole,10,Lithium,280,4,Reduce due to side effects,trihexyphenidyl,2,2,2,1998,1,Lorazepam,2,2,2,210,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,16-5-2018, 15-6-2018, 16-7-2018, 16-8-2018, 15-09-2018, 15-11-2018, 5-3-2019, 3-4-2019, 2-5-2019, 27-5-2019, 27-6-2019, 27-7-2019,27-8-2019, 31-8-2019, 13-9-2019, 26-10-2019,30-11-2019, 27-12-2019, 27-1-2020, 29-2-2020, 22-4-2020, 16-12-2020, 3-5-2022, 19-5-2022, 17-6-2022, 16-7-2022, 9-8-2022, 3-9-2022, 3-10-2022, 2-11-2022, 6-12-2022, 4-1-2023, 9-2-2023, 9-3-2023, 3-4-2023, 24-4-2023, 5-6-2023, 4-7-2023, 7-8-2023, 6-9-2023, 5-10-2023, 4-11-2023, 4-12-2023\n",
      "male,Hinduism,Sonitpur,Assam,Does not respond to queries,Nil,Twice,ASD, ADHD, Moderate IDD, Seizure disorder,ASD,ADHD,Nil,Nil,Nil,Sodium Valproate,400,Risperidone,2,Clonidine,0.2,10,Continued,Aripiprazole,2,2,2,60,1,Amisulpiride,25,25,50,30,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Satisfactory,15-12-2007,12-1-2008,2-2-2008,11-12-2010,13-3-2013,13-4-2013,11-5-2013,12-6-2013,13-7-2013,14-8-2013,19-8-2013,14-9-2013,17-10-2013,16-11-2013,18-12-2013,18-1-2014,19-2-2014,23-4-2014,24-5-2014,28-6-2014,30-7-2014,30-8-2014,1-10-2014,29-10-2014,29-11-2014,31-12-2014,3-2-2015,7-3-2015,9-6-2015,11-7-2015,14-8-2015,29-9-2015,3-11-2015,5-12-2015,5-1-2016,8-1-2016,16-2-2016,21-3-2016,23-4-2016,31-5-2016,11-7-2016,9-8-2016,10-9-2016,22-10-2016,7-1-2017,14-3-2017,6-5-2017,7-7-2017,8-8-2017,12-9-2017,14-10-2017,7-2-2018,20-3-2018,2-5-2018,8-6-2018,20-7-2018,28-12-2018,8-1-2019,25-1-2019,15-3-2019,30-4-2019,7-6-2019,11-7-2019,13-8-2019,3-10-2019,7-11-2019,4-1-2020,24-3-2020,22-4-2020,11-7-2020,19-11-2020,28-8-2021,25-9-2021,26-10-2021,30-10-2021,3-11-2021,10-11-2021,27-11-2021,28-12-2021,28-1-2022,28-2-2022,28-3-2022,28-4-2022,28-5-2022,29-6-2022,28-7-2022,30-8-2022,30-9-2022,9-11-2022,14-12-2022,19-1-2023,20-2-2023,4-4-2023,3-5-2023,6-6-2023,6-7-2023,7-8-2023,7-9-2023,11-10-2023,20-11-2023,18-12-2023\n",
      "male,Islam,Sonitpur,Assam,Excessive use of mobile,Nil,Nil,Nil,Acute and transient psychotic disorder,Nil,Nil,Nil,Nil,Risperidone,2,Trihexyphenidyl,2,Lorazepam,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,17-7-2020,5-7-2021,16-8-2021,17-9-2021,6-11-2021,8-12-2021,2-2-2022,28-2-2022\n",
      "male,Hinduism,Sonitpur,Assam,Does not respond to query,Nil,Nil,Nil,ASD,ADHD,Nil,Nil,Nil,Sodium Valproate,400,Risperidone,2,Atomoxetine,18,0.05,Stopped,Levetiracetam,1000,1000,1000,28,1,Aripiprazole,2,2,2,120,Nil,Nil,Nil,1,Amisulpride,25,50,50,33,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,12-1-2008, 2-2-2010, 11-12-2010,13-3-2013, 13-4-2013, 11-5-2013, 12-6-2013, 13-7-2013, 14-8-2013, 19-8-2013, 14-9-2013, 17-10-2013, 14-9-2013, 17-10-2013, 16-11-2013,18-1-2014, 19-2-2014, 23-4, 2014, 24-5-2014, 23-6-2014, 30-7-2014, 30-8-2014, 1-10-2014, 29-10-2014, 29-11-2014, 31-12-2014, 3-1-2015,7-3-2015, 18-4-2015, 9-6-2015, 11-7-2015, 14-8-2015, 29-9-2015, 3-11-2015, 5-12-2015, 5-1-2016, 8-1-2016, 16-2-2016, 21-3-2016, 23-4-2016, 31-5-2016, 11-7-2016, 9-8-2016, 10-5-2016,22-10, 22-10-2016, 7-1-2017,14-3-2017, 6-5-2017, 7-7-2017, 8-8-2017, 12-9-2017, 14-10-2017, 7-2-2018, 7-2-2018, 20-3-2018, 2-5-2018, 8-6-2018, 20-7-2018, 28-12-2018, 8-1-2018, 25-1-2019, 15-3-2019, 30-4-2019, 30-4-2019, 7-6-2019, 11-7-2019, 13-8-2019, 3-10-2019, 7-11-2019, 4-1-2020, 24-3-2020, 22-4-2020, 11-7-2020, 19-11-2020, 19-11-2020, 8-3-2021, 28-8-2021, 25-9-201, 25-9-2021, 26-10-2021, 30-10-2021, 3-11-2021,10-11-2021,27-11-2021, 28-12-2021, 28-1-2022, 28-2-2022, 28-3-2022, 28-4-2022, 28-5-2022, 28-6-2022, 28-7-2022, 30-8-2022, 30-9-2022, 9-11-2022, 14-12-2022, 19-1-2023, 20-2-2022, 4-4-2023, 3-5-2023, 6-6-2023, 6-7-2023, 7-8-2023, 7-9-2023, 11-10-2023, 20-11-2023, 18-12-2023\n",
      "female,Islam,Sonitpur,Assam,altered consciousness,Nil,once,Seizure Disorder,Depressive Disorder,Hypothroidism,Depressive Disorder,Nil,Nil,Nil,Nil,carbamazepine,200,Clobazam,5,Escitalopram,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,7.10.2020,,6.11.2020,27.11.2020,11.1.2021,4.2.2021,3.3.2021,26.4.2021,18.5.2021,23.6.2021,6.7.2021,27.8.2021,20.9.2021,19.10.2021,13.11.2021,27.11.2021,11.12.2021,14.1.2022,18.2.2022,21.3.2022,5.5.2022,2.6.2022,5.7.2022,29.7.2022,8.9.2022,7.10.2022,5.11.2022,5.12.2022,10.1.2023,28.2.2023,18.3.2023,22.5.2023,4.7.2023,3.8.2023,9.9.2023,30.10.2023,25.11.2023\n",
      "male,Islam,Morigaon,Assam,Fearfulness,Nil,once,Psychosis NOS,Seizure disorder,Psychosis NOS,Nil,Nil,Nil,Nil,Risperidone,2,Olanzapine,10,Sodium Valproate,400,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,15.12.2021,12.3.2022,5.5.2022,1.8.2022,19.8.2022,30.12.2022,14.2.2023,21.3.2023,6.5.2023,19.7.2023,16.9.2023,3.11.2023,21.12.2023\n",
      "male,Islam,Nagaon,Assam,jerky movements with loss of awareness,Nil,once,IDD,Seizure Disorder,ADHD,ADHD,Nil,Nil,Nil,Nil,Carbamazepine,200,Clobazam,10,Clonidine,0.025,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Poor,17.1.2022,22.2.2022,4.4.2022,5.5.2022,24.6.2022,20.8.2022,3.11.2022,31.1.2023,3.5.2023,7.9.2023\n",
      "male,Islam,Sonitpur,Assam,excessiv ecrying ,Current medical conditions,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Phenytoin,30,Levetiracetam,100,Sodium Valproate,100,2.5,loss to follow-up,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Poor,1-4-2022, 4-5-2022, 5-5-2022, 23-5-2022, 26-9-2022, 9-12-2022, 16-12-2022, 23-12-2022, 11-7-2023\n",
      "male,Hinduism,Lakhimpur,Assam,disturbed sleep,Current condition,Nil,Nil,Psychosis NOS,Nil,Nil,Nil,Nil,Olanzapine,10,Fluoxetine,20,trihexyphenidyl,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,5-2-2022, 5-5-2022\n",
      "male,Islam,Darrang,Assam,fearfullness,Nil,Nil,Nil,Acute and transient psychotic disorder,Nil,Nil,Nil,Nil,Olanzapine,5,Trihexyphenidyl,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,12.1.2019,1.2.2019,21.12.2021,19.1.2022,12.2.2022,16.3.2022,5.5.2022\n",
      "female,Hinduism,Sonitpur,Assam,Involuntary jerky movement of whole body,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,400,clobazam,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,17.6.2109,23.7.2019,27.8.2019,24.9.2019,26.10.2019,25.11.2019,26.12.2019,27.1.2020,13.3.2020,23.4.2020,19.5.2020,19.6.2020,22.7.2020,25.7.2020,14.10.2020,17.12.2020,18.1.2021,16.2.2021,19.3.2021,20.4.2021,20.5.2021,1.11.2021,24.11.2021,28.1.2022,8.4.2022,5.5.2022,10.6.2022,13.7.2022,5.9.2022,7.10.2022,10.11.2022,14.12.2022,13.1.2023,13.2.2023,13.3.2023,21.4.2023,23.5.2023,27.6.2023,1.8.2023,31.8.2023,10.10.2023,17.11.2023\n",
      "female,Hinduism,Karbi Anglong,Assam,decreased social interaction,Nil,Nil,Nil,OCD,Depression,Nil,NIl,NIl,Sertraline,50,Clonazepam,0.25,Risperidone,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,Nil,Nil,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,4-4-2022, 5-5-2022, 4-6-2022, 5-7-2022, 4-8-2022, 5-9-2022, 10-10-2022, 15-11-2022, 18-2-2023, 17-3-2023, 17-7-2023, 28-8-2023, 5-10-2023, 1-11-2023, 16-12-2023\n",
      "male,Islam,Nagaon,Assam,Poor undersanding,Nil,once,Psychosis NOS with IDD,Pscyhosis NOS,Nil,Nil,Nil,Nil,Escitalopram,10,Risperidone,2,trihexyphenidyl,2,2,Stopped,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,15-11-2021, 18-1-2022, 23-7-2022, 30-8-2022, 16-11-2022, 16-2-2023, 3-5-2023, 31-10-2023, 29-12-2023\n",
      "male,Hinduism,Udalguri,Assam,decreased social interaction,Nil,Nil,Nil,Psychosis NOS,Nil,Nil,Nil,NIl,Olanzapine,10,Lorazepam,2,trihexyphenidyl,2,5,Stopped,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Poor,11-1-2022, 5-5-2022, 22-11-2022, 24-3-2023, 12-6-2023, 11-9-2023, 16-10-2023, 6-12-2023\n",
      "male,Islam,Nagaon ,Assam,fearfullness,Nil,Nil,Nil,Acute and transient psychotic disorder,Nil,Nil,Nil,Nil,Olanzapine,10,Lorazepam,2,Escitalopram,5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,2-8-2021, 7-10-2021, 8-11-2021, 13-12-2021, 17-1-2022, 3-2-2022, 25-2-2022, 31-3-2022, 5-5-2022, 11-6-2022, 14-7-2022, 17-8-2022, 16-9-2022, 19-10-2022, 19-11-2022, 21-12-2022, 23-1-2023, 23-2-2022, 24-3-2023, 24-4-2023, 24-5-2023, 27-6-2023, 26-7-2023, 26-8-2023, 30-9-2023, 27-10-2023, 30-11-2023\n",
      "male,Islam,Nagaon,Assam,difficulty in reading and writing,Nil,No,Nil,Nil,Nil,Nil,Nil,Nil,sodium Valproate,400,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,29-1-2021, 31-12-2021, 31-1-2022, 7-3-2022, 8-4-2022, 5-5-2022, 9-6-2022, 3-9-2022, 7-11-2022,9-12-2022, 14-2-2023, 24-4-2023, 11-7-2023\n",
      "female,Hinduism,Nagaon,Assam,irrelevant talk,Nil,Nil,Nil,Psychosis,Nil,Nil,Nil,NIl,Olanzapine,20,Fluoxetine,20,Lorazepam,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,26-5-2018, 2-6-2018, 2-7-2018, 31-7-2018, 31-8-2018, 28-9-2018, 29-10-2018, 26-11-2018, 24-12-2018, 23-1-2019, 25-2-2019, 23-3-2019, 26-4-2019, 6-6-2019, 21-8-2019, 18-11-2019, 4-1-2020, 28-1-2020, 23-2-2021, 20-3-2021, 13-4-2021, 10-9-2021, 23-10-2021, 25-11-2021, 2012-20-12-2021, 8-2-2022, 11-3-2022, 13-4-2022, 5-5-2022, 4-6-2022, 8-7-2022, -8-8-2022, 10-9-2022, 11-10-2022, 12-11-2022, 10-1-2023, 10-4-2023, 21-6-2023, 26-8-2023, 23-11-2023\n",
      "male,Islam,Nagaon,Assam,overtalkativeness,Nil,twice,OCD,OCD,BPAD,Nil,Nil,Nil,Olanzapine,10,Fluoxetine,60,Risperidone,1,Olanzapine,loss to follow-up,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,5-5-2022, 27-6-2022, 18-11-2022, 14-3-2023, 26-4-2023\n",
      "male,Hinduism,Sonitpur,Assam,delay developmental milestone,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Risperidone,0.5,Glycopyrolate,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Poor,5-5-2022, 4-7-2022\n",
      "female,Hinduism,Sonitpur,Assam,does not speak more than one word,Nil,once,ASD with DSL with Borderline IQ,ASD,Nil,Nil,Nil,DSL,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Poor,5-5-2022, 2-6-2022, 30-12-2022, 5-1-2023, 12-6-2023, 20-6-2023, \n",
      "female,Hinduism,Udalguri,Assam,sudden loss of consciousness,Nil,No,Nil,depressive disorder  ,dissociative disorder,Nil,Nil,Nil,Escitalopram,5,Olanzapine,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,8-9-2021, 12-11-2021, 5-5-2022, 9-8-2022, 7-10-2022, 13-12-2022, 24-3-2023, 26-6-2023, 12-10-2023\n",
      "male,Hinduism,Sonitpur,Assam,not speaking adequet for age ,Current condition,twice,ASD with IDD,ASD,ADHD,Nil,Nil,Nil,Melatonin,1.5,Methylphenidate,2.5,Nil,Risperidone,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Purchased,Poor,28-11-2020, 11-11-2021, 16-11-2021, 3-1-2022, 12-7-2022, 3-3-2023, 16-3-2023, 6-4-2023\n",
      "male,Hinduism,Sonitpur,Assam,blank stare after getting up suddenly from sleep,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Carbamazepine,100,Clobazam,5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,3.1.2022,31.1.2022,11.3.2022,26.4.2022,13.6.2022,25.7.2022,5.9.2022,28.10.2022,24.1.2023\n",
      "female,Hinduism,Sonitpur,Assam,smiling and muttering to self,Nil,Nil,Nil,Schizophrenia,Nil,Nil,Nil,Nil,Aripiprazole,5,Olanzapine,5,Trifluperazine,5,2,Continued,Lorazepam,2,2,2,30,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,28.12.20, 8.1.21, 20.2.21, 20.3.21, 20.4.21, 2.9.21, 1.11.21, 3.1.22, 2.3.22, 2.5.22, 31.5.22, 28.6.22, 28.7.22, 26.8.22, 22.9.22, 21.10.22, 21.12.22, 23.1.23, 18.2.23, 24.3.23, 21.4.23, 23.5.23, 22.6.23, 22.7.23, 21.8.23, 22.9.23, 21.10.23, 21.11.23, 21.12.23, 19.1.24\n",
      "female,Islam,Sonitpur,Assam,episodes of abnormal body movements,Current condition,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,200,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,04.01.21, 13-03-21, 11-09-21, 25-10-21, 03-01-22, 21-04-22, 23-06-22, 22-08-22, 24-10-22, 09-12-22, 16-01-23, 31-03-23, 17-05-23, 03-07-23, 21-08-23, 13-10-23, 28-11-23\n",
      "male,Islam,Nagaon,Assam,abnormal jerky movement of body with tightening of right side of body,Nil,Nil,Nil,ODD,Nil,Nil,Nil,Nil,Sodium Valproate,200,Risperidone,0.5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,30-12-2020, 30-1-2021, 2-3-2021,2-4-2021, 3-5-2021, 3-6-2021, 3-7-2021, 3-8-2021, 3-9-2021, 3-11-2021, 3-1-2022, 1-4-2022, 11-6-2022, 6-12-2022, 9-2-2023, 29-5-2023, 19-9-2023, 16-1-2024 \n",
      "female,Islam,Sonitpur,Assam,abnormal jerky movement of body with loss of consciousness,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Carbamazepine,200,clobazam,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,20-5-2020, 23-6-2020, 29-7-2020, 9-9-2020, 10-10-2020, 12-11-2020, 30-11-2020, 12-1-2021, 17-2-2021, 26-3-2021, 19-4-2021, 1-6-2021, 29-6-2021, 27-7-2021, 16-8-2021, 4-10-2021, 1-112021, 3-1-2022, 15-2-2022, 18-3-2022, 18-4-2022, 19-5-2022, 27-6-2022, 12-9-2022, 22-10-2022, 31-1-2023, 4-4-2023, 30-6-2023\n",
      "male,Hinduism,Sonitpur,Assam,hoarding of inner garments,Nil,Nil,Nil,Paraphilia,Social Anxiety,SLD,Nil,Nil,Fluoxetine,5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,17.12.2021,3.1.2022\n",
      "male,Hinduism,Sonitpur,Assam,rigidity of all four limbs while sleeping,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,600,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,3.1.2022,5.3.2022\n",
      "male,Islam,lakhimpur,Assam,irrelevant talking,Nil,Nil,Nil,ATPD,Nil,Nil,Nil,Nil,Olanzapine,20,Trihexphenidyl,2,Haloperidol,5,2,loss to follow-up,sodium Valproate,400,600,600,30,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,27-3-2019, 29-4-2019, 28-6-2019, 31-7-2019, 5-9-2019, 4-10-2019, 9-11-2019, 21-12-2019,29-2-2020,  10-8-2020, 3-1-2022\n",
      "male,Hinduism,Nagaon,Assam,wandresome behaviour,Nil,once,bipolar disorder-mania, Nicotine dependence, cannabis use, subclinical hypothyroidism, conduct features,Bipolar disorder-current episode mania,nicotinde dependence syndrome,cannabis abuse,conduct features,SLD,Olanzapine,10,Lithium,600,Sodium Valproate,600,4,Reduced d/t resolution,Lorazepam,2,2,2,44,1,Clonazepam,0.5,0.25,0.5,135,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,25.06.21, 26.06.21, 20.7.21, 24.09.21, 14.10.21, 6.11.21, 6.12.21, 3.1.22, 4.3.22, 2.5.22, 6.6.22, 1.7.22, 25.7.22, 10.9.22, 10.10.22, 8.11.22, 2.12.22, 5.1.23, 21.2.23, 30.3.23, 3.5.23, 1.6.23, 7.7.23, 2.8.23, 4.9.23, 9.10.23, 6.11.23, 11.12.23, 10.1.24\n",
      "female,Islam,Nagaon,Assam,Self muttering and self laughing,Nil,Nil,Nil,Acute and transient psychotic disorder,NIl,Nil,NIl,Nil,Olanzapine,10,Lorazeoam,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,1,Free,Poor,2022-01-03 00:00:00\n",
      "male,Hinduism,Morigaon,Assam,unable to speak properly,Nil,Nil,Nil,ASD,ADHD,Nil,Nil,Nil,Risperidone,0.25,Clonidine,0.025,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Poor,25.3.2021,11.6.2021,3.8.2021,20.9.2021,3.1.2022,3.3.2022,10.3.2022,11.12.2023\n",
      "female,Islam,Sonitpur,Assam,poor academic performance ,Nil,Nil,Nil,CD,ADHD,Nil,Nil,Nil,Clonidine,0.025,Ariprazole,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Poor,28-10-2021, 3-1-2022, 18-5-2022, 20-6-2022, 25-8-2022\n",
      "female,Islam,Nagaon,Assam,clenching of fist,Nil,once,ATPD,ATPD,Nil,Nil,Nil,Nil,Escitalopram,10,Olanzapine,7.5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,3-1-2022, 17-1-2022, 21-1-2022\n",
      "female,Hinduism,Sonitpur,Assam,delayed language development and required assistance in daily activities,Current condition,multiple,ASD, ADHD in remission, separation anxiety, ?OCD, IDD,ASD,?OCD,ADHD in remission,Separation anxiety,Delayed speech and language,Sertraline,25,Ariprazole,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Good,26-10-20, 20-11-20, 21-12-20, 07-01-21, 22-1-21, 29-1-21, 08-02-21, 11-02-21, 22-02-21, 24-09-21, 03-01-22, 10-01-22, 22-07-22, 25-09-23\n",
      "male,Islam,Sonitpur,Assam,involuntary jerky movements of both upper and lower limbs,Current condition,once,Borderline IQ, seizure disorder,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,400,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,8-8-17, 5-9-17, 5-10-17, 30-10-17, 29-11-17, 28-12-17, 1-2-18, 13-2-18, 19-3-18, 17-4-18, 15-5-18, 9-6-18, 10-7-18, 06-8-18, 5-9-18, 28-9-18, 29-10-18, 30-11-18, 27-12-18, 2-2-19, 5-4-19, 3-5-19, 27-5-19, 18-6-19, 15-7-19, 17-8-19, 07-9-19, 3-10-19, 6-11-19, 6-12-19, 4-1-2020, 4-2-20, 7-3-20, 3-7-20, 28-8-20, 27-11-20, 5-2-21, 9-4-21, 3-8-21, 22-10-21, 3-1-22, 6-5-22, 30-7-22, 21-10-22, 27-1-23, 18-4-23, 25-10-23, 2-2-24\n",
      "male,Hinduism,Udalguri,Assam,decreased academic perforamnce,Nil,twice,ADHD, ODD Nicotine used disorder with mild IDD,ADHD,ODD,Nicotine use disorder,Nil,Nil,Olanzapine,10,Fluoxetine,20,Lithium,300,10,Continued,Risperidone,0.5.,0.5,0.5,775,1,Nicotine gum,8,8,10,60,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Good,17-5-2021, 18-6-2021, 13-9-2021, 28-9-2021, 11-10-2021, 5-11-2021, 3-1-2022, 1-2-2022, 28-2-2022, 29-4-2022, 30-5-2022, 1-7-2022, 1-8-2022, 30-8-2022, 30-9-2022, 1-11-2022, 2-12-2022, 3-1-2023, 6-2-2023, 21-3-2023, 2-5-2023, 11-8-2023, 22-9-2023, 1-11-2023, 9-1-2024\n",
      "female,Hinduism,Sonitpur,Assam,Dizziness,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,400,clobazam,5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,21-8-2020, 20-10-2020, 20-11-2020, 19-12-2020, 25-1-2021, 23-2-2021, 23-3-2021, 20-4-2021, 20-5-2021, 19-6-2021, 23-7-2021, 24-8-2021, 5-10-2021, 23-11-2021, 23-12-2021, 24-1-2022, 24-2-2022, 10-5-2022, 7-7-2022, 8-8-2022, 7-9-2022, 11-10-2022, 22-11-2022, 3-1-2023, 6-2-2023, 22-3-2023, 1-5-2023, 30-5-2023, 5-7-2023, 7-8-2023, 12-9-2023, 30-5-20235-7-2023, 27-10-2023, 27-11-2023\n",
      "female,Hinduism,Sonitpur,Assam,involuntary jerky movements of head and legs,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Carbamazepine,100,clobazam,5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,3-1-2022, 25-5-2022\n",
      "male,Hinduism,Sonitpur,Assam,hyperactivity and restlessness,Nil,once,ADHD with severe IDD,ADHD,Nil,Nil,Nil,Nil,Risperidone,1,Clonidineq,0.025,Melatonin,3,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Good,2012-2021, 3-1-2022, 22-6-2022,31-8-2022, 21-3-2023, 21-4-2023, 22-5-2023, 22-6-2023,20-7-2023, 28-1-2023, 21-9-2023, 21-11-2023 16-1-2024\n",
      "male,Islam,Nagaon,Assam,Self absorbed behavior,Nil,No,Nil,Psychosis NOS,Nil,Nil,Nil,Nil,Risperidone,2,Trihexyphenidyle,2,Lorazepam,2,10,loss to follow-up,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,1-11-2021, 1-12-2021, 3-1-2022, 31-1-2022, 8-3-2022, 9-4-2022, 8-8-2022, 10-9-2022, 7-10-2022, 8-11-2022, 10-12-2022, 11-1-2023, 8-2-2023, 9-3-2023, 8-4-2023, 13-5-2023, 3-6-2023, 18-7-2023, 22-8-2023\n",
      "male,Islam,Kamrup (M),Assam,Making unusual sounds and abnormal movements of limbs and eyes,Obsessive Compulsive disorder,multiple,ADHD with Tourette syndrome with OCD with Specific phobia,ADHD,Tourette syndrome,OCD,Specific phobia,Nil,Clonidine,0.05,Lithium carbonate,600,Risperidone,4,50,Continued,Atomoxetine,10,10,18,585,1,Trihexyphenidyl,2,2,2,744,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Satisfactory,13-07-2021,13-08-2021,14-09-2021,19-10-2021,22-10-2021,26-10-2021,03-01-2022,15-02-2022,17-02-2022,25-03-2022,31-03-2022,30-05-2022,22-07-2022,23-07-2022,25-07-2022,26-07-2022,17-10-2022,26-12-2022,10-02-2023,15-05-2023,27-06-2023\n",
      "male,Islam,Nagaon,Assam,sudden jerky movement of body,No,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Carbamazepine,200,Sodium valproate,400,Clobazam,5,0.5,Continued,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,3-1-2022, 3-2-2022, 3-3-2022, 13-4-2022, 15-9-2023, 6-11-2023\n",
      "male,Hinduism,Nagaon,Assam,headache,Current condition,Nil,Nil,Tension headache,Nil,Nil,Nil,Nil,Escitalopram,5,Nil,NIL,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,2022-01-03 00:00:00\n",
      "male,Hinduism,Udalguri,Assam,hearing of voices not heard by other,Nil,once,Psychosis NOS,Psychosis NOS,Nil,Nil,Nil,Nil,Olanzapine,10,Lorazeoam,2,Trihexyphenidyl,2,10,Continued,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Poor,19-7-2021, 21-9-2021, 3-1-2022, 16-7-2022,11-8-2022, 7-09-2022, 8-10-2022, 6-12-2022, 7-1-2023, 13-4-2023.11-5-2023, 11-7-2023, 10-8-2023-14-12-2023, 11-1-2024, 9-2-2024\n",
      "male,Islam,Nagaon,Assam,involuntary jerky movements of hands and legs,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,400,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,19.1.2022,16.2.2022,6.5.2022,23.6.2022,26.7.2022,15.9.2022,14.11.2022,31.12.2022,2.2.2023,4.3.2023,3.5.2023,29.5.2023\n",
      "female,Islam,Nagaon,Assam,jerky movements of bilateral upper and lower limbs,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,200,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,16.11.2021,3.1.2022\n",
      "male,Hinduism,Sonitpur,Assam,repeated complain from school,Nil,No,No,ADHD,ODD,Nil,Nil,SLD,Methylphenidate,2.5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,Nil,Nil,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,Nil,Nil,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,Nil,Nil,Nil,Nil,Nil,NIl,Free,Poor,2023-01-03 00:00:00\n",
      "male,Islam,Nagaon,Assam,abnormal jerky movements of body,Nil,once,Seizure disorder with IDD,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,400,clobazam,5,Levetiracetam,500,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,9-6-2018, 13-7-2018, 11-8-2018, 11-9-2018, 4-10-2018, 5-11-2018, 6-12-2018, 10-6-2019, 10-7-2019, 7-8-2019, 21-8-2019, 1-10-2019, 26-10-2019, 4-12-2019, 6-1-2020, 1-2-2020, 13-3-2020, 12-6-2020, 4-8-2020, 7-9-2020, 4-11-2020, 25-12-2020, 11-2-2021, 17-3-2021, 22-4-2021, 17-8-2021, 21-9-2021, 25-10-2021, 3-1-2022, 17-3-2022, 14-4-2022, 12-5-2022, 27-7-2022, 5-9-2022, 1-10-2022, 27-1-2023, 24-2-2023, 25-3-2023, 17-4-2023, 15-7-2023, 26-10-2023\n",
      "male,Hinduism,Demaji,Assam,irritability,Yes,Nil,Nil,CD,Cannabis use disorder,Nicotine use disorder,Nil,Nil,Fluoxetine,20,Risperidone,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,2022-01-03 00:00:00\n",
      "male,Hinduism,Sonitpur,Assam,doesn't go to school regularly,Nil,twice,Severe depression with psychotic symptom and anxiety disorder,Severe depression with psychotic symptom ,anxiety disorder,Nil,Nil,Nil,Aripiprazole,5,Fluoxetine,20,Lithium,600,10,Continued,trihexyphenidyl,2,2,3,28,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,14-12-2018, 16-1-2019, 2-3-2019, 30-3-2019, 27-4-2019, 1-5-2019, 14-6-2019, 22-7-2019, 10-8-2019, 23-8-2019, 28-7-2020, 5-3-2021, 31-3-2021, 27-4-2021, 5-6-2021, 29-6-2021,6-7-2021, 12-7-2021,25-8-2021, 13-9-2021, 4-10-2021, 1-11-2021, 3-12-2021,3-1-2022,26-2-2022,28-3-2022, 29-4-2022, 28-5-2022, 9-6-2022, 10-6-2022, 8-7-2022, 19-8-2022, 27-9-2022, 27-10-2022, 25-11-2022, 26-12-2022, 3-2-2023, 27-2-2023, 10-4-2023, 12-5-2023, 26-6-2022, 4-8-2023, 8-9-2023, 9-10-2023, 6-11-2023, 11-12-2023, 8-1-2024\n",
      "female,Hinduism,Sonitpur,Assam,Episodesof generalized abnormal jerky movement ,Seizure disorder,once,Seizure Disorder,IDD,Nil,Nil,Nil,Nil,Nil,sodium Valproate,200,clobazam,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,16-10-2019, 15-11-2019, 15-12-2019, 13-1-2020, 11-2-2020, 13-3-2020, 15-5-1010, 17-4-2020, 15-6-2020, 13-8-2020, 22-9-2020, 27-11-2020, 4-1-2021, 28-1-2021, 24-2-2021, 24-3-2021, 30-4-2021, 29-5-2021, 19-6-2021,2-8-2021, 2-9-2021, 4-10-2021, 3-11-2021, 6-12-2021, 3-1-2022 , 2-2-2022, 5-3-2022, 4-4-2022, 7-5-2022, 4-6-2022, 9-7-2022, 16-8-2022, 14-9-2022, 16-10-2022, 25-11-2022, 30-12-2022, 28-1-2023, 11-3-2023, 18-4-2023, 23-5-2023, 21-6-2023, 21-7-2023, 29-8-2023, 28-9-2023, 27-10-2023, 28-11-2023, 29-12-2023\n",
      "male,Christianity,East kameng,Arunachal Prasdesh,loss of consciousness ,Seizure disorder,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Phenytoin,100,clobazam,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,3-11-2022, 3-1-2023, 2-3-2023, 25-4-2023\n",
      "male,Hinduism,Nagaon,Assam,poor comprehension,Nil,Nil,Nil,ADHD,ODD,Nil,Nil,Nil,Clonidine,0.025,Risperidone,0.25,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Satisfactory,26-7-2022, 26-8-2022, 27-9-2022, 18-4-2023, 4-5-2023\n",
      "female,Hinduism,Morigaon,Assam,reduced level of intellectual functioning,Nil,once,ADHD,ADHD,Nil,Nil,Nil,Nil,Clonidine,0.025,Risperidone,0.5,Methylphenidate,2.5,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Satisfactory,1-7-2022, 1-8-2022, 26-8-2022, 1-10-2022, 1-11-2022, 9-1-2023, 14-2-2023\n",
      "female,Islam,Nalbari,Assam,tightening of hands and leg,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,400,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,26-8-2022, 24-9-2022, 1-11-2022\n",
      "male,Islam,Udalguri,Assam,jerky movements of body with frothing, tongue bite,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Carbamazepine,200,Clobazam,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,22-12-21, 24-1-22, 25-02-22, 26-03-22, 25-05-22, 25-06-22, 27-07-22, 26-08-22\n",
      "female,Islam,Udalguri,Assam,Episodes of jerky movements of body with loss of consciousness,Current condition,No,Nil,Nil,Nil,Nil,Nil,Nil,Sodium Valproate,300,clobazam,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,27-7-15, 30-9-15, 5-11-15, 10-12-15, 12-1-16, 11-2-16, 18-5-16, 11-11-16, 21-12-16, 25-1-17, 27-2-17, 3-4-17, 9-5-17, 21-6-17, 3-8-17, 18-9-17, 29-11-17, 3-1-18, 9-2-18, 27-3-18, 26-4-18, 8-6-18, 24-7-18, 12-9-18, 24-10-18, 10-12-18, 25-1-19, 26-3-19, 6-6-19, 26-7-19, 3-9-19, 24-10-19, 18-11-19, 30-12-19, 4-2-20, 5-2-20, 6-5-20, 2-6-20, 25-8-20, 29-10-20, 19-12-20, 21-1-21, 23-3-21, 30-6-21, 19-10-21, 28-12-21, 31-3-22, 5-7-22, 26-8-22, 26-9-22, 3-11-22, 1-12-22, 2-1-23, 7-2-23, 16-3-23, 25-4-23, 5-6-23, 31-7-23, 10-10-23, 2-12-23, 27-1-24\n",
      "male,Hinduism,Udalguri,Assam,Poor comprehension,Nil,thrice,Moderate IDD with behavioural abnormalities, ADHD,ADHD,Nil,Nil,Nil,Nil,clobazam,2.5,Olanzapine,5,Sodium Valproate,200,2,Continued,Atomoxetine,20,37.5,37.5,2133,0.97,Trihexyphenidyl,2,2,2,1817,Nil,Nil,Nil,0.96,Zolpidem,5,5,5,983,Nil,Nil,Nil,0.93,Melatonin,3,3,3,30,Stopped,Good,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Good,9-10-15, 12-11-15, 11-1-15, 9-1-16, 6-2-16, 7-3-16, 9-4-16, 30-4-16, 14-5-16, 22-6-16, 26-7-16, 20-8-16, 6-10-16, 7-11-16, 9-12-16, 23-1-17, 20-2-17, 30-3-17, 28-4-17, 10-6-17, 4-7-17, 1-8-17, 30-8-17, 4-10-17, 27-11-17, 26-12-17, 1-2-18, 7-3-18, 11-4-18, 22-5-18, 25-6-18, 9-8-18, 13-9-18, 13-10-18, 8-11-18, 19-12-18, 17-1-19, 15-2-19, 16-2-19, 20-4-19, 22-5-19, 26-6-19, 29-7-19, 27-8-19, 5-10-19, 5-11-19, 17-12-19, 14-1-20, 19-2-20, 20-3-20, 8-5-20, 5-6-20, 26-9-20, 20-10-20, 24-11-20, 24-12-20, 1-2-21, 8-3-21, 16-4-21, 23-6-21, 20-7-21, 25-8-21, 18-9-21, 26-10-21, 25-11-21, 21-12-21, 20-1-22, 15-2-22, 15-3-22, 22-4-22, 23-5-22, 19-7-22, 26-8-22, 28-9-22, 6-12-22, 24-1-23, 16-3-23, 24-4-23, 7-6-23, 27-7-23, 11-9-23, 31-10-23, 8-1-24\n",
      "female,Islam,Darrang,Assam,delayed developmental milestones,Nil,once,ADHD, conduct disorder, IDD. Limb length descrepancy, Cerebal palsy,ADHD,conduct disorder,Nil,Nil,Nil,Clonidine,0.05,Methylphenidate,5,Risperidone,0.5,2,loss to follow-up,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Good,26-02-21, 06-04-21, 01-10-21, 26-08-22, 14-10-22\n",
      "female,Islam,Nagaon,Assam,irrelevant talk,Nil,Nil,Nil,Schizophrenia,Nil,Nil,Nil,Nil,Risperidone,2,Trihexyphidyl,2,Lithium,300,0.5,loss to follow-up,Lorazepam,2,2,2,388,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,30-9-14, 07-11-14, 2-12-14, 6-1-15, 5-2-15, 7-3-15, 7-4-15, 9-5-15, 8-6-15, 8-7-15, 6-8-15, 4-9-15, 5-10-15, 2-11-15, 17-12-15, 16-1-16, 13-2-16, 14-3-16, 14-4-6, 12-5-16, 11-6-16, 12-7-16, 11-8-16, 10-9-16, 27-9-16, 24-10-16, 24-11-16, 22-12-16, 21-1-17, 21-2-17, 23-3-17, 22-4-17, 22-5-17, 24-6-17, 27-7-17, 26-8-17, 25-9-17, 25-10-17, 23-11-17, 23-12-17, 23-1-18, 20-2-18, 26-3-18, 24-4-18, 24-5-18, 6-6-18, 5-7-18, 4-8-18, 18-9-18, 16-10-18, 15-11-18, 17-12-18, 15-1-19, 16-2-19, 18-3-19, 16-4-19, 16-5-19, 15-6-19, 16-7-19, 14-8-19, 12-9-19, 14-10-19, 12-11-19, 16-12-19, 15-1-20, 15-2-20, 16-3-20, 24-4-20, 18-6-20, 21-7-20, 28-8-20, 28-9-20, 20-11-20, 21-12-20, 4-9-21, 11-10-21, 1-11-21, 3-12-21, 10-1-22, 11-2-22, 11-3-22, 15-4-22, 15-5-22, 18-6-22, 20-7-22, 26-8-22, 13-10-22\n",
      "female,Hinduism,Mandira,Assam,irritability,Depressive disorder,Nil,Nil,Bipolar disorder-current episode mania,Nil,Nil,Nil,Nil,Lithium,600,Ariprazole,10,olanzapine ,10,2,Reduced d/t resolution,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Good,16-5-20, 16-6-20, 9-1-21, 26-8-22, 12-6-23, 24-7-23, 23-8-23\n",
      "male,Hinduism,Udalguri,Assam,irrelevant talk,Nil,once,IDD with ?seizure disorder,Nil,Nil,Nil,Nil,Nil,risperidone,1,Trihexyphenidyl,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Satisfactory,31-05-22, 28-06-22, 26-08-22, 30-09-22, 04-11-22, 09-12-22\n",
      "female,Christianity,Papum Pare,Arunachal Prasdesh,pervasive low mood, irritability,Current condition,once,depressive disorder,depressive disorder,Nil,Nil,Nil,Nil,Escitalopram,5,Olanzapine,2.5,Lithium,300,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,30-06-22, 04-07-22, 29-07-22, 05-08-22, 19-08-22, 26-08-22, 11-10-22, 13-10-22, 11-11-22, 07-02-23, 24-03-23, 23-06-23, 14-07-23, 28-07-23, 15-09-23\n",
      "female,Islam,Golaghat,Assam,Fearfullness,Nil,Nil,Nil,ATPD,Nil,Nil,Nil,Nil,Olanzapine,10,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,26-8-2022, 24-9-2022, 26-10-2022, 18-11-2022, 21-7-2023, 18-8-2023\n",
      "male,Hinduism,Sonitpur,Assam,poor social interaction,Treated at NIMHANS for current issue,once,ADHD,ASD,BPAD,IDD,Early paternal loss,ASD,ADHD,BPAD,Nil,Nil,Sodium Valproate,1000,Olanzapine,20,trihexyphenidyl,2,2,Stopped,Clonidine,0.075,0.2,0.2,1491,1,Aripiprazole,10,20,20,1067,Nil,Nil,Nil,1,Lithium,300,1200,1200,1046,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Satisfactory,7-6-2019,21-6-2019,22-7-2019,22-8-2019,11-11-2019,9-12-2019,6-1-2020,3-2-2020-27-6-2020,5-3-2021,12-3-2021,20-4-2021,11-5-2021,9-8-2021,22-10-2021,14-2-2022,6-5-2022,26-8-2022,31-10-2022,23-1-2023,7-4-2023,30-6-2023,29-9-2023,1-12-2023,5-2-2024\n",
      "female,Hinduism,Sonitpur,Assam,low mood,Nil,once,Depressive disorder with Dissociative disorder,Depressive disorder,Dissociative disorder,Nil,Nil,Nil,Escitalopram,10,Sertraline,100,Aripiprazole,5,300,Continued,Clobazam,10,5,10,293,1,Clonazepam,0.5,0.5,0.5,47,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Good,7-8-2022, 17-8-2022, 26-8-2022, 21-9-2022, 11-11-2022, 18-11-2022, 25-11-2022, 2-12-2022, 9-12-2022, 10-1-2023, 13-1-2023, 19-1-2023, 31-1-2023, 7-2-2023, 24-2-2023, 1-4-2023, 28-4-2023, 30-5-2023, 4-7-2023, 29-7-2023, 31-8-2023, 28-9-2023, 30-10-2023, 25-11-2023, 21-12-2023, 29-1-2024\n",
      "male,Hinduism,Sonitpur,Assam,delayed developmental milestones,Current condition,No,Nil,ADHD,Nil,Nil,Nil,Nil,Methylphenidate,2.5,Sodium valproate,300,Risperidone,0.5,3,Continued,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Good,28-03-22, 13-07-22, 26-08-22, 11-10-22, 15-05-23, 31-07-23, 07-09-23, 03-10-23, 01-11-23, 04-12-23\n",
      "male,Islam,morigaon,Assam,suspiciousness towards parents and neighbours,Nil,once,psychosis NOS,Psychosis NOS,Nil,Nil,Nil,Nil,Risperidone,2,Trihexiphenidyl,2,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,08-06-22, 26-08-22, 19-12-22, 23-01-23, 02-11-23\n",
      "male,Islam,Dhubri,Assam,Irrelevent Talking,Nil,Nil,Nil,BPAD in Mania with psycotic symptoms,Nil,Nil,Nil,Nil,Olanzapine,10,Lorazepam,2,Lithium,450,2,loss to follow-up,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Free,Poor,28-08-2021, 15-07-2022, 17-08-2022\n",
      "male,Islam,Nagaon,Assam,No Memory of events, Cant recognize people ,NIL,NIL,NIL,Depressive Disorder,Nil,Nil,Nil,Nil,Clonazepam,1,Setraline,100,Melatonin,3,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Satisfactory,29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020, 03-12-2020, 04-01-2021, 19-01-2021, 02-02-2021, 10-03-2021, 12-04-2021, 28-08-2021, 22-10-2021, 24-11-2021, 07-02-2022, 17-02-2022, 25-02-2022, 07-03-2022, 04-04-2022, 21-06-2022, 24-08-2022, 24-09-2022, 16-11-2022\n",
      "male,Hinduism,Nagaon,Assam,unable to speak ,Current condition,Once,ADHD, IDD with seizure disorder,ADHD,Nil,Nil,Nil,Nil,Sodium Valproate,300,Olanzapine,2.5,Atomoxetine,5,2.5,Stopped,Clonidine,0.025,0.75,0.75,502,1,Clobazam,5,5,5,60,Nil,Nil,Nil,1,Trihexyphenidyl,1,2,2,959,Nil,Nil,Nil,1,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Nil,Both Free and Purchased,Satisfactory,16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020, 19-06-2020, 17-07-2020, 21-08-2020, 19-11-2020, 19-12-2020, 18-02-2021, 27-02-2021, 28-08-2021, 29-10-2021, 28-12-2021, 21-03-2022, 25-05-2022, 02-07-2022, 13-08-2022, 13-09-2022, 12-10-2022, 12-11-2022, 13-12-2022, 12-01-2023, 08-02-2023, 05-08-2023\n"
     ]
    }
   ],
   "source": [
    "for i in df2['combine']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "43340113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2['combine'] = df2['combine'].str.replace('Nil', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b557f77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female,Islam,Udalguri,Assam,episodes of unresponsiveness ,,,,,,,,,sodium valproate,300,clobazam,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019, 17-12-2019, 18-01-2020, 02-03-2020, 02-05-2020,22-06-2020, 28-08-2020, 17-11-2020, 21-01-2021\n",
      "female,Islam,Nagaon,Assam,Episodes of abnormal jerky movement of body,,,,,,,,,carbamazepine,500,clobazam,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020\n",
      "male,Islam,Nagaon,Assam,episode of abnormal jerky movement with LOC,Seizure disorder,,,,,,,,carbamazepine,200,phenobarbitone,60,clobazam,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Good,31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014, 25-08-2014, 01-02-2016, 30-03-2016, 29-04-2016, 03-06-2016, 28-08-2016, 08-08-2016, 08-09-2016, 05-10-2016, 09-11-2016, 16-12-2016, 23-01-2017, 22-02-2017, 10-03-2017, 21-04-2017, 25-05-2017, 22-06-2017, 20-07-2017, 03-10-2017, 02-11-2017, 06-01-2018, 05-02-2018, 08-03-2018, 07-04-2018, 05-05-2018, 07-06-2018, 09-08-2018, 12-09-2018, 09-10-2018, 12-11-2018, 19-12-2018, 17-01-2019, 13-06-2019, 13-07-2019, 17-08-2019, 17-08-2019, 20-10-2019, 30-11-2019, 03-01-2020, 06-03-2020, 22-06-2020, 02-04-2021, 10-05-2021, 06-08-2021, 07-09-2021, 13-11-2021, 17-01-2022, 19-03-2022, 30-05-2022, 04-07-2022, 09-08-2022, 13-09-2022, 27-10-2022, 28-11-2022, 10-01-2023, 13-02-2023, 22-03-2023, 26-04-2023, 05-06-2023, 17-07-2023, 24-08-2023, 25-09-2023, 06-11-2023\n",
      "male,Hinduism,Sonitpur,Assam,inattention,nil,,,ADHD,,,,motor coordination disorder,clonidine,0.05,,,nil,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Purchased,Good,22-06-2020,30-09-2020\n",
      "female,Islam,Nagaon,Assam,epileptic fits,,,,,,,,,sodium valproate,400,clobazam,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,29-04-2014, 29-05-2014, 04-07-2014, 25-08-14, 01-03-16, 30-03-16, 29-04-16, 03-06-16, 28-06-16, 08-08-16, 08-09-16, 05-10-16, 09-11-16, 16-12-16, 23-01-17, 22-02-17, 10-03-17, 21-04-17, 25-05-17, 22-06-17, 20-07-17, 02-11-17, 06-01-18, 05-02-18, 08-03-18, 07-04-18, 05-05-18, 07-06-18, 27-06-18, 09-08-18, 12-09-18, 09-10-18, 12-11-18, 19-12-18, 17-01-19, 20-02-19, 30-03-19, 02-05-19, 13-06-19, 13-07-19, 17-08-19, 17-09-19, 22-10-19, 30-11-19, 03-01-2020, 28-01-2020, 06-03-2020, 22-06-2020, 02-04-21, 10-05-21, 06-08-21, 07-09-21, 13-11-21, 17-01-22, 19-03-22, 30-05-22, 04-07-22, 09-08-22, 13-09-22, 27-10-22, 28-11-22, 10-1-23, 13-02-23, 23-03-23, 26-04-23, 05-06-23, 17-07-23, 24-08-23, 25-09-23, 06-11-23\n",
      "female,Islam,Sonitpur,Assam,abnormal jerky movements with fall,,once,seizure disorder,,,,,,sodium valproate,500,clobazam,10,Carbamazepine,200,1 tbsp,Reduced d/t resolution,risperidone,0.5,0.5,0.5,540,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,10-06-15, 22-06-15, 15-07-15, 29-07-15, 26-05-15, 23-09-15, 21-10-15, 11-11-15, 21-12-15, 25-1-16, 16-3-16, 18-5-16, 20-07-16, 7-9-16, 26-10-16, 28-12-16, 27-1-17, 22-2-17, 17-3-17, 14-4-17, 12-5-17, 26-6-17, 13-9-17, 11-10-17, 15-11-17, 15-12-17, 7-2-18, 2-4-18, 9-5-18, 31-5-18, 27-6-18, 4-8-18, 24-9-18, 5-11-18, 14-12-18, 15-1-19, 12-2-19, 12-4-19, 25-5-19, 16-7-19, 20-8-19, 21-9-19, 21-10-19, 18-11-19, 20-12-19, 25-1-2020, 24-2-2020, 20-03-20, 19-05-20, 22-06-20, 28-07-20, 20-10-20, 0-11-20, 22-12-20, 19-1-21, 19-2-21, 19-03-21, 12-04-21, 08-05-21, 19-07-21, 13-08-21, 11-10-21, 16-11-21, 17-12-21, 11-01-22, 15-03-21, 12-04-22, 13-06-22, 16-07-22, 16-08-22, 14-11-22, 24-01-23, 28-02-23, 1-04-23, 29-05-23, 4-07-23, 18-08-23, 26-09-23, 07-11-23\n",
      "male,Hinduism,Sonitpur,Assam,abnormal movement of body with deviation of face to opposite side,Seizure disorder,,,,,,,,carbamazepine,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,8-6-2016, 18-7-2016, 19-8-2016, 14-9-16, 4-10-2016,9-11-2016, 9-1-2017, 10-2-2017, 11-3-2017, 10-4-2017, 11-5-2017, 10-6-2017, 8-7-2017, 5-8-2017, 4-9-2017, 14-10-2017, 4-12-2017, 2-1-2018,2-2-2018, 3-3-2018, 4-4-2018, 2-5-2018, 2-6-2018, 2-7-2018, 31-7-2018, 30-8-2018, 28-9-2018, 29-19-2018, 28-11-2018, 27-12-2018, 25-1-2019, 26-2-2019, 26-3-2019, 24-4-2019, 27-5-2019, 27-6-2019, 27-8-2019, 25-9-2019, 25-10-2019, 25-11-2019, 24-12-2019, 21-1-2020, 22-2-2020, 23-3-2020, 21-4-2020, 22-5-2020, 22-6-2020, 9-1-2021, 3-3-2021, 12-4-2021, 14-6-2021, 8-8-2021,14-9-2021, 16-10-2021, 16-11-2021, 3-1-2022,4-2-2022, 5-3-2022, 5-4-2022, 20-5-2022, 6-7-2022, 3-8-2022, 2-9-2022, 30-9-2022, 2-11-2022, 8-12-2022, 28-12-2023, 4-2-2023, 4-3-2023, 4-5-2023, 27-5-2023, 4-7-2023, 1-8-2023, 2-9-2023, 3-10-2023, 1-11-2023\n",
      "male,Hinduism,Sonitpur,Assam,Delayed speech,,NIL,NIL,At risk ADHD,At risk SLD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Good,2020-06-22 00:00:00\n",
      "female,Hinduism,Darrang,Assam,Abnormal jerky movements,,once,depressive disorder, seizure disorder,Depressive disorder due to another medical condition,,,,,sodium valproate,400,Fluoxetine,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Poor,27-12-2019, 17-3-2020, 22-06-2020, 14-12-2020, 22-01-2021, 6-11-2023\n",
      "male,Hinduism,Karbianglong,Assam,Delayed speech,,,,ADHD,vocal tics,,,,clonidine,0.05,Risperidone ,0.5,Melatonin,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Poor,27-02-2020, 22-06-2020\n",
      "female,Islam,Darrang,Assam,Abnormal jerky movements,NIL,NIL,NIL,NIL,NIL,NIL,NIL,NIL,Sodium Valproate,300,nil,nil,nil,nil,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,14-02-2020,22-06-2022\n",
      "female,Hinduism,Sonitpur,Assam,Episodes of loss of consciousness,treated for afebrile seizures,NIL,NIL,NIL,NIL,NIL,NIL,NIL,Sodium Valproate,200,nil,nil,nil,nil,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,08-03-2018,13-06-2019,28-06-2019,22-06-2022,26-11-2020,11-08-2022,06-07-2023\n",
      "female,Hinduism,Sonitpur,Assam,persistent low mood,,,,Depressive disorder due to another medical condition,,,,,escitalopram,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,22.06.2020\n",
      "female,Islam,Sonitpur,Assam,anger outburst,,once,seizure disorder,,,,,,Olanzapine,5,sodum valproate,300,clobazam,5,300,stopped,Levetiracetam,750,1000,1000,90,1,Carbamazepine,400,600,600,30,Skin rashes,12,7,1,Risperidone,1,4,4,1620,,,,0.99,Lorazepam,2,2,2,120,Continued,Good,,,,1,Chlorpromazine,50,50,50,210,Stopped,Good,,,,1,Melatonin,3,3,3,60,Continued,Good,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Satisfactory,15-10-12, 9-1-13, 4-2-13, 7-3-13, 5-4-13, 6-5-13, 5-6-13, 4-7-13, 3-8-13, 2-9-13, 3-10-13, 2-11-13, 21-11-13, 11-3-15, 3-4-15, 22-4-15, 14-5-15, 5-6-15, 13-7-15, 19-8-15, 22-9-15, 21-10-15, 20-11-15, 21-12,15, 19-1-16, 18-2-16, 3-3-16, 2-4-19, 6-5-16, 7-3-17, 13-4-17, 17-5-17, 19-6-17, 20-7-17, 16-8-17, 13-9-17, 14-10-17, 28-10-17, 28-11-17, 30-12-17, 31-1-18, 5-3-18, 4-4-18, 12-4-18, 2-5-18, 28-5-18, 2-7-18, 31-7-18,30-08-18, 29-10-18, 28-11-18, 29-12-18, 29-01-19, 28-2-19, 29-3-19, 27-4-19, 27-5-19, 26-6-19, 25-7-19, 26-8-19, 25-9-19, 26-10-19, 22-11-19, 25-12-19, 20-1-20, 22-2-20, 21-4-20, 22-05-20, 22-6-20, 16-11-20, 11-01-21, 21-03-21, 12-06-23, 30-07-23, 04-08-23, 18-08-23, 19-09-23, 18-10-23\n",
      "male,hinduism,Sonitpur,Assam,episodes of loss of consciousness,,,,,,,,,Divalproaex sodium,250,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,07.03.2019, 24.01.2020, 04.02.2020, 03.03.2020, 14.05.2020, 22.06.2020, 28.09.2020, 20.02.2021, 17.05.2021, 19.8.2021, 06.07.2022, 14.08.2023\n",
      "female,Islam,Nagaon,Assam,jerks of hands and legs,Seizure disorder,once,mania with psychotic symptoms, moderate to severe IDD,Mania with psychotic symptoms,Nicotine dependence,,,,Sodium valproate,600,Olanzapine,20,lithium,900,2,Reduced d/t resolution,Lorazepam,2,2,4,1050,0.54,Clonazepam,0.5,0.5,0.5,60,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,30-08-18, 03-10-18, 17-11-18, 20-12-18, 31-01-19, 15-03-19, 1-05-19, 29-06-19, 25-09-19, 21-10-19, 05-12-19, 24-01-2020, 22-06-2020, 06-10-2020, 23-11-2020, 09-03-21, 11-05-21, 28-07-21, 04-10-21, 26-11-21, 29-01-22, 10-03-22, 20-04-22, 26-05-22, 18-07-22, 07-09-22, 10-10-22, 23-11-22, 04-1-23, 02-03-23, 20-04-23, 09-06-23, 04-08-23, 23-09-23, 04-11-23\n",
      "male,Islam,Nagaon,Assam,anger outburst,,,,acute and transient psychotic disorder,,,,,Olanzapine,10,Lorazepam,2,Chlorpromazine,100,5,Stopped,promethazine,25,25,25,1,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,18-02-2020, 21-03-2020, 09-05-2020, 22-06-2020, 03-09-2020\n",
      "male,Islam,Sonitpur,Assam,overactivity,,once,ASD, at risk ADHD with mild IDD,ASD,at risk ADHD,,,,clonidine,0.025,Methylphenidate,2.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Purchased,Satisfactory,22-06-2020, 31-08-2020, 14-09-2020, 28-10-2020, 20-11-2020, 12-03-2020, 19-03-2021\n",
      "male,Hinduism,Sonitpur,Assam,jerky movement of limbs,,,,,,,,,sodium valproate,200,Clonazepam,0.25,Escitalopram,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,08-12-2020, 16-10-2021, 10-11-2021, 13-12-2021, 17-01-2022, 16-07-2021, 16-08-2021, 13-9-2021, 14-5-2022, 15-6-2022, 15-7-2022, 16-2-2022, 15-3-2022, 18-4-2022, 12-10-2022, 11-11-2022, 13-12-2022, 9-1-2023, 12-8-2022, 12-9-2022, 10-4-2023, 8-5-2023, 10-6-2023, 8-7-2023, 11-2-2023, 4-3-2023, 5-8-2023, 29-8-2023, 7-10-2023, 4-11-2023\n",
      "female,Islam,Sonitpur,Assam,episodes of LOC,seizure disorder,twice,Mild IDD with seizure disorder,,,,,,sodium valproate,100,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,03-07-17, 11-09-17, 19-03-18, 04-05-18, 20-06-18, 03-08-18, 18-09-18, 09-10-18, 28-11-18, 07-02-19, 13-04-19, 23-05-19, 09-07-19, 15-11-19, 04-10-19, 15-11-19, 17-12-19, 23-01-2020, 04-03-2020, 22-04-2020, 22-06-2020, 26-09-2020, 19-11-2020, 29-12-2020, 04-02-21, 06-03-21, 12-04-21, 29-05-21, 09-07-21, 27-08-21, 06-10-21, 17-11-21, 23-12-21, 12-1-22, 05-02-22, 19-02-22, 22-03-22, 02-05-22, 13-06-22, 16-07-22, 23-08-22, 16-08-22, 26-09-22, 05-10-22, 28-10-22, 08-11-22, 07-02-23, 05-04-23, 29-05-23, 04-07-23, 18-07-23, 15-09-23, \n",
      "female,Islam,Sonitpur,Assam,generalised weakness,treated for seizures ,,,Specific learning disorder,,,,,Sodium Valproate,400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,28-11-2018,03-05-2019,06-06-2019,23-07-2019,14-09-2019,12-10-2019,16-11-2019,21-12-2019,31-01-2020,02-03-2020,22-06-2020,24-03-2021,24-04-2021,06-08-2022,27-08-2022,24-09-2022,05-11-2022,19-11-2022,24-12-2022,28-01-2023,06-03-2023,12-04-2023,12-04-2023,15-06-2023,26-07-2023,04-09-2023,16-09-2023,13-10-2023\n",
      "male,Islam,Nagaon,Assam,involuntary movements of hands and feet,,,,ADHD,,,,,Sodium Valproate,200,clobazam,10,Risperidone,0.5,1,Continued,Clonidine,0.05,0.15,0.15,1004,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,05-06-2014,27-06-2014,30-07-2014,02-09-2014,08-10-2014,14-11-2017,30-12-2014,27-02-2015,03-04-2015,09-05-2015,25-06-2015,31-07-2015,01-10-2015,09-11-2015,01-01-2016,12-02-2016,18-03-2016,19-04-2016,07-05-2016,04-06-2016,11-07-2016,05-08-2016,03-09-2016,13-10-2016,09-11-2016,07-12-2016,02-01-2017,01-02-2017,03-03-2017,31-03-2017,10-05-2017,03-06-2017,04-07-2017,08-09-2017,29-06-2018,09-08-2018,18-09-2018,20-10-2018,23-11-2018,30-11-2018,09-02-2019,02-04-2019,27-05-2019,18-06-2019,19-06-2019,26-07-2019,09-09-2019,10-10-2019,16-11-2019,26-11-2019,24-12-2019,04-02-2020,19-03-2020,18-05-2020,22-06-2020,15-10-2020,16-11-2020,17-12-2020,16-01-2021,25-02-2021,19-05-2021,31-07-2021,13-11-2021,20-12-2021,10-01-2022,09-03-2022,12-04-2022,20-06-2022,25-08-2022,09-11-2022,15-02-2023,03-05-2023,04-07-2023,24-08-2023\n",
      "male,Hinduism,Sonitpur,Assam,irritability,,,,ADHD,Tics, transvestism with fetishism,,,Risperidone,1,Trihexiphenidyl,1,Carbamazepine,200,10,Continued,Fluoxetine,10,20,40,1299,0.99,Aripiprazole,2.5,10,10,1299,,,,0.99,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Satisfactory,23-11-2015,28-12-2015,15-02-2016,11-04-2016,25-05-2016,24-06-2016,06-07-2016,03-08-2016,08-09-2016,13-10-2016,10-11-2016,12-12-2016,18-01-2017,02-03-2017,10-04-2017,03-05-2017,29-05-2017,05-06-2017,03-07-2017,02-08-2017,04-09-2017,06-11-2017,04-12-2017,05-01-2018,14-02-2018,02-04-2018,01-06-2018,02-06-2018,04-07-2018,02-08-2018,06-09-2018,09-10-2018,07-11-2018,10-01-2019,11-02-2019,18-03-2019,26-04-2019,28-05-2019,18-06-2019,28-08-2019,04-10-2019,08-11-2019,11-12-2019,16-01-2020,15-02-2020,29-02-2020,22-04-2020,05-05-2020,22-06-2020,21-07-2020,29-08-2020,21-10-2020,15-11-2020,22-12-2020,22-01-2021,06-03-2021,02-04-2021,08-05-2021,25-01-2022,23-08-2022,19-12-2022,24-07-2023,05-10-2023\n",
      "male,Islam,Dhubri,Assam,aggressiveness,aggression,multiple,bipolar disorder NOS, OCD, polysubstance use,Bipolar disorder NOS,OCD,Polysubstance use,,,oxcarbazepine,450,Fluoxetine,20,Naltrexone,50,20,Changed d/t non response,Pregabalin,75,300,300,750,1,Escitalopram,10,20,20,540,switch to mania,77.1,30,1,Olanzapine,10,10,20,810,weight gain,115.7,139,1,Lurasidone,20,40,80,90,Stopped,Partial,,,,1,Lithium,600,600,600,240,Stopped,,,,,1,Risperidone,4,6,8,720,Continued,Partial,,,,Clomipramine,75,150,150,600,Continued,Good,,,,1,Trihexyphenidyl,2,2,2,600,Continued,,,,1,Clonazepam,0.5,0.5,0.5,510,Continued,Good,,,,1,Melatonin,5,5,5,360,Stopped,Good,Sedation,,,1,Both Free and Purchased,Good,13-06-2018,18-08-2018,23-08-2018,19-09-2018,24-10-2018,20-02-2019,13-03-2019,06-04-2019,25-05-2019,31-07-2019,13-09-2019,08-10-2019,17-12-2019,07-01-2020,13-03-2020,11-05-2020,22-06-2020,11-09-2020,23-01-2021,24-03-2021,14-04-2021,12-06-2021,14-06-2021,20-08-2021,10-09-2021,28-09-2021,16-11-2021,01-12-2021,03-12-2021,17-12-2021,31-12-2021,18-02-2022,22-02-2022,11-03-2022,25-03-2022,23-04-2022,01-07-2022,13-08-2022,31-12-2022,12-05-2023,09-06-2023,27-07-2023\n",
      "male,Hinduism,Sonitpur,Assam,decreased interest in studies and poor academic performance,,,,Moderate depressive disorder without somatic symptoms,,,,,Escitalpram,10,Clonazepam,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,17-03-2020, 15-06-2020, 22-06-2020, 24-06-2020, 01-07-2020, 03-08-2020, 24-08-2020, \n",
      "male,Islam,Barpeta,Assam,Excessive talking with tall talks,Current condition,,,Mania with psychotic symptoms,,,,,Olanzpine,20,Lithium carbonate,900,Chlorpromazine,200,4,Changed d/t non response,Zuclopenthixol acetate,100,100,100,2,1,Clonazepam,0.5,0.5,0.5,7,,,,1,Trihexyphenidyl,2,2,2,446,,,,0.26,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,04-01-2020,06-02-2020,11-03-2020,22-06-2020,27-08-2020,30-10-2020,07-01-2021,24-02-2021,02-02-2022\n",
      "male,Islam,Sonitpur,Assam,decrease talk,,,,Acute and transient psychotic disorder,,,,,Olanzapine,15,Chlorpromazine,50,Amitryptiline,25,2,Stopped,Fluoxetine,20,20,40,1366,0.99,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,21-11-2016, 21-12-2016, 21-1-2017, 28-2-2017, 31-3-2017, 2-5-2017, 1-6-2017, 5-7-2017, 12-8-2017, 8-9-2017, 18-10-2017, 21-11-2017, 28-12-2017, 31-1-2018, 21-3-2018, 23-4-2018, 31-5-2018,6-6-2018, 3-7-2018, 25-9-2018, 5-11-2018, 18-12-2018, 29-1-2019, 6-3-2019, 3-4-2019, 19-4-2019, 25-5-2019, 29-6-2019, 9-8-2019, 24-9-2019, 29-10-2019, 1-12-2019, 6-1-2020,14-2-2020, 12-6-2020, 30-10-2020, 11-12-2020, 18-1-2021,19-3-2021, 13-4-2021, 3-8-2021, 6-11-2021, 11-12-2021, 4-2-2022, 14-6-2022, 20-7-2022, 24-8-2022, 12-11-2022, 4-1-2023,18-5-2023, 21-6-2023-11-10-2023 \n",
      "male,Hinduism,Karbi Anglong,Assam,school refusal,,Once,IDD,ADHD,OCD,ODD,ADHD,OCD,ODD,,,Sodium Valproate,375,Clonidine,0.05,Risperidone,1,20,Continued,Melatonin,3,3,3,81,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Satisfactory,23.09.2017,23.10.2017,24.11.2017,05.10.2018,22.09.2021,28.10.2021,13.01.2022\n",
      "male,Islam,Darrang,Assam,delayed developmental milestones,,,,,,,,,Risperidone,0.5,Clonidine,0.25,trihexyphenidyl,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Good,19.07.2017,15.09.2017,13.11.2017,13.06.2019,18.07.2019,21.11.2019,31.12.2019,11.03.2020,23.10.2020,05.04.2021,28.10.2021,11.10.2022,23.06.2023,26.07.2023,28.08.2023,10.10.2023,17.11.2023\n",
      "male,Hinduism,Nagaon,Assam,Episodes ofinvoluntary jerky movements of the body,Current condition,,,,,,,,Carbamazepine,300,Sodium valproate,200,Clobazam,5,60,Changed d/t non response,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Satisfactory,21-11-2014,17-12-2014,15-01-2015,14-02-2015,24-03-2015,13-04-2015,04-05-2015,04-06-2015,23-07-2015,06-08-2015,07-09-2015,03-10-2015,03-11-2015,07-12-2015,24-01-2016,30-01-2016,04-03-2016,05-04-2016,07-05-2016,06-06-2016,30-06-2016,30-07-2016,05-09-2016,23-09-2016,24-10-2016,07-12-2016,30-01-2017,07-03-2017,20-04-2017,17-07-2019,21-09-2019,21-09-2019,19-10-2019,22-11-2019,23-12-2019,22-01-2020,19-02-2020,13-03-2020,23-04-2020,16-06-2020,01-08-2020,02-09-2020,27-11-2020,25-12-2020,04-02-2021,25-02-2021,01-04-2021,22-04-2021,08-05-2021,11-06-2021,19-07-2021,17-08-2021,25-09-2021,28-10-2021,03-12-2021,-4-01-2022,03-02-2022,10-03-2022,14-04-2022,06-05-2022,08-06-2022,09-07-2022,17-08-2022,23-09-2022,02-11-2022,09-12-2022,30-12-2022,15-02,2023,13-03-2023,1-04-2023,04-05-2023,18-05-2023\n",
      "female,Islam,Sonitpur,Assam,Poor self care activity and forgetful after learning,,,,ADHD,conduct disorder,,,,clonidine,0.05,Aripiprazole,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,28-10-21, 03-01-22, 18-05-22, 20-06-22, 25-08-22\n",
      "female,Islam,Nagaon,Assam,Self crying,,,,Psychosis NOS,,,,,Risperidone,2,Sodium valproate,200,trihexyphenidyl,2,10,Stopped,Lithium,600,600,600,60,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,21.04.2016,16.05.2016,23.05.2017,24.07.2017,19.02.2018,26.03.2018,30.11.2018,12.01.2019,02.01.2019,20.02.2020,15.06.2020,11.02.2021,07.10.2021,28.10.2021,03.12.2021,30.12.2021,17.02.2022,24.03.2022,12.05.2022,29.08.2022,06.10.2022,03.05.2023,16.11.2023,27.11.2023\n",
      "male,Hinduism,Udalguri,Assam,abnormal jerky movements with loss of conciousness,,,,Seizure disorder,,,,,Phenytoin,200,Sodium valproate,500,Risperidone,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,25-3-2019, 22-4-2019, 21-5-2019, 28-6-2019, 9-8-2019, 9-9-2019, 11-10-2019, 5-11-2019, 4-12-2019, 6-1-2019, 10-2-2020, 6-7-2020, 24-11-2020, 12-1-2021, 26-4-2021, 30-7-2021, 28-9-2021, 28-10-2021, 28-12-2021, 25-2-2022, 25-4-2022, 25-5-2022, 27-6-2022, 27-7-2022, 26-8-2022, 2-11-2022, 2-1-2023, 27-2-2023, 17-4-2023, 29-5-2023, 27-6-2023, 27-9-2023, 25-10-2023,27-11-2023\n",
      "male,Hinduism,Lakhimpur,Assam,sudden jerky movemnts of body,Current illness,,,depressive disorder,Dissociation,SLD in maths,,,Escitalopram,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,28-08-21, 28-10-21, 27-12-21, 27-1-22, 25-04-22, 27-06-22, 26-08-22, 26-10-22, 18-11-22, 10-04-23, 19-10-23\n",
      "male,Islam,Sonitpur,Assam,abnormal jerky movements,current illness,,,Depressive disorder,history of ADHD,history of conduct disorder,,,sodium Valproate,400,clobazam,10,Escitalopram,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,28-10-21, 29-11-21, 05-01-22, 05-09-22, 09-03-22, 09-04-22\n",
      "female,Islam,Nagaon,Assam,does not obey commands, verbally abusive,,once,ADHD with conduct disorder, IDD, seizure disorder,ADHD,conduct disorder,,,,Atomoxetine,10,sodium Valproate,400,clonidine,0.05,2,loss to follow-up,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Good,30-09-21, 28-10-21, 13-12-21, 29-01-21\n",
      "male,Islam,Nagaon,Assam,irrelevant talk,,No,,Acute and transient psychotic disorder,,,,,Olanzapine,10,Lorazepam,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,30-9-2021, 28-10-2021, 6-2-2023\n",
      "male,Islam,Nagaon,Assam,abnormal jerky movements,,,,Dissociative disorder,Psychosis NOS,,,,Aripiprazole,5,Escitalopram,5,Fluoxetine,20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Poor,8.9.21,20.9.2021,28.10.2021,17.2.2022,4.9.2023,12.9.2023\n",
      "male,Hinduism,Darrang,Assam,intake of cannabis once,,,,Acute and Transient Psychotic disorder,,,,,Olanzapine,10,Trihexyphenidyl,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,05-07-21, 03-09-21, 28-10-21, 02-12-21, 31-01-22, 31-03-22, 31-05-22, 28-06-22, 29-12-22, 13-02-23, 02-06-23, 25-07-23\n",
      "male,Hinduism,Baksa,Assam,tall claim,,,,Cannabis induced psychosis,,,,,Olanzapine,10,Lorazepam,2,trihexyphenidyl,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,3-5-2021, 12-7-2021, 28-10-2021, 24-1-2022, 5-5-2022, 21-7-2022\n",
      "male,Islam,Nagaon,Assam,Tightening of body,,,,,,,,,Sodium Valproate,300,Clobazam,5,,,,,,,,,,,,,,,,,Ni,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,12-12-2022, 26-12-2022,16-1-2023, 16-2-2023\n",
      "male,Hinduism,Darrang,Assam,fearfulness,,Once,Psychosis Nos with Anxiety disorder,Psychosis NOS,Anxiety disorder,,,,amisulpride,400,Clonazepam,0.5,olanzapine ,10,4,Stopped,Aripiprazole,20,25,25,124,1,Fluoxetine,10,10,10,28,,,,1,Melatonin,3,3,3,28,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,18-7-2022, 27-7-202217-8-2022, 15-9-2022, 6-10-2022, 14-10-2022, 16-11-2022, 21-11-2022, 17-12-2022, 13-1-2023, 18-1-2023, 16-2-2023, 15-3-2023, 17-4-2023, 7-6-2023, 31-7-2023, 11-8-2023, 19-8-2023, 20-9-2023, 18-10-2023, 4-11-2023, 2-12-2023\n",
      "male,Hinduism,Udalgiri,Assam,delayed developmental milestones,,,,ASD,ADHD,,,,Methylphenidate,2.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,21-7-2022,16-2-2023, 18-5-2023, 5-10-2023\n",
      "female,Islam,Darrang,Assam,low social interaction,,,,Acute and transient psychotic disorder,,,,,Olanzapine,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,2023-02-16 00:00:00\n",
      "male,Islam,Nagaon,Assam,irrelevant talk,,,,Acute and transient psychotic disorder,,,,,Olanzapine,10,Lorazepam,2,trihexyphenidyl,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,8-11-2021, 30-11-2021, 30-12-2021,29-1-2022, 1-3-2022, 31-3-2022, 5-5-2022, 11-6-2022, 5-7-2022, 4-8-2022, 5-9-2022, 10-10-2022, 10-11-2022, 5-12-2022, 14-1-2023, 16-2-2023, 27-3-2023,6-5-2023, 10-6-2025\n",
      "male,Islam,Nagaon,Assam,Unable to care for self,,once,ADHD with conduct disorder, IDD, seizure disorder,Oppositional defiant disorder,ADHD,,,,Sodium Valproate,400,Risperidone,1,Lorazepam,2,1,loss to follow-up,Melatonin,3,3,3,30,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,16-1-2023, 16-3-2023\n",
      "male,Islam,Nagaon,Assam,unconscious with abnormal body movement,,,,,,,,,Sodium Valproate,200,clobazam,10,Phenobarbitone,30,1,Stopped,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,2-2-2021, 8-5-2021, 14-9-2021, 5-4-2021, -5-5-2021, 28-6-2022, 24-8-2022, 31-10-2022, 16-2-2023, 8-5-2023, 11-7-2023, 1-11-2023\n",
      "female,Islam,Nagaon,Assam,withdrawan to self,,,,Behavioral abnormalities,,,,,Risperidone,1,Piracetam,400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,14-3-2019, 23-12-2019, 5-5-2022, 25-6-2022, 29-8-2022, 31-10-2022, 15-12-202216-2-2023\n",
      "male,Hinduism,Sonitpur,Assam,Reduce social interaction,,Once,Psychosis with OCD,Psychosis,OCD,,,,Olanzapine,10,Fluoxetine,10,Lorazepam,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,5-4-2022, 5-5-2022, 2-6-2022, 1-7-2022, 15-7-2022, 26-7-2022, 4-8-2022, 11-8-2022, 18-8-2022, 25-8-2022, 6-9-2022, 13-10-2022, 10-11-2022, 24-12-2022, 16-2-2023, 5-5-2023, 28-7-2023, 18-10-2023\n",
      "male,Hinduism,Sonitpur,Assam,Dizziness,,,,depressive disorder,dissociative disorder,,,,Escitalopram,10,Clonazepam,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,17-1-2023, 16-2-2023, 3-3-2023, 3-4-2023, 19-5-2023, 24-6-2023, 29-7-2023, 7-9-2023\n",
      "female,Islam,Nagaon,Assam,Delay in developmental milestones,jerky movements of whole body,,,,,,,,Sodium Valproate,100,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,16.02.2023,27.03.2023,15.05.2023\n",
      "male,Islam,Nagaon,Assam,feeling of unreality,,,,Mixed anxiety and depressive disorder,,,,,Fluoxetine,10,Clonazepam,0.25,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,16.02.2023,6.3.2023,22.3.2023,31.3.2023,28.4.2023,16.6.23,1.9.2023,24.10.2023\n",
      "male,Islam,Sonitpur,Assam,headache,,Once,mixed anxiety and depression,Tension headache,anxiety,depression,,,Escitalopram,10,Clonazepam,0.25,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,28-12-2020, 13-4-2021, 25-7-2022, 16-2-2023\n",
      "male,Islam,Nagaon,Assam,decreased interest in studies,,Once,Anxiety disorder,Anxiety disorder,Secondary Enuresis ,,,,Fluoxetine,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,16.2.2023,10.3.2023,17.4.2023,5.6.2023\n",
      "female,Islam,Sonitpur,Assam,low intelligence,,,,ADHD,ODD,,,,Clonidine,0.025,Risperidone,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,15-9-2022, 17-11-2022, 20-12-2022, 16-2-2023, 18-4-2023, 27-7-2023\n",
      "male,Islam,Nagaon,Assam,tonic clonic movement of the body,,,,,,,,,Sodium Valproate,400,clobazam,10,Ariprazole,5,1,Continued,Phenobarbitone,30,90,150,809,0.98,Lorazepam,2,2,2,100,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,20-5-2017, 21-6-2017, 25-8-2018, 1-9-2018, 12-9-2018, 22-10-2018, 23-11-2018, 31-12-2018, 16-2-2019, 22-3-2019, 3-7-2019, 3-8-2019, 11-9-2019, 15-10-2019, 15-11-2019, 23-12-2019, 31-1-2020, 22-2-2020, 9-3-2020, 23-4-2020, 15-6-2020, 18-8-2020, 17-10-2020, 3-12-2020, 28-12-2020, 25-1-2021, 25-2-2021, 7-4-2021, 19-6-2021, 4-8-2021, 6-9-2021, 13-10-2021, 17-11-2021, 30-12-2021, 19-2-2022, 24-3-2022, 21-4-2022, 26-5-2022, 2-6-2022, 9-8-2022, 22-9-2022, 17-11-2022, 7-1-2023, 16-2-2023, 21-3-2023, 29-4-2023, 26-8-2023, 7-10-2023, 4-12-2023\n",
      "male,Hinduism,Morigaon,Assam,Involuntary jerky movement of whole body,,,,,,,,,Sodium Valproate,200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,8-7-2022, 8-8-2022, 8-9-2022, 18-10-2022, 14-11-2022, 12-12-2022, 11-1-2023, 16-2-2023, 4-4-2023, 17-6-2023, 7-8-2023, 27-11-2023\n",
      "female,Hinduism,Sonitpur,Assam,Silly talking,,No,,depressive disorder,, ,,,Escitalopram,2.5,Melatonin,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,7-2-2023, 21-2-2023\n",
      "male,Hinduism,Sonitpur,Assam,increased anger outbursts,,once,ADHD,Tic disorder,IDD,ADHD,Tic Disorder,,,,Risperidone,1,Trihexyphenidyl,1,Methylphenidate,2.5,0.05,Continued,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Good,21.5.2022,1.6.2022,22.6.2022,21.7.2022,27.8.2022,30.7.2022,30.9.2022,1.11.2022,2.12.2022,6.1.2023,16.2.2023,23.3.2023,29.4.2023,10.6.2023,17.7.2023,28.8.2023,9.10.2023,27.11.2023\n",
      "male,Islam,Darrang,Assam,abnormal jerky movements of right upper and lower limbs,,,,,,,,,Levetiracetam,100,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Purchased,Good,16.2.2023,16.3.2023,17.4.2023,15.5.2023\n",
      "male,Hinduism,Sonitpur,Assam,irrelevant talk,,,,Acute and transient psychotic disorder,,,,,Olanzapine,10,Lorazepam,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,2023-02-16 00:00:00\n",
      "male,Islam,Sonitpur,Assam,demand money,,twice,Mild intellectual developemental disorder with behavioral disturbances with seizure disorder with ADHD and ODD,ADHD,ODD,,,,Risperidone,2,Sodium Valproate,500,Clobazam,5,30,Stopped,Clonidine,0.025,0.1,0.1,555,1,Methylphenidate,5,15,20,381,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Good,24-4-2017, 16-5-2017, 8-10-2018, 7-11-2018, 10-12-2018,12-1-2019, 28-3-2019, 30-4-2019, 30-5-2019, 1-7-2019, 5-8-2019, 7-9-2019, 7-10-2019, 11-11-2019,18-12-2019, 20-1-2020, 17-2-2020, 17-3-2020, 18-6-2020, 16-9-2020, 10-11-2020, 28-12-2020, 2-1-2021, 2-2-2021, 22-3-2021, 26-4-2021, 8-6-2022, 8-7-2022, 11-8-2022, 9-9-2022, 30-9-2022, 30-11-2022, 10-1-2023, 16-2-2023, 25-3-2023, 26-4-2023, 30-5-2023,1-7-2023, 5-8-2023, 7-9-2023, 25-10-2023\n",
      "female,Hinduism,Sonitpur,Assam,delayed speech,,Once,ASD,GDD,ASD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Good,16.2.2023,3.3.2023,13.6.2023\n",
      "male,Hinduism,Sonitpur,Assam,Not able to speak since childhood,,twice,ODD and severe Intellectual developmental disorder,,,,,,Risperidone,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,29-12-2017, 11-1-2022, 12-1-2022, 16-2-2023, 18-2-2023\n",
      "male,Hinduism,Sonitpur,Assam,jerky movement ,Yes,,,,,,,,Carbamazepine,200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,4-5-2022, 21-6-2022, 21-7-2022, 20-08-2022, 17-10-2022, 16-11-2022, 19-12-2022, 17-1-2-2023, 16-2-2023, 18-3-2023, 18-4-2023, 16-5-2023, 16-6-2023, 13-7-2023, 7-8-2023, 31-8-2023, 1-11-2023, 2-12-2023\n",
      "female,Hinduism,Sonitpur,Assam,Decreased sleep and appetite,,,,Acute and transient psychotic disorder,,Ni,,,Haloperidol,10,Promethazine,50,Risperidone,2,5,Continued,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,22-9-2022, 20-10-2022, 17-11-2022, 21-12-2022, 16-2-2023, 7-4-2023, 18-7-2023, 17-8-2023, 13-10-2023\n",
      "male,Islam,Sonitpur,Assam,complain from school, ,,,ADHD,,,,,Atomoxetine,10,Risperidone,1,clonidine,0.05,5,loss to follow-up,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,11-1-2018, 8-2-2019, 10-3-2019, 6-4-2019, 4-5-2019, 13-7-2019, 11-2-2020, 2-5-2022, 30-8-2022, 29-92022, 16-2-2023, 20-4-2023\n",
      "male,Hinduism,Udalguri,Assam,Not able to speak,,twice,ADHD, IDD with seizure disorder,ADHD ,,,,,Sodium Valproate,600,clobazam,10,Risperidone,0.5,0.025,Changed d/t non response,Methylphenidate,2.5,5,10,145,0.94,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,12-1-2023, 16-2-2023, 30-3-2023, 07-5-2023, 2-6-2023, 13-7-2023, 21-8-2023, 25-9-2023, 3-11-2023\n",
      "female,Hinduism,Sonitpur,Assam,decreased self care,Similar episode,,,Psychosis NOS,,,,,Olanzapine,10,Lorazepam,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,13-5-2022, 11-6-2022, 15-7-2022, 16-8-2022, 17-1-2023, 18-1-2023, 16-2-2023\n",
      "female,Islam,Nagaon,Assam,abnormal movements of all 4 limbs,Similar complaints,,,,,,,,Sodium valproate,300,Clobazam,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,06-07-15, 02-09-15, 16-10-15, 25-12-15, 08-03-16, 13-06-16, 16-08-16, 24-09-16, 10-10-16, 2-11-16, 12-12-16, 18-01-17, 20-02-17, 24-03-17, 05-05-17, 06-06-17, 11-07-17, 14-08-17, 22-09-17, 22-11-17, 02-01-18, 02-02-18, 11-04-18, 31-05-18, 02-07-18, 06-08-18, 18-09-18, 22-10-18, 18-11-18, 01-01-19, 08-02-19, 18-03-19, 23-04-19, 23-05-19, 19-06-19, 29-07-19, 11-09-19, 31-10-19, 25-12-19, 13-02-2020, 04-03-20, 22-04-20, 16-06-20\n",
      "male,Hinduism,Sonitpur,Assam,Decrease sleep,,Once,BPAD,BPAD in Mania,,,, ,Fluoxetine,10,Olanzapine,10,Lithium,900,50,Stopped,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,27-11-2019, 24-1-2020, 3-3-2020, 22-4-2020, 16-6-2020, 29-7-2020, 3-11-2020, 17-11-2020, 29-12-2020, 10-2-2021, 16-3-2021, 31-3-2021, 30-3-2022, 27-5-2022, 8-7-2022, 22-8-2022, 27-9-2022, 11-11-2022, 14-12-2022, 18-1-2023, 28-2-2023, 18-4-2023, 20-7-2023, 26-9-2023, 6-12-2023\n",
      "female,Islam,Sonitpur,Assam,headache, dizziness,,twice,Anxiety disorder,Anxiety disorder,exam phobia,,,,Amitriptyline,25,Escitalopram,5,Propranolol,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,04-04-08, 12-05-18, 23-06-18, 28-07-18, 15-09-18, 12-03-2020, 22-04-2020, 07-06-2020 \n",
      "female,Islam,Nagaon,Assam,sudden jerky movemnts of body with loss of consciousness,Current condition,Once,Moderate IDD with seizure disorder,,,,,,Sodium Valproate,600,Clobazam,10`,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,28-1-2019, 2-3-2019, 9-4-2019, 29-5-2019, 2-9-2019, 30-9-2019, 27-11-2019, 24-12-2019, 31-1-2020, 4-2-2020, 22-4-2020, 9-6-2020, 8-10-2020, 27-11-2020, 28-12-2020, 29-1-2021, 27-2-2021, 30-3-2021,4-5-2021, 11-6-2021, 9-8-2021, 7-10-2021, 10-11-2021, 15-12-2021, 4-2-2022, 16-3-2022, 21-4-2022, 3-6-2022, 28-6-2022, 4-8-2022, 29-9-2022, 1-11-2022, 15-12-2022, 14-1-2023, 25-2-2023, 11-4-2023, 25-5-2023, 26-3-2023, 25-7-2023, 8-9-2023, 6-10-2023, 4-11-2023, 14-12-2023\n",
      "female,Hinduism,Sonitpur,Assam,generalized fits,similar complaints,once,IDD with epilepsy,,,,,,Carbamazepine,200,Valproate,400,Clobazam,10,0.25,Continued,trihexyphenidyl,2,2,2,1035,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,17-04-10, 18-09-10, 27-10-10, 27-11-10, 12-09-17, 12-10-17, 27-10-17, 22-12-17, 25-01-18, 10-03-18, 24-04-18, 21-05-18, 04-07-18, 13-08-18, 12-09-18, 06-10-18, 14-11-18, 21-12-18, 28-01-19, 15-03-19, 24-04-19, 31-05-19, 09-07-19, 26-08-19, 15-10-19, 30-12-19, 02-03-20, 22-04-20, 25-05-20, 12-08-20, 08-10-20, 30-10-20, 09-01-21, 08-02-21, 08-03-21, 08-04-21, 05-05-21, 21-06-21, 28-09-21, 03-12-21, 27-01-22, 17-04-22, 09-05-22, 13-07-22, 13-09-22, 14-11-22, 27-01-23, 18-03-23, 29-06-23, 24-07-23, 02-09-23, 29-09-23, 14-11-23, 20-12-23\n",
      "male,Hinduism,Sonitpur,Assam,Poor understanding, Restlessness and inattention,,Twice,ADHD,PTSD,ODD,Mild IDD,ADHD,PTSD,ODD,Nicotine use diorder,,Risperidone,1,Fluoxetine,10,Clonidine,0.05,2.5,Stopped,Propranolol,10,10,10,5,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Poor,6-8-2011,14-8-2019,15-6-2020,18-1-2021,24-2-2021,1-3-2021,8-3-2021,30-4-2021,2-6-2021,3-6-2021,18-6-2021\n",
      "female,Hinduism,Udalguri,Assam,irrelevant talk,,Once,BPAD,BPAD,,,,,Olanzapine,15,Aripiprazole,10,Lithium,280,4,Reduce due to side effects,trihexyphenidyl,2,2,2,1998,1,Lorazepam,2,2,2,210,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,16-5-2018, 15-6-2018, 16-7-2018, 16-8-2018, 15-09-2018, 15-11-2018, 5-3-2019, 3-4-2019, 2-5-2019, 27-5-2019, 27-6-2019, 27-7-2019,27-8-2019, 31-8-2019, 13-9-2019, 26-10-2019,30-11-2019, 27-12-2019, 27-1-2020, 29-2-2020, 22-4-2020, 16-12-2020, 3-5-2022, 19-5-2022, 17-6-2022, 16-7-2022, 9-8-2022, 3-9-2022, 3-10-2022, 2-11-2022, 6-12-2022, 4-1-2023, 9-2-2023, 9-3-2023, 3-4-2023, 24-4-2023, 5-6-2023, 4-7-2023, 7-8-2023, 6-9-2023, 5-10-2023, 4-11-2023, 4-12-2023\n",
      "male,Hinduism,Sonitpur,Assam,Does not respond to queries,,Twice,ASD, ADHD, Moderate IDD, Seizure disorder,ASD,ADHD,,,,Sodium Valproate,400,Risperidone,2,Clonidine,0.2,10,Continued,Aripiprazole,2,2,2,60,1,Amisulpiride,25,25,50,30,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Satisfactory,15-12-2007,12-1-2008,2-2-2008,11-12-2010,13-3-2013,13-4-2013,11-5-2013,12-6-2013,13-7-2013,14-8-2013,19-8-2013,14-9-2013,17-10-2013,16-11-2013,18-12-2013,18-1-2014,19-2-2014,23-4-2014,24-5-2014,28-6-2014,30-7-2014,30-8-2014,1-10-2014,29-10-2014,29-11-2014,31-12-2014,3-2-2015,7-3-2015,9-6-2015,11-7-2015,14-8-2015,29-9-2015,3-11-2015,5-12-2015,5-1-2016,8-1-2016,16-2-2016,21-3-2016,23-4-2016,31-5-2016,11-7-2016,9-8-2016,10-9-2016,22-10-2016,7-1-2017,14-3-2017,6-5-2017,7-7-2017,8-8-2017,12-9-2017,14-10-2017,7-2-2018,20-3-2018,2-5-2018,8-6-2018,20-7-2018,28-12-2018,8-1-2019,25-1-2019,15-3-2019,30-4-2019,7-6-2019,11-7-2019,13-8-2019,3-10-2019,7-11-2019,4-1-2020,24-3-2020,22-4-2020,11-7-2020,19-11-2020,28-8-2021,25-9-2021,26-10-2021,30-10-2021,3-11-2021,10-11-2021,27-11-2021,28-12-2021,28-1-2022,28-2-2022,28-3-2022,28-4-2022,28-5-2022,29-6-2022,28-7-2022,30-8-2022,30-9-2022,9-11-2022,14-12-2022,19-1-2023,20-2-2023,4-4-2023,3-5-2023,6-6-2023,6-7-2023,7-8-2023,7-9-2023,11-10-2023,20-11-2023,18-12-2023\n",
      "male,Islam,Sonitpur,Assam,Excessive use of mobile,,,,Acute and transient psychotic disorder,,,,,Risperidone,2,Trihexyphenidyl,2,Lorazepam,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,17-7-2020,5-7-2021,16-8-2021,17-9-2021,6-11-2021,8-12-2021,2-2-2022,28-2-2022\n",
      "male,Hinduism,Sonitpur,Assam,Does not respond to query,,,,ASD,ADHD,,,,Sodium Valproate,400,Risperidone,2,Atomoxetine,18,0.05,Stopped,Levetiracetam,1000,1000,1000,28,1,Aripiprazole,2,2,2,120,,,,1,Amisulpride,25,50,50,33,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,12-1-2008, 2-2-2010, 11-12-2010,13-3-2013, 13-4-2013, 11-5-2013, 12-6-2013, 13-7-2013, 14-8-2013, 19-8-2013, 14-9-2013, 17-10-2013, 14-9-2013, 17-10-2013, 16-11-2013,18-1-2014, 19-2-2014, 23-4, 2014, 24-5-2014, 23-6-2014, 30-7-2014, 30-8-2014, 1-10-2014, 29-10-2014, 29-11-2014, 31-12-2014, 3-1-2015,7-3-2015, 18-4-2015, 9-6-2015, 11-7-2015, 14-8-2015, 29-9-2015, 3-11-2015, 5-12-2015, 5-1-2016, 8-1-2016, 16-2-2016, 21-3-2016, 23-4-2016, 31-5-2016, 11-7-2016, 9-8-2016, 10-5-2016,22-10, 22-10-2016, 7-1-2017,14-3-2017, 6-5-2017, 7-7-2017, 8-8-2017, 12-9-2017, 14-10-2017, 7-2-2018, 7-2-2018, 20-3-2018, 2-5-2018, 8-6-2018, 20-7-2018, 28-12-2018, 8-1-2018, 25-1-2019, 15-3-2019, 30-4-2019, 30-4-2019, 7-6-2019, 11-7-2019, 13-8-2019, 3-10-2019, 7-11-2019, 4-1-2020, 24-3-2020, 22-4-2020, 11-7-2020, 19-11-2020, 19-11-2020, 8-3-2021, 28-8-2021, 25-9-201, 25-9-2021, 26-10-2021, 30-10-2021, 3-11-2021,10-11-2021,27-11-2021, 28-12-2021, 28-1-2022, 28-2-2022, 28-3-2022, 28-4-2022, 28-5-2022, 28-6-2022, 28-7-2022, 30-8-2022, 30-9-2022, 9-11-2022, 14-12-2022, 19-1-2023, 20-2-2022, 4-4-2023, 3-5-2023, 6-6-2023, 6-7-2023, 7-8-2023, 7-9-2023, 11-10-2023, 20-11-2023, 18-12-2023\n",
      "female,Islam,Sonitpur,Assam,altered consciousness,,once,Seizure Disorder,Depressive Disorder,Hypothroidism,Depressive Disorder,,,,,carbamazepine,200,Clobazam,5,Escitalopram,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,7.10.2020,,6.11.2020,27.11.2020,11.1.2021,4.2.2021,3.3.2021,26.4.2021,18.5.2021,23.6.2021,6.7.2021,27.8.2021,20.9.2021,19.10.2021,13.11.2021,27.11.2021,11.12.2021,14.1.2022,18.2.2022,21.3.2022,5.5.2022,2.6.2022,5.7.2022,29.7.2022,8.9.2022,7.10.2022,5.11.2022,5.12.2022,10.1.2023,28.2.2023,18.3.2023,22.5.2023,4.7.2023,3.8.2023,9.9.2023,30.10.2023,25.11.2023\n",
      "male,Islam,Morigaon,Assam,Fearfulness,,once,Psychosis NOS,Seizure disorder,Psychosis NOS,,,,,Risperidone,2,Olanzapine,10,Sodium Valproate,400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,15.12.2021,12.3.2022,5.5.2022,1.8.2022,19.8.2022,30.12.2022,14.2.2023,21.3.2023,6.5.2023,19.7.2023,16.9.2023,3.11.2023,21.12.2023\n",
      "male,Islam,Nagaon,Assam,jerky movements with loss of awareness,,once,IDD,Seizure Disorder,ADHD,ADHD,,,,,Carbamazepine,200,Clobazam,10,Clonidine,0.025,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Poor,17.1.2022,22.2.2022,4.4.2022,5.5.2022,24.6.2022,20.8.2022,3.11.2022,31.1.2023,3.5.2023,7.9.2023\n",
      "male,Islam,Sonitpur,Assam,excessiv ecrying ,Current medical conditions,,,,,,,,Phenytoin,30,Levetiracetam,100,Sodium Valproate,100,2.5,loss to follow-up,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Poor,1-4-2022, 4-5-2022, 5-5-2022, 23-5-2022, 26-9-2022, 9-12-2022, 16-12-2022, 23-12-2022, 11-7-2023\n",
      "male,Hinduism,Lakhimpur,Assam,disturbed sleep,Current condition,,,Psychosis NOS,,,,,Olanzapine,10,Fluoxetine,20,trihexyphenidyl,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,5-2-2022, 5-5-2022\n",
      "male,Islam,Darrang,Assam,fearfullness,,,,Acute and transient psychotic disorder,,,,,Olanzapine,5,Trihexyphenidyl,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,12.1.2019,1.2.2019,21.12.2021,19.1.2022,12.2.2022,16.3.2022,5.5.2022\n",
      "female,Hinduism,Sonitpur,Assam,Involuntary jerky movement of whole body,,,,,,,,,Sodium Valproate,400,clobazam,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,17.6.2109,23.7.2019,27.8.2019,24.9.2019,26.10.2019,25.11.2019,26.12.2019,27.1.2020,13.3.2020,23.4.2020,19.5.2020,19.6.2020,22.7.2020,25.7.2020,14.10.2020,17.12.2020,18.1.2021,16.2.2021,19.3.2021,20.4.2021,20.5.2021,1.11.2021,24.11.2021,28.1.2022,8.4.2022,5.5.2022,10.6.2022,13.7.2022,5.9.2022,7.10.2022,10.11.2022,14.12.2022,13.1.2023,13.2.2023,13.3.2023,21.4.2023,23.5.2023,27.6.2023,1.8.2023,31.8.2023,10.10.2023,17.11.2023\n",
      "female,Hinduism,Karbi Anglong,Assam,decreased social interaction,,,,OCD,Depression,,NIl,NIl,Sertraline,50,Clonazepam,0.25,Risperidone,2,,,,,,,,,,,,,,,,,,,,,,,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,,,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,4-4-2022, 5-5-2022, 4-6-2022, 5-7-2022, 4-8-2022, 5-9-2022, 10-10-2022, 15-11-2022, 18-2-2023, 17-3-2023, 17-7-2023, 28-8-2023, 5-10-2023, 1-11-2023, 16-12-2023\n",
      "male,Islam,Nagaon,Assam,Poor undersanding,,once,Psychosis NOS with IDD,Pscyhosis NOS,,,,,Escitalopram,10,Risperidone,2,trihexyphenidyl,2,2,Stopped,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,15-11-2021, 18-1-2022, 23-7-2022, 30-8-2022, 16-11-2022, 16-2-2023, 3-5-2023, 31-10-2023, 29-12-2023\n",
      "male,Hinduism,Udalguri,Assam,decreased social interaction,,,,Psychosis NOS,,,,NIl,Olanzapine,10,Lorazepam,2,trihexyphenidyl,2,5,Stopped,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,,,,,,,,,,,,,,,,,,,,,,,,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,,,,,,,Both Free and Purchased,Poor,11-1-2022, 5-5-2022, 22-11-2022, 24-3-2023, 12-6-2023, 11-9-2023, 16-10-2023, 6-12-2023\n",
      "male,Islam,Nagaon ,Assam,fearfullness,,,,Acute and transient psychotic disorder,,,,,Olanzapine,10,Lorazepam,2,Escitalopram,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,2-8-2021, 7-10-2021, 8-11-2021, 13-12-2021, 17-1-2022, 3-2-2022, 25-2-2022, 31-3-2022, 5-5-2022, 11-6-2022, 14-7-2022, 17-8-2022, 16-9-2022, 19-10-2022, 19-11-2022, 21-12-2022, 23-1-2023, 23-2-2022, 24-3-2023, 24-4-2023, 24-5-2023, 27-6-2023, 26-7-2023, 26-8-2023, 30-9-2023, 27-10-2023, 30-11-2023\n",
      "male,Islam,Nagaon,Assam,difficulty in reading and writing,,No,,,,,,,sodium Valproate,400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,29-1-2021, 31-12-2021, 31-1-2022, 7-3-2022, 8-4-2022, 5-5-2022, 9-6-2022, 3-9-2022, 7-11-2022,9-12-2022, 14-2-2023, 24-4-2023, 11-7-2023\n",
      "female,Hinduism,Nagaon,Assam,irrelevant talk,,,,Psychosis,,,,NIl,Olanzapine,20,Fluoxetine,20,Lorazepam,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,26-5-2018, 2-6-2018, 2-7-2018, 31-7-2018, 31-8-2018, 28-9-2018, 29-10-2018, 26-11-2018, 24-12-2018, 23-1-2019, 25-2-2019, 23-3-2019, 26-4-2019, 6-6-2019, 21-8-2019, 18-11-2019, 4-1-2020, 28-1-2020, 23-2-2021, 20-3-2021, 13-4-2021, 10-9-2021, 23-10-2021, 25-11-2021, 2012-20-12-2021, 8-2-2022, 11-3-2022, 13-4-2022, 5-5-2022, 4-6-2022, 8-7-2022, -8-8-2022, 10-9-2022, 11-10-2022, 12-11-2022, 10-1-2023, 10-4-2023, 21-6-2023, 26-8-2023, 23-11-2023\n",
      "male,Islam,Nagaon,Assam,overtalkativeness,,twice,OCD,OCD,BPAD,,,,Olanzapine,10,Fluoxetine,60,Risperidone,1,Olanzapine,loss to follow-up,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,5-5-2022, 27-6-2022, 18-11-2022, 14-3-2023, 26-4-2023\n",
      "male,Hinduism,Sonitpur,Assam,delay developmental milestone,,,,,,,,,Risperidone,0.5,Glycopyrolate,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Poor,5-5-2022, 4-7-2022\n",
      "female,Hinduism,Sonitpur,Assam,does not speak more than one word,,once,ASD with DSL with Borderline IQ,ASD,,,,DSL,,,,,,,,,,,,,,,,,,,,,,,,,,,,,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Poor,5-5-2022, 2-6-2022, 30-12-2022, 5-1-2023, 12-6-2023, 20-6-2023, \n",
      "female,Hinduism,Udalguri,Assam,sudden loss of consciousness,,No,,depressive disorder  ,dissociative disorder,,,,Escitalopram,5,Olanzapine,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,8-9-2021, 12-11-2021, 5-5-2022, 9-8-2022, 7-10-2022, 13-12-2022, 24-3-2023, 26-6-2023, 12-10-2023\n",
      "male,Hinduism,Sonitpur,Assam,not speaking adequet for age ,Current condition,twice,ASD with IDD,ASD,ADHD,,,,Melatonin,1.5,Methylphenidate,2.5,,Risperidone,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Purchased,Poor,28-11-2020, 11-11-2021, 16-11-2021, 3-1-2022, 12-7-2022, 3-3-2023, 16-3-2023, 6-4-2023\n",
      "male,Hinduism,Sonitpur,Assam,blank stare after getting up suddenly from sleep,,,,,,,,,Carbamazepine,100,Clobazam,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,3.1.2022,31.1.2022,11.3.2022,26.4.2022,13.6.2022,25.7.2022,5.9.2022,28.10.2022,24.1.2023\n",
      "female,Hinduism,Sonitpur,Assam,smiling and muttering to self,,,,Schizophrenia,,,,,Aripiprazole,5,Olanzapine,5,Trifluperazine,5,2,Continued,Lorazepam,2,2,2,30,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,28.12.20, 8.1.21, 20.2.21, 20.3.21, 20.4.21, 2.9.21, 1.11.21, 3.1.22, 2.3.22, 2.5.22, 31.5.22, 28.6.22, 28.7.22, 26.8.22, 22.9.22, 21.10.22, 21.12.22, 23.1.23, 18.2.23, 24.3.23, 21.4.23, 23.5.23, 22.6.23, 22.7.23, 21.8.23, 22.9.23, 21.10.23, 21.11.23, 21.12.23, 19.1.24\n",
      "female,Islam,Sonitpur,Assam,episodes of abnormal body movements,Current condition,,,,,,,,Sodium Valproate,200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,04.01.21, 13-03-21, 11-09-21, 25-10-21, 03-01-22, 21-04-22, 23-06-22, 22-08-22, 24-10-22, 09-12-22, 16-01-23, 31-03-23, 17-05-23, 03-07-23, 21-08-23, 13-10-23, 28-11-23\n",
      "male,Islam,Nagaon,Assam,abnormal jerky movement of body with tightening of right side of body,,,,ODD,,,,,Sodium Valproate,200,Risperidone,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,30-12-2020, 30-1-2021, 2-3-2021,2-4-2021, 3-5-2021, 3-6-2021, 3-7-2021, 3-8-2021, 3-9-2021, 3-11-2021, 3-1-2022, 1-4-2022, 11-6-2022, 6-12-2022, 9-2-2023, 29-5-2023, 19-9-2023, 16-1-2024 \n",
      "female,Islam,Sonitpur,Assam,abnormal jerky movement of body with loss of consciousness,,,,,,,,,Carbamazepine,200,clobazam,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,20-5-2020, 23-6-2020, 29-7-2020, 9-9-2020, 10-10-2020, 12-11-2020, 30-11-2020, 12-1-2021, 17-2-2021, 26-3-2021, 19-4-2021, 1-6-2021, 29-6-2021, 27-7-2021, 16-8-2021, 4-10-2021, 1-112021, 3-1-2022, 15-2-2022, 18-3-2022, 18-4-2022, 19-5-2022, 27-6-2022, 12-9-2022, 22-10-2022, 31-1-2023, 4-4-2023, 30-6-2023\n",
      "male,Hinduism,Sonitpur,Assam,hoarding of inner garments,,,,Paraphilia,Social Anxiety,SLD,,,Fluoxetine,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,17.12.2021,3.1.2022\n",
      "male,Hinduism,Sonitpur,Assam,rigidity of all four limbs while sleeping,,,,,,,,,Sodium Valproate,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,3.1.2022,5.3.2022\n",
      "male,Islam,lakhimpur,Assam,irrelevant talking,,,,ATPD,,,,,Olanzapine,20,Trihexphenidyl,2,Haloperidol,5,2,loss to follow-up,sodium Valproate,400,600,600,30,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,27-3-2019, 29-4-2019, 28-6-2019, 31-7-2019, 5-9-2019, 4-10-2019, 9-11-2019, 21-12-2019,29-2-2020,  10-8-2020, 3-1-2022\n",
      "male,Hinduism,Nagaon,Assam,wandresome behaviour,,once,bipolar disorder-mania, Nicotine dependence, cannabis use, subclinical hypothyroidism, conduct features,Bipolar disorder-current episode mania,nicotinde dependence syndrome,cannabis abuse,conduct features,SLD,Olanzapine,10,Lithium,600,Sodium Valproate,600,4,Reduced d/t resolution,Lorazepam,2,2,2,44,1,Clonazepam,0.5,0.25,0.5,135,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,25.06.21, 26.06.21, 20.7.21, 24.09.21, 14.10.21, 6.11.21, 6.12.21, 3.1.22, 4.3.22, 2.5.22, 6.6.22, 1.7.22, 25.7.22, 10.9.22, 10.10.22, 8.11.22, 2.12.22, 5.1.23, 21.2.23, 30.3.23, 3.5.23, 1.6.23, 7.7.23, 2.8.23, 4.9.23, 9.10.23, 6.11.23, 11.12.23, 10.1.24\n",
      "female,Islam,Nagaon,Assam,Self muttering and self laughing,,,,Acute and transient psychotic disorder,NIl,,NIl,,Olanzapine,10,Lorazeoam,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,Free,Poor,2022-01-03 00:00:00\n",
      "male,Hinduism,Morigaon,Assam,unable to speak properly,,,,ASD,ADHD,,,,Risperidone,0.25,Clonidine,0.025,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Poor,25.3.2021,11.6.2021,3.8.2021,20.9.2021,3.1.2022,3.3.2022,10.3.2022,11.12.2023\n",
      "female,Islam,Sonitpur,Assam,poor academic performance ,,,,CD,ADHD,,,,Clonidine,0.025,Ariprazole,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Poor,28-10-2021, 3-1-2022, 18-5-2022, 20-6-2022, 25-8-2022\n",
      "female,Islam,Nagaon,Assam,clenching of fist,,once,ATPD,ATPD,,,,,Escitalopram,10,Olanzapine,7.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,3-1-2022, 17-1-2022, 21-1-2022\n",
      "female,Hinduism,Sonitpur,Assam,delayed language development and required assistance in daily activities,Current condition,multiple,ASD, ADHD in remission, separation anxiety, ?OCD, IDD,ASD,?OCD,ADHD in remission,Separation anxiety,Delayed speech and language,Sertraline,25,Ariprazole,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Good,26-10-20, 20-11-20, 21-12-20, 07-01-21, 22-1-21, 29-1-21, 08-02-21, 11-02-21, 22-02-21, 24-09-21, 03-01-22, 10-01-22, 22-07-22, 25-09-23\n",
      "male,Islam,Sonitpur,Assam,involuntary jerky movements of both upper and lower limbs,Current condition,once,Borderline IQ, seizure disorder,,,,,,Sodium Valproate,400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,8-8-17, 5-9-17, 5-10-17, 30-10-17, 29-11-17, 28-12-17, 1-2-18, 13-2-18, 19-3-18, 17-4-18, 15-5-18, 9-6-18, 10-7-18, 06-8-18, 5-9-18, 28-9-18, 29-10-18, 30-11-18, 27-12-18, 2-2-19, 5-4-19, 3-5-19, 27-5-19, 18-6-19, 15-7-19, 17-8-19, 07-9-19, 3-10-19, 6-11-19, 6-12-19, 4-1-2020, 4-2-20, 7-3-20, 3-7-20, 28-8-20, 27-11-20, 5-2-21, 9-4-21, 3-8-21, 22-10-21, 3-1-22, 6-5-22, 30-7-22, 21-10-22, 27-1-23, 18-4-23, 25-10-23, 2-2-24\n",
      "male,Hinduism,Udalguri,Assam,decreased academic perforamnce,,twice,ADHD, ODD Nicotine used disorder with mild IDD,ADHD,ODD,Nicotine use disorder,,,Olanzapine,10,Fluoxetine,20,Lithium,300,10,Continued,Risperidone,0.5.,0.5,0.5,775,1,Nicotine gum,8,8,10,60,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Good,17-5-2021, 18-6-2021, 13-9-2021, 28-9-2021, 11-10-2021, 5-11-2021, 3-1-2022, 1-2-2022, 28-2-2022, 29-4-2022, 30-5-2022, 1-7-2022, 1-8-2022, 30-8-2022, 30-9-2022, 1-11-2022, 2-12-2022, 3-1-2023, 6-2-2023, 21-3-2023, 2-5-2023, 11-8-2023, 22-9-2023, 1-11-2023, 9-1-2024\n",
      "female,Hinduism,Sonitpur,Assam,Dizziness,,,,,,,,,Sodium Valproate,400,clobazam,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,21-8-2020, 20-10-2020, 20-11-2020, 19-12-2020, 25-1-2021, 23-2-2021, 23-3-2021, 20-4-2021, 20-5-2021, 19-6-2021, 23-7-2021, 24-8-2021, 5-10-2021, 23-11-2021, 23-12-2021, 24-1-2022, 24-2-2022, 10-5-2022, 7-7-2022, 8-8-2022, 7-9-2022, 11-10-2022, 22-11-2022, 3-1-2023, 6-2-2023, 22-3-2023, 1-5-2023, 30-5-2023, 5-7-2023, 7-8-2023, 12-9-2023, 30-5-20235-7-2023, 27-10-2023, 27-11-2023\n",
      "female,Hinduism,Sonitpur,Assam,involuntary jerky movements of head and legs,,,,,,,,,Carbamazepine,100,clobazam,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,3-1-2022, 25-5-2022\n",
      "male,Hinduism,Sonitpur,Assam,hyperactivity and restlessness,,once,ADHD with severe IDD,ADHD,,,,,Risperidone,1,Clonidineq,0.025,Melatonin,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Good,2012-2021, 3-1-2022, 22-6-2022,31-8-2022, 21-3-2023, 21-4-2023, 22-5-2023, 22-6-2023,20-7-2023, 28-1-2023, 21-9-2023, 21-11-2023 16-1-2024\n",
      "male,Islam,Nagaon,Assam,Self absorbed behavior,,No,,Psychosis NOS,,,,,Risperidone,2,Trihexyphenidyle,2,Lorazepam,2,10,loss to follow-up,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,1-11-2021, 1-12-2021, 3-1-2022, 31-1-2022, 8-3-2022, 9-4-2022, 8-8-2022, 10-9-2022, 7-10-2022, 8-11-2022, 10-12-2022, 11-1-2023, 8-2-2023, 9-3-2023, 8-4-2023, 13-5-2023, 3-6-2023, 18-7-2023, 22-8-2023\n",
      "male,Islam,Kamrup (M),Assam,Making unusual sounds and abnormal movements of limbs and eyes,Obsessive Compulsive disorder,multiple,ADHD with Tourette syndrome with OCD with Specific phobia,ADHD,Tourette syndrome,OCD,Specific phobia,,Clonidine,0.05,Lithium carbonate,600,Risperidone,4,50,Continued,Atomoxetine,10,10,18,585,1,Trihexyphenidyl,2,2,2,744,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Satisfactory,13-07-2021,13-08-2021,14-09-2021,19-10-2021,22-10-2021,26-10-2021,03-01-2022,15-02-2022,17-02-2022,25-03-2022,31-03-2022,30-05-2022,22-07-2022,23-07-2022,25-07-2022,26-07-2022,17-10-2022,26-12-2022,10-02-2023,15-05-2023,27-06-2023\n",
      "male,Islam,Nagaon,Assam,sudden jerky movement of body,No,,,,,,,,Carbamazepine,200,Sodium valproate,400,Clobazam,5,0.5,Continued,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,3-1-2022, 3-2-2022, 3-3-2022, 13-4-2022, 15-9-2023, 6-11-2023\n",
      "male,Hinduism,Nagaon,Assam,headache,Current condition,,,Tension headache,,,,,Escitalopram,5,,NIL,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,2022-01-03 00:00:00\n",
      "male,Hinduism,Udalguri,Assam,hearing of voices not heard by other,,once,Psychosis NOS,Psychosis NOS,,,,,Olanzapine,10,Lorazeoam,2,Trihexyphenidyl,2,10,Continued,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Poor,19-7-2021, 21-9-2021, 3-1-2022, 16-7-2022,11-8-2022, 7-09-2022, 8-10-2022, 6-12-2022, 7-1-2023, 13-4-2023.11-5-2023, 11-7-2023, 10-8-2023-14-12-2023, 11-1-2024, 9-2-2024\n",
      "male,Islam,Nagaon,Assam,involuntary jerky movements of hands and legs,,,,,,,,,Sodium Valproate,400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,19.1.2022,16.2.2022,6.5.2022,23.6.2022,26.7.2022,15.9.2022,14.11.2022,31.12.2022,2.2.2023,4.3.2023,3.5.2023,29.5.2023\n",
      "female,Islam,Nagaon,Assam,jerky movements of bilateral upper and lower limbs,,,,,,,,,Sodium Valproate,200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,16.11.2021,3.1.2022\n",
      "male,Hinduism,Sonitpur,Assam,repeated complain from school,,No,No,ADHD,ODD,,,SLD,Methylphenidate,2.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,,,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,,,,,,,,,,,,,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,,,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,,,,,,NIl,Free,Poor,2023-01-03 00:00:00\n",
      "male,Islam,Nagaon,Assam,abnormal jerky movements of body,,once,Seizure disorder with IDD,,,,,,Sodium Valproate,400,clobazam,5,Levetiracetam,500,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,9-6-2018, 13-7-2018, 11-8-2018, 11-9-2018, 4-10-2018, 5-11-2018, 6-12-2018, 10-6-2019, 10-7-2019, 7-8-2019, 21-8-2019, 1-10-2019, 26-10-2019, 4-12-2019, 6-1-2020, 1-2-2020, 13-3-2020, 12-6-2020, 4-8-2020, 7-9-2020, 4-11-2020, 25-12-2020, 11-2-2021, 17-3-2021, 22-4-2021, 17-8-2021, 21-9-2021, 25-10-2021, 3-1-2022, 17-3-2022, 14-4-2022, 12-5-2022, 27-7-2022, 5-9-2022, 1-10-2022, 27-1-2023, 24-2-2023, 25-3-2023, 17-4-2023, 15-7-2023, 26-10-2023\n",
      "male,Hinduism,Demaji,Assam,irritability,Yes,,,CD,Cannabis use disorder,Nicotine use disorder,,,Fluoxetine,20,Risperidone,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,2022-01-03 00:00:00\n",
      "male,Hinduism,Sonitpur,Assam,doesn't go to school regularly,,twice,Severe depression with psychotic symptom and anxiety disorder,Severe depression with psychotic symptom ,anxiety disorder,,,,Aripiprazole,5,Fluoxetine,20,Lithium,600,10,Continued,trihexyphenidyl,2,2,3,28,1,,,,,,,,,,,,,,,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,NIl,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,14-12-2018, 16-1-2019, 2-3-2019, 30-3-2019, 27-4-2019, 1-5-2019, 14-6-2019, 22-7-2019, 10-8-2019, 23-8-2019, 28-7-2020, 5-3-2021, 31-3-2021, 27-4-2021, 5-6-2021, 29-6-2021,6-7-2021, 12-7-2021,25-8-2021, 13-9-2021, 4-10-2021, 1-11-2021, 3-12-2021,3-1-2022,26-2-2022,28-3-2022, 29-4-2022, 28-5-2022, 9-6-2022, 10-6-2022, 8-7-2022, 19-8-2022, 27-9-2022, 27-10-2022, 25-11-2022, 26-12-2022, 3-2-2023, 27-2-2023, 10-4-2023, 12-5-2023, 26-6-2022, 4-8-2023, 8-9-2023, 9-10-2023, 6-11-2023, 11-12-2023, 8-1-2024\n",
      "female,Hinduism,Sonitpur,Assam,Episodesof generalized abnormal jerky movement ,Seizure disorder,once,Seizure Disorder,IDD,,,,,,sodium Valproate,200,clobazam,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,16-10-2019, 15-11-2019, 15-12-2019, 13-1-2020, 11-2-2020, 13-3-2020, 15-5-1010, 17-4-2020, 15-6-2020, 13-8-2020, 22-9-2020, 27-11-2020, 4-1-2021, 28-1-2021, 24-2-2021, 24-3-2021, 30-4-2021, 29-5-2021, 19-6-2021,2-8-2021, 2-9-2021, 4-10-2021, 3-11-2021, 6-12-2021, 3-1-2022 , 2-2-2022, 5-3-2022, 4-4-2022, 7-5-2022, 4-6-2022, 9-7-2022, 16-8-2022, 14-9-2022, 16-10-2022, 25-11-2022, 30-12-2022, 28-1-2023, 11-3-2023, 18-4-2023, 23-5-2023, 21-6-2023, 21-7-2023, 29-8-2023, 28-9-2023, 27-10-2023, 28-11-2023, 29-12-2023\n",
      "male,Christianity,East kameng,Arunachal Prasdesh,loss of consciousness ,Seizure disorder,,,,,,,,Phenytoin,100,clobazam,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,3-11-2022, 3-1-2023, 2-3-2023, 25-4-2023\n",
      "male,Hinduism,Nagaon,Assam,poor comprehension,,,,ADHD,ODD,,,,Clonidine,0.025,Risperidone,0.25,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Satisfactory,26-7-2022, 26-8-2022, 27-9-2022, 18-4-2023, 4-5-2023\n",
      "female,Hinduism,Morigaon,Assam,reduced level of intellectual functioning,,once,ADHD,ADHD,,,,,Clonidine,0.025,Risperidone,0.5,Methylphenidate,2.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Satisfactory,1-7-2022, 1-8-2022, 26-8-2022, 1-10-2022, 1-11-2022, 9-1-2023, 14-2-2023\n",
      "female,Islam,Nalbari,Assam,tightening of hands and leg,,,,,,,,,Sodium Valproate,400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,26-8-2022, 24-9-2022, 1-11-2022\n",
      "male,Islam,Udalguri,Assam,jerky movements of body with frothing, tongue bite,,,,,,,,,Carbamazepine,200,Clobazam,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,22-12-21, 24-1-22, 25-02-22, 26-03-22, 25-05-22, 25-06-22, 27-07-22, 26-08-22\n",
      "female,Islam,Udalguri,Assam,Episodes of jerky movements of body with loss of consciousness,Current condition,No,,,,,,,Sodium Valproate,300,clobazam,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,27-7-15, 30-9-15, 5-11-15, 10-12-15, 12-1-16, 11-2-16, 18-5-16, 11-11-16, 21-12-16, 25-1-17, 27-2-17, 3-4-17, 9-5-17, 21-6-17, 3-8-17, 18-9-17, 29-11-17, 3-1-18, 9-2-18, 27-3-18, 26-4-18, 8-6-18, 24-7-18, 12-9-18, 24-10-18, 10-12-18, 25-1-19, 26-3-19, 6-6-19, 26-7-19, 3-9-19, 24-10-19, 18-11-19, 30-12-19, 4-2-20, 5-2-20, 6-5-20, 2-6-20, 25-8-20, 29-10-20, 19-12-20, 21-1-21, 23-3-21, 30-6-21, 19-10-21, 28-12-21, 31-3-22, 5-7-22, 26-8-22, 26-9-22, 3-11-22, 1-12-22, 2-1-23, 7-2-23, 16-3-23, 25-4-23, 5-6-23, 31-7-23, 10-10-23, 2-12-23, 27-1-24\n",
      "male,Hinduism,Udalguri,Assam,Poor comprehension,,thrice,Moderate IDD with behavioural abnormalities, ADHD,ADHD,,,,,clobazam,2.5,Olanzapine,5,Sodium Valproate,200,2,Continued,Atomoxetine,20,37.5,37.5,2133,0.97,Trihexyphenidyl,2,2,2,1817,,,,0.96,Zolpidem,5,5,5,983,,,,0.93,Melatonin,3,3,3,30,Stopped,Good,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Good,9-10-15, 12-11-15, 11-1-15, 9-1-16, 6-2-16, 7-3-16, 9-4-16, 30-4-16, 14-5-16, 22-6-16, 26-7-16, 20-8-16, 6-10-16, 7-11-16, 9-12-16, 23-1-17, 20-2-17, 30-3-17, 28-4-17, 10-6-17, 4-7-17, 1-8-17, 30-8-17, 4-10-17, 27-11-17, 26-12-17, 1-2-18, 7-3-18, 11-4-18, 22-5-18, 25-6-18, 9-8-18, 13-9-18, 13-10-18, 8-11-18, 19-12-18, 17-1-19, 15-2-19, 16-2-19, 20-4-19, 22-5-19, 26-6-19, 29-7-19, 27-8-19, 5-10-19, 5-11-19, 17-12-19, 14-1-20, 19-2-20, 20-3-20, 8-5-20, 5-6-20, 26-9-20, 20-10-20, 24-11-20, 24-12-20, 1-2-21, 8-3-21, 16-4-21, 23-6-21, 20-7-21, 25-8-21, 18-9-21, 26-10-21, 25-11-21, 21-12-21, 20-1-22, 15-2-22, 15-3-22, 22-4-22, 23-5-22, 19-7-22, 26-8-22, 28-9-22, 6-12-22, 24-1-23, 16-3-23, 24-4-23, 7-6-23, 27-7-23, 11-9-23, 31-10-23, 8-1-24\n",
      "female,Islam,Darrang,Assam,delayed developmental milestones,,once,ADHD, conduct disorder, IDD. Limb length descrepancy, Cerebal palsy,ADHD,conduct disorder,,,,Clonidine,0.05,Methylphenidate,5,Risperidone,0.5,2,loss to follow-up,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Good,26-02-21, 06-04-21, 01-10-21, 26-08-22, 14-10-22\n",
      "female,Islam,Nagaon,Assam,irrelevant talk,,,,Schizophrenia,,,,,Risperidone,2,Trihexyphidyl,2,Lithium,300,0.5,loss to follow-up,Lorazepam,2,2,2,388,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,30-9-14, 07-11-14, 2-12-14, 6-1-15, 5-2-15, 7-3-15, 7-4-15, 9-5-15, 8-6-15, 8-7-15, 6-8-15, 4-9-15, 5-10-15, 2-11-15, 17-12-15, 16-1-16, 13-2-16, 14-3-16, 14-4-6, 12-5-16, 11-6-16, 12-7-16, 11-8-16, 10-9-16, 27-9-16, 24-10-16, 24-11-16, 22-12-16, 21-1-17, 21-2-17, 23-3-17, 22-4-17, 22-5-17, 24-6-17, 27-7-17, 26-8-17, 25-9-17, 25-10-17, 23-11-17, 23-12-17, 23-1-18, 20-2-18, 26-3-18, 24-4-18, 24-5-18, 6-6-18, 5-7-18, 4-8-18, 18-9-18, 16-10-18, 15-11-18, 17-12-18, 15-1-19, 16-2-19, 18-3-19, 16-4-19, 16-5-19, 15-6-19, 16-7-19, 14-8-19, 12-9-19, 14-10-19, 12-11-19, 16-12-19, 15-1-20, 15-2-20, 16-3-20, 24-4-20, 18-6-20, 21-7-20, 28-8-20, 28-9-20, 20-11-20, 21-12-20, 4-9-21, 11-10-21, 1-11-21, 3-12-21, 10-1-22, 11-2-22, 11-3-22, 15-4-22, 15-5-22, 18-6-22, 20-7-22, 26-8-22, 13-10-22\n",
      "female,Hinduism,Mandira,Assam,irritability,Depressive disorder,,,Bipolar disorder-current episode mania,,,,,Lithium,600,Ariprazole,10,olanzapine ,10,2,Reduced d/t resolution,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Good,16-5-20, 16-6-20, 9-1-21, 26-8-22, 12-6-23, 24-7-23, 23-8-23\n",
      "male,Hinduism,Udalguri,Assam,irrelevant talk,,once,IDD with ?seizure disorder,,,,,,risperidone,1,Trihexyphenidyl,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Satisfactory,31-05-22, 28-06-22, 26-08-22, 30-09-22, 04-11-22, 09-12-22\n",
      "female,Christianity,Papum Pare,Arunachal Prasdesh,pervasive low mood, irritability,Current condition,once,depressive disorder,depressive disorder,,,,,Escitalopram,5,Olanzapine,2.5,Lithium,300,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,30-06-22, 04-07-22, 29-07-22, 05-08-22, 19-08-22, 26-08-22, 11-10-22, 13-10-22, 11-11-22, 07-02-23, 24-03-23, 23-06-23, 14-07-23, 28-07-23, 15-09-23\n",
      "female,Islam,Golaghat,Assam,Fearfullness,,,,ATPD,,,,,Olanzapine,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,26-8-2022, 24-9-2022, 26-10-2022, 18-11-2022, 21-7-2023, 18-8-2023\n",
      "male,Hinduism,Sonitpur,Assam,poor social interaction,Treated at NIMHANS for current issue,once,ADHD,ASD,BPAD,IDD,Early paternal loss,ASD,ADHD,BPAD,,,Sodium Valproate,1000,Olanzapine,20,trihexyphenidyl,2,2,Stopped,Clonidine,0.075,0.2,0.2,1491,1,Aripiprazole,10,20,20,1067,,,,1,Lithium,300,1200,1200,1046,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Satisfactory,7-6-2019,21-6-2019,22-7-2019,22-8-2019,11-11-2019,9-12-2019,6-1-2020,3-2-2020-27-6-2020,5-3-2021,12-3-2021,20-4-2021,11-5-2021,9-8-2021,22-10-2021,14-2-2022,6-5-2022,26-8-2022,31-10-2022,23-1-2023,7-4-2023,30-6-2023,29-9-2023,1-12-2023,5-2-2024\n",
      "female,Hinduism,Sonitpur,Assam,low mood,,once,Depressive disorder with Dissociative disorder,Depressive disorder,Dissociative disorder,,,,Escitalopram,10,Sertraline,100,Aripiprazole,5,300,Continued,Clobazam,10,5,10,293,1,Clonazepam,0.5,0.5,0.5,47,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Good,7-8-2022, 17-8-2022, 26-8-2022, 21-9-2022, 11-11-2022, 18-11-2022, 25-11-2022, 2-12-2022, 9-12-2022, 10-1-2023, 13-1-2023, 19-1-2023, 31-1-2023, 7-2-2023, 24-2-2023, 1-4-2023, 28-4-2023, 30-5-2023, 4-7-2023, 29-7-2023, 31-8-2023, 28-9-2023, 30-10-2023, 25-11-2023, 21-12-2023, 29-1-2024\n",
      "male,Hinduism,Sonitpur,Assam,delayed developmental milestones,Current condition,No,,ADHD,,,,,Methylphenidate,2.5,Sodium valproate,300,Risperidone,0.5,3,Continued,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Good,28-03-22, 13-07-22, 26-08-22, 11-10-22, 15-05-23, 31-07-23, 07-09-23, 03-10-23, 01-11-23, 04-12-23\n",
      "male,Islam,morigaon,Assam,suspiciousness towards parents and neighbours,,once,psychosis NOS,Psychosis NOS,,,,,Risperidone,2,Trihexiphenidyl,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,08-06-22, 26-08-22, 19-12-22, 23-01-23, 02-11-23\n",
      "male,Islam,Dhubri,Assam,Irrelevent Talking,,,,BPAD in Mania with psycotic symptoms,,,,,Olanzapine,10,Lorazepam,2,Lithium,450,2,loss to follow-up,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Free,Poor,28-08-2021, 15-07-2022, 17-08-2022\n",
      "male,Islam,Nagaon,Assam,No Memory of events, Cant recognize people ,NIL,NIL,NIL,Depressive Disorder,,,,,Clonazepam,1,Setraline,100,Melatonin,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Satisfactory,29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020, 03-12-2020, 04-01-2021, 19-01-2021, 02-02-2021, 10-03-2021, 12-04-2021, 28-08-2021, 22-10-2021, 24-11-2021, 07-02-2022, 17-02-2022, 25-02-2022, 07-03-2022, 04-04-2022, 21-06-2022, 24-08-2022, 24-09-2022, 16-11-2022\n",
      "male,Hinduism,Nagaon,Assam,unable to speak ,Current condition,Once,ADHD, IDD with seizure disorder,ADHD,,,,,Sodium Valproate,300,Olanzapine,2.5,Atomoxetine,5,2.5,Stopped,Clonidine,0.025,0.75,0.75,502,1,Clobazam,5,5,5,60,,,,1,Trihexyphenidyl,1,2,2,959,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Both Free and Purchased,Satisfactory,16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020, 19-06-2020, 17-07-2020, 21-08-2020, 19-11-2020, 19-12-2020, 18-02-2021, 27-02-2021, 28-08-2021, 29-10-2021, 28-12-2021, 21-03-2022, 25-05-2022, 02-07-2022, 13-08-2022, 13-09-2022, 12-10-2022, 12-11-2022, 13-12-2022, 12-01-2023, 08-02-2023, 05-08-2023\n"
     ]
    }
   ],
   "source": [
    "for i in df2['combine']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "97fb98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop('combine', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "328e893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2['total_frequency'] = df2['frequency of follow up at lgb (to write down follow-up dates)'].apply(lambda x: 0 if pd.isnull(x) else len(str(x).split(',')))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8a6d894c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      12\n",
       "2       4\n",
       "3      67\n",
       "4       2\n",
       "5      70\n",
       "       ..\n",
       "163    10\n",
       "164     5\n",
       "186     3\n",
       "187    22\n",
       "191    25\n",
       "Name: total_frequency, Length: 148, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['total_frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e7687f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days between 29-07-2019 and 24-06-2019: 35 days\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def calculate_days_difference(date1_str, date2_str, date_format=\"%d-%m-%Y\"):\n",
    "    date1 = datetime.strptime(date1_str, date_format)\n",
    "    date2 = datetime.strptime(date2_str, date_format)\n",
    "    days_difference = abs((date2 - date1).days)\n",
    "\n",
    "    return days_difference\n",
    "\n",
    "date2_str = \"24-06-2019\"\n",
    "date1_str = \"29-07-2019\"\n",
    "result = calculate_days_difference(date1_str, date2_str)\n",
    "\n",
    "print(f\"Number of days between {date1_str} and {date2_str}: {result} days\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "02ab9b25",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '21-10-19' does not match format '%d-%m-%Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [114], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m     20\u001b[0m date_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m24-06-2019,29-07-2019,09-09-2019,21-10-19\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 21\u001b[0m consecutive_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mextract_consecutive_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m consecutive_pairs:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsecutive Dates: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [114], line 12\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_format)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Convert the date strings to datetime objects\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [datetime\u001b[38;5;241m.\u001b[39mstrptime(date, date_format) \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Extract pairs of consecutive dates\u001b[39;00m\n\u001b[0;32m     15\u001b[0m consecutive_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(date_objects[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], date_objects[\u001b[38;5;241m1\u001b[39m:])\n",
      "Cell \u001b[1;32mIn [114], line 12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Convert the date strings to datetime objects\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Extract pairs of consecutive dates\u001b[39;00m\n\u001b[0;32m     15\u001b[0m consecutive_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(date_objects[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], date_objects[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    347\u001b[0m found \u001b[38;5;241m=\u001b[39m format_regex\u001b[38;5;241m.\u001b[39mmatch(data_string)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n",
      "\u001b[1;31mValueError\u001b[0m: time data '21-10-19' does not match format '%d-%m-%Y'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_consecutive_dates(date_str, date_format=\"%d-%m-%Y\"):\n",
    "\n",
    "    date_list = date_str.split(',')\n",
    "    if len(date_list) < 2:\n",
    "        return 0\n",
    "\n",
    "    date_objects = [datetime.strptime(date, date_format) for date in date_list]\n",
    "\n",
    "    consecutive_pairs = zip(date_objects[:-1], date_objects[1:])\n",
    "\n",
    "    return consecutive_pairs\n",
    "\n",
    "# Example usage:\n",
    "date_str = \"24-06-2019,29-07-2019,09-09-2019,21-10-19\"\n",
    "consecutive_pairs = extract_consecutive_dates(date_str)\n",
    "\n",
    "for pair in consecutive_pairs:\n",
    "    print(f\"Consecutive Dates: {pair[0].strftime('%d-%m-%Y')} and {pair[1].strftime('%d-%m-%Y')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9041eee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data ' 29-07-2019' does not match format '%d-%m-%Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [115], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency of follow up at lgb (to write down follow-up dates)\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mextract_consecutive_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m a:\n",
      "Cell \u001b[1;32mIn [114], line 12\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_format)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Convert the date strings to datetime objects\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [datetime\u001b[38;5;241m.\u001b[39mstrptime(date, date_format) \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Extract pairs of consecutive dates\u001b[39;00m\n\u001b[0;32m     15\u001b[0m consecutive_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(date_objects[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], date_objects[\u001b[38;5;241m1\u001b[39m:])\n",
      "Cell \u001b[1;32mIn [114], line 12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Convert the date strings to datetime objects\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Extract pairs of consecutive dates\u001b[39;00m\n\u001b[0;32m     15\u001b[0m consecutive_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(date_objects[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], date_objects[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    347\u001b[0m found \u001b[38;5;241m=\u001b[39m format_regex\u001b[38;5;241m.\u001b[39mmatch(data_string)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n",
      "\u001b[1;31mValueError\u001b[0m: time data ' 29-07-2019' does not match format '%d-%m-%Y'"
     ]
    }
   ],
   "source": [
    "for i in df2['frequency of follow up at lgb (to write down follow-up dates)']:\n",
    "    a = extract_consecutive_dates(i)\n",
    "    sum = 0\n",
    "    for pair in a:\n",
    "        sum = sum +  calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e221e0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...\n",
       "2         19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020\n",
       "3      31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...\n",
       "4                                  22-06-2020,30-09-2020\n",
       "5      29-04-2014, 29-05-2014, 04-07-2014, 25-08-14, ...\n",
       "                             ...                        \n",
       "163    28-03-22, 13-07-22, 26-08-22, 11-10-22, 15-05-...\n",
       "164     08-06-22, 26-08-22, 19-12-22, 23-01-23, 02-11-23\n",
       "186                   28-08-2021, 15-07-2022, 17-08-2022\n",
       "187    29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...\n",
       "191    16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...\n",
       "Name: frequency of follow up at lgb (to write down follow-up dates), Length: 148, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['frequency of follow up at lgb (to write down follow-up dates)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c663bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['frequency of follow up at lgb (to write down follow-up dates)'] = df2['frequency of follow up at lgb (to write down follow-up dates)'].str.replace(r'\\s', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "64443556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...\n",
       "2            19-12-2019,01-02-2020,20-03-2020,22-06-2020\n",
       "3      31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...\n",
       "4                                  22-06-2020,30-09-2020\n",
       "5      29-04-2014,29-05-2014,04-07-2014,25-08-14,01-0...\n",
       "                             ...                        \n",
       "163    28-03-22,13-07-22,26-08-22,11-10-22,15-05-23,3...\n",
       "164         08-06-22,26-08-22,19-12-22,23-01-23,02-11-23\n",
       "186                     28-08-2021,15-07-2022,17-08-2022\n",
       "187    29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...\n",
       "191    16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...\n",
       "Name: frequency of follow up at lgb (to write down follow-up dates), Length: 148, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['frequency of follow up at lgb (to write down follow-up dates)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0e48579b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains: 19",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [119], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m     19\u001b[0m date_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m24-06-2019,29-07-15,09-09-21,21-10-15\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 20\u001b[0m consecutive_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mextract_consecutive_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m consecutive_pairs:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsecutive Dates: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [119], line 8\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_format)\u001b[0m\n\u001b[0;32m      5\u001b[0m date_list \u001b[38;5;241m=\u001b[39m date_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convert the date strings to datetime objects with flexible year interpretation\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [datetime\u001b[38;5;241m.\u001b[39mstrptime(date, date_format\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Add '20' to the beginning of 2-digit years\u001b[39;00m\n\u001b[0;32m     11\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [date\u001b[38;5;241m.\u001b[39mreplace(year\u001b[38;5;241m=\u001b[39mdate\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m date\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m date \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_objects]\n",
      "Cell \u001b[1;32mIn [119], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m date_list \u001b[38;5;241m=\u001b[39m date_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convert the date strings to datetime objects with flexible year interpretation\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Add '20' to the beginning of 2-digit years\u001b[39;00m\n\u001b[0;32m     11\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [date\u001b[38;5;241m.\u001b[39mreplace(year\u001b[38;5;241m=\u001b[39mdate\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m date\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m date \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_objects]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:352\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n\u001b[0;32m    355\u001b[0m iso_year \u001b[38;5;241m=\u001b[39m year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m month \u001b[38;5;241m=\u001b[39m day \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: unconverted data remains: 19"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_consecutive_dates(date_str, date_format=\"%d-%m-%Y\"):\n",
    "    date_list = date_str.split(',')\n",
    "    date_objects = [datetime.strptime(date, date_format.replace('%Y', '%y')) for date in date_list]\n",
    "    date_objects = [date.replace(year=date.year + 2000) if date.year < 100 else date for date in date_objects]\n",
    "    consecutive_pairs = zip(date_objects[:-1], date_objects[1:])\n",
    "\n",
    "    return consecutive_pairs\n",
    "\n",
    "date_str = \"24-06-2019,29-07-15,09-09-21,21-10-15\"\n",
    "consecutive_pairs = extract_consecutive_dates(date_str)\n",
    "\n",
    "for pair in consecutive_pairs:\n",
    "    print(f\"Consecutive Dates: {pair[0].strftime('%d-%m-%Y')} and {pair[1].strftime('%d-%m-%Y')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4f744455",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains: 19",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [120], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency of follow up at lgb (to write down follow-up dates)\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mextract_consecutive_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m a:\n",
      "Cell \u001b[1;32mIn [119], line 8\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_format)\u001b[0m\n\u001b[0;32m      5\u001b[0m date_list \u001b[38;5;241m=\u001b[39m date_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convert the date strings to datetime objects with flexible year interpretation\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [datetime\u001b[38;5;241m.\u001b[39mstrptime(date, date_format\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Add '20' to the beginning of 2-digit years\u001b[39;00m\n\u001b[0;32m     11\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [date\u001b[38;5;241m.\u001b[39mreplace(year\u001b[38;5;241m=\u001b[39mdate\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m date\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m date \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_objects]\n",
      "Cell \u001b[1;32mIn [119], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m date_list \u001b[38;5;241m=\u001b[39m date_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convert the date strings to datetime objects with flexible year interpretation\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Add '20' to the beginning of 2-digit years\u001b[39;00m\n\u001b[0;32m     11\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [date\u001b[38;5;241m.\u001b[39mreplace(year\u001b[38;5;241m=\u001b[39mdate\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m date\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m date \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_objects]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:352\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n\u001b[0;32m    355\u001b[0m iso_year \u001b[38;5;241m=\u001b[39m year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m month \u001b[38;5;241m=\u001b[39m day \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: unconverted data remains: 19"
     ]
    }
   ],
   "source": [
    "for i in df2['frequency of follow up at lgb (to write down follow-up dates)']:\n",
    "    a = extract_consecutive_dates(i)\n",
    "    sum = 0\n",
    "    for pair in a:\n",
    "        sum = sum +  calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\n",
    "        print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "88e9007d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains: 19",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [121], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m date_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m24-06-2019,29-07-2019,09-09-19\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 24\u001b[0m consecutive_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mextract_consecutive_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_pairs:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m consecutive_pairs:\n",
      "Cell \u001b[1;32mIn [121], line 12\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_format)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Convert the date strings to datetime objects with flexible year interpretation\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [datetime\u001b[38;5;241m.\u001b[39mstrptime(date, date_format\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Add '20' to the beginning of 2-digit years\u001b[39;00m\n\u001b[0;32m     15\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [date\u001b[38;5;241m.\u001b[39mreplace(year\u001b[38;5;241m=\u001b[39mdate\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m date\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m date \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_objects]\n",
      "Cell \u001b[1;32mIn [121], line 12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Convert the date strings to datetime objects with flexible year interpretation\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Add '20' to the beginning of 2-digit years\u001b[39;00m\n\u001b[0;32m     15\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [date\u001b[38;5;241m.\u001b[39mreplace(year\u001b[38;5;241m=\u001b[39mdate\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m date\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m date \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_objects]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:352\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n\u001b[0;32m    355\u001b[0m iso_year \u001b[38;5;241m=\u001b[39m year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m month \u001b[38;5;241m=\u001b[39m day \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: unconverted data remains: 19"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_consecutive_dates(date_str, date_format=\"%d-%m-%Y\"):\n",
    "    date_list = date_str.split(',')\n",
    "    if len(date_list) < 2:\n",
    "        return 0\n",
    "    date_objects = [datetime.strptime(date, date_format.replace('%Y', '%y')) for date in date_list]\n",
    "    date_objects = [date.replace(year=date.year + 2000) if date.year < 100 else date for date in date_objects]\n",
    "    consecutive_pairs = zip(date_objects[:-1], date_objects[1:])\n",
    "\n",
    "    return consecutive_pairs\n",
    "\n",
    "date_str = \"24-06-2019,29-07-2019,09-09-19\"\n",
    "consecutive_pairs = extract_consecutive_dates(date_str)\n",
    "\n",
    "if consecutive_pairs:\n",
    "    for pair in consecutive_pairs:\n",
    "        print(f\"Consecutive Dates: {pair[0].strftime('%d-%m-%Y')} and {pair[1].strftime('%d-%m-%Y')}\")\n",
    "else:\n",
    "    print(\"Insufficient dates to extract consecutive pairs. Output: 0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "aa7dc499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient dates to extract consecutive pairs. Output: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "date_str = \"\"\n",
    "consecutive_pairs = extract_consecutive_dates(date_str)\n",
    "\n",
    "if consecutive_pairs:\n",
    "    for pair in consecutive_pairs:\n",
    "        print(f\"Consecutive Dates: {pair[0].strftime('%d-%m-%Y')} and {pair[1].strftime('%d-%m-%Y')}\")\n",
    "else:\n",
    "    print(\"Insufficient dates to extract consecutive pairs. Output: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "10b2d2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...\n",
       "2            19-12-2019,01-02-2020,20-03-2020,22-06-2020\n",
       "3      31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...\n",
       "4                                  22-06-2020,30-09-2020\n",
       "5      29-04-2014,29-05-2014,04-07-2014,25-08-14,01-0...\n",
       "                             ...                        \n",
       "163    28-03-22,13-07-22,26-08-22,11-10-22,15-05-23,3...\n",
       "164         08-06-22,26-08-22,19-12-22,23-01-23,02-11-23\n",
       "186                     28-08-2021,15-07-2022,17-08-2022\n",
       "187    29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...\n",
       "191    16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...\n",
       "Name: frequency of follow up at lgb (to write down follow-up dates), Length: 148, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['frequency of follow up at lgb (to write down follow-up dates)'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "42036008",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains: 19",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [124], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency of follow up at lgb (to write down follow-up dates)\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mextract_consecutive_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#sum = 0\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m a:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m#sum = sum +  calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m#print(sum)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [121], line 12\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_format)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Convert the date strings to datetime objects with flexible year interpretation\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [datetime\u001b[38;5;241m.\u001b[39mstrptime(date, date_format\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Add '20' to the beginning of 2-digit years\u001b[39;00m\n\u001b[0;32m     15\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [date\u001b[38;5;241m.\u001b[39mreplace(year\u001b[38;5;241m=\u001b[39mdate\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m date\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m date \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_objects]\n",
      "Cell \u001b[1;32mIn [121], line 12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Convert the date strings to datetime objects with flexible year interpretation\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_list]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Add '20' to the beginning of 2-digit years\u001b[39;00m\n\u001b[0;32m     15\u001b[0m date_objects \u001b[38;5;241m=\u001b[39m [date\u001b[38;5;241m.\u001b[39mreplace(year\u001b[38;5;241m=\u001b[39mdate\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m date\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m date \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m date_objects]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:352\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n\u001b[0;32m    355\u001b[0m iso_year \u001b[38;5;241m=\u001b[39m year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m month \u001b[38;5;241m=\u001b[39m day \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: unconverted data remains: 19"
     ]
    }
   ],
   "source": [
    "for i in df2['frequency of follow up at lgb (to write down follow-up dates)']:\n",
    "    a = extract_consecutive_dates(i)\n",
    "    #sum = 0\n",
    "    for pair in a:\n",
    "        #sum = sum +  calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\n",
    "        #print(sum)\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e0dcdb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-06-2019,29-07-2019,09-09-2019,21-10-2019,17-12-2019,18-01-2020,02-03-2020,02-05-2020,22-06-2020,28-08-2020,17-11-2020,21-01-2021\n",
      "19-12-2019,01-02-2020,20-03-2020,22-06-2020\n",
      "31-03-2014,29-04-2014,29-05-2014,04-07-2014,25-08-2014,01-02-2016,30-03-2016,29-04-2016,03-06-2016,28-08-2016,08-08-2016,08-09-2016,05-10-2016,09-11-2016,16-12-2016,23-01-2017,22-02-2017,10-03-2017,21-04-2017,25-05-2017,22-06-2017,20-07-2017,03-10-2017,02-11-2017,06-01-2018,05-02-2018,08-03-2018,07-04-2018,05-05-2018,07-06-2018,09-08-2018,12-09-2018,09-10-2018,12-11-2018,19-12-2018,17-01-2019,13-06-2019,13-07-2019,17-08-2019,17-08-2019,20-10-2019,30-11-2019,03-01-2020,06-03-2020,22-06-2020,02-04-2021,10-05-2021,06-08-2021,07-09-2021,13-11-2021,17-01-2022,19-03-2022,30-05-2022,04-07-2022,09-08-2022,13-09-2022,27-10-2022,28-11-2022,10-01-2023,13-02-2023,22-03-2023,26-04-2023,05-06-2023,17-07-2023,24-08-2023,25-09-2023,06-11-2023\n",
      "22-06-2020,30-09-2020\n",
      "29-04-2014,29-05-2014,04-07-2014,25-08-14,01-03-16,30-03-16,29-04-16,03-06-16,28-06-16,08-08-16,08-09-16,05-10-16,09-11-16,16-12-16,23-01-17,22-02-17,10-03-17,21-04-17,25-05-17,22-06-17,20-07-17,02-11-17,06-01-18,05-02-18,08-03-18,07-04-18,05-05-18,07-06-18,27-06-18,09-08-18,12-09-18,09-10-18,12-11-18,19-12-18,17-01-19,20-02-19,30-03-19,02-05-19,13-06-19,13-07-19,17-08-19,17-09-19,22-10-19,30-11-19,03-01-2020,28-01-2020,06-03-2020,22-06-2020,02-04-21,10-05-21,06-08-21,07-09-21,13-11-21,17-01-22,19-03-22,30-05-22,04-07-22,09-08-22,13-09-22,27-10-22,28-11-22,10-1-23,13-02-23,23-03-23,26-04-23,05-06-23,17-07-23,24-08-23,25-09-23,06-11-23\n",
      "10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,23-09-15,21-10-15,11-11-15,21-12-15,25-1-16,16-3-16,18-5-16,20-07-16,7-9-16,26-10-16,28-12-16,27-1-17,22-2-17,17-3-17,14-4-17,12-5-17,26-6-17,13-9-17,11-10-17,15-11-17,15-12-17,7-2-18,2-4-18,9-5-18,31-5-18,27-6-18,4-8-18,24-9-18,5-11-18,14-12-18,15-1-19,12-2-19,12-4-19,25-5-19,16-7-19,20-8-19,21-9-19,21-10-19,18-11-19,20-12-19,25-1-2020,24-2-2020,20-03-20,19-05-20,22-06-20,28-07-20,20-10-20,0-11-20,22-12-20,19-1-21,19-2-21,19-03-21,12-04-21,08-05-21,19-07-21,13-08-21,11-10-21,16-11-21,17-12-21,11-01-22,15-03-21,12-04-22,13-06-22,16-07-22,16-08-22,14-11-22,24-01-23,28-02-23,1-04-23,29-05-23,4-07-23,18-08-23,26-09-23,07-11-23\n",
      "8-6-2016,18-7-2016,19-8-2016,14-9-16,4-10-2016,9-11-2016,9-1-2017,10-2-2017,11-3-2017,10-4-2017,11-5-2017,10-6-2017,8-7-2017,5-8-2017,4-9-2017,14-10-2017,4-12-2017,2-1-2018,2-2-2018,3-3-2018,4-4-2018,2-5-2018,2-6-2018,2-7-2018,31-7-2018,30-8-2018,28-9-2018,29-19-2018,28-11-2018,27-12-2018,25-1-2019,26-2-2019,26-3-2019,24-4-2019,27-5-2019,27-6-2019,27-8-2019,25-9-2019,25-10-2019,25-11-2019,24-12-2019,21-1-2020,22-2-2020,23-3-2020,21-4-2020,22-5-2020,22-6-2020,9-1-2021,3-3-2021,12-4-2021,14-6-2021,8-8-2021,14-9-2021,16-10-2021,16-11-2021,3-1-2022,4-2-2022,5-3-2022,5-4-2022,20-5-2022,6-7-2022,3-8-2022,2-9-2022,30-9-2022,2-11-2022,8-12-2022,28-12-2023,4-2-2023,4-3-2023,4-5-2023,27-5-2023,4-7-2023,1-8-2023,2-9-2023,3-10-2023,1-11-2023\n",
      "nan\n",
      "27-12-2019,17-3-2020,22-06-2020,14-12-2020,22-01-2021,6-11-2023\n",
      "27-02-2020,22-06-2020\n",
      "14-02-2020,22-06-2022\n",
      "08-03-2018,13-06-2019,28-06-2019,22-06-2022,26-11-2020,11-08-2022,06-07-2023\n",
      "22.06.2020\n",
      "15-10-12,9-1-13,4-2-13,7-3-13,5-4-13,6-5-13,5-6-13,4-7-13,3-8-13,2-9-13,3-10-13,2-11-13,21-11-13,11-3-15,3-4-15,22-4-15,14-5-15,5-6-15,13-7-15,19-8-15,22-9-15,21-10-15,20-11-15,21-12,15,19-1-16,18-2-16,3-3-16,2-4-19,6-5-16,7-3-17,13-4-17,17-5-17,19-6-17,20-7-17,16-8-17,13-9-17,14-10-17,28-10-17,28-11-17,30-12-17,31-1-18,5-3-18,4-4-18,12-4-18,2-5-18,28-5-18,2-7-18,31-7-18,30-08-18,29-10-18,28-11-18,29-12-18,29-01-19,28-2-19,29-3-19,27-4-19,27-5-19,26-6-19,25-7-19,26-8-19,25-9-19,26-10-19,22-11-19,25-12-19,20-1-20,22-2-20,21-4-20,22-05-20,22-6-20,16-11-20,11-01-21,21-03-21,12-06-23,30-07-23,04-08-23,18-08-23,19-09-23,18-10-23\n",
      "07.03.2019,24.01.2020,04.02.2020,03.03.2020,14.05.2020,22.06.2020,28.09.2020,20.02.2021,17.05.2021,19.8.2021,06.07.2022,14.08.2023\n",
      "30-08-18,03-10-18,17-11-18,20-12-18,31-01-19,15-03-19,1-05-19,29-06-19,25-09-19,21-10-19,05-12-19,24-01-2020,22-06-2020,06-10-2020,23-11-2020,09-03-21,11-05-21,28-07-21,04-10-21,26-11-21,29-01-22,10-03-22,20-04-22,26-05-22,18-07-22,07-09-22,10-10-22,23-11-22,04-1-23,02-03-23,20-04-23,09-06-23,04-08-23,23-09-23,04-11-23\n",
      "18-02-2020,21-03-2020,09-05-2020,22-06-2020,03-09-2020\n",
      "22-06-2020,31-08-2020,14-09-2020,28-10-2020,20-11-2020,12-03-2020,19-03-2021\n",
      "08-12-2020,16-10-2021,10-11-2021,13-12-2021,17-01-2022,16-07-2021,16-08-2021,13-9-2021,14-5-2022,15-6-2022,15-7-2022,16-2-2022,15-3-2022,18-4-2022,12-10-2022,11-11-2022,13-12-2022,9-1-2023,12-8-2022,12-9-2022,10-4-2023,8-5-2023,10-6-2023,8-7-2023,11-2-2023,4-3-2023,5-8-2023,29-8-2023,7-10-2023,4-11-2023\n",
      "03-07-17,11-09-17,19-03-18,04-05-18,20-06-18,03-08-18,18-09-18,09-10-18,28-11-18,07-02-19,13-04-19,23-05-19,09-07-19,15-11-19,04-10-19,15-11-19,17-12-19,23-01-2020,04-03-2020,22-04-2020,22-06-2020,26-09-2020,19-11-2020,29-12-2020,04-02-21,06-03-21,12-04-21,29-05-21,09-07-21,27-08-21,06-10-21,17-11-21,23-12-21,12-1-22,05-02-22,19-02-22,22-03-22,02-05-22,13-06-22,16-07-22,23-08-22,16-08-22,26-09-22,05-10-22,28-10-22,08-11-22,07-02-23,05-04-23,29-05-23,04-07-23,18-07-23,15-09-23,\n",
      "28-11-2018,03-05-2019,06-06-2019,23-07-2019,14-09-2019,12-10-2019,16-11-2019,21-12-2019,31-01-2020,02-03-2020,22-06-2020,24-03-2021,24-04-2021,06-08-2022,27-08-2022,24-09-2022,05-11-2022,19-11-2022,24-12-2022,28-01-2023,06-03-2023,12-04-2023,12-04-2023,15-06-2023,26-07-2023,04-09-2023,16-09-2023,13-10-2023\n",
      "05-06-2014,27-06-2014,30-07-2014,02-09-2014,08-10-2014,14-11-2017,30-12-2014,27-02-2015,03-04-2015,09-05-2015,25-06-2015,31-07-2015,01-10-2015,09-11-2015,01-01-2016,12-02-2016,18-03-2016,19-04-2016,07-05-2016,04-06-2016,11-07-2016,05-08-2016,03-09-2016,13-10-2016,09-11-2016,07-12-2016,02-01-2017,01-02-2017,03-03-2017,31-03-2017,10-05-2017,03-06-2017,04-07-2017,08-09-2017,29-06-2018,09-08-2018,18-09-2018,20-10-2018,23-11-2018,30-11-2018,09-02-2019,02-04-2019,27-05-2019,18-06-2019,19-06-2019,26-07-2019,09-09-2019,10-10-2019,16-11-2019,26-11-2019,24-12-2019,04-02-2020,19-03-2020,18-05-2020,22-06-2020,15-10-2020,16-11-2020,17-12-2020,16-01-2021,25-02-2021,19-05-2021,31-07-2021,13-11-2021,20-12-2021,10-01-2022,09-03-2022,12-04-2022,20-06-2022,25-08-2022,09-11-2022,15-02-2023,03-05-2023,04-07-2023,24-08-2023\n",
      "23-11-2015,28-12-2015,15-02-2016,11-04-2016,25-05-2016,24-06-2016,06-07-2016,03-08-2016,08-09-2016,13-10-2016,10-11-2016,12-12-2016,18-01-2017,02-03-2017,10-04-2017,03-05-2017,29-05-2017,05-06-2017,03-07-2017,02-08-2017,04-09-2017,06-11-2017,04-12-2017,05-01-2018,14-02-2018,02-04-2018,01-06-2018,02-06-2018,04-07-2018,02-08-2018,06-09-2018,09-10-2018,07-11-2018,10-01-2019,11-02-2019,18-03-2019,26-04-2019,28-05-2019,18-06-2019,28-08-2019,04-10-2019,08-11-2019,11-12-2019,16-01-2020,15-02-2020,29-02-2020,22-04-2020,05-05-2020,22-06-2020,21-07-2020,29-08-2020,21-10-2020,15-11-2020,22-12-2020,22-01-2021,06-03-2021,02-04-2021,08-05-2021,25-01-2022,23-08-2022,19-12-2022,24-07-2023,05-10-2023\n",
      "13-06-2018,18-08-2018,23-08-2018,19-09-2018,24-10-2018,20-02-2019,13-03-2019,06-04-2019,25-05-2019,31-07-2019,13-09-2019,08-10-2019,17-12-2019,07-01-2020,13-03-2020,11-05-2020,22-06-2020,11-09-2020,23-01-2021,24-03-2021,14-04-2021,12-06-2021,14-06-2021,20-08-2021,10-09-2021,28-09-2021,16-11-2021,01-12-2021,03-12-2021,17-12-2021,31-12-2021,18-02-2022,22-02-2022,11-03-2022,25-03-2022,23-04-2022,01-07-2022,13-08-2022,31-12-2022,12-05-2023,09-06-2023,27-07-2023\n",
      "17-03-2020,15-06-2020,22-06-2020,24-06-2020,01-07-2020,03-08-2020,24-08-2020,\n",
      "04-01-2020,06-02-2020,11-03-2020,22-06-2020,27-08-2020,30-10-2020,07-01-2021,24-02-2021,02-02-2022\n",
      "21-11-2016,21-12-2016,21-1-2017,28-2-2017,31-3-2017,2-5-2017,1-6-2017,5-7-2017,12-8-2017,8-9-2017,18-10-2017,21-11-2017,28-12-2017,31-1-2018,21-3-2018,23-4-2018,31-5-2018,6-6-2018,3-7-2018,25-9-2018,5-11-2018,18-12-2018,29-1-2019,6-3-2019,3-4-2019,19-4-2019,25-5-2019,29-6-2019,9-8-2019,24-9-2019,29-10-2019,1-12-2019,6-1-2020,14-2-2020,12-6-2020,30-10-2020,11-12-2020,18-1-2021,19-3-2021,13-4-2021,3-8-2021,6-11-2021,11-12-2021,4-2-2022,14-6-2022,20-7-2022,24-8-2022,12-11-2022,4-1-2023,18-5-2023,21-6-2023-11-10-2023\n",
      "23.09.2017,23.10.2017,24.11.2017,05.10.2018,22.09.2021,28.10.2021,13.01.2022\n",
      "19.07.2017,15.09.2017,13.11.2017,13.06.2019,18.07.2019,21.11.2019,31.12.2019,11.03.2020,23.10.2020,05.04.2021,28.10.2021,11.10.2022,23.06.2023,26.07.2023,28.08.2023,10.10.2023,17.11.2023\n",
      "21-11-2014,17-12-2014,15-01-2015,14-02-2015,24-03-2015,13-04-2015,04-05-2015,04-06-2015,23-07-2015,06-08-2015,07-09-2015,03-10-2015,03-11-2015,07-12-2015,24-01-2016,30-01-2016,04-03-2016,05-04-2016,07-05-2016,06-06-2016,30-06-2016,30-07-2016,05-09-2016,23-09-2016,24-10-2016,07-12-2016,30-01-2017,07-03-2017,20-04-2017,17-07-2019,21-09-2019,21-09-2019,19-10-2019,22-11-2019,23-12-2019,22-01-2020,19-02-2020,13-03-2020,23-04-2020,16-06-2020,01-08-2020,02-09-2020,27-11-2020,25-12-2020,04-02-2021,25-02-2021,01-04-2021,22-04-2021,08-05-2021,11-06-2021,19-07-2021,17-08-2021,25-09-2021,28-10-2021,03-12-2021,-4-01-2022,03-02-2022,10-03-2022,14-04-2022,06-05-2022,08-06-2022,09-07-2022,17-08-2022,23-09-2022,02-11-2022,09-12-2022,30-12-2022,15-02,2023,13-03-2023,1-04-2023,04-05-2023,18-05-2023\n",
      "28-10-21,03-01-22,18-05-22,20-06-22,25-08-22\n",
      "21.04.2016,16.05.2016,23.05.2017,24.07.2017,19.02.2018,26.03.2018,30.11.2018,12.01.2019,02.01.2019,20.02.2020,15.06.2020,11.02.2021,07.10.2021,28.10.2021,03.12.2021,30.12.2021,17.02.2022,24.03.2022,12.05.2022,29.08.2022,06.10.2022,03.05.2023,16.11.2023,27.11.2023\n",
      "25-3-2019,22-4-2019,21-5-2019,28-6-2019,9-8-2019,9-9-2019,11-10-2019,5-11-2019,4-12-2019,6-1-2019,10-2-2020,6-7-2020,24-11-2020,12-1-2021,26-4-2021,30-7-2021,28-9-2021,28-10-2021,28-12-2021,25-2-2022,25-4-2022,25-5-2022,27-6-2022,27-7-2022,26-8-2022,2-11-2022,2-1-2023,27-2-2023,17-4-2023,29-5-2023,27-6-2023,27-9-2023,25-10-2023,27-11-2023\n",
      "28-08-21,28-10-21,27-12-21,27-1-22,25-04-22,27-06-22,26-08-22,26-10-22,18-11-22,10-04-23,19-10-23\n",
      "28-10-21,29-11-21,05-01-22,05-09-22,09-03-22,09-04-22\n",
      "30-09-21,28-10-21,13-12-21,29-01-21\n",
      "30-9-2021,28-10-2021,6-2-2023\n",
      "8.9.21,20.9.2021,28.10.2021,17.2.2022,4.9.2023,12.9.2023\n",
      "05-07-21,03-09-21,28-10-21,02-12-21,31-01-22,31-03-22,31-05-22,28-06-22,29-12-22,13-02-23,02-06-23,25-07-23\n",
      "3-5-2021,12-7-2021,28-10-2021,24-1-2022,5-5-2022,21-7-2022\n",
      "12-12-2022,26-12-2022,16-1-2023,16-2-2023\n",
      "18-7-2022,27-7-202217-8-2022,15-9-2022,6-10-2022,14-10-2022,16-11-2022,21-11-2022,17-12-2022,13-1-2023,18-1-2023,16-2-2023,15-3-2023,17-4-2023,7-6-2023,31-7-2023,11-8-2023,19-8-2023,20-9-2023,18-10-2023,4-11-2023,2-12-2023\n",
      "21-7-2022,16-2-2023,18-5-2023,5-10-2023\n",
      "nan\n",
      "8-11-2021,30-11-2021,30-12-2021,29-1-2022,1-3-2022,31-3-2022,5-5-2022,11-6-2022,5-7-2022,4-8-2022,5-9-2022,10-10-2022,10-11-2022,5-12-2022,14-1-2023,16-2-2023,27-3-2023,6-5-2023,10-6-2025\n",
      "16-1-2023,16-3-2023\n",
      "2-2-2021,8-5-2021,14-9-2021,5-4-2021,-5-5-2021,28-6-2022,24-8-2022,31-10-2022,16-2-2023,8-5-2023,11-7-2023,1-11-2023\n",
      "14-3-2019,23-12-2019,5-5-2022,25-6-2022,29-8-2022,31-10-2022,15-12-202216-2-2023\n",
      "5-4-2022,5-5-2022,2-6-2022,1-7-2022,15-7-2022,26-7-2022,4-8-2022,11-8-2022,18-8-2022,25-8-2022,6-9-2022,13-10-2022,10-11-2022,24-12-2022,16-2-2023,5-5-2023,28-7-2023,18-10-2023\n",
      "17-1-2023,16-2-2023,3-3-2023,3-4-2023,19-5-2023,24-6-2023,29-7-2023,7-9-2023\n",
      "16.02.2023,27.03.2023,15.05.2023\n",
      "16.02.2023,6.3.2023,22.3.2023,31.3.2023,28.4.2023,16.6.23,1.9.2023,24.10.2023\n",
      "28-12-2020,13-4-2021,25-7-2022,16-2-2023\n",
      "16.2.2023,10.3.2023,17.4.2023,5.6.2023\n",
      "15-9-2022,17-11-2022,20-12-2022,16-2-2023,18-4-2023,27-7-2023\n",
      "20-5-2017,21-6-2017,25-8-2018,1-9-2018,12-9-2018,22-10-2018,23-11-2018,31-12-2018,16-2-2019,22-3-2019,3-7-2019,3-8-2019,11-9-2019,15-10-2019,15-11-2019,23-12-2019,31-1-2020,22-2-2020,9-3-2020,23-4-2020,15-6-2020,18-8-2020,17-10-2020,3-12-2020,28-12-2020,25-1-2021,25-2-2021,7-4-2021,19-6-2021,4-8-2021,6-9-2021,13-10-2021,17-11-2021,30-12-2021,19-2-2022,24-3-2022,21-4-2022,26-5-2022,2-6-2022,9-8-2022,22-9-2022,17-11-2022,7-1-2023,16-2-2023,21-3-2023,29-4-2023,26-8-2023,7-10-2023,4-12-2023\n",
      "8-7-2022,8-8-2022,8-9-2022,18-10-2022,14-11-2022,12-12-2022,11-1-2023,16-2-2023,4-4-2023,17-6-2023,7-8-2023,27-11-2023\n",
      "7-2-2023,21-2-2023\n",
      "21.5.2022,1.6.2022,22.6.2022,21.7.2022,27.8.2022,30.7.2022,30.9.2022,1.11.2022,2.12.2022,6.1.2023,16.2.2023,23.3.2023,29.4.2023,10.6.2023,17.7.2023,28.8.2023,9.10.2023,27.11.2023\n",
      "16.2.2023,16.3.2023,17.4.2023,15.5.2023\n",
      "nan\n",
      "24-4-2017,16-5-2017,8-10-2018,7-11-2018,10-12-2018,12-1-2019,28-3-2019,30-4-2019,30-5-2019,1-7-2019,5-8-2019,7-9-2019,7-10-2019,11-11-2019,18-12-2019,20-1-2020,17-2-2020,17-3-2020,18-6-2020,16-9-2020,10-11-2020,28-12-2020,2-1-2021,2-2-2021,22-3-2021,26-4-2021,8-6-2022,8-7-2022,11-8-2022,9-9-2022,30-9-2022,30-11-2022,10-1-2023,16-2-2023,25-3-2023,26-4-2023,30-5-2023,1-7-2023,5-8-2023,7-9-2023,25-10-2023\n",
      "16.2.2023,3.3.2023,13.6.2023\n",
      "29-12-2017,11-1-2022,12-1-2022,16-2-2023,18-2-2023\n",
      "4-5-2022,21-6-2022,21-7-2022,20-08-2022,17-10-2022,16-11-2022,19-12-2022,17-1-2-2023,16-2-2023,18-3-2023,18-4-2023,16-5-2023,16-6-2023,13-7-2023,7-8-2023,31-8-2023,1-11-2023,2-12-2023\n",
      "22-9-2022,20-10-2022,17-11-2022,21-12-2022,16-2-2023,7-4-2023,18-7-2023,17-8-2023,13-10-2023\n",
      "11-1-2018,8-2-2019,10-3-2019,6-4-2019,4-5-2019,13-7-2019,11-2-2020,2-5-2022,30-8-2022,29-92022,16-2-2023,20-4-2023\n",
      "12-1-2023,16-2-2023,30-3-2023,07-5-2023,2-6-2023,13-7-2023,21-8-2023,25-9-2023,3-11-2023\n",
      "13-5-2022,11-6-2022,15-7-2022,16-8-2022,17-1-2023,18-1-2023,16-2-2023\n",
      "06-07-15,02-09-15,16-10-15,25-12-15,08-03-16,13-06-16,16-08-16,24-09-16,10-10-16,2-11-16,12-12-16,18-01-17,20-02-17,24-03-17,05-05-17,06-06-17,11-07-17,14-08-17,22-09-17,22-11-17,02-01-18,02-02-18,11-04-18,31-05-18,02-07-18,06-08-18,18-09-18,22-10-18,18-11-18,01-01-19,08-02-19,18-03-19,23-04-19,23-05-19,19-06-19,29-07-19,11-09-19,31-10-19,25-12-19,13-02-2020,04-03-20,22-04-20,16-06-20\n",
      "27-11-2019,24-1-2020,3-3-2020,22-4-2020,16-6-2020,29-7-2020,3-11-2020,17-11-2020,29-12-2020,10-2-2021,16-3-2021,31-3-2021,30-3-2022,27-5-2022,8-7-2022,22-8-2022,27-9-2022,11-11-2022,14-12-2022,18-1-2023,28-2-2023,18-4-2023,20-7-2023,26-9-2023,6-12-2023\n",
      "04-04-08,12-05-18,23-06-18,28-07-18,15-09-18,12-03-2020,22-04-2020,07-06-2020\n",
      "28-1-2019,2-3-2019,9-4-2019,29-5-2019,2-9-2019,30-9-2019,27-11-2019,24-12-2019,31-1-2020,4-2-2020,22-4-2020,9-6-2020,8-10-2020,27-11-2020,28-12-2020,29-1-2021,27-2-2021,30-3-2021,4-5-2021,11-6-2021,9-8-2021,7-10-2021,10-11-2021,15-12-2021,4-2-2022,16-3-2022,21-4-2022,3-6-2022,28-6-2022,4-8-2022,29-9-2022,1-11-2022,15-12-2022,14-1-2023,25-2-2023,11-4-2023,25-5-2023,26-3-2023,25-7-2023,8-9-2023,6-10-2023,4-11-2023,14-12-2023\n",
      "17-04-10,18-09-10,27-10-10,27-11-10,12-09-17,12-10-17,27-10-17,22-12-17,25-01-18,10-03-18,24-04-18,21-05-18,04-07-18,13-08-18,12-09-18,06-10-18,14-11-18,21-12-18,28-01-19,15-03-19,24-04-19,31-05-19,09-07-19,26-08-19,15-10-19,30-12-19,02-03-20,22-04-20,25-05-20,12-08-20,08-10-20,30-10-20,09-01-21,08-02-21,08-03-21,08-04-21,05-05-21,21-06-21,28-09-21,03-12-21,27-01-22,17-04-22,09-05-22,13-07-22,13-09-22,14-11-22,27-01-23,18-03-23,29-06-23,24-07-23,02-09-23,29-09-23,14-11-23,20-12-23\n",
      "6-8-2011,14-8-2019,15-6-2020,18-1-2021,24-2-2021,1-3-2021,8-3-2021,30-4-2021,2-6-2021,3-6-2021,18-6-2021\n",
      "16-5-2018,15-6-2018,16-7-2018,16-8-2018,15-09-2018,15-11-2018,5-3-2019,3-4-2019,2-5-2019,27-5-2019,27-6-2019,27-7-2019,27-8-2019,31-8-2019,13-9-2019,26-10-2019,30-11-2019,27-12-2019,27-1-2020,29-2-2020,22-4-2020,16-12-2020,3-5-2022,19-5-2022,17-6-2022,16-7-2022,9-8-2022,3-9-2022,3-10-2022,2-11-2022,6-12-2022,4-1-2023,9-2-2023,9-3-2023,3-4-2023,24-4-2023,5-6-2023,4-7-2023,7-8-2023,6-9-2023,5-10-2023,4-11-2023,4-12-2023\n",
      "15-12-2007,12-1-2008,2-2-2008,11-12-2010,13-3-2013,13-4-2013,11-5-2013,12-6-2013,13-7-2013,14-8-2013,19-8-2013,14-9-2013,17-10-2013,16-11-2013,18-12-2013,18-1-2014,19-2-2014,23-4-2014,24-5-2014,28-6-2014,30-7-2014,30-8-2014,1-10-2014,29-10-2014,29-11-2014,31-12-2014,3-2-2015,7-3-2015,9-6-2015,11-7-2015,14-8-2015,29-9-2015,3-11-2015,5-12-2015,5-1-2016,8-1-2016,16-2-2016,21-3-2016,23-4-2016,31-5-2016,11-7-2016,9-8-2016,10-9-2016,22-10-2016,7-1-2017,14-3-2017,6-5-2017,7-7-2017,8-8-2017,12-9-2017,14-10-2017,7-2-2018,20-3-2018,2-5-2018,8-6-2018,20-7-2018,28-12-2018,8-1-2019,25-1-2019,15-3-2019,30-4-2019,7-6-2019,11-7-2019,13-8-2019,3-10-2019,7-11-2019,4-1-2020,24-3-2020,22-4-2020,11-7-2020,19-11-2020,28-8-2021,25-9-2021,26-10-2021,30-10-2021,3-11-2021,10-11-2021,27-11-2021,28-12-2021,28-1-2022,28-2-2022,28-3-2022,28-4-2022,28-5-2022,29-6-2022,28-7-2022,30-8-2022,30-9-2022,9-11-2022,14-12-2022,19-1-2023,20-2-2023,4-4-2023,3-5-2023,6-6-2023,6-7-2023,7-8-2023,7-9-2023,11-10-2023,20-11-2023,18-12-2023\n",
      "17-7-2020,5-7-2021,16-8-2021,17-9-2021,6-11-2021,8-12-2021,2-2-2022,28-2-2022\n",
      "12-1-2008,2-2-2010,11-12-2010,13-3-2013,13-4-2013,11-5-2013,12-6-2013,13-7-2013,14-8-2013,19-8-2013,14-9-2013,17-10-2013,14-9-2013,17-10-2013,16-11-2013,18-1-2014,19-2-2014,23-4,2014,24-5-2014,23-6-2014,30-7-2014,30-8-2014,1-10-2014,29-10-2014,29-11-2014,31-12-2014,3-1-2015,7-3-2015,18-4-2015,9-6-2015,11-7-2015,14-8-2015,29-9-2015,3-11-2015,5-12-2015,5-1-2016,8-1-2016,16-2-2016,21-3-2016,23-4-2016,31-5-2016,11-7-2016,9-8-2016,10-5-2016,22-10,22-10-2016,7-1-2017,14-3-2017,6-5-2017,7-7-2017,8-8-2017,12-9-2017,14-10-2017,7-2-2018,7-2-2018,20-3-2018,2-5-2018,8-6-2018,20-7-2018,28-12-2018,8-1-2018,25-1-2019,15-3-2019,30-4-2019,30-4-2019,7-6-2019,11-7-2019,13-8-2019,3-10-2019,7-11-2019,4-1-2020,24-3-2020,22-4-2020,11-7-2020,19-11-2020,19-11-2020,8-3-2021,28-8-2021,25-9-201,25-9-2021,26-10-2021,30-10-2021,3-11-2021,10-11-2021,27-11-2021,28-12-2021,28-1-2022,28-2-2022,28-3-2022,28-4-2022,28-5-2022,28-6-2022,28-7-2022,30-8-2022,30-9-2022,9-11-2022,14-12-2022,19-1-2023,20-2-2022,4-4-2023,3-5-2023,6-6-2023,6-7-2023,7-8-2023,7-9-2023,11-10-2023,20-11-2023,18-12-2023\n",
      "7.10.2020,,6.11.2020,27.11.2020,11.1.2021,4.2.2021,3.3.2021,26.4.2021,18.5.2021,23.6.2021,6.7.2021,27.8.2021,20.9.2021,19.10.2021,13.11.2021,27.11.2021,11.12.2021,14.1.2022,18.2.2022,21.3.2022,5.5.2022,2.6.2022,5.7.2022,29.7.2022,8.9.2022,7.10.2022,5.11.2022,5.12.2022,10.1.2023,28.2.2023,18.3.2023,22.5.2023,4.7.2023,3.8.2023,9.9.2023,30.10.2023,25.11.2023\n",
      "15.12.2021,12.3.2022,5.5.2022,1.8.2022,19.8.2022,30.12.2022,14.2.2023,21.3.2023,6.5.2023,19.7.2023,16.9.2023,3.11.2023,21.12.2023\n",
      "17.1.2022,22.2.2022,4.4.2022,5.5.2022,24.6.2022,20.8.2022,3.11.2022,31.1.2023,3.5.2023,7.9.2023\n",
      "1-4-2022,4-5-2022,5-5-2022,23-5-2022,26-9-2022,9-12-2022,16-12-2022,23-12-2022,11-7-2023\n",
      "5-2-2022,5-5-2022\n",
      "12.1.2019,1.2.2019,21.12.2021,19.1.2022,12.2.2022,16.3.2022,5.5.2022\n",
      "17.6.2109,23.7.2019,27.8.2019,24.9.2019,26.10.2019,25.11.2019,26.12.2019,27.1.2020,13.3.2020,23.4.2020,19.5.2020,19.6.2020,22.7.2020,25.7.2020,14.10.2020,17.12.2020,18.1.2021,16.2.2021,19.3.2021,20.4.2021,20.5.2021,1.11.2021,24.11.2021,28.1.2022,8.4.2022,5.5.2022,10.6.2022,13.7.2022,5.9.2022,7.10.2022,10.11.2022,14.12.2022,13.1.2023,13.2.2023,13.3.2023,21.4.2023,23.5.2023,27.6.2023,1.8.2023,31.8.2023,10.10.2023,17.11.2023\n",
      "4-4-2022,5-5-2022,4-6-2022,5-7-2022,4-8-2022,5-9-2022,10-10-2022,15-11-2022,18-2-2023,17-3-2023,17-7-2023,28-8-2023,5-10-2023,1-11-2023,16-12-2023\n",
      "15-11-2021,18-1-2022,23-7-2022,30-8-2022,16-11-2022,16-2-2023,3-5-2023,31-10-2023,29-12-2023\n",
      "11-1-2022,5-5-2022,22-11-2022,24-3-2023,12-6-2023,11-9-2023,16-10-2023,6-12-2023\n",
      "2-8-2021,7-10-2021,8-11-2021,13-12-2021,17-1-2022,3-2-2022,25-2-2022,31-3-2022,5-5-2022,11-6-2022,14-7-2022,17-8-2022,16-9-2022,19-10-2022,19-11-2022,21-12-2022,23-1-2023,23-2-2022,24-3-2023,24-4-2023,24-5-2023,27-6-2023,26-7-2023,26-8-2023,30-9-2023,27-10-2023,30-11-2023\n",
      "29-1-2021,31-12-2021,31-1-2022,7-3-2022,8-4-2022,5-5-2022,9-6-2022,3-9-2022,7-11-2022,9-12-2022,14-2-2023,24-4-2023,11-7-2023\n",
      "26-5-2018,2-6-2018,2-7-2018,31-7-2018,31-8-2018,28-9-2018,29-10-2018,26-11-2018,24-12-2018,23-1-2019,25-2-2019,23-3-2019,26-4-2019,6-6-2019,21-8-2019,18-11-2019,4-1-2020,28-1-2020,23-2-2021,20-3-2021,13-4-2021,10-9-2021,23-10-2021,25-11-2021,2012-20-12-2021,8-2-2022,11-3-2022,13-4-2022,5-5-2022,4-6-2022,8-7-2022,-8-8-2022,10-9-2022,11-10-2022,12-11-2022,10-1-2023,10-4-2023,21-6-2023,26-8-2023,23-11-2023\n",
      "5-5-2022,27-6-2022,18-11-2022,14-3-2023,26-4-2023\n",
      "5-5-2022,4-7-2022\n",
      "5-5-2022,2-6-2022,30-12-2022,5-1-2023,12-6-2023,20-6-2023,\n",
      "8-9-2021,12-11-2021,5-5-2022,9-8-2022,7-10-2022,13-12-2022,24-3-2023,26-6-2023,12-10-2023\n",
      "28-11-2020,11-11-2021,16-11-2021,3-1-2022,12-7-2022,3-3-2023,16-3-2023,6-4-2023\n",
      "3.1.2022,31.1.2022,11.3.2022,26.4.2022,13.6.2022,25.7.2022,5.9.2022,28.10.2022,24.1.2023\n",
      "28.12.20,8.1.21,20.2.21,20.3.21,20.4.21,2.9.21,1.11.21,3.1.22,2.3.22,2.5.22,31.5.22,28.6.22,28.7.22,26.8.22,22.9.22,21.10.22,21.12.22,23.1.23,18.2.23,24.3.23,21.4.23,23.5.23,22.6.23,22.7.23,21.8.23,22.9.23,21.10.23,21.11.23,21.12.23,19.1.24\n",
      "04.01.21,13-03-21,11-09-21,25-10-21,03-01-22,21-04-22,23-06-22,22-08-22,24-10-22,09-12-22,16-01-23,31-03-23,17-05-23,03-07-23,21-08-23,13-10-23,28-11-23\n",
      "30-12-2020,30-1-2021,2-3-2021,2-4-2021,3-5-2021,3-6-2021,3-7-2021,3-8-2021,3-9-2021,3-11-2021,3-1-2022,1-4-2022,11-6-2022,6-12-2022,9-2-2023,29-5-2023,19-9-2023,16-1-2024\n",
      "20-5-2020,23-6-2020,29-7-2020,9-9-2020,10-10-2020,12-11-2020,30-11-2020,12-1-2021,17-2-2021,26-3-2021,19-4-2021,1-6-2021,29-6-2021,27-7-2021,16-8-2021,4-10-2021,1-112021,3-1-2022,15-2-2022,18-3-2022,18-4-2022,19-5-2022,27-6-2022,12-9-2022,22-10-2022,31-1-2023,4-4-2023,30-6-2023\n",
      "17.12.2021,3.1.2022\n",
      "3.1.2022,5.3.2022\n",
      "27-3-2019,29-4-2019,28-6-2019,31-7-2019,5-9-2019,4-10-2019,9-11-2019,21-12-2019,29-2-2020,10-8-2020,3-1-2022\n",
      "25.06.21,26.06.21,20.7.21,24.09.21,14.10.21,6.11.21,6.12.21,3.1.22,4.3.22,2.5.22,6.6.22,1.7.22,25.7.22,10.9.22,10.10.22,8.11.22,2.12.22,5.1.23,21.2.23,30.3.23,3.5.23,1.6.23,7.7.23,2.8.23,4.9.23,9.10.23,6.11.23,11.12.23,10.1.24\n",
      "nan\n",
      "25.3.2021,11.6.2021,3.8.2021,20.9.2021,3.1.2022,3.3.2022,10.3.2022,11.12.2023\n",
      "28-10-2021,3-1-2022,18-5-2022,20-6-2022,25-8-2022\n",
      "3-1-2022,17-1-2022,21-1-2022\n",
      "26-10-20,20-11-20,21-12-20,07-01-21,22-1-21,29-1-21,08-02-21,11-02-21,22-02-21,24-09-21,03-01-22,10-01-22,22-07-22,25-09-23\n",
      "8-8-17,5-9-17,5-10-17,30-10-17,29-11-17,28-12-17,1-2-18,13-2-18,19-3-18,17-4-18,15-5-18,9-6-18,10-7-18,06-8-18,5-9-18,28-9-18,29-10-18,30-11-18,27-12-18,2-2-19,5-4-19,3-5-19,27-5-19,18-6-19,15-7-19,17-8-19,07-9-19,3-10-19,6-11-19,6-12-19,4-1-2020,4-2-20,7-3-20,3-7-20,28-8-20,27-11-20,5-2-21,9-4-21,3-8-21,22-10-21,3-1-22,6-5-22,30-7-22,21-10-22,27-1-23,18-4-23,25-10-23,2-2-24\n",
      "17-5-2021,18-6-2021,13-9-2021,28-9-2021,11-10-2021,5-11-2021,3-1-2022,1-2-2022,28-2-2022,29-4-2022,30-5-2022,1-7-2022,1-8-2022,30-8-2022,30-9-2022,1-11-2022,2-12-2022,3-1-2023,6-2-2023,21-3-2023,2-5-2023,11-8-2023,22-9-2023,1-11-2023,9-1-2024\n",
      "21-8-2020,20-10-2020,20-11-2020,19-12-2020,25-1-2021,23-2-2021,23-3-2021,20-4-2021,20-5-2021,19-6-2021,23-7-2021,24-8-2021,5-10-2021,23-11-2021,23-12-2021,24-1-2022,24-2-2022,10-5-2022,7-7-2022,8-8-2022,7-9-2022,11-10-2022,22-11-2022,3-1-2023,6-2-2023,22-3-2023,1-5-2023,30-5-2023,5-7-2023,7-8-2023,12-9-2023,30-5-20235-7-2023,27-10-2023,27-11-2023\n",
      "3-1-2022,25-5-2022\n",
      "2012-2021,3-1-2022,22-6-2022,31-8-2022,21-3-2023,21-4-2023,22-5-2023,22-6-2023,20-7-2023,28-1-2023,21-9-2023,21-11-202316-1-2024\n",
      "1-11-2021,1-12-2021,3-1-2022,31-1-2022,8-3-2022,9-4-2022,8-8-2022,10-9-2022,7-10-2022,8-11-2022,10-12-2022,11-1-2023,8-2-2023,9-3-2023,8-4-2023,13-5-2023,3-6-2023,18-7-2023,22-8-2023\n",
      "13-07-2021,13-08-2021,14-09-2021,19-10-2021,22-10-2021,26-10-2021,03-01-2022,15-02-2022,17-02-2022,25-03-2022,31-03-2022,30-05-2022,22-07-2022,23-07-2022,25-07-2022,26-07-2022,17-10-2022,26-12-2022,10-02-2023,15-05-2023,27-06-2023\n",
      "3-1-2022,3-2-2022,3-3-2022,13-4-2022,15-9-2023,6-11-2023\n",
      "nan\n",
      "19-7-2021,21-9-2021,3-1-2022,16-7-2022,11-8-2022,7-09-2022,8-10-2022,6-12-2022,7-1-2023,13-4-2023.11-5-2023,11-7-2023,10-8-2023-14-12-2023,11-1-2024,9-2-2024\n",
      "19.1.2022,16.2.2022,6.5.2022,23.6.2022,26.7.2022,15.9.2022,14.11.2022,31.12.2022,2.2.2023,4.3.2023,3.5.2023,29.5.2023\n",
      "16.11.2021,3.1.2022\n",
      "nan\n",
      "9-6-2018,13-7-2018,11-8-2018,11-9-2018,4-10-2018,5-11-2018,6-12-2018,10-6-2019,10-7-2019,7-8-2019,21-8-2019,1-10-2019,26-10-2019,4-12-2019,6-1-2020,1-2-2020,13-3-2020,12-6-2020,4-8-2020,7-9-2020,4-11-2020,25-12-2020,11-2-2021,17-3-2021,22-4-2021,17-8-2021,21-9-2021,25-10-2021,3-1-2022,17-3-2022,14-4-2022,12-5-2022,27-7-2022,5-9-2022,1-10-2022,27-1-2023,24-2-2023,25-3-2023,17-4-2023,15-7-2023,26-10-2023\n",
      "nan\n",
      "14-12-2018,16-1-2019,2-3-2019,30-3-2019,27-4-2019,1-5-2019,14-6-2019,22-7-2019,10-8-2019,23-8-2019,28-7-2020,5-3-2021,31-3-2021,27-4-2021,5-6-2021,29-6-2021,6-7-2021,12-7-2021,25-8-2021,13-9-2021,4-10-2021,1-11-2021,3-12-2021,3-1-2022,26-2-2022,28-3-2022,29-4-2022,28-5-2022,9-6-2022,10-6-2022,8-7-2022,19-8-2022,27-9-2022,27-10-2022,25-11-2022,26-12-2022,3-2-2023,27-2-2023,10-4-2023,12-5-2023,26-6-2022,4-8-2023,8-9-2023,9-10-2023,6-11-2023,11-12-2023,8-1-2024\n",
      "16-10-2019,15-11-2019,15-12-2019,13-1-2020,11-2-2020,13-3-2020,15-5-1010,17-4-2020,15-6-2020,13-8-2020,22-9-2020,27-11-2020,4-1-2021,28-1-2021,24-2-2021,24-3-2021,30-4-2021,29-5-2021,19-6-2021,2-8-2021,2-9-2021,4-10-2021,3-11-2021,6-12-2021,3-1-2022,2-2-2022,5-3-2022,4-4-2022,7-5-2022,4-6-2022,9-7-2022,16-8-2022,14-9-2022,16-10-2022,25-11-2022,30-12-2022,28-1-2023,11-3-2023,18-4-2023,23-5-2023,21-6-2023,21-7-2023,29-8-2023,28-9-2023,27-10-2023,28-11-2023,29-12-2023\n",
      "3-11-2022,3-1-2023,2-3-2023,25-4-2023\n",
      "26-7-2022,26-8-2022,27-9-2022,18-4-2023,4-5-2023\n",
      "1-7-2022,1-8-2022,26-8-2022,1-10-2022,1-11-2022,9-1-2023,14-2-2023\n",
      "26-8-2022,24-9-2022,1-11-2022\n",
      "22-12-21,24-1-22,25-02-22,26-03-22,25-05-22,25-06-22,27-07-22,26-08-22\n",
      "27-7-15,30-9-15,5-11-15,10-12-15,12-1-16,11-2-16,18-5-16,11-11-16,21-12-16,25-1-17,27-2-17,3-4-17,9-5-17,21-6-17,3-8-17,18-9-17,29-11-17,3-1-18,9-2-18,27-3-18,26-4-18,8-6-18,24-7-18,12-9-18,24-10-18,10-12-18,25-1-19,26-3-19,6-6-19,26-7-19,3-9-19,24-10-19,18-11-19,30-12-19,4-2-20,5-2-20,6-5-20,2-6-20,25-8-20,29-10-20,19-12-20,21-1-21,23-3-21,30-6-21,19-10-21,28-12-21,31-3-22,5-7-22,26-8-22,26-9-22,3-11-22,1-12-22,2-1-23,7-2-23,16-3-23,25-4-23,5-6-23,31-7-23,10-10-23,2-12-23,27-1-24\n",
      "9-10-15,12-11-15,11-1-15,9-1-16,6-2-16,7-3-16,9-4-16,30-4-16,14-5-16,22-6-16,26-7-16,20-8-16,6-10-16,7-11-16,9-12-16,23-1-17,20-2-17,30-3-17,28-4-17,10-6-17,4-7-17,1-8-17,30-8-17,4-10-17,27-11-17,26-12-17,1-2-18,7-3-18,11-4-18,22-5-18,25-6-18,9-8-18,13-9-18,13-10-18,8-11-18,19-12-18,17-1-19,15-2-19,16-2-19,20-4-19,22-5-19,26-6-19,29-7-19,27-8-19,5-10-19,5-11-19,17-12-19,14-1-20,19-2-20,20-3-20,8-5-20,5-6-20,26-9-20,20-10-20,24-11-20,24-12-20,1-2-21,8-3-21,16-4-21,23-6-21,20-7-21,25-8-21,18-9-21,26-10-21,25-11-21,21-12-21,20-1-22,15-2-22,15-3-22,22-4-22,23-5-22,19-7-22,26-8-22,28-9-22,6-12-22,24-1-23,16-3-23,24-4-23,7-6-23,27-7-23,11-9-23,31-10-23,8-1-24\n",
      "26-02-21,06-04-21,01-10-21,26-08-22,14-10-22\n",
      "30-9-14,07-11-14,2-12-14,6-1-15,5-2-15,7-3-15,7-4-15,9-5-15,8-6-15,8-7-15,6-8-15,4-9-15,5-10-15,2-11-15,17-12-15,16-1-16,13-2-16,14-3-16,14-4-6,12-5-16,11-6-16,12-7-16,11-8-16,10-9-16,27-9-16,24-10-16,24-11-16,22-12-16,21-1-17,21-2-17,23-3-17,22-4-17,22-5-17,24-6-17,27-7-17,26-8-17,25-9-17,25-10-17,23-11-17,23-12-17,23-1-18,20-2-18,26-3-18,24-4-18,24-5-18,6-6-18,5-7-18,4-8-18,18-9-18,16-10-18,15-11-18,17-12-18,15-1-19,16-2-19,18-3-19,16-4-19,16-5-19,15-6-19,16-7-19,14-8-19,12-9-19,14-10-19,12-11-19,16-12-19,15-1-20,15-2-20,16-3-20,24-4-20,18-6-20,21-7-20,28-8-20,28-9-20,20-11-20,21-12-20,4-9-21,11-10-21,1-11-21,3-12-21,10-1-22,11-2-22,11-3-22,15-4-22,15-5-22,18-6-22,20-7-22,26-8-22,13-10-22\n",
      "16-5-20,16-6-20,9-1-21,26-8-22,12-6-23,24-7-23,23-8-23\n",
      "31-05-22,28-06-22,26-08-22,30-09-22,04-11-22,09-12-22\n",
      "30-06-22,04-07-22,29-07-22,05-08-22,19-08-22,26-08-22,11-10-22,13-10-22,11-11-22,07-02-23,24-03-23,23-06-23,14-07-23,28-07-23,15-09-23\n",
      "26-8-2022,24-9-2022,26-10-2022,18-11-2022,21-7-2023,18-8-2023\n",
      "7-6-2019,21-6-2019,22-7-2019,22-8-2019,11-11-2019,9-12-2019,6-1-2020,3-2-2020-27-6-2020,5-3-2021,12-3-2021,20-4-2021,11-5-2021,9-8-2021,22-10-2021,14-2-2022,6-5-2022,26-8-2022,31-10-2022,23-1-2023,7-4-2023,30-6-2023,29-9-2023,1-12-2023,5-2-2024\n",
      "7-8-2022,17-8-2022,26-8-2022,21-9-2022,11-11-2022,18-11-2022,25-11-2022,2-12-2022,9-12-2022,10-1-2023,13-1-2023,19-1-2023,31-1-2023,7-2-2023,24-2-2023,1-4-2023,28-4-2023,30-5-2023,4-7-2023,29-7-2023,31-8-2023,28-9-2023,30-10-2023,25-11-2023,21-12-2023,29-1-2024\n",
      "28-03-22,13-07-22,26-08-22,11-10-22,15-05-23,31-07-23,07-09-23,03-10-23,01-11-23,04-12-23\n",
      "08-06-22,26-08-22,19-12-22,23-01-23,02-11-23\n",
      "28-08-2021,15-07-2022,17-08-2022\n",
      "29-06-2020,21-08-2020,30-08-2020,31-10-2020,03-12-2020,04-01-2021,19-01-2021,02-02-2021,10-03-2021,12-04-2021,28-08-2021,22-10-2021,24-11-2021,07-02-2022,17-02-2022,25-02-2022,07-03-2022,04-04-2022,21-06-2022,24-08-2022,24-09-2022,16-11-2022\n",
      "16-05-2019,14-08-2019,03-02-2020,06-02-2020,19-06-2020,17-07-2020,21-08-2020,19-11-2020,19-12-2020,18-02-2021,27-02-2021,28-08-2021,29-10-2021,28-12-2021,21-03-2022,25-05-2022,02-07-2022,13-08-2022,13-09-2022,12-10-2022,12-11-2022,13-12-2022,12-01-2023,08-02-2023,05-08-2023\n"
     ]
    }
   ],
   "source": [
    "for i in df2['frequency of follow up at lgb (to write down follow-up dates)']:\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1c811c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2019, 6, 24, 0, 0), datetime.datetime(2019, 7, 29, 0, 0))\n",
      "Consecutive Dates: 24-06-2019 and 29-07-2019\n",
      "(datetime.datetime(2019, 7, 29, 0, 0), datetime.datetime(2019, 9, 9, 0, 0))\n",
      "Consecutive Dates: 29-07-2019 and 09-09-2019\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_consecutive_dates(date_str, date_format=\"%d-%m-%y\"):\n",
    "    date_list = date_str.split(',')\n",
    "    date_objects = []\n",
    "    for date in date_list:\n",
    "        try:\n",
    "            date_objects.append(datetime.strptime(date, date_format))\n",
    "        except ValueError:\n",
    "            date_objects.append(datetime.strptime(date, \"%d-%m-%Y\"))\n",
    "\n",
    "    consecutive_pairs = zip(date_objects[:-1], date_objects[1:])\n",
    "\n",
    "    return consecutive_pairs\n",
    "\n",
    "date_str = \"24-06-2019,29-07-2019,09-09-19\"\n",
    "consecutive_pairs = extract_consecutive_dates(date_str)\n",
    "\n",
    "for pair in consecutive_pairs:\n",
    "    print(pair)\n",
    "    print(f\"Consecutive Dates: {pair[0].strftime('%d-%m-%Y')} and {pair[1].strftime('%d-%m-%Y')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f6d0025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2014, 1, 1, 0, 0), datetime.datetime(2014, 1, 1, 0, 0))\n",
      "Consecutive Dates: 01-01-2014 and 01-01-2014\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_consecutive_dates(date_str, date_format=\"%d-%m-%y\"):\n",
    "    date_list = date_str.split(',')\n",
    "\n",
    "    if len(date_list) < 2:\n",
    "        return [(datetime.strptime(\"01-01-2014\", \"%d-%m-%Y\"), datetime.strptime(\"01-01-2014\", \"%d-%m-%Y\"))]\n",
    "    date_objects = []\n",
    "    for date in date_list:\n",
    "        try:\n",
    "            date_objects.append(datetime.strptime(date, date_format))\n",
    "        except ValueError:\n",
    "            date_objects.append(datetime.strptime(date, \"%d-%m-%Y\"))\n",
    "\n",
    "    consecutive_pairs = zip(date_objects[:-1], date_objects[1:])\n",
    "\n",
    "    return consecutive_pairs\n",
    "\n",
    "date_str = \"24-06-2019\"\n",
    "consecutive_pairs = extract_consecutive_dates(date_str)\n",
    "\n",
    "for pair in consecutive_pairs:\n",
    "    print(pair)\n",
    "    print(f\"Consecutive Dates: {pair[0].strftime('%d-%m-%Y')} and {pair[1].strftime('%d-%m-%Y')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4cb1321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2019, 6, 24, 0, 0), datetime.datetime(2019, 7, 29, 0, 0))\n",
      "(datetime.datetime(2019, 7, 29, 0, 0), datetime.datetime(2019, 9, 9, 0, 0))\n",
      "(datetime.datetime(2019, 9, 9, 0, 0), datetime.datetime(2019, 10, 21, 0, 0))\n",
      "(datetime.datetime(2019, 10, 21, 0, 0), datetime.datetime(2019, 12, 17, 0, 0))\n",
      "(datetime.datetime(2019, 12, 17, 0, 0), datetime.datetime(2020, 1, 18, 0, 0))\n",
      "(datetime.datetime(2020, 1, 18, 0, 0), datetime.datetime(2020, 3, 2, 0, 0))\n",
      "(datetime.datetime(2020, 3, 2, 0, 0), datetime.datetime(2020, 5, 2, 0, 0))\n",
      "(datetime.datetime(2020, 5, 2, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2020, 8, 28, 0, 0))\n",
      "(datetime.datetime(2020, 8, 28, 0, 0), datetime.datetime(2020, 11, 17, 0, 0))\n",
      "(datetime.datetime(2020, 11, 17, 0, 0), datetime.datetime(2021, 1, 21, 0, 0))\n",
      "(datetime.datetime(2019, 12, 19, 0, 0), datetime.datetime(2020, 2, 1, 0, 0))\n",
      "(datetime.datetime(2020, 2, 1, 0, 0), datetime.datetime(2020, 3, 20, 0, 0))\n",
      "(datetime.datetime(2020, 3, 20, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2014, 3, 31, 0, 0), datetime.datetime(2014, 4, 29, 0, 0))\n",
      "(datetime.datetime(2014, 4, 29, 0, 0), datetime.datetime(2014, 5, 29, 0, 0))\n",
      "(datetime.datetime(2014, 5, 29, 0, 0), datetime.datetime(2014, 7, 4, 0, 0))\n",
      "(datetime.datetime(2014, 7, 4, 0, 0), datetime.datetime(2014, 8, 25, 0, 0))\n",
      "(datetime.datetime(2014, 8, 25, 0, 0), datetime.datetime(2016, 2, 1, 0, 0))\n",
      "(datetime.datetime(2016, 2, 1, 0, 0), datetime.datetime(2016, 3, 30, 0, 0))\n",
      "(datetime.datetime(2016, 3, 30, 0, 0), datetime.datetime(2016, 4, 29, 0, 0))\n",
      "(datetime.datetime(2016, 4, 29, 0, 0), datetime.datetime(2016, 6, 3, 0, 0))\n",
      "(datetime.datetime(2016, 6, 3, 0, 0), datetime.datetime(2016, 8, 28, 0, 0))\n",
      "(datetime.datetime(2016, 8, 28, 0, 0), datetime.datetime(2016, 8, 8, 0, 0))\n",
      "(datetime.datetime(2016, 8, 8, 0, 0), datetime.datetime(2016, 9, 8, 0, 0))\n",
      "(datetime.datetime(2016, 9, 8, 0, 0), datetime.datetime(2016, 10, 5, 0, 0))\n",
      "(datetime.datetime(2016, 10, 5, 0, 0), datetime.datetime(2016, 11, 9, 0, 0))\n",
      "(datetime.datetime(2016, 11, 9, 0, 0), datetime.datetime(2016, 12, 16, 0, 0))\n",
      "(datetime.datetime(2016, 12, 16, 0, 0), datetime.datetime(2017, 1, 23, 0, 0))\n",
      "(datetime.datetime(2017, 1, 23, 0, 0), datetime.datetime(2017, 2, 22, 0, 0))\n",
      "(datetime.datetime(2017, 2, 22, 0, 0), datetime.datetime(2017, 3, 10, 0, 0))\n",
      "(datetime.datetime(2017, 3, 10, 0, 0), datetime.datetime(2017, 4, 21, 0, 0))\n",
      "(datetime.datetime(2017, 4, 21, 0, 0), datetime.datetime(2017, 5, 25, 0, 0))\n",
      "(datetime.datetime(2017, 5, 25, 0, 0), datetime.datetime(2017, 6, 22, 0, 0))\n",
      "(datetime.datetime(2017, 6, 22, 0, 0), datetime.datetime(2017, 7, 20, 0, 0))\n",
      "(datetime.datetime(2017, 7, 20, 0, 0), datetime.datetime(2017, 10, 3, 0, 0))\n",
      "(datetime.datetime(2017, 10, 3, 0, 0), datetime.datetime(2017, 11, 2, 0, 0))\n",
      "(datetime.datetime(2017, 11, 2, 0, 0), datetime.datetime(2018, 1, 6, 0, 0))\n",
      "(datetime.datetime(2018, 1, 6, 0, 0), datetime.datetime(2018, 2, 5, 0, 0))\n",
      "(datetime.datetime(2018, 2, 5, 0, 0), datetime.datetime(2018, 3, 8, 0, 0))\n",
      "(datetime.datetime(2018, 3, 8, 0, 0), datetime.datetime(2018, 4, 7, 0, 0))\n",
      "(datetime.datetime(2018, 4, 7, 0, 0), datetime.datetime(2018, 5, 5, 0, 0))\n",
      "(datetime.datetime(2018, 5, 5, 0, 0), datetime.datetime(2018, 6, 7, 0, 0))\n",
      "(datetime.datetime(2018, 6, 7, 0, 0), datetime.datetime(2018, 8, 9, 0, 0))\n",
      "(datetime.datetime(2018, 8, 9, 0, 0), datetime.datetime(2018, 9, 12, 0, 0))\n",
      "(datetime.datetime(2018, 9, 12, 0, 0), datetime.datetime(2018, 10, 9, 0, 0))\n",
      "(datetime.datetime(2018, 10, 9, 0, 0), datetime.datetime(2018, 11, 12, 0, 0))\n",
      "(datetime.datetime(2018, 11, 12, 0, 0), datetime.datetime(2018, 12, 19, 0, 0))\n",
      "(datetime.datetime(2018, 12, 19, 0, 0), datetime.datetime(2019, 1, 17, 0, 0))\n",
      "(datetime.datetime(2019, 1, 17, 0, 0), datetime.datetime(2019, 6, 13, 0, 0))\n",
      "(datetime.datetime(2019, 6, 13, 0, 0), datetime.datetime(2019, 7, 13, 0, 0))\n",
      "(datetime.datetime(2019, 7, 13, 0, 0), datetime.datetime(2019, 8, 17, 0, 0))\n",
      "(datetime.datetime(2019, 8, 17, 0, 0), datetime.datetime(2019, 8, 17, 0, 0))\n",
      "(datetime.datetime(2019, 8, 17, 0, 0), datetime.datetime(2019, 10, 20, 0, 0))\n",
      "(datetime.datetime(2019, 10, 20, 0, 0), datetime.datetime(2019, 11, 30, 0, 0))\n",
      "(datetime.datetime(2019, 11, 30, 0, 0), datetime.datetime(2020, 1, 3, 0, 0))\n",
      "(datetime.datetime(2020, 1, 3, 0, 0), datetime.datetime(2020, 3, 6, 0, 0))\n",
      "(datetime.datetime(2020, 3, 6, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2021, 4, 2, 0, 0))\n",
      "(datetime.datetime(2021, 4, 2, 0, 0), datetime.datetime(2021, 5, 10, 0, 0))\n",
      "(datetime.datetime(2021, 5, 10, 0, 0), datetime.datetime(2021, 8, 6, 0, 0))\n",
      "(datetime.datetime(2021, 8, 6, 0, 0), datetime.datetime(2021, 9, 7, 0, 0))\n",
      "(datetime.datetime(2021, 9, 7, 0, 0), datetime.datetime(2021, 11, 13, 0, 0))\n",
      "(datetime.datetime(2021, 11, 13, 0, 0), datetime.datetime(2022, 1, 17, 0, 0))\n",
      "(datetime.datetime(2022, 1, 17, 0, 0), datetime.datetime(2022, 3, 19, 0, 0))\n",
      "(datetime.datetime(2022, 3, 19, 0, 0), datetime.datetime(2022, 5, 30, 0, 0))\n",
      "(datetime.datetime(2022, 5, 30, 0, 0), datetime.datetime(2022, 7, 4, 0, 0))\n",
      "(datetime.datetime(2022, 7, 4, 0, 0), datetime.datetime(2022, 8, 9, 0, 0))\n",
      "(datetime.datetime(2022, 8, 9, 0, 0), datetime.datetime(2022, 9, 13, 0, 0))\n",
      "(datetime.datetime(2022, 9, 13, 0, 0), datetime.datetime(2022, 10, 27, 0, 0))\n",
      "(datetime.datetime(2022, 10, 27, 0, 0), datetime.datetime(2022, 11, 28, 0, 0))\n",
      "(datetime.datetime(2022, 11, 28, 0, 0), datetime.datetime(2023, 1, 10, 0, 0))\n",
      "(datetime.datetime(2023, 1, 10, 0, 0), datetime.datetime(2023, 2, 13, 0, 0))\n",
      "(datetime.datetime(2023, 2, 13, 0, 0), datetime.datetime(2023, 3, 22, 0, 0))\n",
      "(datetime.datetime(2023, 3, 22, 0, 0), datetime.datetime(2023, 4, 26, 0, 0))\n",
      "(datetime.datetime(2023, 4, 26, 0, 0), datetime.datetime(2023, 6, 5, 0, 0))\n",
      "(datetime.datetime(2023, 6, 5, 0, 0), datetime.datetime(2023, 7, 17, 0, 0))\n",
      "(datetime.datetime(2023, 7, 17, 0, 0), datetime.datetime(2023, 8, 24, 0, 0))\n",
      "(datetime.datetime(2023, 8, 24, 0, 0), datetime.datetime(2023, 9, 25, 0, 0))\n",
      "(datetime.datetime(2023, 9, 25, 0, 0), datetime.datetime(2023, 11, 6, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2020, 9, 30, 0, 0))\n",
      "(datetime.datetime(2014, 4, 29, 0, 0), datetime.datetime(2014, 5, 29, 0, 0))\n",
      "(datetime.datetime(2014, 5, 29, 0, 0), datetime.datetime(2014, 7, 4, 0, 0))\n",
      "(datetime.datetime(2014, 7, 4, 0, 0), datetime.datetime(2014, 8, 25, 0, 0))\n",
      "(datetime.datetime(2014, 8, 25, 0, 0), datetime.datetime(2016, 3, 1, 0, 0))\n",
      "(datetime.datetime(2016, 3, 1, 0, 0), datetime.datetime(2016, 3, 30, 0, 0))\n",
      "(datetime.datetime(2016, 3, 30, 0, 0), datetime.datetime(2016, 4, 29, 0, 0))\n",
      "(datetime.datetime(2016, 4, 29, 0, 0), datetime.datetime(2016, 6, 3, 0, 0))\n",
      "(datetime.datetime(2016, 6, 3, 0, 0), datetime.datetime(2016, 6, 28, 0, 0))\n",
      "(datetime.datetime(2016, 6, 28, 0, 0), datetime.datetime(2016, 8, 8, 0, 0))\n",
      "(datetime.datetime(2016, 8, 8, 0, 0), datetime.datetime(2016, 9, 8, 0, 0))\n",
      "(datetime.datetime(2016, 9, 8, 0, 0), datetime.datetime(2016, 10, 5, 0, 0))\n",
      "(datetime.datetime(2016, 10, 5, 0, 0), datetime.datetime(2016, 11, 9, 0, 0))\n",
      "(datetime.datetime(2016, 11, 9, 0, 0), datetime.datetime(2016, 12, 16, 0, 0))\n",
      "(datetime.datetime(2016, 12, 16, 0, 0), datetime.datetime(2017, 1, 23, 0, 0))\n",
      "(datetime.datetime(2017, 1, 23, 0, 0), datetime.datetime(2017, 2, 22, 0, 0))\n",
      "(datetime.datetime(2017, 2, 22, 0, 0), datetime.datetime(2017, 3, 10, 0, 0))\n",
      "(datetime.datetime(2017, 3, 10, 0, 0), datetime.datetime(2017, 4, 21, 0, 0))\n",
      "(datetime.datetime(2017, 4, 21, 0, 0), datetime.datetime(2017, 5, 25, 0, 0))\n",
      "(datetime.datetime(2017, 5, 25, 0, 0), datetime.datetime(2017, 6, 22, 0, 0))\n",
      "(datetime.datetime(2017, 6, 22, 0, 0), datetime.datetime(2017, 7, 20, 0, 0))\n",
      "(datetime.datetime(2017, 7, 20, 0, 0), datetime.datetime(2017, 11, 2, 0, 0))\n",
      "(datetime.datetime(2017, 11, 2, 0, 0), datetime.datetime(2018, 1, 6, 0, 0))\n",
      "(datetime.datetime(2018, 1, 6, 0, 0), datetime.datetime(2018, 2, 5, 0, 0))\n",
      "(datetime.datetime(2018, 2, 5, 0, 0), datetime.datetime(2018, 3, 8, 0, 0))\n",
      "(datetime.datetime(2018, 3, 8, 0, 0), datetime.datetime(2018, 4, 7, 0, 0))\n",
      "(datetime.datetime(2018, 4, 7, 0, 0), datetime.datetime(2018, 5, 5, 0, 0))\n",
      "(datetime.datetime(2018, 5, 5, 0, 0), datetime.datetime(2018, 6, 7, 0, 0))\n",
      "(datetime.datetime(2018, 6, 7, 0, 0), datetime.datetime(2018, 6, 27, 0, 0))\n",
      "(datetime.datetime(2018, 6, 27, 0, 0), datetime.datetime(2018, 8, 9, 0, 0))\n",
      "(datetime.datetime(2018, 8, 9, 0, 0), datetime.datetime(2018, 9, 12, 0, 0))\n",
      "(datetime.datetime(2018, 9, 12, 0, 0), datetime.datetime(2018, 10, 9, 0, 0))\n",
      "(datetime.datetime(2018, 10, 9, 0, 0), datetime.datetime(2018, 11, 12, 0, 0))\n",
      "(datetime.datetime(2018, 11, 12, 0, 0), datetime.datetime(2018, 12, 19, 0, 0))\n",
      "(datetime.datetime(2018, 12, 19, 0, 0), datetime.datetime(2019, 1, 17, 0, 0))\n",
      "(datetime.datetime(2019, 1, 17, 0, 0), datetime.datetime(2019, 2, 20, 0, 0))\n",
      "(datetime.datetime(2019, 2, 20, 0, 0), datetime.datetime(2019, 3, 30, 0, 0))\n",
      "(datetime.datetime(2019, 3, 30, 0, 0), datetime.datetime(2019, 5, 2, 0, 0))\n",
      "(datetime.datetime(2019, 5, 2, 0, 0), datetime.datetime(2019, 6, 13, 0, 0))\n",
      "(datetime.datetime(2019, 6, 13, 0, 0), datetime.datetime(2019, 7, 13, 0, 0))\n",
      "(datetime.datetime(2019, 7, 13, 0, 0), datetime.datetime(2019, 8, 17, 0, 0))\n",
      "(datetime.datetime(2019, 8, 17, 0, 0), datetime.datetime(2019, 9, 17, 0, 0))\n",
      "(datetime.datetime(2019, 9, 17, 0, 0), datetime.datetime(2019, 10, 22, 0, 0))\n",
      "(datetime.datetime(2019, 10, 22, 0, 0), datetime.datetime(2019, 11, 30, 0, 0))\n",
      "(datetime.datetime(2019, 11, 30, 0, 0), datetime.datetime(2020, 1, 3, 0, 0))\n",
      "(datetime.datetime(2020, 1, 3, 0, 0), datetime.datetime(2020, 1, 28, 0, 0))\n",
      "(datetime.datetime(2020, 1, 28, 0, 0), datetime.datetime(2020, 3, 6, 0, 0))\n",
      "(datetime.datetime(2020, 3, 6, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2021, 4, 2, 0, 0))\n",
      "(datetime.datetime(2021, 4, 2, 0, 0), datetime.datetime(2021, 5, 10, 0, 0))\n",
      "(datetime.datetime(2021, 5, 10, 0, 0), datetime.datetime(2021, 8, 6, 0, 0))\n",
      "(datetime.datetime(2021, 8, 6, 0, 0), datetime.datetime(2021, 9, 7, 0, 0))\n",
      "(datetime.datetime(2021, 9, 7, 0, 0), datetime.datetime(2021, 11, 13, 0, 0))\n",
      "(datetime.datetime(2021, 11, 13, 0, 0), datetime.datetime(2022, 1, 17, 0, 0))\n",
      "(datetime.datetime(2022, 1, 17, 0, 0), datetime.datetime(2022, 3, 19, 0, 0))\n",
      "(datetime.datetime(2022, 3, 19, 0, 0), datetime.datetime(2022, 5, 30, 0, 0))\n",
      "(datetime.datetime(2022, 5, 30, 0, 0), datetime.datetime(2022, 7, 4, 0, 0))\n",
      "(datetime.datetime(2022, 7, 4, 0, 0), datetime.datetime(2022, 8, 9, 0, 0))\n",
      "(datetime.datetime(2022, 8, 9, 0, 0), datetime.datetime(2022, 9, 13, 0, 0))\n",
      "(datetime.datetime(2022, 9, 13, 0, 0), datetime.datetime(2022, 10, 27, 0, 0))\n",
      "(datetime.datetime(2022, 10, 27, 0, 0), datetime.datetime(2022, 11, 28, 0, 0))\n",
      "(datetime.datetime(2022, 11, 28, 0, 0), datetime.datetime(2023, 1, 10, 0, 0))\n",
      "(datetime.datetime(2023, 1, 10, 0, 0), datetime.datetime(2023, 2, 13, 0, 0))\n",
      "(datetime.datetime(2023, 2, 13, 0, 0), datetime.datetime(2023, 3, 23, 0, 0))\n",
      "(datetime.datetime(2023, 3, 23, 0, 0), datetime.datetime(2023, 4, 26, 0, 0))\n",
      "(datetime.datetime(2023, 4, 26, 0, 0), datetime.datetime(2023, 6, 5, 0, 0))\n",
      "(datetime.datetime(2023, 6, 5, 0, 0), datetime.datetime(2023, 7, 17, 0, 0))\n",
      "(datetime.datetime(2023, 7, 17, 0, 0), datetime.datetime(2023, 8, 24, 0, 0))\n",
      "(datetime.datetime(2023, 8, 24, 0, 0), datetime.datetime(2023, 9, 25, 0, 0))\n",
      "(datetime.datetime(2023, 9, 25, 0, 0), datetime.datetime(2023, 11, 6, 0, 0))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data '0-11-20' does not match format '%d-%m-%Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [127], line 16\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_format)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Try parsing with the specified format\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     date_objects\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# If it fails, try parsing with the format for four-digit years\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03mformat string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n",
      "\u001b[1;31mValueError\u001b[0m: time data '0-11-20' does not match format '%d-%m-%y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [128], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency of follow up at lgb (to write down follow-up dates)\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mextract_consecutive_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#sum = 0\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m a:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m#sum = sum +  calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m#print(sum)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [127], line 19\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_format)\u001b[0m\n\u001b[0;32m     16\u001b[0m         date_objects\u001b[38;5;241m.\u001b[39mappend(datetime\u001b[38;5;241m.\u001b[39mstrptime(date, date_format))\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;66;03m# If it fails, try parsing with the format for four-digit years\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m         date_objects\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Extract pairs of consecutive dates\u001b[39;00m\n\u001b[0;32m     22\u001b[0m consecutive_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(date_objects[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], date_objects[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    347\u001b[0m found \u001b[38;5;241m=\u001b[39m format_regex\u001b[38;5;241m.\u001b[39mmatch(data_string)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n",
      "\u001b[1;31mValueError\u001b[0m: time data '0-11-20' does not match format '%d-%m-%Y'"
     ]
    }
   ],
   "source": [
    "for i in df2['frequency of follow up at lgb (to write down follow-up dates)']:\n",
    "    a = extract_consecutive_dates(i)\n",
    "    #sum = 0\n",
    "    for pair in a:\n",
    "        #sum = sum +  calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\n",
    "        #print(sum)\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e3b95a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['frequency of follow up at lgb (to write down follow-up dates)'] = df2['frequency of follow up at lgb (to write down follow-up dates)'].replace('0-11-20', '01-11-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "870e7720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2019, 6, 24, 0, 0), datetime.datetime(2019, 7, 29, 0, 0))\n",
      "(datetime.datetime(2019, 7, 29, 0, 0), datetime.datetime(2019, 9, 9, 0, 0))\n",
      "(datetime.datetime(2019, 9, 9, 0, 0), datetime.datetime(2019, 10, 21, 0, 0))\n",
      "(datetime.datetime(2019, 10, 21, 0, 0), datetime.datetime(2019, 12, 17, 0, 0))\n",
      "(datetime.datetime(2019, 12, 17, 0, 0), datetime.datetime(2020, 1, 18, 0, 0))\n",
      "(datetime.datetime(2020, 1, 18, 0, 0), datetime.datetime(2020, 3, 2, 0, 0))\n",
      "(datetime.datetime(2020, 3, 2, 0, 0), datetime.datetime(2020, 5, 2, 0, 0))\n",
      "(datetime.datetime(2020, 5, 2, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2020, 8, 28, 0, 0))\n",
      "(datetime.datetime(2020, 8, 28, 0, 0), datetime.datetime(2020, 11, 17, 0, 0))\n",
      "(datetime.datetime(2020, 11, 17, 0, 0), datetime.datetime(2021, 1, 21, 0, 0))\n",
      "(datetime.datetime(2019, 12, 19, 0, 0), datetime.datetime(2020, 2, 1, 0, 0))\n",
      "(datetime.datetime(2020, 2, 1, 0, 0), datetime.datetime(2020, 3, 20, 0, 0))\n",
      "(datetime.datetime(2020, 3, 20, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2014, 3, 31, 0, 0), datetime.datetime(2014, 4, 29, 0, 0))\n",
      "(datetime.datetime(2014, 4, 29, 0, 0), datetime.datetime(2014, 5, 29, 0, 0))\n",
      "(datetime.datetime(2014, 5, 29, 0, 0), datetime.datetime(2014, 7, 4, 0, 0))\n",
      "(datetime.datetime(2014, 7, 4, 0, 0), datetime.datetime(2014, 8, 25, 0, 0))\n",
      "(datetime.datetime(2014, 8, 25, 0, 0), datetime.datetime(2016, 2, 1, 0, 0))\n",
      "(datetime.datetime(2016, 2, 1, 0, 0), datetime.datetime(2016, 3, 30, 0, 0))\n",
      "(datetime.datetime(2016, 3, 30, 0, 0), datetime.datetime(2016, 4, 29, 0, 0))\n",
      "(datetime.datetime(2016, 4, 29, 0, 0), datetime.datetime(2016, 6, 3, 0, 0))\n",
      "(datetime.datetime(2016, 6, 3, 0, 0), datetime.datetime(2016, 8, 28, 0, 0))\n",
      "(datetime.datetime(2016, 8, 28, 0, 0), datetime.datetime(2016, 8, 8, 0, 0))\n",
      "(datetime.datetime(2016, 8, 8, 0, 0), datetime.datetime(2016, 9, 8, 0, 0))\n",
      "(datetime.datetime(2016, 9, 8, 0, 0), datetime.datetime(2016, 10, 5, 0, 0))\n",
      "(datetime.datetime(2016, 10, 5, 0, 0), datetime.datetime(2016, 11, 9, 0, 0))\n",
      "(datetime.datetime(2016, 11, 9, 0, 0), datetime.datetime(2016, 12, 16, 0, 0))\n",
      "(datetime.datetime(2016, 12, 16, 0, 0), datetime.datetime(2017, 1, 23, 0, 0))\n",
      "(datetime.datetime(2017, 1, 23, 0, 0), datetime.datetime(2017, 2, 22, 0, 0))\n",
      "(datetime.datetime(2017, 2, 22, 0, 0), datetime.datetime(2017, 3, 10, 0, 0))\n",
      "(datetime.datetime(2017, 3, 10, 0, 0), datetime.datetime(2017, 4, 21, 0, 0))\n",
      "(datetime.datetime(2017, 4, 21, 0, 0), datetime.datetime(2017, 5, 25, 0, 0))\n",
      "(datetime.datetime(2017, 5, 25, 0, 0), datetime.datetime(2017, 6, 22, 0, 0))\n",
      "(datetime.datetime(2017, 6, 22, 0, 0), datetime.datetime(2017, 7, 20, 0, 0))\n",
      "(datetime.datetime(2017, 7, 20, 0, 0), datetime.datetime(2017, 10, 3, 0, 0))\n",
      "(datetime.datetime(2017, 10, 3, 0, 0), datetime.datetime(2017, 11, 2, 0, 0))\n",
      "(datetime.datetime(2017, 11, 2, 0, 0), datetime.datetime(2018, 1, 6, 0, 0))\n",
      "(datetime.datetime(2018, 1, 6, 0, 0), datetime.datetime(2018, 2, 5, 0, 0))\n",
      "(datetime.datetime(2018, 2, 5, 0, 0), datetime.datetime(2018, 3, 8, 0, 0))\n",
      "(datetime.datetime(2018, 3, 8, 0, 0), datetime.datetime(2018, 4, 7, 0, 0))\n",
      "(datetime.datetime(2018, 4, 7, 0, 0), datetime.datetime(2018, 5, 5, 0, 0))\n",
      "(datetime.datetime(2018, 5, 5, 0, 0), datetime.datetime(2018, 6, 7, 0, 0))\n",
      "(datetime.datetime(2018, 6, 7, 0, 0), datetime.datetime(2018, 8, 9, 0, 0))\n",
      "(datetime.datetime(2018, 8, 9, 0, 0), datetime.datetime(2018, 9, 12, 0, 0))\n",
      "(datetime.datetime(2018, 9, 12, 0, 0), datetime.datetime(2018, 10, 9, 0, 0))\n",
      "(datetime.datetime(2018, 10, 9, 0, 0), datetime.datetime(2018, 11, 12, 0, 0))\n",
      "(datetime.datetime(2018, 11, 12, 0, 0), datetime.datetime(2018, 12, 19, 0, 0))\n",
      "(datetime.datetime(2018, 12, 19, 0, 0), datetime.datetime(2019, 1, 17, 0, 0))\n",
      "(datetime.datetime(2019, 1, 17, 0, 0), datetime.datetime(2019, 6, 13, 0, 0))\n",
      "(datetime.datetime(2019, 6, 13, 0, 0), datetime.datetime(2019, 7, 13, 0, 0))\n",
      "(datetime.datetime(2019, 7, 13, 0, 0), datetime.datetime(2019, 8, 17, 0, 0))\n",
      "(datetime.datetime(2019, 8, 17, 0, 0), datetime.datetime(2019, 8, 17, 0, 0))\n",
      "(datetime.datetime(2019, 8, 17, 0, 0), datetime.datetime(2019, 10, 20, 0, 0))\n",
      "(datetime.datetime(2019, 10, 20, 0, 0), datetime.datetime(2019, 11, 30, 0, 0))\n",
      "(datetime.datetime(2019, 11, 30, 0, 0), datetime.datetime(2020, 1, 3, 0, 0))\n",
      "(datetime.datetime(2020, 1, 3, 0, 0), datetime.datetime(2020, 3, 6, 0, 0))\n",
      "(datetime.datetime(2020, 3, 6, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2021, 4, 2, 0, 0))\n",
      "(datetime.datetime(2021, 4, 2, 0, 0), datetime.datetime(2021, 5, 10, 0, 0))\n",
      "(datetime.datetime(2021, 5, 10, 0, 0), datetime.datetime(2021, 8, 6, 0, 0))\n",
      "(datetime.datetime(2021, 8, 6, 0, 0), datetime.datetime(2021, 9, 7, 0, 0))\n",
      "(datetime.datetime(2021, 9, 7, 0, 0), datetime.datetime(2021, 11, 13, 0, 0))\n",
      "(datetime.datetime(2021, 11, 13, 0, 0), datetime.datetime(2022, 1, 17, 0, 0))\n",
      "(datetime.datetime(2022, 1, 17, 0, 0), datetime.datetime(2022, 3, 19, 0, 0))\n",
      "(datetime.datetime(2022, 3, 19, 0, 0), datetime.datetime(2022, 5, 30, 0, 0))\n",
      "(datetime.datetime(2022, 5, 30, 0, 0), datetime.datetime(2022, 7, 4, 0, 0))\n",
      "(datetime.datetime(2022, 7, 4, 0, 0), datetime.datetime(2022, 8, 9, 0, 0))\n",
      "(datetime.datetime(2022, 8, 9, 0, 0), datetime.datetime(2022, 9, 13, 0, 0))\n",
      "(datetime.datetime(2022, 9, 13, 0, 0), datetime.datetime(2022, 10, 27, 0, 0))\n",
      "(datetime.datetime(2022, 10, 27, 0, 0), datetime.datetime(2022, 11, 28, 0, 0))\n",
      "(datetime.datetime(2022, 11, 28, 0, 0), datetime.datetime(2023, 1, 10, 0, 0))\n",
      "(datetime.datetime(2023, 1, 10, 0, 0), datetime.datetime(2023, 2, 13, 0, 0))\n",
      "(datetime.datetime(2023, 2, 13, 0, 0), datetime.datetime(2023, 3, 22, 0, 0))\n",
      "(datetime.datetime(2023, 3, 22, 0, 0), datetime.datetime(2023, 4, 26, 0, 0))\n",
      "(datetime.datetime(2023, 4, 26, 0, 0), datetime.datetime(2023, 6, 5, 0, 0))\n",
      "(datetime.datetime(2023, 6, 5, 0, 0), datetime.datetime(2023, 7, 17, 0, 0))\n",
      "(datetime.datetime(2023, 7, 17, 0, 0), datetime.datetime(2023, 8, 24, 0, 0))\n",
      "(datetime.datetime(2023, 8, 24, 0, 0), datetime.datetime(2023, 9, 25, 0, 0))\n",
      "(datetime.datetime(2023, 9, 25, 0, 0), datetime.datetime(2023, 11, 6, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2020, 9, 30, 0, 0))\n",
      "(datetime.datetime(2014, 4, 29, 0, 0), datetime.datetime(2014, 5, 29, 0, 0))\n",
      "(datetime.datetime(2014, 5, 29, 0, 0), datetime.datetime(2014, 7, 4, 0, 0))\n",
      "(datetime.datetime(2014, 7, 4, 0, 0), datetime.datetime(2014, 8, 25, 0, 0))\n",
      "(datetime.datetime(2014, 8, 25, 0, 0), datetime.datetime(2016, 3, 1, 0, 0))\n",
      "(datetime.datetime(2016, 3, 1, 0, 0), datetime.datetime(2016, 3, 30, 0, 0))\n",
      "(datetime.datetime(2016, 3, 30, 0, 0), datetime.datetime(2016, 4, 29, 0, 0))\n",
      "(datetime.datetime(2016, 4, 29, 0, 0), datetime.datetime(2016, 6, 3, 0, 0))\n",
      "(datetime.datetime(2016, 6, 3, 0, 0), datetime.datetime(2016, 6, 28, 0, 0))\n",
      "(datetime.datetime(2016, 6, 28, 0, 0), datetime.datetime(2016, 8, 8, 0, 0))\n",
      "(datetime.datetime(2016, 8, 8, 0, 0), datetime.datetime(2016, 9, 8, 0, 0))\n",
      "(datetime.datetime(2016, 9, 8, 0, 0), datetime.datetime(2016, 10, 5, 0, 0))\n",
      "(datetime.datetime(2016, 10, 5, 0, 0), datetime.datetime(2016, 11, 9, 0, 0))\n",
      "(datetime.datetime(2016, 11, 9, 0, 0), datetime.datetime(2016, 12, 16, 0, 0))\n",
      "(datetime.datetime(2016, 12, 16, 0, 0), datetime.datetime(2017, 1, 23, 0, 0))\n",
      "(datetime.datetime(2017, 1, 23, 0, 0), datetime.datetime(2017, 2, 22, 0, 0))\n",
      "(datetime.datetime(2017, 2, 22, 0, 0), datetime.datetime(2017, 3, 10, 0, 0))\n",
      "(datetime.datetime(2017, 3, 10, 0, 0), datetime.datetime(2017, 4, 21, 0, 0))\n",
      "(datetime.datetime(2017, 4, 21, 0, 0), datetime.datetime(2017, 5, 25, 0, 0))\n",
      "(datetime.datetime(2017, 5, 25, 0, 0), datetime.datetime(2017, 6, 22, 0, 0))\n",
      "(datetime.datetime(2017, 6, 22, 0, 0), datetime.datetime(2017, 7, 20, 0, 0))\n",
      "(datetime.datetime(2017, 7, 20, 0, 0), datetime.datetime(2017, 11, 2, 0, 0))\n",
      "(datetime.datetime(2017, 11, 2, 0, 0), datetime.datetime(2018, 1, 6, 0, 0))\n",
      "(datetime.datetime(2018, 1, 6, 0, 0), datetime.datetime(2018, 2, 5, 0, 0))\n",
      "(datetime.datetime(2018, 2, 5, 0, 0), datetime.datetime(2018, 3, 8, 0, 0))\n",
      "(datetime.datetime(2018, 3, 8, 0, 0), datetime.datetime(2018, 4, 7, 0, 0))\n",
      "(datetime.datetime(2018, 4, 7, 0, 0), datetime.datetime(2018, 5, 5, 0, 0))\n",
      "(datetime.datetime(2018, 5, 5, 0, 0), datetime.datetime(2018, 6, 7, 0, 0))\n",
      "(datetime.datetime(2018, 6, 7, 0, 0), datetime.datetime(2018, 6, 27, 0, 0))\n",
      "(datetime.datetime(2018, 6, 27, 0, 0), datetime.datetime(2018, 8, 9, 0, 0))\n",
      "(datetime.datetime(2018, 8, 9, 0, 0), datetime.datetime(2018, 9, 12, 0, 0))\n",
      "(datetime.datetime(2018, 9, 12, 0, 0), datetime.datetime(2018, 10, 9, 0, 0))\n",
      "(datetime.datetime(2018, 10, 9, 0, 0), datetime.datetime(2018, 11, 12, 0, 0))\n",
      "(datetime.datetime(2018, 11, 12, 0, 0), datetime.datetime(2018, 12, 19, 0, 0))\n",
      "(datetime.datetime(2018, 12, 19, 0, 0), datetime.datetime(2019, 1, 17, 0, 0))\n",
      "(datetime.datetime(2019, 1, 17, 0, 0), datetime.datetime(2019, 2, 20, 0, 0))\n",
      "(datetime.datetime(2019, 2, 20, 0, 0), datetime.datetime(2019, 3, 30, 0, 0))\n",
      "(datetime.datetime(2019, 3, 30, 0, 0), datetime.datetime(2019, 5, 2, 0, 0))\n",
      "(datetime.datetime(2019, 5, 2, 0, 0), datetime.datetime(2019, 6, 13, 0, 0))\n",
      "(datetime.datetime(2019, 6, 13, 0, 0), datetime.datetime(2019, 7, 13, 0, 0))\n",
      "(datetime.datetime(2019, 7, 13, 0, 0), datetime.datetime(2019, 8, 17, 0, 0))\n",
      "(datetime.datetime(2019, 8, 17, 0, 0), datetime.datetime(2019, 9, 17, 0, 0))\n",
      "(datetime.datetime(2019, 9, 17, 0, 0), datetime.datetime(2019, 10, 22, 0, 0))\n",
      "(datetime.datetime(2019, 10, 22, 0, 0), datetime.datetime(2019, 11, 30, 0, 0))\n",
      "(datetime.datetime(2019, 11, 30, 0, 0), datetime.datetime(2020, 1, 3, 0, 0))\n",
      "(datetime.datetime(2020, 1, 3, 0, 0), datetime.datetime(2020, 1, 28, 0, 0))\n",
      "(datetime.datetime(2020, 1, 28, 0, 0), datetime.datetime(2020, 3, 6, 0, 0))\n",
      "(datetime.datetime(2020, 3, 6, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2021, 4, 2, 0, 0))\n",
      "(datetime.datetime(2021, 4, 2, 0, 0), datetime.datetime(2021, 5, 10, 0, 0))\n",
      "(datetime.datetime(2021, 5, 10, 0, 0), datetime.datetime(2021, 8, 6, 0, 0))\n",
      "(datetime.datetime(2021, 8, 6, 0, 0), datetime.datetime(2021, 9, 7, 0, 0))\n",
      "(datetime.datetime(2021, 9, 7, 0, 0), datetime.datetime(2021, 11, 13, 0, 0))\n",
      "(datetime.datetime(2021, 11, 13, 0, 0), datetime.datetime(2022, 1, 17, 0, 0))\n",
      "(datetime.datetime(2022, 1, 17, 0, 0), datetime.datetime(2022, 3, 19, 0, 0))\n",
      "(datetime.datetime(2022, 3, 19, 0, 0), datetime.datetime(2022, 5, 30, 0, 0))\n",
      "(datetime.datetime(2022, 5, 30, 0, 0), datetime.datetime(2022, 7, 4, 0, 0))\n",
      "(datetime.datetime(2022, 7, 4, 0, 0), datetime.datetime(2022, 8, 9, 0, 0))\n",
      "(datetime.datetime(2022, 8, 9, 0, 0), datetime.datetime(2022, 9, 13, 0, 0))\n",
      "(datetime.datetime(2022, 9, 13, 0, 0), datetime.datetime(2022, 10, 27, 0, 0))\n",
      "(datetime.datetime(2022, 10, 27, 0, 0), datetime.datetime(2022, 11, 28, 0, 0))\n",
      "(datetime.datetime(2022, 11, 28, 0, 0), datetime.datetime(2023, 1, 10, 0, 0))\n",
      "(datetime.datetime(2023, 1, 10, 0, 0), datetime.datetime(2023, 2, 13, 0, 0))\n",
      "(datetime.datetime(2023, 2, 13, 0, 0), datetime.datetime(2023, 3, 23, 0, 0))\n",
      "(datetime.datetime(2023, 3, 23, 0, 0), datetime.datetime(2023, 4, 26, 0, 0))\n",
      "(datetime.datetime(2023, 4, 26, 0, 0), datetime.datetime(2023, 6, 5, 0, 0))\n",
      "(datetime.datetime(2023, 6, 5, 0, 0), datetime.datetime(2023, 7, 17, 0, 0))\n",
      "(datetime.datetime(2023, 7, 17, 0, 0), datetime.datetime(2023, 8, 24, 0, 0))\n",
      "(datetime.datetime(2023, 8, 24, 0, 0), datetime.datetime(2023, 9, 25, 0, 0))\n",
      "(datetime.datetime(2023, 9, 25, 0, 0), datetime.datetime(2023, 11, 6, 0, 0))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data '0-11-20' does not match format '%d-%m-%Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [127], line 16\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_format)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Try parsing with the specified format\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     date_objects\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# If it fails, try parsing with the format for four-digit years\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03mformat string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n",
      "\u001b[1;31mValueError\u001b[0m: time data '0-11-20' does not match format '%d-%m-%y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [130], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency of follow up at lgb (to write down follow-up dates)\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mextract_consecutive_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#sum = 0\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m a:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m#sum = sum +  calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m#print(sum)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [127], line 19\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_format)\u001b[0m\n\u001b[0;32m     16\u001b[0m         date_objects\u001b[38;5;241m.\u001b[39mappend(datetime\u001b[38;5;241m.\u001b[39mstrptime(date, date_format))\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;66;03m# If it fails, try parsing with the format for four-digit years\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m         date_objects\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Extract pairs of consecutive dates\u001b[39;00m\n\u001b[0;32m     22\u001b[0m consecutive_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(date_objects[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], date_objects[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    347\u001b[0m found \u001b[38;5;241m=\u001b[39m format_regex\u001b[38;5;241m.\u001b[39mmatch(data_string)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n",
      "\u001b[1;31mValueError\u001b[0m: time data '0-11-20' does not match format '%d-%m-%Y'"
     ]
    }
   ],
   "source": [
    "for i in df2['frequency of follow up at lgb (to write down follow-up dates)']:\n",
    "    a = extract_consecutive_dates(i)\n",
    "    for pair in a:\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bb766c3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'float' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [131], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming df2 is your DataFrame\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency of follow up at lgb (to write down follow-up dates)\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Check if the value contains '0-11-20'\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0-11-20\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# Replace '0-11-20' with '01-11-20' using .loc\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         df2\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency of follow up at lgb (to write down follow-up dates)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0-11-20\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01-11-20\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Print the modified DataFrame\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'float' is not iterable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i, value in enumerate(df2['frequency of follow up at lgb (to write down follow-up dates)']):\n",
    "    if '0-11-20' in value:\n",
    "        df2.loc[i, 'frequency of follow up at lgb (to write down follow-up dates)'] = value.replace('0-11-20', '01-11-20')\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a487b589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0    female     Islam   \n",
      "2                            17.0                   18.0    female     Islam   \n",
      "3                             7.0                   17.0      male     Islam   \n",
      "4                            10.0                   10.0      male  Hinduism   \n",
      "5                             8.0                   15.0    female     Islam   \n",
      "..                            ...                    ...       ...       ...   \n",
      "164                          16.0                   17.0      male     Islam   \n",
      "186                          15.0                   15.0      male     Islam   \n",
      "187                          15.0                   17.0      male     Islam   \n",
      "191                           5.0                    8.0      male  Hinduism   \n",
      "75                            NaN                    NaN       NaN       NaN   \n",
      "\n",
      "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
      "1                                                  NaN                                         \n",
      "2                                              Primary                                         \n",
      "3                                                  NaN                                         \n",
      "4                                              primary                                         \n",
      "5                                  no formal education                                         \n",
      "..                                                 ...                                         \n",
      "164                                            primary                                         \n",
      "186                                        high school                                         \n",
      "187                                        high school                                         \n",
      "191                                            primary                                         \n",
      "75                                                 NaN                                         \n",
      "\n",
      "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                      NaN       Rural                           62.0   \n",
      "2                  Primary       Rural                           55.0   \n",
      "3                      NaN       Rural                          102.0   \n",
      "4                  Primary       Rural                           29.0   \n",
      "5      no formal education       Rural                          102.0   \n",
      "..                     ...         ...                            ...   \n",
      "164                primary       Rural                          110.0   \n",
      "186            high school       Rural                          326.0   \n",
      "187            high school       Rural                           37.0   \n",
      "191                primary       Rural                           63.0   \n",
      "75                     NaN         NaN                            NaN   \n",
      "\n",
      "     District  State  ... No of relapses/exacerbations  \\\n",
      "1    Udalguri  Assam  ...                          6.0   \n",
      "2      Nagaon  Assam  ...                          0.0   \n",
      "3      Nagaon  Assam  ...                          6.0   \n",
      "4    Sonitpur  Assam  ...                          1.0   \n",
      "5      Nagaon  Assam  ...                         33.0   \n",
      "..        ...    ...  ...                          ...   \n",
      "164  morigaon  Assam  ...                          2.0   \n",
      "186    Dhubri  Assam  ...                          1.0   \n",
      "187    Nagaon  Assam  ...                          0.0   \n",
      "191    Nagaon  Assam  ...                          0.0   \n",
      "75        NaN    NaN  ...                          NaN   \n",
      "\n",
      "     Off-medications duration (to add all such durations over follow-up in days)  \\\n",
      "1                                                   22                             \n",
      "2                                                   30                             \n",
      "3                                                   58                             \n",
      "4                                                   20                             \n",
      "5                                                   65                             \n",
      "..                                                 ...                             \n",
      "164                                                330                             \n",
      "186                                                180                             \n",
      "187                                                120                             \n",
      "191                                                  0                             \n",
      "75                                                 NaN                             \n",
      "\n",
      "            Final  \\\n",
      "1    Satisfactory   \n",
      "2            Poor   \n",
      "3            Good   \n",
      "4            Good   \n",
      "5    Satisfactory   \n",
      "..            ...   \n",
      "164          Poor   \n",
      "186          Poor   \n",
      "187  Satisfactory   \n",
      "191  Satisfactory   \n",
      "75            NaN   \n",
      "\n",
      "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
      "1                                                 1.66                                    \n",
      "2                                                 1.78                                    \n",
      "3                                                  NaN                                    \n",
      "4                                                    1                                    \n",
      "5                                                  6.6                                    \n",
      "..                                                 ...                                    \n",
      "164                                                3.8                                    \n",
      "186                                                4.3                                    \n",
      "187                                               1.21                                    \n",
      "191                                               2.15                                    \n",
      "75                                                 NaN                                    \n",
      "\n",
      "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
      "1                                                  395                                  \n",
      "2                                                  240                                  \n",
      "3                                                  NaN                                  \n",
      "4                                                   90                                  \n",
      "5                                                  480                                  \n",
      "..                                                 ...                                  \n",
      "164                                                113                                  \n",
      "186                                                170                                  \n",
      "187                                                390                                  \n",
      "191                                               1619                                  \n",
      "75                                                 NaN                                  \n",
      "\n",
      "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
      "1                                                  626                                                   \n",
      "2                                                  330                                                   \n",
      "3                                                 1320                                                   \n",
      "4                                                   90                                                   \n",
      "5                                                 3495                                                   \n",
      "..                                                 ...                                                   \n",
      "164                                                576                                                   \n",
      "186                                                384                                                   \n",
      "187                                                875                                                   \n",
      "191                                               1619                                                   \n",
      "75                                                 NaN                                                   \n",
      "\n",
      "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
      "1    24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...              \n",
      "2    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
      "3    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
      "4                                22-06-2020,30-09-2020              \n",
      "5    10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...              \n",
      "..                                                 ...              \n",
      "164       08-06-22,26-08-22,19-12-22,23-01-23,02-11-23              \n",
      "186                   28-08-2021,15-07-2022,17-08-2022              \n",
      "187  29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...              \n",
      "191  16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...              \n",
      "75   16-5-2018,15-6-2018,16-7-2018,16-8-2018,15-09-...              \n",
      "\n",
      "    total number of follow up at LGBRIMH Number of In patient cares  \\\n",
      "1                                   12.0                        0.0   \n",
      "2                                    4.0                        0.0   \n",
      "3                                   69.0                        0.0   \n",
      "4                                    2.0                        1.0   \n",
      "5                                   71.0                        0.0   \n",
      "..                                   ...                        ...   \n",
      "164                                  5.0                        0.0   \n",
      "186                                  3.0                        0.0   \n",
      "187                                 24.0                        0.0   \n",
      "191                                 25.0                        0.0   \n",
      "75                                   NaN                        NaN   \n",
      "\n",
      "    total_frequency  \n",
      "1              12.0  \n",
      "2               4.0  \n",
      "3              67.0  \n",
      "4               2.0  \n",
      "5              70.0  \n",
      "..              ...  \n",
      "164             5.0  \n",
      "186             3.0  \n",
      "187            22.0  \n",
      "191            25.0  \n",
      "75              NaN  \n",
      "\n",
      "[149 rows x 265 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "column_name = 'frequency of follow up at lgb (to write down follow-up dates)'\n",
    "\n",
    "for i, value in enumerate(df2[column_name]):\n",
    "    if isinstance(value, str) and '0-11-20' in value:\n",
    "        df2.loc[i, column_name] = value.replace('0-11-20', '01-11-20')\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "89c5f216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...\n",
       "2      31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...\n",
       "3      31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...\n",
       "4                                  22-06-2020,30-09-2020\n",
       "5      10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...\n",
       "                             ...                        \n",
       "164         08-06-22,26-08-22,19-12-22,23-01-23,02-11-23\n",
       "186                     28-08-2021,15-07-2022,17-08-2022\n",
       "187    29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...\n",
       "191    16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...\n",
       "75     16-5-2018,15-6-2018,16-7-2018,16-8-2018,15-09-...\n",
       "Name: frequency of follow up at lgb (to write down follow-up dates), Length: 149, dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['frequency of follow up at lgb (to write down follow-up dates)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "de988d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2019, 6, 24, 0, 0), datetime.datetime(2019, 7, 29, 0, 0))\n",
      "(datetime.datetime(2019, 7, 29, 0, 0), datetime.datetime(2019, 9, 9, 0, 0))\n",
      "(datetime.datetime(2019, 9, 9, 0, 0), datetime.datetime(2019, 10, 21, 0, 0))\n",
      "(datetime.datetime(2019, 10, 21, 0, 0), datetime.datetime(2019, 12, 17, 0, 0))\n",
      "(datetime.datetime(2019, 12, 17, 0, 0), datetime.datetime(2020, 1, 18, 0, 0))\n",
      "(datetime.datetime(2020, 1, 18, 0, 0), datetime.datetime(2020, 3, 2, 0, 0))\n",
      "(datetime.datetime(2020, 3, 2, 0, 0), datetime.datetime(2020, 5, 2, 0, 0))\n",
      "(datetime.datetime(2020, 5, 2, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2020, 8, 28, 0, 0))\n",
      "(datetime.datetime(2020, 8, 28, 0, 0), datetime.datetime(2020, 11, 17, 0, 0))\n",
      "(datetime.datetime(2020, 11, 17, 0, 0), datetime.datetime(2021, 1, 21, 0, 0))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data '301-11-2019' does not match format '%d-%m-%Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [127], line 16\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_format)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Try parsing with the specified format\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     date_objects\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# If it fails, try parsing with the format for four-digit years\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03mformat string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n",
      "\u001b[1;31mValueError\u001b[0m: time data '301-11-2019' does not match format '%d-%m-%y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [134], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency of follow up at lgb (to write down follow-up dates)\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mextract_consecutive_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#sum = 0\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m a:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m#sum = sum +  calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m#print(sum)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [127], line 19\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_format)\u001b[0m\n\u001b[0;32m     16\u001b[0m         date_objects\u001b[38;5;241m.\u001b[39mappend(datetime\u001b[38;5;241m.\u001b[39mstrptime(date, date_format))\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;66;03m# If it fails, try parsing with the format for four-digit years\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m         date_objects\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Extract pairs of consecutive dates\u001b[39;00m\n\u001b[0;32m     22\u001b[0m consecutive_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(date_objects[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], date_objects[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    347\u001b[0m found \u001b[38;5;241m=\u001b[39m format_regex\u001b[38;5;241m.\u001b[39mmatch(data_string)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n",
      "\u001b[1;31mValueError\u001b[0m: time data '301-11-2019' does not match format '%d-%m-%Y'"
     ]
    }
   ],
   "source": [
    "for i in df2['frequency of follow up at lgb (to write down follow-up dates)']:\n",
    "    a = extract_consecutive_dates(i)\n",
    "    #sum = 0\n",
    "    for pair in a:\n",
    "        #sum = sum +  calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\n",
    "        #print(sum)\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ae3370bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_consecutive_dates(date_str, date_formats=[\"%d-%m-%Y\", \"%d-%m-%y\", \"%d.%m.%Y\", \"%d.%m.%y\"]):\n",
    "    date_list = date_str.split(',')\n",
    "\n",
    "    date_objects = []\n",
    "    for date in date_list:\n",
    "        parsed_date = None\n",
    "        for format_str in date_formats:\n",
    "            try:\n",
    "                parsed_date = datetime.strptime(date, format_str)\n",
    "                break \n",
    "            except ValueError:\n",
    "                pass  \n",
    "\n",
    "        if parsed_date:\n",
    "            parsed_date = parsed_date.replace(year=parsed_date.year + 2000) if parsed_date.year < 100 else parsed_date\n",
    "            date_objects.append(parsed_date)\n",
    "\n",
    "    consecutive_pairs = zip(date_objects[:-1], date_objects[1:])\n",
    "\n",
    "    return consecutive_pairs\n",
    "\n",
    "date_str = \"\"\n",
    "consecutive_pairs = extract_consecutive_dates(date_str)\n",
    "\n",
    "for pair in consecutive_pairs:\n",
    "    print(f\"Consecutive Dates: {pair[0].strftime('%d-%m-%Y')} and {pair[1].strftime('%d-%m-%Y')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "63c20e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-06-2019,29-07-2019,09-09-2019,21-10-2019,17-12-2019,18-01-2020,02-03-2020,02-05-2020,22-06-2020,28-08-2020,17-11-2020,21-01-2021\n",
      "(datetime.datetime(2019, 6, 24, 0, 0), datetime.datetime(2019, 7, 29, 0, 0))\n",
      "(datetime.datetime(2019, 7, 29, 0, 0), datetime.datetime(2019, 9, 9, 0, 0))\n",
      "(datetime.datetime(2019, 9, 9, 0, 0), datetime.datetime(2019, 10, 21, 0, 0))\n",
      "(datetime.datetime(2019, 10, 21, 0, 0), datetime.datetime(2019, 12, 17, 0, 0))\n",
      "(datetime.datetime(2019, 12, 17, 0, 0), datetime.datetime(2020, 1, 18, 0, 0))\n",
      "(datetime.datetime(2020, 1, 18, 0, 0), datetime.datetime(2020, 3, 2, 0, 0))\n",
      "(datetime.datetime(2020, 3, 2, 0, 0), datetime.datetime(2020, 5, 2, 0, 0))\n",
      "(datetime.datetime(2020, 5, 2, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2020, 8, 28, 0, 0))\n",
      "(datetime.datetime(2020, 8, 28, 0, 0), datetime.datetime(2020, 11, 17, 0, 0))\n",
      "(datetime.datetime(2020, 11, 17, 0, 0), datetime.datetime(2021, 1, 21, 0, 0))\n",
      "31-03-2014,29-04-2014,29-05-2014,04-07-2014,25-08-2014,01-02-2016,30-03-2016,29-04-2016,03-06-2016,28-08-2016,08-08-2016,08-09-2016,05-10-2016,09-11-2016,16-12-2016,23-01-2017,22-02-2017,10-03-2017,21-04-2017,25-05-2017,22-06-2017,20-07-2017,03-10-2017,02-11-2017,06-01-2018,05-02-2018,08-03-2018,07-04-2018,05-05-2018,07-06-2018,09-08-2018,12-09-2018,09-10-2018,12-11-2018,19-12-2018,17-01-2019,13-06-2019,13-07-2019,17-08-2019,17-08-2019,20-10-2019,301-11-2019,03-01-2020,06-03-2020,22-06-2020,02-04-2021,10-05-2021,06-08-2021,07-09-2021,13-11-2021,17-01-2022,19-03-2022,30-05-2022,04-07-2022,09-08-2022,13-09-2022,27-10-2022,28-11-2022,10-01-2023,13-02-2023,22-03-2023,26-04-2023,05-06-2023,17-07-2023,24-08-2023,25-09-2023,06-11-2023\n",
      "(datetime.datetime(2014, 3, 31, 0, 0), datetime.datetime(2014, 4, 29, 0, 0))\n",
      "(datetime.datetime(2014, 4, 29, 0, 0), datetime.datetime(2014, 5, 29, 0, 0))\n",
      "(datetime.datetime(2014, 5, 29, 0, 0), datetime.datetime(2014, 7, 4, 0, 0))\n",
      "(datetime.datetime(2014, 7, 4, 0, 0), datetime.datetime(2014, 8, 25, 0, 0))\n",
      "(datetime.datetime(2014, 8, 25, 0, 0), datetime.datetime(2016, 2, 1, 0, 0))\n",
      "(datetime.datetime(2016, 2, 1, 0, 0), datetime.datetime(2016, 3, 30, 0, 0))\n",
      "(datetime.datetime(2016, 3, 30, 0, 0), datetime.datetime(2016, 4, 29, 0, 0))\n",
      "(datetime.datetime(2016, 4, 29, 0, 0), datetime.datetime(2016, 6, 3, 0, 0))\n",
      "(datetime.datetime(2016, 6, 3, 0, 0), datetime.datetime(2016, 8, 28, 0, 0))\n",
      "(datetime.datetime(2016, 8, 28, 0, 0), datetime.datetime(2016, 8, 8, 0, 0))\n",
      "(datetime.datetime(2016, 8, 8, 0, 0), datetime.datetime(2016, 9, 8, 0, 0))\n",
      "(datetime.datetime(2016, 9, 8, 0, 0), datetime.datetime(2016, 10, 5, 0, 0))\n",
      "(datetime.datetime(2016, 10, 5, 0, 0), datetime.datetime(2016, 11, 9, 0, 0))\n",
      "(datetime.datetime(2016, 11, 9, 0, 0), datetime.datetime(2016, 12, 16, 0, 0))\n",
      "(datetime.datetime(2016, 12, 16, 0, 0), datetime.datetime(2017, 1, 23, 0, 0))\n",
      "(datetime.datetime(2017, 1, 23, 0, 0), datetime.datetime(2017, 2, 22, 0, 0))\n",
      "(datetime.datetime(2017, 2, 22, 0, 0), datetime.datetime(2017, 3, 10, 0, 0))\n",
      "(datetime.datetime(2017, 3, 10, 0, 0), datetime.datetime(2017, 4, 21, 0, 0))\n",
      "(datetime.datetime(2017, 4, 21, 0, 0), datetime.datetime(2017, 5, 25, 0, 0))\n",
      "(datetime.datetime(2017, 5, 25, 0, 0), datetime.datetime(2017, 6, 22, 0, 0))\n",
      "(datetime.datetime(2017, 6, 22, 0, 0), datetime.datetime(2017, 7, 20, 0, 0))\n",
      "(datetime.datetime(2017, 7, 20, 0, 0), datetime.datetime(2017, 10, 3, 0, 0))\n",
      "(datetime.datetime(2017, 10, 3, 0, 0), datetime.datetime(2017, 11, 2, 0, 0))\n",
      "(datetime.datetime(2017, 11, 2, 0, 0), datetime.datetime(2018, 1, 6, 0, 0))\n",
      "(datetime.datetime(2018, 1, 6, 0, 0), datetime.datetime(2018, 2, 5, 0, 0))\n",
      "(datetime.datetime(2018, 2, 5, 0, 0), datetime.datetime(2018, 3, 8, 0, 0))\n",
      "(datetime.datetime(2018, 3, 8, 0, 0), datetime.datetime(2018, 4, 7, 0, 0))\n",
      "(datetime.datetime(2018, 4, 7, 0, 0), datetime.datetime(2018, 5, 5, 0, 0))\n",
      "(datetime.datetime(2018, 5, 5, 0, 0), datetime.datetime(2018, 6, 7, 0, 0))\n",
      "(datetime.datetime(2018, 6, 7, 0, 0), datetime.datetime(2018, 8, 9, 0, 0))\n",
      "(datetime.datetime(2018, 8, 9, 0, 0), datetime.datetime(2018, 9, 12, 0, 0))\n",
      "(datetime.datetime(2018, 9, 12, 0, 0), datetime.datetime(2018, 10, 9, 0, 0))\n",
      "(datetime.datetime(2018, 10, 9, 0, 0), datetime.datetime(2018, 11, 12, 0, 0))\n",
      "(datetime.datetime(2018, 11, 12, 0, 0), datetime.datetime(2018, 12, 19, 0, 0))\n",
      "(datetime.datetime(2018, 12, 19, 0, 0), datetime.datetime(2019, 1, 17, 0, 0))\n",
      "(datetime.datetime(2019, 1, 17, 0, 0), datetime.datetime(2019, 6, 13, 0, 0))\n",
      "(datetime.datetime(2019, 6, 13, 0, 0), datetime.datetime(2019, 7, 13, 0, 0))\n",
      "(datetime.datetime(2019, 7, 13, 0, 0), datetime.datetime(2019, 8, 17, 0, 0))\n",
      "(datetime.datetime(2019, 8, 17, 0, 0), datetime.datetime(2019, 8, 17, 0, 0))\n",
      "(datetime.datetime(2019, 8, 17, 0, 0), datetime.datetime(2019, 10, 20, 0, 0))\n",
      "(datetime.datetime(2019, 10, 20, 0, 0), datetime.datetime(2020, 1, 3, 0, 0))\n",
      "(datetime.datetime(2020, 1, 3, 0, 0), datetime.datetime(2020, 3, 6, 0, 0))\n",
      "(datetime.datetime(2020, 3, 6, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2021, 4, 2, 0, 0))\n",
      "(datetime.datetime(2021, 4, 2, 0, 0), datetime.datetime(2021, 5, 10, 0, 0))\n",
      "(datetime.datetime(2021, 5, 10, 0, 0), datetime.datetime(2021, 8, 6, 0, 0))\n",
      "(datetime.datetime(2021, 8, 6, 0, 0), datetime.datetime(2021, 9, 7, 0, 0))\n",
      "(datetime.datetime(2021, 9, 7, 0, 0), datetime.datetime(2021, 11, 13, 0, 0))\n",
      "(datetime.datetime(2021, 11, 13, 0, 0), datetime.datetime(2022, 1, 17, 0, 0))\n",
      "(datetime.datetime(2022, 1, 17, 0, 0), datetime.datetime(2022, 3, 19, 0, 0))\n",
      "(datetime.datetime(2022, 3, 19, 0, 0), datetime.datetime(2022, 5, 30, 0, 0))\n",
      "(datetime.datetime(2022, 5, 30, 0, 0), datetime.datetime(2022, 7, 4, 0, 0))\n",
      "(datetime.datetime(2022, 7, 4, 0, 0), datetime.datetime(2022, 8, 9, 0, 0))\n",
      "(datetime.datetime(2022, 8, 9, 0, 0), datetime.datetime(2022, 9, 13, 0, 0))\n",
      "(datetime.datetime(2022, 9, 13, 0, 0), datetime.datetime(2022, 10, 27, 0, 0))\n",
      "(datetime.datetime(2022, 10, 27, 0, 0), datetime.datetime(2022, 11, 28, 0, 0))\n",
      "(datetime.datetime(2022, 11, 28, 0, 0), datetime.datetime(2023, 1, 10, 0, 0))\n",
      "(datetime.datetime(2023, 1, 10, 0, 0), datetime.datetime(2023, 2, 13, 0, 0))\n",
      "(datetime.datetime(2023, 2, 13, 0, 0), datetime.datetime(2023, 3, 22, 0, 0))\n",
      "(datetime.datetime(2023, 3, 22, 0, 0), datetime.datetime(2023, 4, 26, 0, 0))\n",
      "(datetime.datetime(2023, 4, 26, 0, 0), datetime.datetime(2023, 6, 5, 0, 0))\n",
      "(datetime.datetime(2023, 6, 5, 0, 0), datetime.datetime(2023, 7, 17, 0, 0))\n",
      "(datetime.datetime(2023, 7, 17, 0, 0), datetime.datetime(2023, 8, 24, 0, 0))\n",
      "(datetime.datetime(2023, 8, 24, 0, 0), datetime.datetime(2023, 9, 25, 0, 0))\n",
      "(datetime.datetime(2023, 9, 25, 0, 0), datetime.datetime(2023, 11, 6, 0, 0))\n",
      "31-03-2014,29-04-2014,29-05-2014,04-07-2014,25-08-2014,01-02-2016,30-03-2016,29-04-2016,03-06-2016,28-08-2016,08-08-2016,08-09-2016,05-10-2016,09-11-2016,16-12-2016,23-01-2017,22-02-2017,10-03-2017,21-04-2017,25-05-2017,22-06-2017,20-07-2017,03-10-2017,02-11-2017,06-01-2018,05-02-2018,08-03-2018,07-04-2018,05-05-2018,07-06-2018,09-08-2018,12-09-2018,09-10-2018,12-11-2018,19-12-2018,17-01-2019,13-06-2019,13-07-2019,17-08-2019,17-08-2019,20-10-2019,30-11-2019,03-01-2020,06-03-2020,22-06-2020,02-04-2021,10-05-2021,06-08-2021,07-09-2021,13-11-2021,17-01-2022,19-03-2022,30-05-2022,04-07-2022,09-08-2022,13-09-2022,27-10-2022,28-11-2022,10-01-2023,13-02-2023,22-03-2023,26-04-2023,05-06-2023,17-07-2023,24-08-2023,25-09-2023,06-11-2023\n",
      "(datetime.datetime(2014, 3, 31, 0, 0), datetime.datetime(2014, 4, 29, 0, 0))\n",
      "(datetime.datetime(2014, 4, 29, 0, 0), datetime.datetime(2014, 5, 29, 0, 0))\n",
      "(datetime.datetime(2014, 5, 29, 0, 0), datetime.datetime(2014, 7, 4, 0, 0))\n",
      "(datetime.datetime(2014, 7, 4, 0, 0), datetime.datetime(2014, 8, 25, 0, 0))\n",
      "(datetime.datetime(2014, 8, 25, 0, 0), datetime.datetime(2016, 2, 1, 0, 0))\n",
      "(datetime.datetime(2016, 2, 1, 0, 0), datetime.datetime(2016, 3, 30, 0, 0))\n",
      "(datetime.datetime(2016, 3, 30, 0, 0), datetime.datetime(2016, 4, 29, 0, 0))\n",
      "(datetime.datetime(2016, 4, 29, 0, 0), datetime.datetime(2016, 6, 3, 0, 0))\n",
      "(datetime.datetime(2016, 6, 3, 0, 0), datetime.datetime(2016, 8, 28, 0, 0))\n",
      "(datetime.datetime(2016, 8, 28, 0, 0), datetime.datetime(2016, 8, 8, 0, 0))\n",
      "(datetime.datetime(2016, 8, 8, 0, 0), datetime.datetime(2016, 9, 8, 0, 0))\n",
      "(datetime.datetime(2016, 9, 8, 0, 0), datetime.datetime(2016, 10, 5, 0, 0))\n",
      "(datetime.datetime(2016, 10, 5, 0, 0), datetime.datetime(2016, 11, 9, 0, 0))\n",
      "(datetime.datetime(2016, 11, 9, 0, 0), datetime.datetime(2016, 12, 16, 0, 0))\n",
      "(datetime.datetime(2016, 12, 16, 0, 0), datetime.datetime(2017, 1, 23, 0, 0))\n",
      "(datetime.datetime(2017, 1, 23, 0, 0), datetime.datetime(2017, 2, 22, 0, 0))\n",
      "(datetime.datetime(2017, 2, 22, 0, 0), datetime.datetime(2017, 3, 10, 0, 0))\n",
      "(datetime.datetime(2017, 3, 10, 0, 0), datetime.datetime(2017, 4, 21, 0, 0))\n",
      "(datetime.datetime(2017, 4, 21, 0, 0), datetime.datetime(2017, 5, 25, 0, 0))\n",
      "(datetime.datetime(2017, 5, 25, 0, 0), datetime.datetime(2017, 6, 22, 0, 0))\n",
      "(datetime.datetime(2017, 6, 22, 0, 0), datetime.datetime(2017, 7, 20, 0, 0))\n",
      "(datetime.datetime(2017, 7, 20, 0, 0), datetime.datetime(2017, 10, 3, 0, 0))\n",
      "(datetime.datetime(2017, 10, 3, 0, 0), datetime.datetime(2017, 11, 2, 0, 0))\n",
      "(datetime.datetime(2017, 11, 2, 0, 0), datetime.datetime(2018, 1, 6, 0, 0))\n",
      "(datetime.datetime(2018, 1, 6, 0, 0), datetime.datetime(2018, 2, 5, 0, 0))\n",
      "(datetime.datetime(2018, 2, 5, 0, 0), datetime.datetime(2018, 3, 8, 0, 0))\n",
      "(datetime.datetime(2018, 3, 8, 0, 0), datetime.datetime(2018, 4, 7, 0, 0))\n",
      "(datetime.datetime(2018, 4, 7, 0, 0), datetime.datetime(2018, 5, 5, 0, 0))\n",
      "(datetime.datetime(2018, 5, 5, 0, 0), datetime.datetime(2018, 6, 7, 0, 0))\n",
      "(datetime.datetime(2018, 6, 7, 0, 0), datetime.datetime(2018, 8, 9, 0, 0))\n",
      "(datetime.datetime(2018, 8, 9, 0, 0), datetime.datetime(2018, 9, 12, 0, 0))\n",
      "(datetime.datetime(2018, 9, 12, 0, 0), datetime.datetime(2018, 10, 9, 0, 0))\n",
      "(datetime.datetime(2018, 10, 9, 0, 0), datetime.datetime(2018, 11, 12, 0, 0))\n",
      "(datetime.datetime(2018, 11, 12, 0, 0), datetime.datetime(2018, 12, 19, 0, 0))\n",
      "(datetime.datetime(2018, 12, 19, 0, 0), datetime.datetime(2019, 1, 17, 0, 0))\n",
      "(datetime.datetime(2019, 1, 17, 0, 0), datetime.datetime(2019, 6, 13, 0, 0))\n",
      "(datetime.datetime(2019, 6, 13, 0, 0), datetime.datetime(2019, 7, 13, 0, 0))\n",
      "(datetime.datetime(2019, 7, 13, 0, 0), datetime.datetime(2019, 8, 17, 0, 0))\n",
      "(datetime.datetime(2019, 8, 17, 0, 0), datetime.datetime(2019, 8, 17, 0, 0))\n",
      "(datetime.datetime(2019, 8, 17, 0, 0), datetime.datetime(2019, 10, 20, 0, 0))\n",
      "(datetime.datetime(2019, 10, 20, 0, 0), datetime.datetime(2019, 11, 30, 0, 0))\n",
      "(datetime.datetime(2019, 11, 30, 0, 0), datetime.datetime(2020, 1, 3, 0, 0))\n",
      "(datetime.datetime(2020, 1, 3, 0, 0), datetime.datetime(2020, 3, 6, 0, 0))\n",
      "(datetime.datetime(2020, 3, 6, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2021, 4, 2, 0, 0))\n",
      "(datetime.datetime(2021, 4, 2, 0, 0), datetime.datetime(2021, 5, 10, 0, 0))\n",
      "(datetime.datetime(2021, 5, 10, 0, 0), datetime.datetime(2021, 8, 6, 0, 0))\n",
      "(datetime.datetime(2021, 8, 6, 0, 0), datetime.datetime(2021, 9, 7, 0, 0))\n",
      "(datetime.datetime(2021, 9, 7, 0, 0), datetime.datetime(2021, 11, 13, 0, 0))\n",
      "(datetime.datetime(2021, 11, 13, 0, 0), datetime.datetime(2022, 1, 17, 0, 0))\n",
      "(datetime.datetime(2022, 1, 17, 0, 0), datetime.datetime(2022, 3, 19, 0, 0))\n",
      "(datetime.datetime(2022, 3, 19, 0, 0), datetime.datetime(2022, 5, 30, 0, 0))\n",
      "(datetime.datetime(2022, 5, 30, 0, 0), datetime.datetime(2022, 7, 4, 0, 0))\n",
      "(datetime.datetime(2022, 7, 4, 0, 0), datetime.datetime(2022, 8, 9, 0, 0))\n",
      "(datetime.datetime(2022, 8, 9, 0, 0), datetime.datetime(2022, 9, 13, 0, 0))\n",
      "(datetime.datetime(2022, 9, 13, 0, 0), datetime.datetime(2022, 10, 27, 0, 0))\n",
      "(datetime.datetime(2022, 10, 27, 0, 0), datetime.datetime(2022, 11, 28, 0, 0))\n",
      "(datetime.datetime(2022, 11, 28, 0, 0), datetime.datetime(2023, 1, 10, 0, 0))\n",
      "(datetime.datetime(2023, 1, 10, 0, 0), datetime.datetime(2023, 2, 13, 0, 0))\n",
      "(datetime.datetime(2023, 2, 13, 0, 0), datetime.datetime(2023, 3, 22, 0, 0))\n",
      "(datetime.datetime(2023, 3, 22, 0, 0), datetime.datetime(2023, 4, 26, 0, 0))\n",
      "(datetime.datetime(2023, 4, 26, 0, 0), datetime.datetime(2023, 6, 5, 0, 0))\n",
      "(datetime.datetime(2023, 6, 5, 0, 0), datetime.datetime(2023, 7, 17, 0, 0))\n",
      "(datetime.datetime(2023, 7, 17, 0, 0), datetime.datetime(2023, 8, 24, 0, 0))\n",
      "(datetime.datetime(2023, 8, 24, 0, 0), datetime.datetime(2023, 9, 25, 0, 0))\n",
      "(datetime.datetime(2023, 9, 25, 0, 0), datetime.datetime(2023, 11, 6, 0, 0))\n",
      "22-06-2020,30-09-2020\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2020, 9, 30, 0, 0))\n",
      "10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,23-09-15,21-10-15,11-11-15,21-12-15,25-1-16,16-3-16,18-5-16,20-07-16,7-9-16,26-10-16,28-12-16,27-1-17,22-2-17,17-3-17,14-4-17,12-5-17,26-6-17,13-9-17,11-10-17,15-11-17,15-12-17,7-2-18,2-4-18,9-5-18,31-5-18,27-6-18,4-8-18,24-9-18,5-11-18,14-12-18,15-1-19,12-2-19,12-4-19,25-5-19,16-7-19,20-8-19,21-9-19,21-10-19,18-11-19,20-12-19,25-1-2020,24-2-2020,20-03-20,19-05-20,22-06-20,28-07-20,20-10-20,01-11-20,22-12-20,19-1-21,19-2-21,19-03-21,12-04-21,08-05-21,19-07-21,13-08-21,11-10-21,16-11-21,17-12-21,11-01-22,15-03-21,12-04-22,13-06-22,16-07-22,16-08-22,14-11-22,24-01-23,28-02-23,1-04-23,29-05-23,4-07-23,18-08-23,26-09-23,07-11-23\n",
      "(datetime.datetime(2015, 6, 10, 0, 0), datetime.datetime(2015, 6, 22, 0, 0))\n",
      "(datetime.datetime(2015, 6, 22, 0, 0), datetime.datetime(2015, 7, 15, 0, 0))\n",
      "(datetime.datetime(2015, 7, 15, 0, 0), datetime.datetime(2015, 7, 29, 0, 0))\n",
      "(datetime.datetime(2015, 7, 29, 0, 0), datetime.datetime(2015, 5, 26, 0, 0))\n",
      "(datetime.datetime(2015, 5, 26, 0, 0), datetime.datetime(2015, 9, 23, 0, 0))\n",
      "(datetime.datetime(2015, 9, 23, 0, 0), datetime.datetime(2015, 10, 21, 0, 0))\n",
      "(datetime.datetime(2015, 10, 21, 0, 0), datetime.datetime(2015, 11, 11, 0, 0))\n",
      "(datetime.datetime(2015, 11, 11, 0, 0), datetime.datetime(2015, 12, 21, 0, 0))\n",
      "(datetime.datetime(2015, 12, 21, 0, 0), datetime.datetime(2016, 1, 25, 0, 0))\n",
      "(datetime.datetime(2016, 1, 25, 0, 0), datetime.datetime(2016, 3, 16, 0, 0))\n",
      "(datetime.datetime(2016, 3, 16, 0, 0), datetime.datetime(2016, 5, 18, 0, 0))\n",
      "(datetime.datetime(2016, 5, 18, 0, 0), datetime.datetime(2016, 7, 20, 0, 0))\n",
      "(datetime.datetime(2016, 7, 20, 0, 0), datetime.datetime(2016, 9, 7, 0, 0))\n",
      "(datetime.datetime(2016, 9, 7, 0, 0), datetime.datetime(2016, 10, 26, 0, 0))\n",
      "(datetime.datetime(2016, 10, 26, 0, 0), datetime.datetime(2016, 12, 28, 0, 0))\n",
      "(datetime.datetime(2016, 12, 28, 0, 0), datetime.datetime(2017, 1, 27, 0, 0))\n",
      "(datetime.datetime(2017, 1, 27, 0, 0), datetime.datetime(2017, 2, 22, 0, 0))\n",
      "(datetime.datetime(2017, 2, 22, 0, 0), datetime.datetime(2017, 3, 17, 0, 0))\n",
      "(datetime.datetime(2017, 3, 17, 0, 0), datetime.datetime(2017, 4, 14, 0, 0))\n",
      "(datetime.datetime(2017, 4, 14, 0, 0), datetime.datetime(2017, 5, 12, 0, 0))\n",
      "(datetime.datetime(2017, 5, 12, 0, 0), datetime.datetime(2017, 6, 26, 0, 0))\n",
      "(datetime.datetime(2017, 6, 26, 0, 0), datetime.datetime(2017, 9, 13, 0, 0))\n",
      "(datetime.datetime(2017, 9, 13, 0, 0), datetime.datetime(2017, 10, 11, 0, 0))\n",
      "(datetime.datetime(2017, 10, 11, 0, 0), datetime.datetime(2017, 11, 15, 0, 0))\n",
      "(datetime.datetime(2017, 11, 15, 0, 0), datetime.datetime(2017, 12, 15, 0, 0))\n",
      "(datetime.datetime(2017, 12, 15, 0, 0), datetime.datetime(2018, 2, 7, 0, 0))\n",
      "(datetime.datetime(2018, 2, 7, 0, 0), datetime.datetime(2018, 4, 2, 0, 0))\n",
      "(datetime.datetime(2018, 4, 2, 0, 0), datetime.datetime(2018, 5, 9, 0, 0))\n",
      "(datetime.datetime(2018, 5, 9, 0, 0), datetime.datetime(2018, 5, 31, 0, 0))\n",
      "(datetime.datetime(2018, 5, 31, 0, 0), datetime.datetime(2018, 6, 27, 0, 0))\n",
      "(datetime.datetime(2018, 6, 27, 0, 0), datetime.datetime(2018, 8, 4, 0, 0))\n",
      "(datetime.datetime(2018, 8, 4, 0, 0), datetime.datetime(2018, 9, 24, 0, 0))\n",
      "(datetime.datetime(2018, 9, 24, 0, 0), datetime.datetime(2018, 11, 5, 0, 0))\n",
      "(datetime.datetime(2018, 11, 5, 0, 0), datetime.datetime(2018, 12, 14, 0, 0))\n",
      "(datetime.datetime(2018, 12, 14, 0, 0), datetime.datetime(2019, 1, 15, 0, 0))\n",
      "(datetime.datetime(2019, 1, 15, 0, 0), datetime.datetime(2019, 2, 12, 0, 0))\n",
      "(datetime.datetime(2019, 2, 12, 0, 0), datetime.datetime(2019, 4, 12, 0, 0))\n",
      "(datetime.datetime(2019, 4, 12, 0, 0), datetime.datetime(2019, 5, 25, 0, 0))\n",
      "(datetime.datetime(2019, 5, 25, 0, 0), datetime.datetime(2019, 7, 16, 0, 0))\n",
      "(datetime.datetime(2019, 7, 16, 0, 0), datetime.datetime(2019, 8, 20, 0, 0))\n",
      "(datetime.datetime(2019, 8, 20, 0, 0), datetime.datetime(2019, 9, 21, 0, 0))\n",
      "(datetime.datetime(2019, 9, 21, 0, 0), datetime.datetime(2019, 10, 21, 0, 0))\n",
      "(datetime.datetime(2019, 10, 21, 0, 0), datetime.datetime(2019, 11, 18, 0, 0))\n",
      "(datetime.datetime(2019, 11, 18, 0, 0), datetime.datetime(2019, 12, 20, 0, 0))\n",
      "(datetime.datetime(2019, 12, 20, 0, 0), datetime.datetime(2020, 1, 25, 0, 0))\n",
      "(datetime.datetime(2020, 1, 25, 0, 0), datetime.datetime(2020, 2, 24, 0, 0))\n",
      "(datetime.datetime(2020, 2, 24, 0, 0), datetime.datetime(2020, 3, 20, 0, 0))\n",
      "(datetime.datetime(2020, 3, 20, 0, 0), datetime.datetime(2020, 5, 19, 0, 0))\n",
      "(datetime.datetime(2020, 5, 19, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2020, 7, 28, 0, 0))\n",
      "(datetime.datetime(2020, 7, 28, 0, 0), datetime.datetime(2020, 10, 20, 0, 0))\n",
      "(datetime.datetime(2020, 10, 20, 0, 0), datetime.datetime(2020, 11, 1, 0, 0))\n",
      "(datetime.datetime(2020, 11, 1, 0, 0), datetime.datetime(2020, 12, 22, 0, 0))\n",
      "(datetime.datetime(2020, 12, 22, 0, 0), datetime.datetime(2021, 1, 19, 0, 0))\n",
      "(datetime.datetime(2021, 1, 19, 0, 0), datetime.datetime(2021, 2, 19, 0, 0))\n",
      "(datetime.datetime(2021, 2, 19, 0, 0), datetime.datetime(2021, 3, 19, 0, 0))\n",
      "(datetime.datetime(2021, 3, 19, 0, 0), datetime.datetime(2021, 4, 12, 0, 0))\n",
      "(datetime.datetime(2021, 4, 12, 0, 0), datetime.datetime(2021, 5, 8, 0, 0))\n",
      "(datetime.datetime(2021, 5, 8, 0, 0), datetime.datetime(2021, 7, 19, 0, 0))\n",
      "(datetime.datetime(2021, 7, 19, 0, 0), datetime.datetime(2021, 8, 13, 0, 0))\n",
      "(datetime.datetime(2021, 8, 13, 0, 0), datetime.datetime(2021, 10, 11, 0, 0))\n",
      "(datetime.datetime(2021, 10, 11, 0, 0), datetime.datetime(2021, 11, 16, 0, 0))\n",
      "(datetime.datetime(2021, 11, 16, 0, 0), datetime.datetime(2021, 12, 17, 0, 0))\n",
      "(datetime.datetime(2021, 12, 17, 0, 0), datetime.datetime(2022, 1, 11, 0, 0))\n",
      "(datetime.datetime(2022, 1, 11, 0, 0), datetime.datetime(2021, 3, 15, 0, 0))\n",
      "(datetime.datetime(2021, 3, 15, 0, 0), datetime.datetime(2022, 4, 12, 0, 0))\n",
      "(datetime.datetime(2022, 4, 12, 0, 0), datetime.datetime(2022, 6, 13, 0, 0))\n",
      "(datetime.datetime(2022, 6, 13, 0, 0), datetime.datetime(2022, 7, 16, 0, 0))\n",
      "(datetime.datetime(2022, 7, 16, 0, 0), datetime.datetime(2022, 8, 16, 0, 0))\n",
      "(datetime.datetime(2022, 8, 16, 0, 0), datetime.datetime(2022, 11, 14, 0, 0))\n",
      "(datetime.datetime(2022, 11, 14, 0, 0), datetime.datetime(2023, 1, 24, 0, 0))\n",
      "(datetime.datetime(2023, 1, 24, 0, 0), datetime.datetime(2023, 2, 28, 0, 0))\n",
      "(datetime.datetime(2023, 2, 28, 0, 0), datetime.datetime(2023, 4, 1, 0, 0))\n",
      "(datetime.datetime(2023, 4, 1, 0, 0), datetime.datetime(2023, 5, 29, 0, 0))\n",
      "(datetime.datetime(2023, 5, 29, 0, 0), datetime.datetime(2023, 7, 4, 0, 0))\n",
      "(datetime.datetime(2023, 7, 4, 0, 0), datetime.datetime(2023, 8, 18, 0, 0))\n",
      "(datetime.datetime(2023, 8, 18, 0, 0), datetime.datetime(2023, 9, 26, 0, 0))\n",
      "(datetime.datetime(2023, 9, 26, 0, 0), datetime.datetime(2023, 11, 7, 0, 0))\n",
      "10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,23-09-15,21-10-15,11-11-15,21-12-15,25-1-16,16-3-16,18-5-16,20-07-16,7-9-16,26-10-16,28-12-16,27-1-17,22-2-17,17-3-17,14-4-17,12-5-17,26-6-17,13-9-17,11-10-17,15-11-17,15-12-17,7-2-18,2-4-18,9-5-18,31-5-18,27-6-18,4-8-18,24-9-18,5-11-18,14-12-18,15-1-19,12-2-19,12-4-19,25-5-19,16-7-19,20-8-19,21-9-19,21-10-19,18-11-19,20-12-19,25-1-2020,24-2-2020,20-03-20,19-05-20,22-06-20,28-07-20,20-10-20,0-11-20,22-12-20,19-1-21,19-2-21,19-03-21,12-04-21,08-05-21,19-07-21,13-08-21,11-10-21,16-11-21,17-12-21,11-01-22,15-03-21,12-04-22,13-06-22,16-07-22,16-08-22,14-11-22,24-01-23,28-02-23,1-04-23,29-05-23,4-07-23,18-08-23,26-09-23,07-11-23\n",
      "(datetime.datetime(2015, 6, 10, 0, 0), datetime.datetime(2015, 6, 22, 0, 0))\n",
      "(datetime.datetime(2015, 6, 22, 0, 0), datetime.datetime(2015, 7, 15, 0, 0))\n",
      "(datetime.datetime(2015, 7, 15, 0, 0), datetime.datetime(2015, 7, 29, 0, 0))\n",
      "(datetime.datetime(2015, 7, 29, 0, 0), datetime.datetime(2015, 5, 26, 0, 0))\n",
      "(datetime.datetime(2015, 5, 26, 0, 0), datetime.datetime(2015, 9, 23, 0, 0))\n",
      "(datetime.datetime(2015, 9, 23, 0, 0), datetime.datetime(2015, 10, 21, 0, 0))\n",
      "(datetime.datetime(2015, 10, 21, 0, 0), datetime.datetime(2015, 11, 11, 0, 0))\n",
      "(datetime.datetime(2015, 11, 11, 0, 0), datetime.datetime(2015, 12, 21, 0, 0))\n",
      "(datetime.datetime(2015, 12, 21, 0, 0), datetime.datetime(2016, 1, 25, 0, 0))\n",
      "(datetime.datetime(2016, 1, 25, 0, 0), datetime.datetime(2016, 3, 16, 0, 0))\n",
      "(datetime.datetime(2016, 3, 16, 0, 0), datetime.datetime(2016, 5, 18, 0, 0))\n",
      "(datetime.datetime(2016, 5, 18, 0, 0), datetime.datetime(2016, 7, 20, 0, 0))\n",
      "(datetime.datetime(2016, 7, 20, 0, 0), datetime.datetime(2016, 9, 7, 0, 0))\n",
      "(datetime.datetime(2016, 9, 7, 0, 0), datetime.datetime(2016, 10, 26, 0, 0))\n",
      "(datetime.datetime(2016, 10, 26, 0, 0), datetime.datetime(2016, 12, 28, 0, 0))\n",
      "(datetime.datetime(2016, 12, 28, 0, 0), datetime.datetime(2017, 1, 27, 0, 0))\n",
      "(datetime.datetime(2017, 1, 27, 0, 0), datetime.datetime(2017, 2, 22, 0, 0))\n",
      "(datetime.datetime(2017, 2, 22, 0, 0), datetime.datetime(2017, 3, 17, 0, 0))\n",
      "(datetime.datetime(2017, 3, 17, 0, 0), datetime.datetime(2017, 4, 14, 0, 0))\n",
      "(datetime.datetime(2017, 4, 14, 0, 0), datetime.datetime(2017, 5, 12, 0, 0))\n",
      "(datetime.datetime(2017, 5, 12, 0, 0), datetime.datetime(2017, 6, 26, 0, 0))\n",
      "(datetime.datetime(2017, 6, 26, 0, 0), datetime.datetime(2017, 9, 13, 0, 0))\n",
      "(datetime.datetime(2017, 9, 13, 0, 0), datetime.datetime(2017, 10, 11, 0, 0))\n",
      "(datetime.datetime(2017, 10, 11, 0, 0), datetime.datetime(2017, 11, 15, 0, 0))\n",
      "(datetime.datetime(2017, 11, 15, 0, 0), datetime.datetime(2017, 12, 15, 0, 0))\n",
      "(datetime.datetime(2017, 12, 15, 0, 0), datetime.datetime(2018, 2, 7, 0, 0))\n",
      "(datetime.datetime(2018, 2, 7, 0, 0), datetime.datetime(2018, 4, 2, 0, 0))\n",
      "(datetime.datetime(2018, 4, 2, 0, 0), datetime.datetime(2018, 5, 9, 0, 0))\n",
      "(datetime.datetime(2018, 5, 9, 0, 0), datetime.datetime(2018, 5, 31, 0, 0))\n",
      "(datetime.datetime(2018, 5, 31, 0, 0), datetime.datetime(2018, 6, 27, 0, 0))\n",
      "(datetime.datetime(2018, 6, 27, 0, 0), datetime.datetime(2018, 8, 4, 0, 0))\n",
      "(datetime.datetime(2018, 8, 4, 0, 0), datetime.datetime(2018, 9, 24, 0, 0))\n",
      "(datetime.datetime(2018, 9, 24, 0, 0), datetime.datetime(2018, 11, 5, 0, 0))\n",
      "(datetime.datetime(2018, 11, 5, 0, 0), datetime.datetime(2018, 12, 14, 0, 0))\n",
      "(datetime.datetime(2018, 12, 14, 0, 0), datetime.datetime(2019, 1, 15, 0, 0))\n",
      "(datetime.datetime(2019, 1, 15, 0, 0), datetime.datetime(2019, 2, 12, 0, 0))\n",
      "(datetime.datetime(2019, 2, 12, 0, 0), datetime.datetime(2019, 4, 12, 0, 0))\n",
      "(datetime.datetime(2019, 4, 12, 0, 0), datetime.datetime(2019, 5, 25, 0, 0))\n",
      "(datetime.datetime(2019, 5, 25, 0, 0), datetime.datetime(2019, 7, 16, 0, 0))\n",
      "(datetime.datetime(2019, 7, 16, 0, 0), datetime.datetime(2019, 8, 20, 0, 0))\n",
      "(datetime.datetime(2019, 8, 20, 0, 0), datetime.datetime(2019, 9, 21, 0, 0))\n",
      "(datetime.datetime(2019, 9, 21, 0, 0), datetime.datetime(2019, 10, 21, 0, 0))\n",
      "(datetime.datetime(2019, 10, 21, 0, 0), datetime.datetime(2019, 11, 18, 0, 0))\n",
      "(datetime.datetime(2019, 11, 18, 0, 0), datetime.datetime(2019, 12, 20, 0, 0))\n",
      "(datetime.datetime(2019, 12, 20, 0, 0), datetime.datetime(2020, 1, 25, 0, 0))\n",
      "(datetime.datetime(2020, 1, 25, 0, 0), datetime.datetime(2020, 2, 24, 0, 0))\n",
      "(datetime.datetime(2020, 2, 24, 0, 0), datetime.datetime(2020, 3, 20, 0, 0))\n",
      "(datetime.datetime(2020, 3, 20, 0, 0), datetime.datetime(2020, 5, 19, 0, 0))\n",
      "(datetime.datetime(2020, 5, 19, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2020, 7, 28, 0, 0))\n",
      "(datetime.datetime(2020, 7, 28, 0, 0), datetime.datetime(2020, 10, 20, 0, 0))\n",
      "(datetime.datetime(2020, 10, 20, 0, 0), datetime.datetime(2020, 12, 22, 0, 0))\n",
      "(datetime.datetime(2020, 12, 22, 0, 0), datetime.datetime(2021, 1, 19, 0, 0))\n",
      "(datetime.datetime(2021, 1, 19, 0, 0), datetime.datetime(2021, 2, 19, 0, 0))\n",
      "(datetime.datetime(2021, 2, 19, 0, 0), datetime.datetime(2021, 3, 19, 0, 0))\n",
      "(datetime.datetime(2021, 3, 19, 0, 0), datetime.datetime(2021, 4, 12, 0, 0))\n",
      "(datetime.datetime(2021, 4, 12, 0, 0), datetime.datetime(2021, 5, 8, 0, 0))\n",
      "(datetime.datetime(2021, 5, 8, 0, 0), datetime.datetime(2021, 7, 19, 0, 0))\n",
      "(datetime.datetime(2021, 7, 19, 0, 0), datetime.datetime(2021, 8, 13, 0, 0))\n",
      "(datetime.datetime(2021, 8, 13, 0, 0), datetime.datetime(2021, 10, 11, 0, 0))\n",
      "(datetime.datetime(2021, 10, 11, 0, 0), datetime.datetime(2021, 11, 16, 0, 0))\n",
      "(datetime.datetime(2021, 11, 16, 0, 0), datetime.datetime(2021, 12, 17, 0, 0))\n",
      "(datetime.datetime(2021, 12, 17, 0, 0), datetime.datetime(2022, 1, 11, 0, 0))\n",
      "(datetime.datetime(2022, 1, 11, 0, 0), datetime.datetime(2021, 3, 15, 0, 0))\n",
      "(datetime.datetime(2021, 3, 15, 0, 0), datetime.datetime(2022, 4, 12, 0, 0))\n",
      "(datetime.datetime(2022, 4, 12, 0, 0), datetime.datetime(2022, 6, 13, 0, 0))\n",
      "(datetime.datetime(2022, 6, 13, 0, 0), datetime.datetime(2022, 7, 16, 0, 0))\n",
      "(datetime.datetime(2022, 7, 16, 0, 0), datetime.datetime(2022, 8, 16, 0, 0))\n",
      "(datetime.datetime(2022, 8, 16, 0, 0), datetime.datetime(2022, 11, 14, 0, 0))\n",
      "(datetime.datetime(2022, 11, 14, 0, 0), datetime.datetime(2023, 1, 24, 0, 0))\n",
      "(datetime.datetime(2023, 1, 24, 0, 0), datetime.datetime(2023, 2, 28, 0, 0))\n",
      "(datetime.datetime(2023, 2, 28, 0, 0), datetime.datetime(2023, 4, 1, 0, 0))\n",
      "(datetime.datetime(2023, 4, 1, 0, 0), datetime.datetime(2023, 5, 29, 0, 0))\n",
      "(datetime.datetime(2023, 5, 29, 0, 0), datetime.datetime(2023, 7, 4, 0, 0))\n",
      "(datetime.datetime(2023, 7, 4, 0, 0), datetime.datetime(2023, 8, 18, 0, 0))\n",
      "(datetime.datetime(2023, 8, 18, 0, 0), datetime.datetime(2023, 9, 26, 0, 0))\n",
      "(datetime.datetime(2023, 9, 26, 0, 0), datetime.datetime(2023, 11, 7, 0, 0))\n",
      "8-6-2016,18-7-2016,19-8-2016,14-9-16,4-10-2016,9-11-2016,9-1-2017,10-2-2017,11-3-2017,10-4-2017,11-5-2017,10-6-2017,8-7-2017,5-8-2017,4-9-2017,14-10-2017,4-12-2017,2-1-2018,2-2-2018,3-3-2018,4-4-2018,2-5-2018,2-6-2018,2-7-2018,31-7-2018,30-8-2018,28-9-2018,29-19-2018,28-11-2018,27-12-2018,25-1-2019,26-2-2019,26-3-2019,24-4-2019,27-5-2019,27-6-2019,27-8-2019,25-9-2019,25-10-2019,25-11-2019,24-12-2019,21-1-2020,22-2-2020,23-3-2020,21-4-2020,22-5-2020,22-6-2020,9-1-2021,3-3-2021,12-4-2021,14-6-2021,8-8-2021,14-9-2021,16-10-2021,16-11-2021,3-1-2022,4-2-2022,5-3-2022,5-4-2022,20-5-2022,6-7-2022,3-8-2022,2-9-2022,30-9-2022,2-11-2022,8-12-2022,28-12-2023,4-2-2023,4-3-2023,4-5-2023,27-5-2023,4-7-2023,1-8-2023,2-9-2023,3-10-2023,1-11-2023\n",
      "(datetime.datetime(2016, 6, 8, 0, 0), datetime.datetime(2016, 7, 18, 0, 0))\n",
      "(datetime.datetime(2016, 7, 18, 0, 0), datetime.datetime(2016, 8, 19, 0, 0))\n",
      "(datetime.datetime(2016, 8, 19, 0, 0), datetime.datetime(2016, 9, 14, 0, 0))\n",
      "(datetime.datetime(2016, 9, 14, 0, 0), datetime.datetime(2016, 10, 4, 0, 0))\n",
      "(datetime.datetime(2016, 10, 4, 0, 0), datetime.datetime(2016, 11, 9, 0, 0))\n",
      "(datetime.datetime(2016, 11, 9, 0, 0), datetime.datetime(2017, 1, 9, 0, 0))\n",
      "(datetime.datetime(2017, 1, 9, 0, 0), datetime.datetime(2017, 2, 10, 0, 0))\n",
      "(datetime.datetime(2017, 2, 10, 0, 0), datetime.datetime(2017, 3, 11, 0, 0))\n",
      "(datetime.datetime(2017, 3, 11, 0, 0), datetime.datetime(2017, 4, 10, 0, 0))\n",
      "(datetime.datetime(2017, 4, 10, 0, 0), datetime.datetime(2017, 5, 11, 0, 0))\n",
      "(datetime.datetime(2017, 5, 11, 0, 0), datetime.datetime(2017, 6, 10, 0, 0))\n",
      "(datetime.datetime(2017, 6, 10, 0, 0), datetime.datetime(2017, 7, 8, 0, 0))\n",
      "(datetime.datetime(2017, 7, 8, 0, 0), datetime.datetime(2017, 8, 5, 0, 0))\n",
      "(datetime.datetime(2017, 8, 5, 0, 0), datetime.datetime(2017, 9, 4, 0, 0))\n",
      "(datetime.datetime(2017, 9, 4, 0, 0), datetime.datetime(2017, 10, 14, 0, 0))\n",
      "(datetime.datetime(2017, 10, 14, 0, 0), datetime.datetime(2017, 12, 4, 0, 0))\n",
      "(datetime.datetime(2017, 12, 4, 0, 0), datetime.datetime(2018, 1, 2, 0, 0))\n",
      "(datetime.datetime(2018, 1, 2, 0, 0), datetime.datetime(2018, 2, 2, 0, 0))\n",
      "(datetime.datetime(2018, 2, 2, 0, 0), datetime.datetime(2018, 3, 3, 0, 0))\n",
      "(datetime.datetime(2018, 3, 3, 0, 0), datetime.datetime(2018, 4, 4, 0, 0))\n",
      "(datetime.datetime(2018, 4, 4, 0, 0), datetime.datetime(2018, 5, 2, 0, 0))\n",
      "(datetime.datetime(2018, 5, 2, 0, 0), datetime.datetime(2018, 6, 2, 0, 0))\n",
      "(datetime.datetime(2018, 6, 2, 0, 0), datetime.datetime(2018, 7, 2, 0, 0))\n",
      "(datetime.datetime(2018, 7, 2, 0, 0), datetime.datetime(2018, 7, 31, 0, 0))\n",
      "(datetime.datetime(2018, 7, 31, 0, 0), datetime.datetime(2018, 8, 30, 0, 0))\n",
      "(datetime.datetime(2018, 8, 30, 0, 0), datetime.datetime(2018, 9, 28, 0, 0))\n",
      "(datetime.datetime(2018, 9, 28, 0, 0), datetime.datetime(2018, 11, 28, 0, 0))\n",
      "(datetime.datetime(2018, 11, 28, 0, 0), datetime.datetime(2018, 12, 27, 0, 0))\n",
      "(datetime.datetime(2018, 12, 27, 0, 0), datetime.datetime(2019, 1, 25, 0, 0))\n",
      "(datetime.datetime(2019, 1, 25, 0, 0), datetime.datetime(2019, 2, 26, 0, 0))\n",
      "(datetime.datetime(2019, 2, 26, 0, 0), datetime.datetime(2019, 3, 26, 0, 0))\n",
      "(datetime.datetime(2019, 3, 26, 0, 0), datetime.datetime(2019, 4, 24, 0, 0))\n",
      "(datetime.datetime(2019, 4, 24, 0, 0), datetime.datetime(2019, 5, 27, 0, 0))\n",
      "(datetime.datetime(2019, 5, 27, 0, 0), datetime.datetime(2019, 6, 27, 0, 0))\n",
      "(datetime.datetime(2019, 6, 27, 0, 0), datetime.datetime(2019, 8, 27, 0, 0))\n",
      "(datetime.datetime(2019, 8, 27, 0, 0), datetime.datetime(2019, 9, 25, 0, 0))\n",
      "(datetime.datetime(2019, 9, 25, 0, 0), datetime.datetime(2019, 10, 25, 0, 0))\n",
      "(datetime.datetime(2019, 10, 25, 0, 0), datetime.datetime(2019, 11, 25, 0, 0))\n",
      "(datetime.datetime(2019, 11, 25, 0, 0), datetime.datetime(2019, 12, 24, 0, 0))\n",
      "(datetime.datetime(2019, 12, 24, 0, 0), datetime.datetime(2020, 1, 21, 0, 0))\n",
      "(datetime.datetime(2020, 1, 21, 0, 0), datetime.datetime(2020, 2, 22, 0, 0))\n",
      "(datetime.datetime(2020, 2, 22, 0, 0), datetime.datetime(2020, 3, 23, 0, 0))\n",
      "(datetime.datetime(2020, 3, 23, 0, 0), datetime.datetime(2020, 4, 21, 0, 0))\n",
      "(datetime.datetime(2020, 4, 21, 0, 0), datetime.datetime(2020, 5, 22, 0, 0))\n",
      "(datetime.datetime(2020, 5, 22, 0, 0), datetime.datetime(2020, 6, 22, 0, 0))\n",
      "(datetime.datetime(2020, 6, 22, 0, 0), datetime.datetime(2021, 1, 9, 0, 0))\n",
      "(datetime.datetime(2021, 1, 9, 0, 0), datetime.datetime(2021, 3, 3, 0, 0))\n",
      "(datetime.datetime(2021, 3, 3, 0, 0), datetime.datetime(2021, 4, 12, 0, 0))\n",
      "(datetime.datetime(2021, 4, 12, 0, 0), datetime.datetime(2021, 6, 14, 0, 0))\n",
      "(datetime.datetime(2021, 6, 14, 0, 0), datetime.datetime(2021, 8, 8, 0, 0))\n",
      "(datetime.datetime(2021, 8, 8, 0, 0), datetime.datetime(2021, 9, 14, 0, 0))\n",
      "(datetime.datetime(2021, 9, 14, 0, 0), datetime.datetime(2021, 10, 16, 0, 0))\n",
      "(datetime.datetime(2021, 10, 16, 0, 0), datetime.datetime(2021, 11, 16, 0, 0))\n",
      "(datetime.datetime(2021, 11, 16, 0, 0), datetime.datetime(2022, 1, 3, 0, 0))\n",
      "(datetime.datetime(2022, 1, 3, 0, 0), datetime.datetime(2022, 2, 4, 0, 0))\n",
      "(datetime.datetime(2022, 2, 4, 0, 0), datetime.datetime(2022, 3, 5, 0, 0))\n",
      "(datetime.datetime(2022, 3, 5, 0, 0), datetime.datetime(2022, 4, 5, 0, 0))\n",
      "(datetime.datetime(2022, 4, 5, 0, 0), datetime.datetime(2022, 5, 20, 0, 0))\n",
      "(datetime.datetime(2022, 5, 20, 0, 0), datetime.datetime(2022, 7, 6, 0, 0))\n",
      "(datetime.datetime(2022, 7, 6, 0, 0), datetime.datetime(2022, 8, 3, 0, 0))\n",
      "(datetime.datetime(2022, 8, 3, 0, 0), datetime.datetime(2022, 9, 2, 0, 0))\n",
      "(datetime.datetime(2022, 9, 2, 0, 0), datetime.datetime(2022, 9, 30, 0, 0))\n",
      "(datetime.datetime(2022, 9, 30, 0, 0), datetime.datetime(2022, 11, 2, 0, 0))\n",
      "(datetime.datetime(2022, 11, 2, 0, 0), datetime.datetime(2022, 12, 8, 0, 0))\n",
      "(datetime.datetime(2022, 12, 8, 0, 0), datetime.datetime(2023, 12, 28, 0, 0))\n",
      "(datetime.datetime(2023, 12, 28, 0, 0), datetime.datetime(2023, 2, 4, 0, 0))\n",
      "(datetime.datetime(2023, 2, 4, 0, 0), datetime.datetime(2023, 3, 4, 0, 0))\n",
      "(datetime.datetime(2023, 3, 4, 0, 0), datetime.datetime(2023, 5, 4, 0, 0))\n",
      "(datetime.datetime(2023, 5, 4, 0, 0), datetime.datetime(2023, 5, 27, 0, 0))\n",
      "(datetime.datetime(2023, 5, 27, 0, 0), datetime.datetime(2023, 7, 4, 0, 0))\n",
      "(datetime.datetime(2023, 7, 4, 0, 0), datetime.datetime(2023, 8, 1, 0, 0))\n",
      "(datetime.datetime(2023, 8, 1, 0, 0), datetime.datetime(2023, 9, 2, 0, 0))\n",
      "(datetime.datetime(2023, 9, 2, 0, 0), datetime.datetime(2023, 10, 3, 0, 0))\n",
      "(datetime.datetime(2023, 10, 3, 0, 0), datetime.datetime(2023, 11, 1, 0, 0))\n",
      "nan\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [136], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency of follow up at lgb (to write down follow-up dates)\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m----> 3\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mextract_consecutive_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#sum = 0\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m a:\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m#sum = sum +  calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\u001b[39;00m\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m#print(sum)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [135], line 5\u001b[0m, in \u001b[0;36mextract_consecutive_dates\u001b[1;34m(date_str, date_formats)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_consecutive_dates\u001b[39m(date_str, date_formats\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm.\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm.\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Split the string into a list of date strings\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     date_list \u001b[38;5;241m=\u001b[39m \u001b[43mdate_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Convert the date strings to datetime objects with flexible year interpretation\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     date_objects \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "for i in df2['frequency of follow up at lgb (to write down follow-up dates)']:\n",
    "    print(i)\n",
    "    a = extract_consecutive_dates(i)\n",
    "    #sum = 0\n",
    "    for pair in a:\n",
    "        #sum = sum +  calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\n",
    "        #print(sum)\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e734ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "def extract_consecutive_dates(date_str, date_formats=[\"%d-%m-%Y\", \"%d-%m-%y\", \"%d.%m.%Y\", \"%d.%m.%y\"]):\n",
    "    if isinstance(date_str, float) and math.isnan(date_str):\n",
    "        return []\n",
    "    date_list = date_str.split(',')\n",
    "    date_objects = []\n",
    "    for date in date_list:\n",
    "        parsed_date = None\n",
    "        for format_str in date_formats:\n",
    "            try:\n",
    "                parsed_date = datetime.strptime(date, format_str)\n",
    "                break  \n",
    "            except ValueError:\n",
    "                pass \n",
    "\n",
    "        if parsed_date:\n",
    "            parsed_date = parsed_date.replace(year=parsed_date.year + 2000) if parsed_date.year < 100 else parsed_date\n",
    "            date_objects.append(parsed_date)\n",
    "    consecutive_pairs = zip(date_objects[:-1], date_objects[1:])\n",
    "\n",
    "    return consecutive_pairs\n",
    "\n",
    "date_str = float('nan') \n",
    "consecutive_pairs = extract_consecutive_dates(date_str)\n",
    "\n",
    "for pair in consecutive_pairs:\n",
    "    print(f\"Consecutive Dates: {pair[0].strftime('%d-%m-%Y')} and {pair[1].strftime('%d-%m-%Y')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "589f05b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consecutive Dates: 24-06-2019 and 29-07-2019\n",
      "Consecutive Dates: 29-07-2019 and 09-09-2019\n",
      "Consecutive Dates: 09-09-2019 and 21-10-2019\n",
      "Consecutive Dates: 21-10-2019 and 17-12-2019\n",
      "Consecutive Dates: 17-12-2019 and 18-01-2020\n",
      "Consecutive Dates: 18-01-2020 and 02-03-2020\n",
      "Consecutive Dates: 02-03-2020 and 02-05-2020\n",
      "Consecutive Dates: 02-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 28-08-2020\n",
      "Consecutive Dates: 28-08-2020 and 17-11-2020\n",
      "Consecutive Dates: 17-11-2020 and 21-01-2021\n",
      "\n",
      "Consecutive Dates: 31-03-2014 and 29-04-2014\n",
      "Consecutive Dates: 29-04-2014 and 29-05-2014\n",
      "Consecutive Dates: 29-05-2014 and 04-07-2014\n",
      "Consecutive Dates: 04-07-2014 and 25-08-2014\n",
      "Consecutive Dates: 25-08-2014 and 01-02-2016\n",
      "Consecutive Dates: 01-02-2016 and 30-03-2016\n",
      "Consecutive Dates: 30-03-2016 and 29-04-2016\n",
      "Consecutive Dates: 29-04-2016 and 03-06-2016\n",
      "Consecutive Dates: 03-06-2016 and 28-08-2016\n",
      "Consecutive Dates: 28-08-2016 and 08-08-2016\n",
      "Consecutive Dates: 08-08-2016 and 08-09-2016\n",
      "Consecutive Dates: 08-09-2016 and 05-10-2016\n",
      "Consecutive Dates: 05-10-2016 and 09-11-2016\n",
      "Consecutive Dates: 09-11-2016 and 16-12-2016\n",
      "Consecutive Dates: 16-12-2016 and 23-01-2017\n",
      "Consecutive Dates: 23-01-2017 and 22-02-2017\n",
      "Consecutive Dates: 22-02-2017 and 10-03-2017\n",
      "Consecutive Dates: 10-03-2017 and 21-04-2017\n",
      "Consecutive Dates: 21-04-2017 and 25-05-2017\n",
      "Consecutive Dates: 25-05-2017 and 22-06-2017\n",
      "Consecutive Dates: 22-06-2017 and 20-07-2017\n",
      "Consecutive Dates: 20-07-2017 and 03-10-2017\n",
      "Consecutive Dates: 03-10-2017 and 02-11-2017\n",
      "Consecutive Dates: 02-11-2017 and 06-01-2018\n",
      "Consecutive Dates: 06-01-2018 and 05-02-2018\n",
      "Consecutive Dates: 05-02-2018 and 08-03-2018\n",
      "Consecutive Dates: 08-03-2018 and 07-04-2018\n",
      "Consecutive Dates: 07-04-2018 and 05-05-2018\n",
      "Consecutive Dates: 05-05-2018 and 07-06-2018\n",
      "Consecutive Dates: 07-06-2018 and 09-08-2018\n",
      "Consecutive Dates: 09-08-2018 and 12-09-2018\n",
      "Consecutive Dates: 12-09-2018 and 09-10-2018\n",
      "Consecutive Dates: 09-10-2018 and 12-11-2018\n",
      "Consecutive Dates: 12-11-2018 and 19-12-2018\n",
      "Consecutive Dates: 19-12-2018 and 17-01-2019\n",
      "Consecutive Dates: 17-01-2019 and 13-06-2019\n",
      "Consecutive Dates: 13-06-2019 and 13-07-2019\n",
      "Consecutive Dates: 13-07-2019 and 17-08-2019\n",
      "Consecutive Dates: 17-08-2019 and 17-08-2019\n",
      "Consecutive Dates: 17-08-2019 and 20-10-2019\n",
      "Consecutive Dates: 20-10-2019 and 03-01-2020\n",
      "Consecutive Dates: 03-01-2020 and 06-03-2020\n",
      "Consecutive Dates: 06-03-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 02-04-2021\n",
      "Consecutive Dates: 02-04-2021 and 10-05-2021\n",
      "Consecutive Dates: 10-05-2021 and 06-08-2021\n",
      "Consecutive Dates: 06-08-2021 and 07-09-2021\n",
      "Consecutive Dates: 07-09-2021 and 13-11-2021\n",
      "Consecutive Dates: 13-11-2021 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 19-03-2022\n",
      "Consecutive Dates: 19-03-2022 and 30-05-2022\n",
      "Consecutive Dates: 30-05-2022 and 04-07-2022\n",
      "Consecutive Dates: 04-07-2022 and 09-08-2022\n",
      "Consecutive Dates: 09-08-2022 and 13-09-2022\n",
      "Consecutive Dates: 13-09-2022 and 27-10-2022\n",
      "Consecutive Dates: 27-10-2022 and 28-11-2022\n",
      "Consecutive Dates: 28-11-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 13-02-2023\n",
      "Consecutive Dates: 13-02-2023 and 22-03-2023\n",
      "Consecutive Dates: 22-03-2023 and 26-04-2023\n",
      "Consecutive Dates: 26-04-2023 and 05-06-2023\n",
      "Consecutive Dates: 05-06-2023 and 17-07-2023\n",
      "Consecutive Dates: 17-07-2023 and 24-08-2023\n",
      "Consecutive Dates: 24-08-2023 and 25-09-2023\n",
      "Consecutive Dates: 25-09-2023 and 06-11-2023\n",
      "\n",
      "Consecutive Dates: 31-03-2014 and 29-04-2014\n",
      "Consecutive Dates: 29-04-2014 and 29-05-2014\n",
      "Consecutive Dates: 29-05-2014 and 04-07-2014\n",
      "Consecutive Dates: 04-07-2014 and 25-08-2014\n",
      "Consecutive Dates: 25-08-2014 and 01-02-2016\n",
      "Consecutive Dates: 01-02-2016 and 30-03-2016\n",
      "Consecutive Dates: 30-03-2016 and 29-04-2016\n",
      "Consecutive Dates: 29-04-2016 and 03-06-2016\n",
      "Consecutive Dates: 03-06-2016 and 28-08-2016\n",
      "Consecutive Dates: 28-08-2016 and 08-08-2016\n",
      "Consecutive Dates: 08-08-2016 and 08-09-2016\n",
      "Consecutive Dates: 08-09-2016 and 05-10-2016\n",
      "Consecutive Dates: 05-10-2016 and 09-11-2016\n",
      "Consecutive Dates: 09-11-2016 and 16-12-2016\n",
      "Consecutive Dates: 16-12-2016 and 23-01-2017\n",
      "Consecutive Dates: 23-01-2017 and 22-02-2017\n",
      "Consecutive Dates: 22-02-2017 and 10-03-2017\n",
      "Consecutive Dates: 10-03-2017 and 21-04-2017\n",
      "Consecutive Dates: 21-04-2017 and 25-05-2017\n",
      "Consecutive Dates: 25-05-2017 and 22-06-2017\n",
      "Consecutive Dates: 22-06-2017 and 20-07-2017\n",
      "Consecutive Dates: 20-07-2017 and 03-10-2017\n",
      "Consecutive Dates: 03-10-2017 and 02-11-2017\n",
      "Consecutive Dates: 02-11-2017 and 06-01-2018\n",
      "Consecutive Dates: 06-01-2018 and 05-02-2018\n",
      "Consecutive Dates: 05-02-2018 and 08-03-2018\n",
      "Consecutive Dates: 08-03-2018 and 07-04-2018\n",
      "Consecutive Dates: 07-04-2018 and 05-05-2018\n",
      "Consecutive Dates: 05-05-2018 and 07-06-2018\n",
      "Consecutive Dates: 07-06-2018 and 09-08-2018\n",
      "Consecutive Dates: 09-08-2018 and 12-09-2018\n",
      "Consecutive Dates: 12-09-2018 and 09-10-2018\n",
      "Consecutive Dates: 09-10-2018 and 12-11-2018\n",
      "Consecutive Dates: 12-11-2018 and 19-12-2018\n",
      "Consecutive Dates: 19-12-2018 and 17-01-2019\n",
      "Consecutive Dates: 17-01-2019 and 13-06-2019\n",
      "Consecutive Dates: 13-06-2019 and 13-07-2019\n",
      "Consecutive Dates: 13-07-2019 and 17-08-2019\n",
      "Consecutive Dates: 17-08-2019 and 17-08-2019\n",
      "Consecutive Dates: 17-08-2019 and 20-10-2019\n",
      "Consecutive Dates: 20-10-2019 and 30-11-2019\n",
      "Consecutive Dates: 30-11-2019 and 03-01-2020\n",
      "Consecutive Dates: 03-01-2020 and 06-03-2020\n",
      "Consecutive Dates: 06-03-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 02-04-2021\n",
      "Consecutive Dates: 02-04-2021 and 10-05-2021\n",
      "Consecutive Dates: 10-05-2021 and 06-08-2021\n",
      "Consecutive Dates: 06-08-2021 and 07-09-2021\n",
      "Consecutive Dates: 07-09-2021 and 13-11-2021\n",
      "Consecutive Dates: 13-11-2021 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 19-03-2022\n",
      "Consecutive Dates: 19-03-2022 and 30-05-2022\n",
      "Consecutive Dates: 30-05-2022 and 04-07-2022\n",
      "Consecutive Dates: 04-07-2022 and 09-08-2022\n",
      "Consecutive Dates: 09-08-2022 and 13-09-2022\n",
      "Consecutive Dates: 13-09-2022 and 27-10-2022\n",
      "Consecutive Dates: 27-10-2022 and 28-11-2022\n",
      "Consecutive Dates: 28-11-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 13-02-2023\n",
      "Consecutive Dates: 13-02-2023 and 22-03-2023\n",
      "Consecutive Dates: 22-03-2023 and 26-04-2023\n",
      "Consecutive Dates: 26-04-2023 and 05-06-2023\n",
      "Consecutive Dates: 05-06-2023 and 17-07-2023\n",
      "Consecutive Dates: 17-07-2023 and 24-08-2023\n",
      "Consecutive Dates: 24-08-2023 and 25-09-2023\n",
      "Consecutive Dates: 25-09-2023 and 06-11-2023\n",
      "\n",
      "Consecutive Dates: 22-06-2020 and 30-09-2020\n",
      "\n",
      "Consecutive Dates: 10-06-2015 and 22-06-2015\n",
      "Consecutive Dates: 22-06-2015 and 15-07-2015\n",
      "Consecutive Dates: 15-07-2015 and 29-07-2015\n",
      "Consecutive Dates: 29-07-2015 and 26-05-2015\n",
      "Consecutive Dates: 26-05-2015 and 23-09-2015\n",
      "Consecutive Dates: 23-09-2015 and 21-10-2015\n",
      "Consecutive Dates: 21-10-2015 and 11-11-2015\n",
      "Consecutive Dates: 11-11-2015 and 21-12-2015\n",
      "Consecutive Dates: 21-12-2015 and 25-01-2016\n",
      "Consecutive Dates: 25-01-2016 and 16-03-2016\n",
      "Consecutive Dates: 16-03-2016 and 18-05-2016\n",
      "Consecutive Dates: 18-05-2016 and 20-07-2016\n",
      "Consecutive Dates: 20-07-2016 and 07-09-2016\n",
      "Consecutive Dates: 07-09-2016 and 26-10-2016\n",
      "Consecutive Dates: 26-10-2016 and 28-12-2016\n",
      "Consecutive Dates: 28-12-2016 and 27-01-2017\n",
      "Consecutive Dates: 27-01-2017 and 22-02-2017\n",
      "Consecutive Dates: 22-02-2017 and 17-03-2017\n",
      "Consecutive Dates: 17-03-2017 and 14-04-2017\n",
      "Consecutive Dates: 14-04-2017 and 12-05-2017\n",
      "Consecutive Dates: 12-05-2017 and 26-06-2017\n",
      "Consecutive Dates: 26-06-2017 and 13-09-2017\n",
      "Consecutive Dates: 13-09-2017 and 11-10-2017\n",
      "Consecutive Dates: 11-10-2017 and 15-11-2017\n",
      "Consecutive Dates: 15-11-2017 and 15-12-2017\n",
      "Consecutive Dates: 15-12-2017 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 02-04-2018\n",
      "Consecutive Dates: 02-04-2018 and 09-05-2018\n",
      "Consecutive Dates: 09-05-2018 and 31-05-2018\n",
      "Consecutive Dates: 31-05-2018 and 27-06-2018\n",
      "Consecutive Dates: 27-06-2018 and 04-08-2018\n",
      "Consecutive Dates: 04-08-2018 and 24-09-2018\n",
      "Consecutive Dates: 24-09-2018 and 05-11-2018\n",
      "Consecutive Dates: 05-11-2018 and 14-12-2018\n",
      "Consecutive Dates: 14-12-2018 and 15-01-2019\n",
      "Consecutive Dates: 15-01-2019 and 12-02-2019\n",
      "Consecutive Dates: 12-02-2019 and 12-04-2019\n",
      "Consecutive Dates: 12-04-2019 and 25-05-2019\n",
      "Consecutive Dates: 25-05-2019 and 16-07-2019\n",
      "Consecutive Dates: 16-07-2019 and 20-08-2019\n",
      "Consecutive Dates: 20-08-2019 and 21-09-2019\n",
      "Consecutive Dates: 21-09-2019 and 21-10-2019\n",
      "Consecutive Dates: 21-10-2019 and 18-11-2019\n",
      "Consecutive Dates: 18-11-2019 and 20-12-2019\n",
      "Consecutive Dates: 20-12-2019 and 25-01-2020\n",
      "Consecutive Dates: 25-01-2020 and 24-02-2020\n",
      "Consecutive Dates: 24-02-2020 and 20-03-2020\n",
      "Consecutive Dates: 20-03-2020 and 19-05-2020\n",
      "Consecutive Dates: 19-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 28-07-2020\n",
      "Consecutive Dates: 28-07-2020 and 20-10-2020\n",
      "Consecutive Dates: 20-10-2020 and 01-11-2020\n",
      "Consecutive Dates: 01-11-2020 and 22-12-2020\n",
      "Consecutive Dates: 22-12-2020 and 19-01-2021\n",
      "Consecutive Dates: 19-01-2021 and 19-02-2021\n",
      "Consecutive Dates: 19-02-2021 and 19-03-2021\n",
      "Consecutive Dates: 19-03-2021 and 12-04-2021\n",
      "Consecutive Dates: 12-04-2021 and 08-05-2021\n",
      "Consecutive Dates: 08-05-2021 and 19-07-2021\n",
      "Consecutive Dates: 19-07-2021 and 13-08-2021\n",
      "Consecutive Dates: 13-08-2021 and 11-10-2021\n",
      "Consecutive Dates: 11-10-2021 and 16-11-2021\n",
      "Consecutive Dates: 16-11-2021 and 17-12-2021\n",
      "Consecutive Dates: 17-12-2021 and 11-01-2022\n",
      "Consecutive Dates: 11-01-2022 and 15-03-2021\n",
      "Consecutive Dates: 15-03-2021 and 12-04-2022\n",
      "Consecutive Dates: 12-04-2022 and 13-06-2022\n",
      "Consecutive Dates: 13-06-2022 and 16-07-2022\n",
      "Consecutive Dates: 16-07-2022 and 16-08-2022\n",
      "Consecutive Dates: 16-08-2022 and 14-11-2022\n",
      "Consecutive Dates: 14-11-2022 and 24-01-2023\n",
      "Consecutive Dates: 24-01-2023 and 28-02-2023\n",
      "Consecutive Dates: 28-02-2023 and 01-04-2023\n",
      "Consecutive Dates: 01-04-2023 and 29-05-2023\n",
      "Consecutive Dates: 29-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 18-08-2023\n",
      "Consecutive Dates: 18-08-2023 and 26-09-2023\n",
      "Consecutive Dates: 26-09-2023 and 07-11-2023\n",
      "\n",
      "Consecutive Dates: 10-06-2015 and 22-06-2015\n",
      "Consecutive Dates: 22-06-2015 and 15-07-2015\n",
      "Consecutive Dates: 15-07-2015 and 29-07-2015\n",
      "Consecutive Dates: 29-07-2015 and 26-05-2015\n",
      "Consecutive Dates: 26-05-2015 and 23-09-2015\n",
      "Consecutive Dates: 23-09-2015 and 21-10-2015\n",
      "Consecutive Dates: 21-10-2015 and 11-11-2015\n",
      "Consecutive Dates: 11-11-2015 and 21-12-2015\n",
      "Consecutive Dates: 21-12-2015 and 25-01-2016\n",
      "Consecutive Dates: 25-01-2016 and 16-03-2016\n",
      "Consecutive Dates: 16-03-2016 and 18-05-2016\n",
      "Consecutive Dates: 18-05-2016 and 20-07-2016\n",
      "Consecutive Dates: 20-07-2016 and 07-09-2016\n",
      "Consecutive Dates: 07-09-2016 and 26-10-2016\n",
      "Consecutive Dates: 26-10-2016 and 28-12-2016\n",
      "Consecutive Dates: 28-12-2016 and 27-01-2017\n",
      "Consecutive Dates: 27-01-2017 and 22-02-2017\n",
      "Consecutive Dates: 22-02-2017 and 17-03-2017\n",
      "Consecutive Dates: 17-03-2017 and 14-04-2017\n",
      "Consecutive Dates: 14-04-2017 and 12-05-2017\n",
      "Consecutive Dates: 12-05-2017 and 26-06-2017\n",
      "Consecutive Dates: 26-06-2017 and 13-09-2017\n",
      "Consecutive Dates: 13-09-2017 and 11-10-2017\n",
      "Consecutive Dates: 11-10-2017 and 15-11-2017\n",
      "Consecutive Dates: 15-11-2017 and 15-12-2017\n",
      "Consecutive Dates: 15-12-2017 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 02-04-2018\n",
      "Consecutive Dates: 02-04-2018 and 09-05-2018\n",
      "Consecutive Dates: 09-05-2018 and 31-05-2018\n",
      "Consecutive Dates: 31-05-2018 and 27-06-2018\n",
      "Consecutive Dates: 27-06-2018 and 04-08-2018\n",
      "Consecutive Dates: 04-08-2018 and 24-09-2018\n",
      "Consecutive Dates: 24-09-2018 and 05-11-2018\n",
      "Consecutive Dates: 05-11-2018 and 14-12-2018\n",
      "Consecutive Dates: 14-12-2018 and 15-01-2019\n",
      "Consecutive Dates: 15-01-2019 and 12-02-2019\n",
      "Consecutive Dates: 12-02-2019 and 12-04-2019\n",
      "Consecutive Dates: 12-04-2019 and 25-05-2019\n",
      "Consecutive Dates: 25-05-2019 and 16-07-2019\n",
      "Consecutive Dates: 16-07-2019 and 20-08-2019\n",
      "Consecutive Dates: 20-08-2019 and 21-09-2019\n",
      "Consecutive Dates: 21-09-2019 and 21-10-2019\n",
      "Consecutive Dates: 21-10-2019 and 18-11-2019\n",
      "Consecutive Dates: 18-11-2019 and 20-12-2019\n",
      "Consecutive Dates: 20-12-2019 and 25-01-2020\n",
      "Consecutive Dates: 25-01-2020 and 24-02-2020\n",
      "Consecutive Dates: 24-02-2020 and 20-03-2020\n",
      "Consecutive Dates: 20-03-2020 and 19-05-2020\n",
      "Consecutive Dates: 19-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 28-07-2020\n",
      "Consecutive Dates: 28-07-2020 and 20-10-2020\n",
      "Consecutive Dates: 20-10-2020 and 22-12-2020\n",
      "Consecutive Dates: 22-12-2020 and 19-01-2021\n",
      "Consecutive Dates: 19-01-2021 and 19-02-2021\n",
      "Consecutive Dates: 19-02-2021 and 19-03-2021\n",
      "Consecutive Dates: 19-03-2021 and 12-04-2021\n",
      "Consecutive Dates: 12-04-2021 and 08-05-2021\n",
      "Consecutive Dates: 08-05-2021 and 19-07-2021\n",
      "Consecutive Dates: 19-07-2021 and 13-08-2021\n",
      "Consecutive Dates: 13-08-2021 and 11-10-2021\n",
      "Consecutive Dates: 11-10-2021 and 16-11-2021\n",
      "Consecutive Dates: 16-11-2021 and 17-12-2021\n",
      "Consecutive Dates: 17-12-2021 and 11-01-2022\n",
      "Consecutive Dates: 11-01-2022 and 15-03-2021\n",
      "Consecutive Dates: 15-03-2021 and 12-04-2022\n",
      "Consecutive Dates: 12-04-2022 and 13-06-2022\n",
      "Consecutive Dates: 13-06-2022 and 16-07-2022\n",
      "Consecutive Dates: 16-07-2022 and 16-08-2022\n",
      "Consecutive Dates: 16-08-2022 and 14-11-2022\n",
      "Consecutive Dates: 14-11-2022 and 24-01-2023\n",
      "Consecutive Dates: 24-01-2023 and 28-02-2023\n",
      "Consecutive Dates: 28-02-2023 and 01-04-2023\n",
      "Consecutive Dates: 01-04-2023 and 29-05-2023\n",
      "Consecutive Dates: 29-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 18-08-2023\n",
      "Consecutive Dates: 18-08-2023 and 26-09-2023\n",
      "Consecutive Dates: 26-09-2023 and 07-11-2023\n",
      "\n",
      "Consecutive Dates: 08-06-2016 and 18-07-2016\n",
      "Consecutive Dates: 18-07-2016 and 19-08-2016\n",
      "Consecutive Dates: 19-08-2016 and 14-09-2016\n",
      "Consecutive Dates: 14-09-2016 and 04-10-2016\n",
      "Consecutive Dates: 04-10-2016 and 09-11-2016\n",
      "Consecutive Dates: 09-11-2016 and 09-01-2017\n",
      "Consecutive Dates: 09-01-2017 and 10-02-2017\n",
      "Consecutive Dates: 10-02-2017 and 11-03-2017\n",
      "Consecutive Dates: 11-03-2017 and 10-04-2017\n",
      "Consecutive Dates: 10-04-2017 and 11-05-2017\n",
      "Consecutive Dates: 11-05-2017 and 10-06-2017\n",
      "Consecutive Dates: 10-06-2017 and 08-07-2017\n",
      "Consecutive Dates: 08-07-2017 and 05-08-2017\n",
      "Consecutive Dates: 05-08-2017 and 04-09-2017\n",
      "Consecutive Dates: 04-09-2017 and 14-10-2017\n",
      "Consecutive Dates: 14-10-2017 and 04-12-2017\n",
      "Consecutive Dates: 04-12-2017 and 02-01-2018\n",
      "Consecutive Dates: 02-01-2018 and 02-02-2018\n",
      "Consecutive Dates: 02-02-2018 and 03-03-2018\n",
      "Consecutive Dates: 03-03-2018 and 04-04-2018\n",
      "Consecutive Dates: 04-04-2018 and 02-05-2018\n",
      "Consecutive Dates: 02-05-2018 and 02-06-2018\n",
      "Consecutive Dates: 02-06-2018 and 02-07-2018\n",
      "Consecutive Dates: 02-07-2018 and 31-07-2018\n",
      "Consecutive Dates: 31-07-2018 and 30-08-2018\n",
      "Consecutive Dates: 30-08-2018 and 28-09-2018\n",
      "Consecutive Dates: 28-09-2018 and 28-11-2018\n",
      "Consecutive Dates: 28-11-2018 and 27-12-2018\n",
      "Consecutive Dates: 27-12-2018 and 25-01-2019\n",
      "Consecutive Dates: 25-01-2019 and 26-02-2019\n",
      "Consecutive Dates: 26-02-2019 and 26-03-2019\n",
      "Consecutive Dates: 26-03-2019 and 24-04-2019\n",
      "Consecutive Dates: 24-04-2019 and 27-05-2019\n",
      "Consecutive Dates: 27-05-2019 and 27-06-2019\n",
      "Consecutive Dates: 27-06-2019 and 27-08-2019\n",
      "Consecutive Dates: 27-08-2019 and 25-09-2019\n",
      "Consecutive Dates: 25-09-2019 and 25-10-2019\n",
      "Consecutive Dates: 25-10-2019 and 25-11-2019\n",
      "Consecutive Dates: 25-11-2019 and 24-12-2019\n",
      "Consecutive Dates: 24-12-2019 and 21-01-2020\n",
      "Consecutive Dates: 21-01-2020 and 22-02-2020\n",
      "Consecutive Dates: 22-02-2020 and 23-03-2020\n",
      "Consecutive Dates: 23-03-2020 and 21-04-2020\n",
      "Consecutive Dates: 21-04-2020 and 22-05-2020\n",
      "Consecutive Dates: 22-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 09-01-2021\n",
      "Consecutive Dates: 09-01-2021 and 03-03-2021\n",
      "Consecutive Dates: 03-03-2021 and 12-04-2021\n",
      "Consecutive Dates: 12-04-2021 and 14-06-2021\n",
      "Consecutive Dates: 14-06-2021 and 08-08-2021\n",
      "Consecutive Dates: 08-08-2021 and 14-09-2021\n",
      "Consecutive Dates: 14-09-2021 and 16-10-2021\n",
      "Consecutive Dates: 16-10-2021 and 16-11-2021\n",
      "Consecutive Dates: 16-11-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 04-02-2022\n",
      "Consecutive Dates: 04-02-2022 and 05-03-2022\n",
      "Consecutive Dates: 05-03-2022 and 05-04-2022\n",
      "Consecutive Dates: 05-04-2022 and 20-05-2022\n",
      "Consecutive Dates: 20-05-2022 and 06-07-2022\n",
      "Consecutive Dates: 06-07-2022 and 03-08-2022\n",
      "Consecutive Dates: 03-08-2022 and 02-09-2022\n",
      "Consecutive Dates: 02-09-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 02-11-2022\n",
      "Consecutive Dates: 02-11-2022 and 08-12-2022\n",
      "Consecutive Dates: 08-12-2022 and 28-12-2023\n",
      "Consecutive Dates: 28-12-2023 and 04-02-2023\n",
      "Consecutive Dates: 04-02-2023 and 04-03-2023\n",
      "Consecutive Dates: 04-03-2023 and 04-05-2023\n",
      "Consecutive Dates: 04-05-2023 and 27-05-2023\n",
      "Consecutive Dates: 27-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 01-08-2023\n",
      "Consecutive Dates: 01-08-2023 and 02-09-2023\n",
      "Consecutive Dates: 02-09-2023 and 03-10-2023\n",
      "Consecutive Dates: 03-10-2023 and 01-11-2023\n",
      "\n",
      "\n",
      "Consecutive Dates: 27-12-2019 and 17-03-2020\n",
      "Consecutive Dates: 17-03-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 14-12-2020\n",
      "Consecutive Dates: 14-12-2020 and 22-01-2021\n",
      "Consecutive Dates: 22-01-2021 and 06-11-2023\n",
      "\n",
      "Consecutive Dates: 27-02-2020 and 22-06-2020\n",
      "\n",
      "Consecutive Dates: 14-02-2020 and 22-06-2022\n",
      "\n",
      "Consecutive Dates: 08-03-2018 and 13-06-2019\n",
      "Consecutive Dates: 13-06-2019 and 28-06-2019\n",
      "Consecutive Dates: 28-06-2019 and 22-06-2022\n",
      "Consecutive Dates: 22-06-2022 and 26-11-2020\n",
      "Consecutive Dates: 26-11-2020 and 11-08-2022\n",
      "Consecutive Dates: 11-08-2022 and 06-07-2023\n",
      "\n",
      "\n",
      "Consecutive Dates: 15-10-2012 and 09-01-2013\n",
      "Consecutive Dates: 09-01-2013 and 04-02-2013\n",
      "Consecutive Dates: 04-02-2013 and 07-03-2013\n",
      "Consecutive Dates: 07-03-2013 and 05-04-2013\n",
      "Consecutive Dates: 05-04-2013 and 06-05-2013\n",
      "Consecutive Dates: 06-05-2013 and 05-06-2013\n",
      "Consecutive Dates: 05-06-2013 and 04-07-2013\n",
      "Consecutive Dates: 04-07-2013 and 03-08-2013\n",
      "Consecutive Dates: 03-08-2013 and 02-09-2013\n",
      "Consecutive Dates: 02-09-2013 and 03-10-2013\n",
      "Consecutive Dates: 03-10-2013 and 02-11-2013\n",
      "Consecutive Dates: 02-11-2013 and 21-11-2013\n",
      "Consecutive Dates: 21-11-2013 and 11-03-2015\n",
      "Consecutive Dates: 11-03-2015 and 03-04-2015\n",
      "Consecutive Dates: 03-04-2015 and 22-04-2015\n",
      "Consecutive Dates: 22-04-2015 and 14-05-2015\n",
      "Consecutive Dates: 14-05-2015 and 05-06-2015\n",
      "Consecutive Dates: 05-06-2015 and 13-07-2015\n",
      "Consecutive Dates: 13-07-2015 and 19-08-2015\n",
      "Consecutive Dates: 19-08-2015 and 22-09-2015\n",
      "Consecutive Dates: 22-09-2015 and 21-10-2015\n",
      "Consecutive Dates: 21-10-2015 and 20-11-2015\n",
      "Consecutive Dates: 20-11-2015 and 19-01-2016\n",
      "Consecutive Dates: 19-01-2016 and 18-02-2016\n",
      "Consecutive Dates: 18-02-2016 and 03-03-2016\n",
      "Consecutive Dates: 03-03-2016 and 02-04-2019\n",
      "Consecutive Dates: 02-04-2019 and 06-05-2016\n",
      "Consecutive Dates: 06-05-2016 and 07-03-2017\n",
      "Consecutive Dates: 07-03-2017 and 13-04-2017\n",
      "Consecutive Dates: 13-04-2017 and 17-05-2017\n",
      "Consecutive Dates: 17-05-2017 and 19-06-2017\n",
      "Consecutive Dates: 19-06-2017 and 20-07-2017\n",
      "Consecutive Dates: 20-07-2017 and 16-08-2017\n",
      "Consecutive Dates: 16-08-2017 and 13-09-2017\n",
      "Consecutive Dates: 13-09-2017 and 14-10-2017\n",
      "Consecutive Dates: 14-10-2017 and 28-10-2017\n",
      "Consecutive Dates: 28-10-2017 and 28-11-2017\n",
      "Consecutive Dates: 28-11-2017 and 30-12-2017\n",
      "Consecutive Dates: 30-12-2017 and 31-01-2018\n",
      "Consecutive Dates: 31-01-2018 and 05-03-2018\n",
      "Consecutive Dates: 05-03-2018 and 04-04-2018\n",
      "Consecutive Dates: 04-04-2018 and 12-04-2018\n",
      "Consecutive Dates: 12-04-2018 and 02-05-2018\n",
      "Consecutive Dates: 02-05-2018 and 28-05-2018\n",
      "Consecutive Dates: 28-05-2018 and 02-07-2018\n",
      "Consecutive Dates: 02-07-2018 and 31-07-2018\n",
      "Consecutive Dates: 31-07-2018 and 30-08-2018\n",
      "Consecutive Dates: 30-08-2018 and 29-10-2018\n",
      "Consecutive Dates: 29-10-2018 and 28-11-2018\n",
      "Consecutive Dates: 28-11-2018 and 29-12-2018\n",
      "Consecutive Dates: 29-12-2018 and 29-01-2019\n",
      "Consecutive Dates: 29-01-2019 and 28-02-2019\n",
      "Consecutive Dates: 28-02-2019 and 29-03-2019\n",
      "Consecutive Dates: 29-03-2019 and 27-04-2019\n",
      "Consecutive Dates: 27-04-2019 and 27-05-2019\n",
      "Consecutive Dates: 27-05-2019 and 26-06-2019\n",
      "Consecutive Dates: 26-06-2019 and 25-07-2019\n",
      "Consecutive Dates: 25-07-2019 and 26-08-2019\n",
      "Consecutive Dates: 26-08-2019 and 25-09-2019\n",
      "Consecutive Dates: 25-09-2019 and 26-10-2019\n",
      "Consecutive Dates: 26-10-2019 and 22-11-2019\n",
      "Consecutive Dates: 22-11-2019 and 25-12-2019\n",
      "Consecutive Dates: 25-12-2019 and 20-01-2020\n",
      "Consecutive Dates: 20-01-2020 and 22-02-2020\n",
      "Consecutive Dates: 22-02-2020 and 21-04-2020\n",
      "Consecutive Dates: 21-04-2020 and 22-05-2020\n",
      "Consecutive Dates: 22-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 16-11-2020\n",
      "Consecutive Dates: 16-11-2020 and 11-01-2021\n",
      "Consecutive Dates: 11-01-2021 and 21-03-2021\n",
      "Consecutive Dates: 21-03-2021 and 12-06-2023\n",
      "Consecutive Dates: 12-06-2023 and 30-07-2023\n",
      "Consecutive Dates: 30-07-2023 and 04-08-2023\n",
      "Consecutive Dates: 04-08-2023 and 18-08-2023\n",
      "Consecutive Dates: 18-08-2023 and 19-09-2023\n",
      "Consecutive Dates: 19-09-2023 and 18-10-2023\n",
      "\n",
      "Consecutive Dates: 07-03-2019 and 24-01-2020\n",
      "Consecutive Dates: 24-01-2020 and 04-02-2020\n",
      "Consecutive Dates: 04-02-2020 and 03-03-2020\n",
      "Consecutive Dates: 03-03-2020 and 14-05-2020\n",
      "Consecutive Dates: 14-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 28-09-2020\n",
      "Consecutive Dates: 28-09-2020 and 20-02-2021\n",
      "Consecutive Dates: 20-02-2021 and 17-05-2021\n",
      "Consecutive Dates: 17-05-2021 and 19-08-2021\n",
      "Consecutive Dates: 19-08-2021 and 06-07-2022\n",
      "Consecutive Dates: 06-07-2022 and 14-08-2023\n",
      "\n",
      "Consecutive Dates: 30-08-2018 and 03-10-2018\n",
      "Consecutive Dates: 03-10-2018 and 17-11-2018\n",
      "Consecutive Dates: 17-11-2018 and 20-12-2018\n",
      "Consecutive Dates: 20-12-2018 and 31-01-2019\n",
      "Consecutive Dates: 31-01-2019 and 15-03-2019\n",
      "Consecutive Dates: 15-03-2019 and 01-05-2019\n",
      "Consecutive Dates: 01-05-2019 and 29-06-2019\n",
      "Consecutive Dates: 29-06-2019 and 25-09-2019\n",
      "Consecutive Dates: 25-09-2019 and 21-10-2019\n",
      "Consecutive Dates: 21-10-2019 and 05-12-2019\n",
      "Consecutive Dates: 05-12-2019 and 24-01-2020\n",
      "Consecutive Dates: 24-01-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 06-10-2020\n",
      "Consecutive Dates: 06-10-2020 and 23-11-2020\n",
      "Consecutive Dates: 23-11-2020 and 09-03-2021\n",
      "Consecutive Dates: 09-03-2021 and 11-05-2021\n",
      "Consecutive Dates: 11-05-2021 and 28-07-2021\n",
      "Consecutive Dates: 28-07-2021 and 04-10-2021\n",
      "Consecutive Dates: 04-10-2021 and 26-11-2021\n",
      "Consecutive Dates: 26-11-2021 and 29-01-2022\n",
      "Consecutive Dates: 29-01-2022 and 10-03-2022\n",
      "Consecutive Dates: 10-03-2022 and 20-04-2022\n",
      "Consecutive Dates: 20-04-2022 and 26-05-2022\n",
      "Consecutive Dates: 26-05-2022 and 18-07-2022\n",
      "Consecutive Dates: 18-07-2022 and 07-09-2022\n",
      "Consecutive Dates: 07-09-2022 and 10-10-2022\n",
      "Consecutive Dates: 10-10-2022 and 23-11-2022\n",
      "Consecutive Dates: 23-11-2022 and 04-01-2023\n",
      "Consecutive Dates: 04-01-2023 and 02-03-2023\n",
      "Consecutive Dates: 02-03-2023 and 20-04-2023\n",
      "Consecutive Dates: 20-04-2023 and 09-06-2023\n",
      "Consecutive Dates: 09-06-2023 and 04-08-2023\n",
      "Consecutive Dates: 04-08-2023 and 23-09-2023\n",
      "Consecutive Dates: 23-09-2023 and 04-11-2023\n",
      "\n",
      "Consecutive Dates: 22-06-2020 and 31-08-2020\n",
      "Consecutive Dates: 31-08-2020 and 14-09-2020\n",
      "Consecutive Dates: 14-09-2020 and 28-10-2020\n",
      "Consecutive Dates: 28-10-2020 and 12-03-2020\n",
      "Consecutive Dates: 12-03-2020 and 19-03-2021\n",
      "\n",
      "Consecutive Dates: 08-12-2020 and 16-10-2021\n",
      "Consecutive Dates: 16-10-2021 and 13-12-2021\n",
      "Consecutive Dates: 13-12-2021 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 16-07-2021\n",
      "Consecutive Dates: 16-07-2021 and 16-08-2021\n",
      "Consecutive Dates: 16-08-2021 and 13-09-2021\n",
      "Consecutive Dates: 13-09-2021 and 14-05-2022\n",
      "Consecutive Dates: 14-05-2022 and 15-06-2022\n",
      "Consecutive Dates: 15-06-2022 and 15-07-2022\n",
      "Consecutive Dates: 15-07-2022 and 16-02-2022\n",
      "Consecutive Dates: 16-02-2022 and 15-03-2022\n",
      "Consecutive Dates: 15-03-2022 and 18-04-2022\n",
      "Consecutive Dates: 18-04-2022 and 12-10-2022\n",
      "Consecutive Dates: 12-10-2022 and 11-11-2022\n",
      "Consecutive Dates: 11-11-2022 and 13-12-2022\n",
      "Consecutive Dates: 13-12-2022 and 09-01-2023\n",
      "Consecutive Dates: 09-01-2023 and 12-08-2022\n",
      "Consecutive Dates: 12-08-2022 and 12-09-2022\n",
      "Consecutive Dates: 12-09-2022 and 10-04-2023\n",
      "Consecutive Dates: 10-04-2023 and 08-05-2023\n",
      "Consecutive Dates: 08-05-2023 and 10-06-2023\n",
      "Consecutive Dates: 10-06-2023 and 08-07-2023\n",
      "Consecutive Dates: 08-07-2023 and 11-02-2023\n",
      "Consecutive Dates: 11-02-2023 and 04-03-2023\n",
      "Consecutive Dates: 04-03-2023 and 05-08-2023\n",
      "Consecutive Dates: 05-08-2023 and 29-08-2023\n",
      "Consecutive Dates: 29-08-2023 and 07-10-2023\n",
      "Consecutive Dates: 07-10-2023 and 04-11-2023\n",
      "\n",
      "Consecutive Dates: 08-12-2020 and 16-10-2021\n",
      "Consecutive Dates: 16-10-2021 and 10-11-2021\n",
      "Consecutive Dates: 10-11-2021 and 13-12-2021\n",
      "Consecutive Dates: 13-12-2021 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 16-07-2021\n",
      "Consecutive Dates: 16-07-2021 and 16-08-2021\n",
      "Consecutive Dates: 16-08-2021 and 13-09-2021\n",
      "Consecutive Dates: 13-09-2021 and 14-05-2022\n",
      "Consecutive Dates: 14-05-2022 and 15-06-2022\n",
      "Consecutive Dates: 15-06-2022 and 15-07-2022\n",
      "Consecutive Dates: 15-07-2022 and 16-02-2022\n",
      "Consecutive Dates: 16-02-2022 and 15-03-2022\n",
      "Consecutive Dates: 15-03-2022 and 18-04-2022\n",
      "Consecutive Dates: 18-04-2022 and 12-10-2022\n",
      "Consecutive Dates: 12-10-2022 and 11-11-2022\n",
      "Consecutive Dates: 11-11-2022 and 13-12-2022\n",
      "Consecutive Dates: 13-12-2022 and 09-01-2023\n",
      "Consecutive Dates: 09-01-2023 and 12-08-2022\n",
      "Consecutive Dates: 12-08-2022 and 12-09-2022\n",
      "Consecutive Dates: 12-09-2022 and 10-04-2023\n",
      "Consecutive Dates: 10-04-2023 and 08-05-2023\n",
      "Consecutive Dates: 08-05-2023 and 10-06-2023\n",
      "Consecutive Dates: 10-06-2023 and 08-07-2023\n",
      "Consecutive Dates: 08-07-2023 and 11-02-2023\n",
      "Consecutive Dates: 11-02-2023 and 04-03-2023\n",
      "Consecutive Dates: 04-03-2023 and 05-08-2023\n",
      "Consecutive Dates: 05-08-2023 and 29-08-2023\n",
      "Consecutive Dates: 29-08-2023 and 07-10-2023\n",
      "Consecutive Dates: 07-10-2023 and 04-11-2023\n",
      "\n",
      "Consecutive Dates: 03-07-2017 and 11-09-2017\n",
      "Consecutive Dates: 11-09-2017 and 19-03-2018\n",
      "Consecutive Dates: 19-03-2018 and 04-05-2018\n",
      "Consecutive Dates: 04-05-2018 and 20-06-2018\n",
      "Consecutive Dates: 20-06-2018 and 03-08-2018\n",
      "Consecutive Dates: 03-08-2018 and 18-09-2018\n",
      "Consecutive Dates: 18-09-2018 and 09-10-2018\n",
      "Consecutive Dates: 09-10-2018 and 28-11-2018\n",
      "Consecutive Dates: 28-11-2018 and 07-02-2019\n",
      "Consecutive Dates: 07-02-2019 and 13-04-2019\n",
      "Consecutive Dates: 13-04-2019 and 23-05-2019\n",
      "Consecutive Dates: 23-05-2019 and 09-07-2019\n",
      "Consecutive Dates: 09-07-2019 and 15-11-2019\n",
      "Consecutive Dates: 15-11-2019 and 04-10-2019\n",
      "Consecutive Dates: 04-10-2019 and 15-11-2019\n",
      "Consecutive Dates: 15-11-2019 and 17-12-2019\n",
      "Consecutive Dates: 17-12-2019 and 23-01-2020\n",
      "Consecutive Dates: 23-01-2020 and 04-03-2020\n",
      "Consecutive Dates: 04-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 26-09-2020\n",
      "Consecutive Dates: 26-09-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 29-12-2020\n",
      "Consecutive Dates: 29-12-2020 and 04-02-2021\n",
      "Consecutive Dates: 04-02-2021 and 06-03-2021\n",
      "Consecutive Dates: 06-03-2021 and 12-04-2021\n",
      "Consecutive Dates: 12-04-2021 and 29-05-2021\n",
      "Consecutive Dates: 29-05-2021 and 09-07-2021\n",
      "Consecutive Dates: 09-07-2021 and 27-08-2021\n",
      "Consecutive Dates: 27-08-2021 and 06-10-2021\n",
      "Consecutive Dates: 06-10-2021 and 17-11-2021\n",
      "Consecutive Dates: 17-11-2021 and 23-12-2021\n",
      "Consecutive Dates: 23-12-2021 and 12-01-2022\n",
      "Consecutive Dates: 12-01-2022 and 05-02-2022\n",
      "Consecutive Dates: 05-02-2022 and 19-02-2022\n",
      "Consecutive Dates: 19-02-2022 and 22-03-2022\n",
      "Consecutive Dates: 22-03-2022 and 02-05-2022\n",
      "Consecutive Dates: 02-05-2022 and 13-06-2022\n",
      "Consecutive Dates: 13-06-2022 and 16-07-2022\n",
      "Consecutive Dates: 16-07-2022 and 23-08-2022\n",
      "Consecutive Dates: 23-08-2022 and 16-08-2022\n",
      "Consecutive Dates: 16-08-2022 and 26-09-2022\n",
      "Consecutive Dates: 26-09-2022 and 05-10-2022\n",
      "Consecutive Dates: 05-10-2022 and 28-10-2022\n",
      "Consecutive Dates: 28-10-2022 and 08-11-2022\n",
      "Consecutive Dates: 08-11-2022 and 07-02-2023\n",
      "Consecutive Dates: 07-02-2023 and 05-04-2023\n",
      "Consecutive Dates: 05-04-2023 and 29-05-2023\n",
      "Consecutive Dates: 29-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 18-07-2023\n",
      "Consecutive Dates: 18-07-2023 and 15-09-2023\n",
      "\n",
      "Consecutive Dates: 05-06-2014 and 27-06-2014\n",
      "Consecutive Dates: 27-06-2014 and 30-07-2014\n",
      "Consecutive Dates: 30-07-2014 and 02-09-2014\n",
      "Consecutive Dates: 02-09-2014 and 08-10-2014\n",
      "Consecutive Dates: 08-10-2014 and 14-11-2017\n",
      "Consecutive Dates: 14-11-2017 and 30-12-2014\n",
      "Consecutive Dates: 30-12-2014 and 27-02-2015\n",
      "Consecutive Dates: 27-02-2015 and 03-04-2015\n",
      "Consecutive Dates: 03-04-2015 and 09-05-2015\n",
      "Consecutive Dates: 09-05-2015 and 25-06-2015\n",
      "Consecutive Dates: 25-06-2015 and 31-07-2015\n",
      "Consecutive Dates: 31-07-2015 and 01-10-2015\n",
      "Consecutive Dates: 01-10-2015 and 09-11-2015\n",
      "Consecutive Dates: 09-11-2015 and 01-01-2016\n",
      "Consecutive Dates: 01-01-2016 and 12-02-2016\n",
      "Consecutive Dates: 12-02-2016 and 18-03-2016\n",
      "Consecutive Dates: 18-03-2016 and 19-04-2016\n",
      "Consecutive Dates: 19-04-2016 and 07-05-2016\n",
      "Consecutive Dates: 07-05-2016 and 04-06-2016\n",
      "Consecutive Dates: 04-06-2016 and 11-07-2016\n",
      "Consecutive Dates: 11-07-2016 and 05-08-2016\n",
      "Consecutive Dates: 05-08-2016 and 03-09-2016\n",
      "Consecutive Dates: 03-09-2016 and 13-10-2016\n",
      "Consecutive Dates: 13-10-2016 and 09-11-2016\n",
      "Consecutive Dates: 09-11-2016 and 07-12-2016\n",
      "Consecutive Dates: 07-12-2016 and 02-01-2017\n",
      "Consecutive Dates: 02-01-2017 and 01-02-2017\n",
      "Consecutive Dates: 01-02-2017 and 03-03-2017\n",
      "Consecutive Dates: 03-03-2017 and 31-03-2017\n",
      "Consecutive Dates: 31-03-2017 and 10-05-2017\n",
      "Consecutive Dates: 10-05-2017 and 03-06-2017\n",
      "Consecutive Dates: 03-06-2017 and 04-07-2017\n",
      "Consecutive Dates: 04-07-2017 and 08-09-2017\n",
      "Consecutive Dates: 08-09-2017 and 29-06-2018\n",
      "Consecutive Dates: 29-06-2018 and 09-08-2018\n",
      "Consecutive Dates: 09-08-2018 and 18-09-2018\n",
      "Consecutive Dates: 18-09-2018 and 20-10-2018\n",
      "Consecutive Dates: 20-10-2018 and 23-11-2018\n",
      "Consecutive Dates: 23-11-2018 and 09-02-2019\n",
      "Consecutive Dates: 09-02-2019 and 02-04-2019\n",
      "Consecutive Dates: 02-04-2019 and 27-05-2019\n",
      "Consecutive Dates: 27-05-2019 and 18-06-2019\n",
      "Consecutive Dates: 18-06-2019 and 19-06-2019\n",
      "Consecutive Dates: 19-06-2019 and 26-07-2019\n",
      "Consecutive Dates: 26-07-2019 and 09-09-2019\n",
      "Consecutive Dates: 09-09-2019 and 10-10-2019\n",
      "Consecutive Dates: 10-10-2019 and 16-11-2019\n",
      "Consecutive Dates: 16-11-2019 and 26-11-2019\n",
      "Consecutive Dates: 26-11-2019 and 24-12-2019\n",
      "Consecutive Dates: 24-12-2019 and 04-02-2020\n",
      "Consecutive Dates: 04-02-2020 and 19-03-2020\n",
      "Consecutive Dates: 19-03-2020 and 18-05-2020\n",
      "Consecutive Dates: 18-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 15-10-2020\n",
      "Consecutive Dates: 15-10-2020 and 16-11-2020\n",
      "Consecutive Dates: 16-11-2020 and 17-12-2020\n",
      "Consecutive Dates: 17-12-2020 and 16-01-2021\n",
      "Consecutive Dates: 16-01-2021 and 25-02-2021\n",
      "Consecutive Dates: 25-02-2021 and 19-05-2021\n",
      "Consecutive Dates: 19-05-2021 and 31-07-2021\n",
      "Consecutive Dates: 31-07-2021 and 13-11-2021\n",
      "Consecutive Dates: 13-11-2021 and 20-12-2021\n",
      "Consecutive Dates: 20-12-2021 and 10-01-2022\n",
      "Consecutive Dates: 10-01-2022 and 09-03-2022\n",
      "Consecutive Dates: 09-03-2022 and 12-04-2022\n",
      "Consecutive Dates: 12-04-2022 and 20-06-2022\n",
      "Consecutive Dates: 20-06-2022 and 25-08-2022\n",
      "Consecutive Dates: 25-08-2022 and 09-11-2022\n",
      "Consecutive Dates: 09-11-2022 and 15-02-2023\n",
      "Consecutive Dates: 15-02-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 24-08-2023\n",
      "\n",
      "Consecutive Dates: 23-11-2015 and 28-12-2015\n",
      "Consecutive Dates: 28-12-2015 and 15-02-2016\n",
      "Consecutive Dates: 15-02-2016 and 11-04-2016\n",
      "Consecutive Dates: 11-04-2016 and 25-05-2016\n",
      "Consecutive Dates: 25-05-2016 and 24-06-2016\n",
      "Consecutive Dates: 24-06-2016 and 06-07-2016\n",
      "Consecutive Dates: 06-07-2016 and 03-08-2016\n",
      "Consecutive Dates: 03-08-2016 and 08-09-2016\n",
      "Consecutive Dates: 08-09-2016 and 13-10-2016\n",
      "Consecutive Dates: 13-10-2016 and 12-12-2016\n",
      "Consecutive Dates: 12-12-2016 and 18-01-2017\n",
      "Consecutive Dates: 18-01-2017 and 02-03-2017\n",
      "Consecutive Dates: 02-03-2017 and 10-04-2017\n",
      "Consecutive Dates: 10-04-2017 and 03-05-2017\n",
      "Consecutive Dates: 03-05-2017 and 29-05-2017\n",
      "Consecutive Dates: 29-05-2017 and 05-06-2017\n",
      "Consecutive Dates: 05-06-2017 and 03-07-2017\n",
      "Consecutive Dates: 03-07-2017 and 02-08-2017\n",
      "Consecutive Dates: 02-08-2017 and 04-09-2017\n",
      "Consecutive Dates: 04-09-2017 and 06-11-2017\n",
      "Consecutive Dates: 06-11-2017 and 04-12-2017\n",
      "Consecutive Dates: 04-12-2017 and 05-01-2018\n",
      "Consecutive Dates: 05-01-2018 and 14-02-2018\n",
      "Consecutive Dates: 14-02-2018 and 02-04-2018\n",
      "Consecutive Dates: 02-04-2018 and 01-06-2018\n",
      "Consecutive Dates: 01-06-2018 and 02-06-2018\n",
      "Consecutive Dates: 02-06-2018 and 04-07-2018\n",
      "Consecutive Dates: 04-07-2018 and 02-08-2018\n",
      "Consecutive Dates: 02-08-2018 and 06-09-2018\n",
      "Consecutive Dates: 06-09-2018 and 09-10-2018\n",
      "Consecutive Dates: 09-10-2018 and 07-11-2018\n",
      "Consecutive Dates: 07-11-2018 and 10-01-2019\n",
      "Consecutive Dates: 10-01-2019 and 11-02-2019\n",
      "Consecutive Dates: 11-02-2019 and 18-03-2019\n",
      "Consecutive Dates: 18-03-2019 and 26-04-2019\n",
      "Consecutive Dates: 26-04-2019 and 28-05-2019\n",
      "Consecutive Dates: 28-05-2019 and 18-06-2019\n",
      "Consecutive Dates: 18-06-2019 and 28-08-2019\n",
      "Consecutive Dates: 28-08-2019 and 04-10-2019\n",
      "Consecutive Dates: 04-10-2019 and 08-11-2019\n",
      "Consecutive Dates: 08-11-2019 and 11-12-2019\n",
      "Consecutive Dates: 11-12-2019 and 16-01-2020\n",
      "Consecutive Dates: 16-01-2020 and 15-02-2020\n",
      "Consecutive Dates: 15-02-2020 and 29-02-2020\n",
      "Consecutive Dates: 29-02-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 05-05-2020\n",
      "Consecutive Dates: 05-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 21-07-2020\n",
      "Consecutive Dates: 21-07-2020 and 29-08-2020\n",
      "Consecutive Dates: 29-08-2020 and 21-10-2020\n",
      "Consecutive Dates: 21-10-2020 and 15-11-2020\n",
      "Consecutive Dates: 15-11-2020 and 22-12-2020\n",
      "Consecutive Dates: 22-12-2020 and 22-01-2021\n",
      "Consecutive Dates: 22-01-2021 and 06-03-2021\n",
      "Consecutive Dates: 06-03-2021 and 02-04-2021\n",
      "Consecutive Dates: 02-04-2021 and 08-05-2021\n",
      "Consecutive Dates: 08-05-2021 and 25-01-2022\n",
      "Consecutive Dates: 25-01-2022 and 23-08-2022\n",
      "Consecutive Dates: 23-08-2022 and 19-12-2022\n",
      "Consecutive Dates: 19-12-2022 and 24-07-2023\n",
      "Consecutive Dates: 24-07-2023 and 05-10-2023\n",
      "\n",
      "Consecutive Dates: 23-11-2015 and 28-12-2015\n",
      "Consecutive Dates: 28-12-2015 and 15-02-2016\n",
      "Consecutive Dates: 15-02-2016 and 11-04-2016\n",
      "Consecutive Dates: 11-04-2016 and 25-05-2016\n",
      "Consecutive Dates: 25-05-2016 and 24-06-2016\n",
      "Consecutive Dates: 24-06-2016 and 06-07-2016\n",
      "Consecutive Dates: 06-07-2016 and 03-08-2016\n",
      "Consecutive Dates: 03-08-2016 and 08-09-2016\n",
      "Consecutive Dates: 08-09-2016 and 13-10-2016\n",
      "Consecutive Dates: 13-10-2016 and 10-11-2016\n",
      "Consecutive Dates: 10-11-2016 and 12-12-2016\n",
      "Consecutive Dates: 12-12-2016 and 18-01-2017\n",
      "Consecutive Dates: 18-01-2017 and 02-03-2017\n",
      "Consecutive Dates: 02-03-2017 and 10-04-2017\n",
      "Consecutive Dates: 10-04-2017 and 03-05-2017\n",
      "Consecutive Dates: 03-05-2017 and 29-05-2017\n",
      "Consecutive Dates: 29-05-2017 and 05-06-2017\n",
      "Consecutive Dates: 05-06-2017 and 03-07-2017\n",
      "Consecutive Dates: 03-07-2017 and 02-08-2017\n",
      "Consecutive Dates: 02-08-2017 and 04-09-2017\n",
      "Consecutive Dates: 04-09-2017 and 06-11-2017\n",
      "Consecutive Dates: 06-11-2017 and 04-12-2017\n",
      "Consecutive Dates: 04-12-2017 and 05-01-2018\n",
      "Consecutive Dates: 05-01-2018 and 14-02-2018\n",
      "Consecutive Dates: 14-02-2018 and 02-04-2018\n",
      "Consecutive Dates: 02-04-2018 and 01-06-2018\n",
      "Consecutive Dates: 01-06-2018 and 02-06-2018\n",
      "Consecutive Dates: 02-06-2018 and 04-07-2018\n",
      "Consecutive Dates: 04-07-2018 and 02-08-2018\n",
      "Consecutive Dates: 02-08-2018 and 06-09-2018\n",
      "Consecutive Dates: 06-09-2018 and 09-10-2018\n",
      "Consecutive Dates: 09-10-2018 and 07-11-2018\n",
      "Consecutive Dates: 07-11-2018 and 10-01-2019\n",
      "Consecutive Dates: 10-01-2019 and 11-02-2019\n",
      "Consecutive Dates: 11-02-2019 and 18-03-2019\n",
      "Consecutive Dates: 18-03-2019 and 26-04-2019\n",
      "Consecutive Dates: 26-04-2019 and 28-05-2019\n",
      "Consecutive Dates: 28-05-2019 and 18-06-2019\n",
      "Consecutive Dates: 18-06-2019 and 28-08-2019\n",
      "Consecutive Dates: 28-08-2019 and 04-10-2019\n",
      "Consecutive Dates: 04-10-2019 and 08-11-2019\n",
      "Consecutive Dates: 08-11-2019 and 11-12-2019\n",
      "Consecutive Dates: 11-12-2019 and 16-01-2020\n",
      "Consecutive Dates: 16-01-2020 and 15-02-2020\n",
      "Consecutive Dates: 15-02-2020 and 29-02-2020\n",
      "Consecutive Dates: 29-02-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 05-05-2020\n",
      "Consecutive Dates: 05-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 21-07-2020\n",
      "Consecutive Dates: 21-07-2020 and 29-08-2020\n",
      "Consecutive Dates: 29-08-2020 and 21-10-2020\n",
      "Consecutive Dates: 21-10-2020 and 15-11-2020\n",
      "Consecutive Dates: 15-11-2020 and 22-12-2020\n",
      "Consecutive Dates: 22-12-2020 and 22-01-2021\n",
      "Consecutive Dates: 22-01-2021 and 06-03-2021\n",
      "Consecutive Dates: 06-03-2021 and 02-04-2021\n",
      "Consecutive Dates: 02-04-2021 and 08-05-2021\n",
      "Consecutive Dates: 08-05-2021 and 25-01-2022\n",
      "Consecutive Dates: 25-01-2022 and 23-08-2022\n",
      "Consecutive Dates: 23-08-2022 and 19-12-2022\n",
      "Consecutive Dates: 19-12-2022 and 24-07-2023\n",
      "Consecutive Dates: 24-07-2023 and 05-10-2023\n",
      "\n",
      "Consecutive Dates: 13-06-2018 and 18-08-2018\n",
      "Consecutive Dates: 18-08-2018 and 23-08-2018\n",
      "Consecutive Dates: 23-08-2018 and 19-09-2018\n",
      "Consecutive Dates: 19-09-2018 and 24-10-2018\n",
      "Consecutive Dates: 24-10-2018 and 20-02-2019\n",
      "Consecutive Dates: 20-02-2019 and 13-03-2019\n",
      "Consecutive Dates: 13-03-2019 and 06-04-2019\n",
      "Consecutive Dates: 06-04-2019 and 25-05-2019\n",
      "Consecutive Dates: 25-05-2019 and 31-07-2019\n",
      "Consecutive Dates: 31-07-2019 and 13-09-2019\n",
      "Consecutive Dates: 13-09-2019 and 08-10-2019\n",
      "Consecutive Dates: 08-10-2019 and 17-12-2019\n",
      "Consecutive Dates: 17-12-2019 and 07-01-2020\n",
      "Consecutive Dates: 07-01-2020 and 13-03-2020\n",
      "Consecutive Dates: 13-03-2020 and 11-05-2020\n",
      "Consecutive Dates: 11-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 11-09-2020\n",
      "Consecutive Dates: 11-09-2020 and 23-01-2021\n",
      "Consecutive Dates: 23-01-2021 and 24-03-2021\n",
      "Consecutive Dates: 24-03-2021 and 14-04-2021\n",
      "Consecutive Dates: 14-04-2021 and 12-06-2021\n",
      "Consecutive Dates: 12-06-2021 and 14-06-2021\n",
      "Consecutive Dates: 14-06-2021 and 20-08-2021\n",
      "Consecutive Dates: 20-08-2021 and 10-09-2021\n",
      "Consecutive Dates: 10-09-2021 and 28-09-2021\n",
      "Consecutive Dates: 28-09-2021 and 16-11-2021\n",
      "Consecutive Dates: 16-11-2021 and 01-12-2021\n",
      "Consecutive Dates: 01-12-2021 and 03-12-2021\n",
      "Consecutive Dates: 03-12-2021 and 17-12-2021\n",
      "Consecutive Dates: 17-12-2021 and 31-12-2021\n",
      "Consecutive Dates: 31-12-2021 and 18-02-2022\n",
      "Consecutive Dates: 18-02-2022 and 22-02-2022\n",
      "Consecutive Dates: 22-02-2022 and 11-03-2022\n",
      "Consecutive Dates: 11-03-2022 and 25-03-2022\n",
      "Consecutive Dates: 25-03-2022 and 23-04-2022\n",
      "Consecutive Dates: 23-04-2022 and 01-07-2022\n",
      "Consecutive Dates: 01-07-2022 and 13-08-2022\n",
      "Consecutive Dates: 13-08-2022 and 31-12-2022\n",
      "Consecutive Dates: 31-12-2022 and 12-05-2023\n",
      "Consecutive Dates: 12-05-2023 and 09-06-2023\n",
      "Consecutive Dates: 09-06-2023 and 27-07-2023\n",
      "\n",
      "Consecutive Dates: 17-03-2020 and 15-06-2020\n",
      "Consecutive Dates: 15-06-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 24-06-2020\n",
      "Consecutive Dates: 24-06-2020 and 01-07-2020\n",
      "Consecutive Dates: 01-07-2020 and 03-08-2020\n",
      "Consecutive Dates: 03-08-2020 and 24-08-2020\n",
      "\n",
      "Consecutive Dates: 04-01-2020 and 06-02-2020\n",
      "Consecutive Dates: 06-02-2020 and 11-03-2020\n",
      "Consecutive Dates: 11-03-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 27-08-2020\n",
      "Consecutive Dates: 27-08-2020 and 30-10-2020\n",
      "Consecutive Dates: 30-10-2020 and 07-01-2021\n",
      "Consecutive Dates: 07-01-2021 and 24-02-2021\n",
      "Consecutive Dates: 24-02-2021 and 02-02-2022\n",
      "\n",
      "Consecutive Dates: 21-11-2016 and 21-12-2016\n",
      "Consecutive Dates: 21-12-2016 and 21-01-2017\n",
      "Consecutive Dates: 21-01-2017 and 28-02-2017\n",
      "Consecutive Dates: 28-02-2017 and 31-03-2017\n",
      "Consecutive Dates: 31-03-2017 and 02-05-2017\n",
      "Consecutive Dates: 02-05-2017 and 01-06-2017\n",
      "Consecutive Dates: 01-06-2017 and 05-07-2017\n",
      "Consecutive Dates: 05-07-2017 and 12-08-2017\n",
      "Consecutive Dates: 12-08-2017 and 08-09-2017\n",
      "Consecutive Dates: 08-09-2017 and 18-10-2017\n",
      "Consecutive Dates: 18-10-2017 and 21-11-2017\n",
      "Consecutive Dates: 21-11-2017 and 28-12-2017\n",
      "Consecutive Dates: 28-12-2017 and 31-01-2018\n",
      "Consecutive Dates: 31-01-2018 and 21-03-2018\n",
      "Consecutive Dates: 21-03-2018 and 23-04-2018\n",
      "Consecutive Dates: 23-04-2018 and 31-05-2018\n",
      "Consecutive Dates: 31-05-2018 and 06-06-2018\n",
      "Consecutive Dates: 06-06-2018 and 03-07-2018\n",
      "Consecutive Dates: 03-07-2018 and 25-09-2018\n",
      "Consecutive Dates: 25-09-2018 and 05-11-2018\n",
      "Consecutive Dates: 05-11-2018 and 18-12-2018\n",
      "Consecutive Dates: 18-12-2018 and 29-01-2019\n",
      "Consecutive Dates: 29-01-2019 and 06-03-2019\n",
      "Consecutive Dates: 06-03-2019 and 03-04-2019\n",
      "Consecutive Dates: 03-04-2019 and 19-04-2019\n",
      "Consecutive Dates: 19-04-2019 and 25-05-2019\n",
      "Consecutive Dates: 25-05-2019 and 29-06-2019\n",
      "Consecutive Dates: 29-06-2019 and 09-08-2019\n",
      "Consecutive Dates: 09-08-2019 and 24-09-2019\n",
      "Consecutive Dates: 24-09-2019 and 29-10-2019\n",
      "Consecutive Dates: 29-10-2019 and 01-12-2019\n",
      "Consecutive Dates: 01-12-2019 and 06-01-2020\n",
      "Consecutive Dates: 06-01-2020 and 14-02-2020\n",
      "Consecutive Dates: 14-02-2020 and 12-06-2020\n",
      "Consecutive Dates: 12-06-2020 and 30-10-2020\n",
      "Consecutive Dates: 30-10-2020 and 11-12-2020\n",
      "Consecutive Dates: 11-12-2020 and 18-01-2021\n",
      "Consecutive Dates: 18-01-2021 and 19-03-2021\n",
      "Consecutive Dates: 19-03-2021 and 13-04-2021\n",
      "Consecutive Dates: 13-04-2021 and 03-08-2021\n",
      "Consecutive Dates: 03-08-2021 and 06-11-2021\n",
      "Consecutive Dates: 06-11-2021 and 11-12-2021\n",
      "Consecutive Dates: 11-12-2021 and 04-02-2022\n",
      "Consecutive Dates: 04-02-2022 and 14-06-2022\n",
      "Consecutive Dates: 14-06-2022 and 20-07-2022\n",
      "Consecutive Dates: 20-07-2022 and 24-08-2022\n",
      "Consecutive Dates: 24-08-2022 and 12-11-2022\n",
      "Consecutive Dates: 12-11-2022 and 04-01-2023\n",
      "Consecutive Dates: 04-01-2023 and 18-05-2023\n",
      "\n",
      "Consecutive Dates: 23-09-2017 and 23-10-2017\n",
      "Consecutive Dates: 23-10-2017 and 24-11-2017\n",
      "Consecutive Dates: 24-11-2017 and 05-10-2018\n",
      "Consecutive Dates: 05-10-2018 and 22-09-2021\n",
      "Consecutive Dates: 22-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 13-01-2022\n",
      "\n",
      "Consecutive Dates: 19-07-2017 and 15-09-2017\n",
      "Consecutive Dates: 15-09-2017 and 13-11-2017\n",
      "Consecutive Dates: 13-11-2017 and 13-06-2019\n",
      "Consecutive Dates: 13-06-2019 and 18-07-2019\n",
      "Consecutive Dates: 18-07-2019 and 21-11-2019\n",
      "Consecutive Dates: 21-11-2019 and 31-12-2019\n",
      "Consecutive Dates: 31-12-2019 and 11-03-2020\n",
      "Consecutive Dates: 11-03-2020 and 23-10-2020\n",
      "Consecutive Dates: 23-10-2020 and 05-04-2021\n",
      "Consecutive Dates: 05-04-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 11-10-2022\n",
      "Consecutive Dates: 11-10-2022 and 23-06-2023\n",
      "Consecutive Dates: 23-06-2023 and 26-07-2023\n",
      "Consecutive Dates: 26-07-2023 and 28-08-2023\n",
      "Consecutive Dates: 28-08-2023 and 10-10-2023\n",
      "Consecutive Dates: 10-10-2023 and 17-11-2023\n",
      "\n",
      "Consecutive Dates: 21-11-2014 and 17-12-2014\n",
      "Consecutive Dates: 17-12-2014 and 15-01-2015\n",
      "Consecutive Dates: 15-01-2015 and 14-02-2015\n",
      "Consecutive Dates: 14-02-2015 and 24-03-2015\n",
      "Consecutive Dates: 24-03-2015 and 13-04-2015\n",
      "Consecutive Dates: 13-04-2015 and 04-05-2015\n",
      "Consecutive Dates: 04-05-2015 and 04-06-2015\n",
      "Consecutive Dates: 04-06-2015 and 23-07-2015\n",
      "Consecutive Dates: 23-07-2015 and 06-08-2015\n",
      "Consecutive Dates: 06-08-2015 and 07-09-2015\n",
      "Consecutive Dates: 07-09-2015 and 03-10-2015\n",
      "Consecutive Dates: 03-10-2015 and 03-11-2015\n",
      "Consecutive Dates: 03-11-2015 and 07-12-2015\n",
      "Consecutive Dates: 07-12-2015 and 24-01-2016\n",
      "Consecutive Dates: 24-01-2016 and 30-01-2016\n",
      "Consecutive Dates: 30-01-2016 and 04-03-2016\n",
      "Consecutive Dates: 04-03-2016 and 05-04-2016\n",
      "Consecutive Dates: 05-04-2016 and 07-05-2016\n",
      "Consecutive Dates: 07-05-2016 and 06-06-2016\n",
      "Consecutive Dates: 06-06-2016 and 30-06-2016\n",
      "Consecutive Dates: 30-06-2016 and 30-07-2016\n",
      "Consecutive Dates: 30-07-2016 and 05-09-2016\n",
      "Consecutive Dates: 05-09-2016 and 23-09-2016\n",
      "Consecutive Dates: 23-09-2016 and 24-10-2016\n",
      "Consecutive Dates: 24-10-2016 and 07-12-2016\n",
      "Consecutive Dates: 07-12-2016 and 30-01-2017\n",
      "Consecutive Dates: 30-01-2017 and 07-03-2017\n",
      "Consecutive Dates: 07-03-2017 and 20-04-2017\n",
      "Consecutive Dates: 20-04-2017 and 17-07-2019\n",
      "Consecutive Dates: 17-07-2019 and 21-09-2019\n",
      "Consecutive Dates: 21-09-2019 and 21-09-2019\n",
      "Consecutive Dates: 21-09-2019 and 19-10-2019\n",
      "Consecutive Dates: 19-10-2019 and 22-11-2019\n",
      "Consecutive Dates: 22-11-2019 and 23-12-2019\n",
      "Consecutive Dates: 23-12-2019 and 22-01-2020\n",
      "Consecutive Dates: 22-01-2020 and 19-02-2020\n",
      "Consecutive Dates: 19-02-2020 and 13-03-2020\n",
      "Consecutive Dates: 13-03-2020 and 23-04-2020\n",
      "Consecutive Dates: 23-04-2020 and 16-06-2020\n",
      "Consecutive Dates: 16-06-2020 and 01-08-2020\n",
      "Consecutive Dates: 01-08-2020 and 02-09-2020\n",
      "Consecutive Dates: 02-09-2020 and 27-11-2020\n",
      "Consecutive Dates: 27-11-2020 and 25-12-2020\n",
      "Consecutive Dates: 25-12-2020 and 04-02-2021\n",
      "Consecutive Dates: 04-02-2021 and 25-02-2021\n",
      "Consecutive Dates: 25-02-2021 and 01-04-2021\n",
      "Consecutive Dates: 01-04-2021 and 22-04-2021\n",
      "Consecutive Dates: 22-04-2021 and 08-05-2021\n",
      "Consecutive Dates: 08-05-2021 and 11-06-2021\n",
      "Consecutive Dates: 11-06-2021 and 19-07-2021\n",
      "Consecutive Dates: 19-07-2021 and 17-08-2021\n",
      "Consecutive Dates: 17-08-2021 and 25-09-2021\n",
      "Consecutive Dates: 25-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 03-12-2021\n",
      "Consecutive Dates: 03-12-2021 and 03-02-2022\n",
      "Consecutive Dates: 03-02-2022 and 10-03-2022\n",
      "Consecutive Dates: 10-03-2022 and 14-04-2022\n",
      "Consecutive Dates: 14-04-2022 and 06-05-2022\n",
      "Consecutive Dates: 06-05-2022 and 08-06-2022\n",
      "Consecutive Dates: 08-06-2022 and 09-07-2022\n",
      "Consecutive Dates: 09-07-2022 and 17-08-2022\n",
      "Consecutive Dates: 17-08-2022 and 23-09-2022\n",
      "Consecutive Dates: 23-09-2022 and 02-11-2022\n",
      "Consecutive Dates: 02-11-2022 and 09-12-2022\n",
      "Consecutive Dates: 09-12-2022 and 30-12-2022\n",
      "Consecutive Dates: 30-12-2022 and 13-03-2023\n",
      "Consecutive Dates: 13-03-2023 and 01-04-2023\n",
      "Consecutive Dates: 01-04-2023 and 04-05-2023\n",
      "Consecutive Dates: 04-05-2023 and 18-05-2023\n",
      "\n",
      "Consecutive Dates: 28-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 18-05-2022\n",
      "Consecutive Dates: 18-05-2022 and 20-06-2022\n",
      "Consecutive Dates: 20-06-2022 and 25-08-2022\n",
      "\n",
      "Consecutive Dates: 21-04-2016 and 16-05-2016\n",
      "Consecutive Dates: 16-05-2016 and 23-05-2017\n",
      "Consecutive Dates: 23-05-2017 and 24-07-2017\n",
      "Consecutive Dates: 24-07-2017 and 19-02-2018\n",
      "Consecutive Dates: 19-02-2018 and 26-03-2018\n",
      "Consecutive Dates: 26-03-2018 and 30-11-2018\n",
      "Consecutive Dates: 30-11-2018 and 12-01-2019\n",
      "Consecutive Dates: 12-01-2019 and 02-01-2019\n",
      "Consecutive Dates: 02-01-2019 and 20-02-2020\n",
      "Consecutive Dates: 20-02-2020 and 15-06-2020\n",
      "Consecutive Dates: 15-06-2020 and 11-02-2021\n",
      "Consecutive Dates: 11-02-2021 and 07-10-2021\n",
      "Consecutive Dates: 07-10-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 03-12-2021\n",
      "Consecutive Dates: 03-12-2021 and 30-12-2021\n",
      "Consecutive Dates: 30-12-2021 and 17-02-2022\n",
      "Consecutive Dates: 17-02-2022 and 24-03-2022\n",
      "Consecutive Dates: 24-03-2022 and 12-05-2022\n",
      "Consecutive Dates: 12-05-2022 and 29-08-2022\n",
      "Consecutive Dates: 29-08-2022 and 06-10-2022\n",
      "Consecutive Dates: 06-10-2022 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 16-11-2023\n",
      "Consecutive Dates: 16-11-2023 and 27-11-2023\n",
      "\n",
      "Consecutive Dates: 25-03-2019 and 22-04-2019\n",
      "Consecutive Dates: 22-04-2019 and 21-05-2019\n",
      "Consecutive Dates: 21-05-2019 and 28-06-2019\n",
      "Consecutive Dates: 28-06-2019 and 09-08-2019\n",
      "Consecutive Dates: 09-08-2019 and 09-09-2019\n",
      "Consecutive Dates: 09-09-2019 and 11-10-2019\n",
      "Consecutive Dates: 11-10-2019 and 05-11-2019\n",
      "Consecutive Dates: 05-11-2019 and 04-12-2019\n",
      "Consecutive Dates: 04-12-2019 and 06-01-2019\n",
      "Consecutive Dates: 06-01-2019 and 10-02-2020\n",
      "Consecutive Dates: 10-02-2020 and 06-07-2020\n",
      "Consecutive Dates: 06-07-2020 and 24-11-2020\n",
      "Consecutive Dates: 24-11-2020 and 12-01-2021\n",
      "Consecutive Dates: 12-01-2021 and 26-04-2021\n",
      "Consecutive Dates: 26-04-2021 and 30-07-2021\n",
      "Consecutive Dates: 30-07-2021 and 28-09-2021\n",
      "Consecutive Dates: 28-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 25-02-2022\n",
      "Consecutive Dates: 25-02-2022 and 25-04-2022\n",
      "Consecutive Dates: 25-04-2022 and 25-05-2022\n",
      "Consecutive Dates: 25-05-2022 and 27-06-2022\n",
      "Consecutive Dates: 27-06-2022 and 27-07-2022\n",
      "Consecutive Dates: 27-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 02-11-2022\n",
      "Consecutive Dates: 02-11-2022 and 02-01-2023\n",
      "Consecutive Dates: 02-01-2023 and 27-02-2023\n",
      "Consecutive Dates: 27-02-2023 and 17-04-2023\n",
      "Consecutive Dates: 17-04-2023 and 29-05-2023\n",
      "Consecutive Dates: 29-05-2023 and 27-06-2023\n",
      "Consecutive Dates: 27-06-2023 and 27-09-2023\n",
      "Consecutive Dates: 27-09-2023 and 25-10-2023\n",
      "Consecutive Dates: 25-10-2023 and 27-11-2023\n",
      "\n",
      "Consecutive Dates: 28-08-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 27-12-2021\n",
      "Consecutive Dates: 27-12-2021 and 27-01-2022\n",
      "Consecutive Dates: 27-01-2022 and 25-04-2022\n",
      "Consecutive Dates: 25-04-2022 and 27-06-2022\n",
      "Consecutive Dates: 27-06-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 26-10-2022\n",
      "Consecutive Dates: 26-10-2022 and 18-11-2022\n",
      "Consecutive Dates: 18-11-2022 and 10-04-2023\n",
      "Consecutive Dates: 10-04-2023 and 19-10-2023\n",
      "\n",
      "Consecutive Dates: 28-10-2021 and 29-11-2021\n",
      "Consecutive Dates: 29-11-2021 and 05-01-2022\n",
      "Consecutive Dates: 05-01-2022 and 05-09-2022\n",
      "Consecutive Dates: 05-09-2022 and 09-03-2022\n",
      "Consecutive Dates: 09-03-2022 and 09-04-2022\n",
      "\n",
      "Consecutive Dates: 30-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 13-12-2021\n",
      "Consecutive Dates: 13-12-2021 and 29-01-2021\n",
      "\n",
      "Consecutive Dates: 30-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 06-02-2023\n",
      "\n",
      "Consecutive Dates: 08-09-2021 and 20-09-2021\n",
      "Consecutive Dates: 20-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 17-02-2022\n",
      "Consecutive Dates: 17-02-2022 and 04-09-2023\n",
      "Consecutive Dates: 04-09-2023 and 12-09-2023\n",
      "\n",
      "Consecutive Dates: 05-07-2021 and 03-09-2021\n",
      "Consecutive Dates: 03-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 02-12-2021\n",
      "Consecutive Dates: 02-12-2021 and 31-01-2022\n",
      "Consecutive Dates: 31-01-2022 and 31-03-2022\n",
      "Consecutive Dates: 31-03-2022 and 31-05-2022\n",
      "Consecutive Dates: 31-05-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 29-12-2022\n",
      "Consecutive Dates: 29-12-2022 and 13-02-2023\n",
      "Consecutive Dates: 13-02-2023 and 02-06-2023\n",
      "Consecutive Dates: 02-06-2023 and 25-07-2023\n",
      "\n",
      "Consecutive Dates: 03-05-2021 and 12-07-2021\n",
      "Consecutive Dates: 12-07-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 24-01-2022\n",
      "Consecutive Dates: 24-01-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 21-07-2022\n",
      "\n",
      "Consecutive Dates: 08-11-2021 and 30-12-2021\n",
      "Consecutive Dates: 30-12-2021 and 29-01-2022\n",
      "Consecutive Dates: 29-01-2022 and 01-03-2022\n",
      "Consecutive Dates: 01-03-2022 and 31-03-2022\n",
      "Consecutive Dates: 31-03-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 11-06-2022\n",
      "Consecutive Dates: 11-06-2022 and 05-07-2022\n",
      "Consecutive Dates: 05-07-2022 and 04-08-2022\n",
      "Consecutive Dates: 04-08-2022 and 05-09-2022\n",
      "Consecutive Dates: 05-09-2022 and 10-10-2022\n",
      "Consecutive Dates: 10-10-2022 and 05-12-2022\n",
      "Consecutive Dates: 05-12-2022 and 14-01-2023\n",
      "Consecutive Dates: 14-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 27-03-2023\n",
      "Consecutive Dates: 27-03-2023 and 06-05-2023\n",
      "Consecutive Dates: 06-05-2023 and 10-06-2025\n",
      "\n",
      "Consecutive Dates: 18-07-2022 and 15-09-2022\n",
      "Consecutive Dates: 15-09-2022 and 06-10-2022\n",
      "Consecutive Dates: 06-10-2022 and 14-10-2022\n",
      "Consecutive Dates: 14-10-2022 and 16-11-2022\n",
      "Consecutive Dates: 16-11-2022 and 21-11-2022\n",
      "Consecutive Dates: 21-11-2022 and 17-12-2022\n",
      "Consecutive Dates: 17-12-2022 and 13-01-2023\n",
      "Consecutive Dates: 13-01-2023 and 18-01-2023\n",
      "Consecutive Dates: 18-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 15-03-2023\n",
      "Consecutive Dates: 15-03-2023 and 17-04-2023\n",
      "Consecutive Dates: 17-04-2023 and 07-06-2023\n",
      "Consecutive Dates: 07-06-2023 and 31-07-2023\n",
      "Consecutive Dates: 31-07-2023 and 11-08-2023\n",
      "Consecutive Dates: 11-08-2023 and 19-08-2023\n",
      "Consecutive Dates: 19-08-2023 and 20-09-2023\n",
      "Consecutive Dates: 20-09-2023 and 18-10-2023\n",
      "Consecutive Dates: 18-10-2023 and 04-11-2023\n",
      "Consecutive Dates: 04-11-2023 and 02-12-2023\n",
      "\n",
      "Consecutive Dates: 21-07-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 18-05-2023\n",
      "Consecutive Dates: 18-05-2023 and 05-10-2023\n",
      "\n",
      "\n",
      "Consecutive Dates: 05-04-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 02-06-2022\n",
      "Consecutive Dates: 02-06-2022 and 01-07-2022\n",
      "Consecutive Dates: 01-07-2022 and 15-07-2022\n",
      "Consecutive Dates: 15-07-2022 and 26-07-2022\n",
      "Consecutive Dates: 26-07-2022 and 04-08-2022\n",
      "Consecutive Dates: 04-08-2022 and 11-08-2022\n",
      "Consecutive Dates: 11-08-2022 and 18-08-2022\n",
      "Consecutive Dates: 18-08-2022 and 25-08-2022\n",
      "Consecutive Dates: 25-08-2022 and 06-09-2022\n",
      "Consecutive Dates: 06-09-2022 and 13-10-2022\n",
      "Consecutive Dates: 13-10-2022 and 24-12-2022\n",
      "Consecutive Dates: 24-12-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 05-05-2023\n",
      "Consecutive Dates: 05-05-2023 and 28-07-2023\n",
      "Consecutive Dates: 28-07-2023 and 18-10-2023\n",
      "\n",
      "Consecutive Dates: 16-01-2023 and 16-03-2023\n",
      "\n",
      "Consecutive Dates: 02-02-2021 and 08-05-2021\n",
      "Consecutive Dates: 08-05-2021 and 14-09-2021\n",
      "Consecutive Dates: 14-09-2021 and 05-04-2021\n",
      "Consecutive Dates: 05-04-2021 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 24-08-2022\n",
      "Consecutive Dates: 24-08-2022 and 31-10-2022\n",
      "Consecutive Dates: 31-10-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 08-05-2023\n",
      "Consecutive Dates: 08-05-2023 and 11-07-2023\n",
      "Consecutive Dates: 11-07-2023 and 01-11-2023\n",
      "\n",
      "Consecutive Dates: 14-03-2019 and 23-12-2019\n",
      "Consecutive Dates: 23-12-2019 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 25-06-2022\n",
      "Consecutive Dates: 25-06-2022 and 29-08-2022\n",
      "Consecutive Dates: 29-08-2022 and 31-10-2022\n",
      "\n",
      "Consecutive Dates: 05-04-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 02-06-2022\n",
      "Consecutive Dates: 02-06-2022 and 01-07-2022\n",
      "Consecutive Dates: 01-07-2022 and 15-07-2022\n",
      "Consecutive Dates: 15-07-2022 and 26-07-2022\n",
      "Consecutive Dates: 26-07-2022 and 04-08-2022\n",
      "Consecutive Dates: 04-08-2022 and 11-08-2022\n",
      "Consecutive Dates: 11-08-2022 and 18-08-2022\n",
      "Consecutive Dates: 18-08-2022 and 25-08-2022\n",
      "Consecutive Dates: 25-08-2022 and 06-09-2022\n",
      "Consecutive Dates: 06-09-2022 and 13-10-2022\n",
      "Consecutive Dates: 13-10-2022 and 10-11-2022\n",
      "Consecutive Dates: 10-11-2022 and 24-12-2022\n",
      "Consecutive Dates: 24-12-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 05-05-2023\n",
      "Consecutive Dates: 05-05-2023 and 28-07-2023\n",
      "Consecutive Dates: 28-07-2023 and 18-10-2023\n",
      "\n",
      "Consecutive Dates: 17-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 03-03-2023\n",
      "Consecutive Dates: 03-03-2023 and 03-04-2023\n",
      "Consecutive Dates: 03-04-2023 and 19-05-2023\n",
      "Consecutive Dates: 19-05-2023 and 24-06-2023\n",
      "Consecutive Dates: 24-06-2023 and 29-07-2023\n",
      "Consecutive Dates: 29-07-2023 and 07-09-2023\n",
      "\n",
      "Consecutive Dates: 16-02-2023 and 27-03-2023\n",
      "Consecutive Dates: 27-03-2023 and 15-05-2023\n",
      "\n",
      "Consecutive Dates: 16-02-2023 and 06-03-2023\n",
      "Consecutive Dates: 06-03-2023 and 22-03-2023\n",
      "Consecutive Dates: 22-03-2023 and 31-03-2023\n",
      "Consecutive Dates: 31-03-2023 and 28-04-2023\n",
      "Consecutive Dates: 28-04-2023 and 16-06-2023\n",
      "Consecutive Dates: 16-06-2023 and 01-09-2023\n",
      "Consecutive Dates: 01-09-2023 and 24-10-2023\n",
      "\n",
      "Consecutive Dates: 28-12-2020 and 13-04-2021\n",
      "Consecutive Dates: 13-04-2021 and 25-07-2022\n",
      "Consecutive Dates: 25-07-2022 and 16-02-2023\n",
      "\n",
      "Consecutive Dates: 16-02-2023 and 10-03-2023\n",
      "Consecutive Dates: 10-03-2023 and 17-04-2023\n",
      "Consecutive Dates: 17-04-2023 and 05-06-2023\n",
      "\n",
      "Consecutive Dates: 15-09-2022 and 17-11-2022\n",
      "Consecutive Dates: 17-11-2022 and 20-12-2022\n",
      "Consecutive Dates: 20-12-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 18-04-2023\n",
      "Consecutive Dates: 18-04-2023 and 27-07-2023\n",
      "\n",
      "Consecutive Dates: 20-05-2017 and 21-06-2017\n",
      "Consecutive Dates: 21-06-2017 and 25-08-2018\n",
      "Consecutive Dates: 25-08-2018 and 01-09-2018\n",
      "Consecutive Dates: 01-09-2018 and 12-09-2018\n",
      "Consecutive Dates: 12-09-2018 and 22-10-2018\n",
      "Consecutive Dates: 22-10-2018 and 23-11-2018\n",
      "Consecutive Dates: 23-11-2018 and 31-12-2018\n",
      "Consecutive Dates: 31-12-2018 and 16-02-2019\n",
      "Consecutive Dates: 16-02-2019 and 22-03-2019\n",
      "Consecutive Dates: 22-03-2019 and 03-07-2019\n",
      "Consecutive Dates: 03-07-2019 and 03-08-2019\n",
      "Consecutive Dates: 03-08-2019 and 11-09-2019\n",
      "Consecutive Dates: 11-09-2019 and 15-10-2019\n",
      "Consecutive Dates: 15-10-2019 and 15-11-2019\n",
      "Consecutive Dates: 15-11-2019 and 23-12-2019\n",
      "Consecutive Dates: 23-12-2019 and 31-01-2020\n",
      "Consecutive Dates: 31-01-2020 and 22-02-2020\n",
      "Consecutive Dates: 22-02-2020 and 09-03-2020\n",
      "Consecutive Dates: 09-03-2020 and 23-04-2020\n",
      "Consecutive Dates: 23-04-2020 and 15-06-2020\n",
      "Consecutive Dates: 15-06-2020 and 18-08-2020\n",
      "Consecutive Dates: 18-08-2020 and 17-10-2020\n",
      "Consecutive Dates: 17-10-2020 and 03-12-2020\n",
      "Consecutive Dates: 03-12-2020 and 28-12-2020\n",
      "Consecutive Dates: 28-12-2020 and 25-01-2021\n",
      "Consecutive Dates: 25-01-2021 and 25-02-2021\n",
      "Consecutive Dates: 25-02-2021 and 07-04-2021\n",
      "Consecutive Dates: 07-04-2021 and 19-06-2021\n",
      "Consecutive Dates: 19-06-2021 and 04-08-2021\n",
      "Consecutive Dates: 04-08-2021 and 06-09-2021\n",
      "Consecutive Dates: 06-09-2021 and 13-10-2021\n",
      "Consecutive Dates: 13-10-2021 and 17-11-2021\n",
      "Consecutive Dates: 17-11-2021 and 30-12-2021\n",
      "Consecutive Dates: 30-12-2021 and 19-02-2022\n",
      "Consecutive Dates: 19-02-2022 and 24-03-2022\n",
      "Consecutive Dates: 24-03-2022 and 21-04-2022\n",
      "Consecutive Dates: 21-04-2022 and 26-05-2022\n",
      "Consecutive Dates: 26-05-2022 and 02-06-2022\n",
      "Consecutive Dates: 02-06-2022 and 09-08-2022\n",
      "Consecutive Dates: 09-08-2022 and 22-09-2022\n",
      "Consecutive Dates: 22-09-2022 and 17-11-2022\n",
      "Consecutive Dates: 17-11-2022 and 07-01-2023\n",
      "Consecutive Dates: 07-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 21-03-2023\n",
      "Consecutive Dates: 21-03-2023 and 29-04-2023\n",
      "Consecutive Dates: 29-04-2023 and 26-08-2023\n",
      "Consecutive Dates: 26-08-2023 and 07-10-2023\n",
      "Consecutive Dates: 07-10-2023 and 04-12-2023\n",
      "\n",
      "Consecutive Dates: 08-07-2022 and 08-08-2022\n",
      "Consecutive Dates: 08-08-2022 and 08-09-2022\n",
      "Consecutive Dates: 08-09-2022 and 18-10-2022\n",
      "Consecutive Dates: 18-10-2022 and 14-11-2022\n",
      "Consecutive Dates: 14-11-2022 and 12-12-2022\n",
      "Consecutive Dates: 12-12-2022 and 11-01-2023\n",
      "Consecutive Dates: 11-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 04-04-2023\n",
      "Consecutive Dates: 04-04-2023 and 17-06-2023\n",
      "Consecutive Dates: 17-06-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 27-11-2023\n",
      "\n",
      "Consecutive Dates: 24-04-2017 and 16-05-2017\n",
      "Consecutive Dates: 16-05-2017 and 08-10-2018\n",
      "Consecutive Dates: 08-10-2018 and 07-11-2018\n",
      "Consecutive Dates: 07-11-2018 and 10-12-2018\n",
      "Consecutive Dates: 10-12-2018 and 12-01-2019\n",
      "Consecutive Dates: 12-01-2019 and 28-03-2019\n",
      "Consecutive Dates: 28-03-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 30-05-2019\n",
      "Consecutive Dates: 30-05-2019 and 01-07-2019\n",
      "Consecutive Dates: 01-07-2019 and 05-08-2019\n",
      "Consecutive Dates: 05-08-2019 and 07-09-2019\n",
      "Consecutive Dates: 07-09-2019 and 07-10-2019\n",
      "Consecutive Dates: 07-10-2019 and 11-11-2019\n",
      "Consecutive Dates: 11-11-2019 and 18-12-2019\n",
      "Consecutive Dates: 18-12-2019 and 20-01-2020\n",
      "Consecutive Dates: 20-01-2020 and 17-02-2020\n",
      "Consecutive Dates: 17-02-2020 and 17-03-2020\n",
      "Consecutive Dates: 17-03-2020 and 18-06-2020\n",
      "Consecutive Dates: 18-06-2020 and 16-09-2020\n",
      "Consecutive Dates: 16-09-2020 and 28-12-2020\n",
      "Consecutive Dates: 28-12-2020 and 02-01-2021\n",
      "Consecutive Dates: 02-01-2021 and 02-02-2021\n",
      "Consecutive Dates: 02-02-2021 and 22-03-2021\n",
      "Consecutive Dates: 22-03-2021 and 26-04-2021\n",
      "Consecutive Dates: 26-04-2021 and 08-06-2022\n",
      "Consecutive Dates: 08-06-2022 and 08-07-2022\n",
      "Consecutive Dates: 08-07-2022 and 11-08-2022\n",
      "Consecutive Dates: 11-08-2022 and 09-09-2022\n",
      "Consecutive Dates: 09-09-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 25-03-2023\n",
      "Consecutive Dates: 25-03-2023 and 26-04-2023\n",
      "Consecutive Dates: 26-04-2023 and 30-05-2023\n",
      "Consecutive Dates: 30-05-2023 and 01-07-2023\n",
      "Consecutive Dates: 01-07-2023 and 05-08-2023\n",
      "Consecutive Dates: 05-08-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 25-10-2023\n",
      "\n",
      "Consecutive Dates: 21-05-2022 and 01-06-2022\n",
      "Consecutive Dates: 01-06-2022 and 22-06-2022\n",
      "Consecutive Dates: 22-06-2022 and 21-07-2022\n",
      "Consecutive Dates: 21-07-2022 and 27-08-2022\n",
      "Consecutive Dates: 27-08-2022 and 30-07-2022\n",
      "Consecutive Dates: 30-07-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 01-11-2022\n",
      "Consecutive Dates: 01-11-2022 and 02-12-2022\n",
      "Consecutive Dates: 02-12-2022 and 06-01-2023\n",
      "Consecutive Dates: 06-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 23-03-2023\n",
      "Consecutive Dates: 23-03-2023 and 29-04-2023\n",
      "Consecutive Dates: 29-04-2023 and 10-06-2023\n",
      "Consecutive Dates: 10-06-2023 and 17-07-2023\n",
      "Consecutive Dates: 17-07-2023 and 28-08-2023\n",
      "Consecutive Dates: 28-08-2023 and 09-10-2023\n",
      "Consecutive Dates: 09-10-2023 and 27-11-2023\n",
      "\n",
      "Consecutive Dates: 16-02-2023 and 16-03-2023\n",
      "Consecutive Dates: 16-03-2023 and 17-04-2023\n",
      "Consecutive Dates: 17-04-2023 and 15-05-2023\n",
      "\n",
      "\n",
      "Consecutive Dates: 24-04-2017 and 16-05-2017\n",
      "Consecutive Dates: 16-05-2017 and 08-10-2018\n",
      "Consecutive Dates: 08-10-2018 and 07-11-2018\n",
      "Consecutive Dates: 07-11-2018 and 10-12-2018\n",
      "Consecutive Dates: 10-12-2018 and 12-01-2019\n",
      "Consecutive Dates: 12-01-2019 and 28-03-2019\n",
      "Consecutive Dates: 28-03-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 30-05-2019\n",
      "Consecutive Dates: 30-05-2019 and 01-07-2019\n",
      "Consecutive Dates: 01-07-2019 and 05-08-2019\n",
      "Consecutive Dates: 05-08-2019 and 07-09-2019\n",
      "Consecutive Dates: 07-09-2019 and 07-10-2019\n",
      "Consecutive Dates: 07-10-2019 and 11-11-2019\n",
      "Consecutive Dates: 11-11-2019 and 18-12-2019\n",
      "Consecutive Dates: 18-12-2019 and 20-01-2020\n",
      "Consecutive Dates: 20-01-2020 and 17-02-2020\n",
      "Consecutive Dates: 17-02-2020 and 17-03-2020\n",
      "Consecutive Dates: 17-03-2020 and 18-06-2020\n",
      "Consecutive Dates: 18-06-2020 and 16-09-2020\n",
      "Consecutive Dates: 16-09-2020 and 10-11-2020\n",
      "Consecutive Dates: 10-11-2020 and 28-12-2020\n",
      "Consecutive Dates: 28-12-2020 and 02-01-2021\n",
      "Consecutive Dates: 02-01-2021 and 02-02-2021\n",
      "Consecutive Dates: 02-02-2021 and 22-03-2021\n",
      "Consecutive Dates: 22-03-2021 and 26-04-2021\n",
      "Consecutive Dates: 26-04-2021 and 08-06-2022\n",
      "Consecutive Dates: 08-06-2022 and 08-07-2022\n",
      "Consecutive Dates: 08-07-2022 and 11-08-2022\n",
      "Consecutive Dates: 11-08-2022 and 09-09-2022\n",
      "Consecutive Dates: 09-09-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 30-11-2022\n",
      "Consecutive Dates: 30-11-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 25-03-2023\n",
      "Consecutive Dates: 25-03-2023 and 26-04-2023\n",
      "Consecutive Dates: 26-04-2023 and 30-05-2023\n",
      "Consecutive Dates: 30-05-2023 and 01-07-2023\n",
      "Consecutive Dates: 01-07-2023 and 05-08-2023\n",
      "Consecutive Dates: 05-08-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 25-10-2023\n",
      "\n",
      "Consecutive Dates: 16-02-2023 and 03-03-2023\n",
      "Consecutive Dates: 03-03-2023 and 13-06-2023\n",
      "\n",
      "Consecutive Dates: 29-12-2017 and 11-01-2022\n",
      "Consecutive Dates: 11-01-2022 and 12-01-2022\n",
      "Consecutive Dates: 12-01-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 18-02-2023\n",
      "\n",
      "Consecutive Dates: 04-05-2022 and 21-06-2022\n",
      "Consecutive Dates: 21-06-2022 and 21-07-2022\n",
      "Consecutive Dates: 21-07-2022 and 20-08-2022\n",
      "Consecutive Dates: 20-08-2022 and 17-10-2022\n",
      "Consecutive Dates: 17-10-2022 and 16-11-2022\n",
      "Consecutive Dates: 16-11-2022 and 19-12-2022\n",
      "Consecutive Dates: 19-12-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 18-03-2023\n",
      "Consecutive Dates: 18-03-2023 and 18-04-2023\n",
      "Consecutive Dates: 18-04-2023 and 16-05-2023\n",
      "Consecutive Dates: 16-05-2023 and 16-06-2023\n",
      "Consecutive Dates: 16-06-2023 and 13-07-2023\n",
      "Consecutive Dates: 13-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 31-08-2023\n",
      "Consecutive Dates: 31-08-2023 and 01-11-2023\n",
      "Consecutive Dates: 01-11-2023 and 02-12-2023\n",
      "\n",
      "Consecutive Dates: 22-09-2022 and 20-10-2022\n",
      "Consecutive Dates: 20-10-2022 and 17-11-2022\n",
      "Consecutive Dates: 17-11-2022 and 21-12-2022\n",
      "Consecutive Dates: 21-12-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 07-04-2023\n",
      "Consecutive Dates: 07-04-2023 and 18-07-2023\n",
      "Consecutive Dates: 18-07-2023 and 17-08-2023\n",
      "Consecutive Dates: 17-08-2023 and 13-10-2023\n",
      "\n",
      "Consecutive Dates: 11-01-2018 and 08-02-2019\n",
      "Consecutive Dates: 08-02-2019 and 10-03-2019\n",
      "Consecutive Dates: 10-03-2019 and 06-04-2019\n",
      "Consecutive Dates: 06-04-2019 and 04-05-2019\n",
      "Consecutive Dates: 04-05-2019 and 13-07-2019\n",
      "Consecutive Dates: 13-07-2019 and 11-02-2020\n",
      "Consecutive Dates: 11-02-2020 and 02-05-2022\n",
      "Consecutive Dates: 02-05-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 20-04-2023\n",
      "\n",
      "Consecutive Dates: 28-01-2019 and 02-03-2019\n",
      "Consecutive Dates: 02-03-2019 and 09-04-2019\n",
      "Consecutive Dates: 09-04-2019 and 29-05-2019\n",
      "Consecutive Dates: 29-05-2019 and 02-09-2019\n",
      "Consecutive Dates: 02-09-2019 and 30-09-2019\n",
      "Consecutive Dates: 30-09-2019 and 27-11-2019\n",
      "Consecutive Dates: 27-11-2019 and 24-12-2019\n",
      "Consecutive Dates: 24-12-2019 and 31-01-2020\n",
      "Consecutive Dates: 31-01-2020 and 04-02-2020\n",
      "Consecutive Dates: 04-02-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 09-06-2020\n",
      "Consecutive Dates: 09-06-2020 and 08-10-2020\n",
      "Consecutive Dates: 08-10-2020 and 27-11-2020\n",
      "Consecutive Dates: 27-11-2020 and 28-12-2020\n",
      "Consecutive Dates: 28-12-2020 and 29-01-2021\n",
      "Consecutive Dates: 29-01-2021 and 27-02-2021\n",
      "Consecutive Dates: 27-02-2021 and 30-03-2021\n",
      "Consecutive Dates: 30-03-2021 and 04-05-2021\n",
      "Consecutive Dates: 04-05-2021 and 11-06-2021\n",
      "Consecutive Dates: 11-06-2021 and 09-08-2021\n",
      "Consecutive Dates: 09-08-2021 and 07-10-2021\n",
      "Consecutive Dates: 07-10-2021 and 15-12-2021\n",
      "Consecutive Dates: 15-12-2021 and 04-02-2022\n",
      "Consecutive Dates: 04-02-2022 and 16-03-2022\n",
      "Consecutive Dates: 16-03-2022 and 21-04-2022\n",
      "Consecutive Dates: 21-04-2022 and 03-06-2022\n",
      "Consecutive Dates: 03-06-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 04-08-2022\n",
      "Consecutive Dates: 04-08-2022 and 29-09-2022\n",
      "Consecutive Dates: 29-09-2022 and 01-11-2022\n",
      "Consecutive Dates: 01-11-2022 and 15-12-2022\n",
      "Consecutive Dates: 15-12-2022 and 14-01-2023\n",
      "Consecutive Dates: 14-01-2023 and 25-02-2023\n",
      "Consecutive Dates: 25-02-2023 and 11-04-2023\n",
      "Consecutive Dates: 11-04-2023 and 25-05-2023\n",
      "Consecutive Dates: 25-05-2023 and 26-03-2023\n",
      "Consecutive Dates: 26-03-2023 and 25-07-2023\n",
      "Consecutive Dates: 25-07-2023 and 08-09-2023\n",
      "Consecutive Dates: 08-09-2023 and 06-10-2023\n",
      "Consecutive Dates: 06-10-2023 and 04-11-2023\n",
      "Consecutive Dates: 04-11-2023 and 14-12-2023\n",
      "\n",
      "Consecutive Dates: 13-05-2022 and 11-06-2022\n",
      "Consecutive Dates: 11-06-2022 and 15-07-2022\n",
      "Consecutive Dates: 15-07-2022 and 16-08-2022\n",
      "Consecutive Dates: 16-08-2022 and 17-01-2023\n",
      "Consecutive Dates: 17-01-2023 and 18-01-2023\n",
      "Consecutive Dates: 18-01-2023 and 16-02-2023\n",
      "\n",
      "Consecutive Dates: 15-12-2007 and 12-01-2008\n",
      "Consecutive Dates: 12-01-2008 and 02-02-2008\n",
      "Consecutive Dates: 02-02-2008 and 11-12-2010\n",
      "Consecutive Dates: 11-12-2010 and 13-03-2013\n",
      "Consecutive Dates: 13-03-2013 and 13-04-2013\n",
      "Consecutive Dates: 13-04-2013 and 11-05-2013\n",
      "Consecutive Dates: 11-05-2013 and 12-06-2013\n",
      "Consecutive Dates: 12-06-2013 and 13-07-2013\n",
      "Consecutive Dates: 13-07-2013 and 14-08-2013\n",
      "Consecutive Dates: 14-08-2013 and 19-08-2013\n",
      "Consecutive Dates: 19-08-2013 and 14-09-2013\n",
      "Consecutive Dates: 14-09-2013 and 17-10-2013\n",
      "Consecutive Dates: 17-10-2013 and 16-11-2013\n",
      "Consecutive Dates: 16-11-2013 and 18-12-2013\n",
      "Consecutive Dates: 18-12-2013 and 18-01-2014\n",
      "Consecutive Dates: 18-01-2014 and 19-02-2014\n",
      "Consecutive Dates: 19-02-2014 and 23-04-2014\n",
      "Consecutive Dates: 23-04-2014 and 24-05-2014\n",
      "Consecutive Dates: 24-05-2014 and 28-06-2014\n",
      "Consecutive Dates: 28-06-2014 and 30-07-2014\n",
      "Consecutive Dates: 30-07-2014 and 30-08-2014\n",
      "Consecutive Dates: 30-08-2014 and 01-10-2014\n",
      "Consecutive Dates: 01-10-2014 and 29-10-2014\n",
      "Consecutive Dates: 29-10-2014 and 29-11-2014\n",
      "Consecutive Dates: 29-11-2014 and 31-12-2014\n",
      "Consecutive Dates: 31-12-2014 and 03-02-2015\n",
      "Consecutive Dates: 03-02-2015 and 07-03-2015\n",
      "Consecutive Dates: 07-03-2015 and 09-06-2015\n",
      "Consecutive Dates: 09-06-2015 and 11-07-2015\n",
      "Consecutive Dates: 11-07-2015 and 14-08-2015\n",
      "Consecutive Dates: 14-08-2015 and 29-09-2015\n",
      "Consecutive Dates: 29-09-2015 and 03-11-2015\n",
      "Consecutive Dates: 03-11-2015 and 05-12-2015\n",
      "Consecutive Dates: 05-12-2015 and 05-01-2016\n",
      "Consecutive Dates: 05-01-2016 and 08-01-2016\n",
      "Consecutive Dates: 08-01-2016 and 16-02-2016\n",
      "Consecutive Dates: 16-02-2016 and 21-03-2016\n",
      "Consecutive Dates: 21-03-2016 and 23-04-2016\n",
      "Consecutive Dates: 23-04-2016 and 31-05-2016\n",
      "Consecutive Dates: 31-05-2016 and 11-07-2016\n",
      "Consecutive Dates: 11-07-2016 and 09-08-2016\n",
      "Consecutive Dates: 09-08-2016 and 10-09-2016\n",
      "Consecutive Dates: 10-09-2016 and 22-10-2016\n",
      "Consecutive Dates: 22-10-2016 and 07-01-2017\n",
      "Consecutive Dates: 07-01-2017 and 14-03-2017\n",
      "Consecutive Dates: 14-03-2017 and 06-05-2017\n",
      "Consecutive Dates: 06-05-2017 and 07-07-2017\n",
      "Consecutive Dates: 07-07-2017 and 08-08-2017\n",
      "Consecutive Dates: 08-08-2017 and 12-09-2017\n",
      "Consecutive Dates: 12-09-2017 and 14-10-2017\n",
      "Consecutive Dates: 14-10-2017 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 20-03-2018\n",
      "Consecutive Dates: 20-03-2018 and 02-05-2018\n",
      "Consecutive Dates: 02-05-2018 and 08-06-2018\n",
      "Consecutive Dates: 08-06-2018 and 20-07-2018\n",
      "Consecutive Dates: 20-07-2018 and 28-12-2018\n",
      "Consecutive Dates: 28-12-2018 and 08-01-2019\n",
      "Consecutive Dates: 08-01-2019 and 25-01-2019\n",
      "Consecutive Dates: 25-01-2019 and 15-03-2019\n",
      "Consecutive Dates: 15-03-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 07-06-2019\n",
      "Consecutive Dates: 07-06-2019 and 11-07-2019\n",
      "Consecutive Dates: 11-07-2019 and 13-08-2019\n",
      "Consecutive Dates: 13-08-2019 and 03-10-2019\n",
      "Consecutive Dates: 03-10-2019 and 07-11-2019\n",
      "Consecutive Dates: 07-11-2019 and 04-01-2020\n",
      "Consecutive Dates: 04-01-2020 and 24-03-2020\n",
      "Consecutive Dates: 24-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 11-07-2020\n",
      "Consecutive Dates: 11-07-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 28-08-2021\n",
      "Consecutive Dates: 28-08-2021 and 25-09-2021\n",
      "Consecutive Dates: 25-09-2021 and 26-10-2021\n",
      "Consecutive Dates: 26-10-2021 and 30-10-2021\n",
      "Consecutive Dates: 30-10-2021 and 03-11-2021\n",
      "Consecutive Dates: 03-11-2021 and 27-11-2021\n",
      "Consecutive Dates: 27-11-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 28-01-2022\n",
      "Consecutive Dates: 28-01-2022 and 28-02-2022\n",
      "Consecutive Dates: 28-02-2022 and 28-03-2022\n",
      "Consecutive Dates: 28-03-2022 and 28-04-2022\n",
      "Consecutive Dates: 28-04-2022 and 28-05-2022\n",
      "Consecutive Dates: 28-05-2022 and 29-06-2022\n",
      "Consecutive Dates: 29-06-2022 and 28-07-2022\n",
      "Consecutive Dates: 28-07-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 09-11-2022\n",
      "Consecutive Dates: 09-11-2022 and 14-12-2022\n",
      "Consecutive Dates: 14-12-2022 and 19-01-2023\n",
      "Consecutive Dates: 19-01-2023 and 20-02-2023\n",
      "Consecutive Dates: 20-02-2023 and 04-04-2023\n",
      "Consecutive Dates: 04-04-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 06-06-2023\n",
      "Consecutive Dates: 06-06-2023 and 06-07-2023\n",
      "Consecutive Dates: 06-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 11-10-2023\n",
      "Consecutive Dates: 11-10-2023 and 18-12-2023\n",
      "\n",
      "Consecutive Dates: 27-11-2019 and 24-01-2020\n",
      "Consecutive Dates: 24-01-2020 and 03-03-2020\n",
      "Consecutive Dates: 03-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 16-06-2020\n",
      "Consecutive Dates: 16-06-2020 and 29-07-2020\n",
      "Consecutive Dates: 29-07-2020 and 03-11-2020\n",
      "Consecutive Dates: 03-11-2020 and 17-11-2020\n",
      "Consecutive Dates: 17-11-2020 and 29-12-2020\n",
      "Consecutive Dates: 29-12-2020 and 10-02-2021\n",
      "Consecutive Dates: 10-02-2021 and 16-03-2021\n",
      "Consecutive Dates: 16-03-2021 and 31-03-2021\n",
      "Consecutive Dates: 31-03-2021 and 30-03-2022\n",
      "Consecutive Dates: 30-03-2022 and 27-05-2022\n",
      "Consecutive Dates: 27-05-2022 and 08-07-2022\n",
      "Consecutive Dates: 08-07-2022 and 22-08-2022\n",
      "Consecutive Dates: 22-08-2022 and 27-09-2022\n",
      "Consecutive Dates: 27-09-2022 and 11-11-2022\n",
      "Consecutive Dates: 11-11-2022 and 14-12-2022\n",
      "Consecutive Dates: 14-12-2022 and 18-01-2023\n",
      "Consecutive Dates: 18-01-2023 and 28-02-2023\n",
      "Consecutive Dates: 28-02-2023 and 18-04-2023\n",
      "Consecutive Dates: 18-04-2023 and 20-07-2023\n",
      "Consecutive Dates: 20-07-2023 and 26-09-2023\n",
      "Consecutive Dates: 26-09-2023 and 06-12-2023\n",
      "\n",
      "Consecutive Dates: 12-01-2008 and 02-02-2010\n",
      "Consecutive Dates: 02-02-2010 and 11-12-2010\n",
      "Consecutive Dates: 11-12-2010 and 13-03-2013\n",
      "Consecutive Dates: 13-03-2013 and 13-04-2013\n",
      "Consecutive Dates: 13-04-2013 and 11-05-2013\n",
      "Consecutive Dates: 11-05-2013 and 12-06-2013\n",
      "Consecutive Dates: 12-06-2013 and 13-07-2013\n",
      "Consecutive Dates: 13-07-2013 and 14-08-2013\n",
      "Consecutive Dates: 14-08-2013 and 19-08-2013\n",
      "Consecutive Dates: 19-08-2013 and 14-09-2013\n",
      "Consecutive Dates: 14-09-2013 and 17-10-2013\n",
      "Consecutive Dates: 17-10-2013 and 14-09-2013\n",
      "Consecutive Dates: 14-09-2013 and 17-10-2013\n",
      "Consecutive Dates: 17-10-2013 and 16-11-2013\n",
      "Consecutive Dates: 16-11-2013 and 18-01-2014\n",
      "Consecutive Dates: 18-01-2014 and 19-02-2014\n",
      "Consecutive Dates: 19-02-2014 and 24-05-2014\n",
      "Consecutive Dates: 24-05-2014 and 23-06-2014\n",
      "Consecutive Dates: 23-06-2014 and 30-07-2014\n",
      "Consecutive Dates: 30-07-2014 and 30-08-2014\n",
      "Consecutive Dates: 30-08-2014 and 01-10-2014\n",
      "Consecutive Dates: 01-10-2014 and 29-10-2014\n",
      "Consecutive Dates: 29-10-2014 and 29-11-2014\n",
      "Consecutive Dates: 29-11-2014 and 31-12-2014\n",
      "Consecutive Dates: 31-12-2014 and 03-01-2015\n",
      "Consecutive Dates: 03-01-2015 and 07-03-2015\n",
      "Consecutive Dates: 07-03-2015 and 18-04-2015\n",
      "Consecutive Dates: 18-04-2015 and 09-06-2015\n",
      "Consecutive Dates: 09-06-2015 and 11-07-2015\n",
      "Consecutive Dates: 11-07-2015 and 14-08-2015\n",
      "Consecutive Dates: 14-08-2015 and 29-09-2015\n",
      "Consecutive Dates: 29-09-2015 and 03-11-2015\n",
      "Consecutive Dates: 03-11-2015 and 05-12-2015\n",
      "Consecutive Dates: 05-12-2015 and 05-01-2016\n",
      "Consecutive Dates: 05-01-2016 and 08-01-2016\n",
      "Consecutive Dates: 08-01-2016 and 16-02-2016\n",
      "Consecutive Dates: 16-02-2016 and 21-03-2016\n",
      "Consecutive Dates: 21-03-2016 and 23-04-2016\n",
      "Consecutive Dates: 23-04-2016 and 31-05-2016\n",
      "Consecutive Dates: 31-05-2016 and 11-07-2016\n",
      "Consecutive Dates: 11-07-2016 and 09-08-2016\n",
      "Consecutive Dates: 09-08-2016 and 10-05-2016\n",
      "Consecutive Dates: 10-05-2016 and 22-10-2016\n",
      "Consecutive Dates: 22-10-2016 and 07-01-2017\n",
      "Consecutive Dates: 07-01-2017 and 14-03-2017\n",
      "Consecutive Dates: 14-03-2017 and 06-05-2017\n",
      "Consecutive Dates: 06-05-2017 and 07-07-2017\n",
      "Consecutive Dates: 07-07-2017 and 08-08-2017\n",
      "Consecutive Dates: 08-08-2017 and 12-09-2017\n",
      "Consecutive Dates: 12-09-2017 and 14-10-2017\n",
      "Consecutive Dates: 14-10-2017 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 20-03-2018\n",
      "Consecutive Dates: 20-03-2018 and 02-05-2018\n",
      "Consecutive Dates: 02-05-2018 and 08-06-2018\n",
      "Consecutive Dates: 08-06-2018 and 20-07-2018\n",
      "Consecutive Dates: 20-07-2018 and 28-12-2018\n",
      "Consecutive Dates: 28-12-2018 and 08-01-2018\n",
      "Consecutive Dates: 08-01-2018 and 25-01-2019\n",
      "Consecutive Dates: 25-01-2019 and 15-03-2019\n",
      "Consecutive Dates: 15-03-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 07-06-2019\n",
      "Consecutive Dates: 07-06-2019 and 11-07-2019\n",
      "Consecutive Dates: 11-07-2019 and 13-08-2019\n",
      "Consecutive Dates: 13-08-2019 and 03-10-2019\n",
      "Consecutive Dates: 03-10-2019 and 07-11-2019\n",
      "Consecutive Dates: 07-11-2019 and 04-01-2020\n",
      "Consecutive Dates: 04-01-2020 and 24-03-2020\n",
      "Consecutive Dates: 24-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 11-07-2020\n",
      "Consecutive Dates: 11-07-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 08-03-2021\n",
      "Consecutive Dates: 08-03-2021 and 28-08-2021\n",
      "Consecutive Dates: 28-08-2021 and 25-09-2021\n",
      "Consecutive Dates: 25-09-2021 and 26-10-2021\n",
      "Consecutive Dates: 26-10-2021 and 30-10-2021\n",
      "Consecutive Dates: 30-10-2021 and 03-11-2021\n",
      "Consecutive Dates: 03-11-2021 and 27-11-2021\n",
      "Consecutive Dates: 27-11-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 28-01-2022\n",
      "Consecutive Dates: 28-01-2022 and 28-02-2022\n",
      "Consecutive Dates: 28-02-2022 and 28-03-2022\n",
      "Consecutive Dates: 28-03-2022 and 28-04-2022\n",
      "Consecutive Dates: 28-04-2022 and 28-05-2022\n",
      "Consecutive Dates: 28-05-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 28-07-2022\n",
      "Consecutive Dates: 28-07-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 09-11-2022\n",
      "Consecutive Dates: 09-11-2022 and 14-12-2022\n",
      "Consecutive Dates: 14-12-2022 and 19-01-2023\n",
      "Consecutive Dates: 19-01-2023 and 20-02-2022\n",
      "Consecutive Dates: 20-02-2022 and 04-04-2023\n",
      "Consecutive Dates: 04-04-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 06-06-2023\n",
      "Consecutive Dates: 06-06-2023 and 06-07-2023\n",
      "Consecutive Dates: 06-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 11-10-2023\n",
      "Consecutive Dates: 11-10-2023 and 18-12-2023\n",
      "\n",
      "Consecutive Dates: 28-01-2019 and 02-03-2019\n",
      "Consecutive Dates: 02-03-2019 and 09-04-2019\n",
      "Consecutive Dates: 09-04-2019 and 29-05-2019\n",
      "Consecutive Dates: 29-05-2019 and 02-09-2019\n",
      "Consecutive Dates: 02-09-2019 and 30-09-2019\n",
      "Consecutive Dates: 30-09-2019 and 27-11-2019\n",
      "Consecutive Dates: 27-11-2019 and 24-12-2019\n",
      "Consecutive Dates: 24-12-2019 and 31-01-2020\n",
      "Consecutive Dates: 31-01-2020 and 04-02-2020\n",
      "Consecutive Dates: 04-02-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 09-06-2020\n",
      "Consecutive Dates: 09-06-2020 and 08-10-2020\n",
      "Consecutive Dates: 08-10-2020 and 27-11-2020\n",
      "Consecutive Dates: 27-11-2020 and 28-12-2020\n",
      "Consecutive Dates: 28-12-2020 and 29-01-2021\n",
      "Consecutive Dates: 29-01-2021 and 27-02-2021\n",
      "Consecutive Dates: 27-02-2021 and 30-03-2021\n",
      "Consecutive Dates: 30-03-2021 and 04-05-2021\n",
      "Consecutive Dates: 04-05-2021 and 11-06-2021\n",
      "Consecutive Dates: 11-06-2021 and 09-08-2021\n",
      "Consecutive Dates: 09-08-2021 and 07-10-2021\n",
      "Consecutive Dates: 07-10-2021 and 10-11-2021\n",
      "Consecutive Dates: 10-11-2021 and 15-12-2021\n",
      "Consecutive Dates: 15-12-2021 and 04-02-2022\n",
      "Consecutive Dates: 04-02-2022 and 16-03-2022\n",
      "Consecutive Dates: 16-03-2022 and 21-04-2022\n",
      "Consecutive Dates: 21-04-2022 and 03-06-2022\n",
      "Consecutive Dates: 03-06-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 04-08-2022\n",
      "Consecutive Dates: 04-08-2022 and 29-09-2022\n",
      "Consecutive Dates: 29-09-2022 and 01-11-2022\n",
      "Consecutive Dates: 01-11-2022 and 15-12-2022\n",
      "Consecutive Dates: 15-12-2022 and 14-01-2023\n",
      "Consecutive Dates: 14-01-2023 and 25-02-2023\n",
      "Consecutive Dates: 25-02-2023 and 11-04-2023\n",
      "Consecutive Dates: 11-04-2023 and 25-05-2023\n",
      "Consecutive Dates: 25-05-2023 and 26-03-2023\n",
      "Consecutive Dates: 26-03-2023 and 25-07-2023\n",
      "Consecutive Dates: 25-07-2023 and 08-09-2023\n",
      "Consecutive Dates: 08-09-2023 and 06-10-2023\n",
      "Consecutive Dates: 06-10-2023 and 04-11-2023\n",
      "Consecutive Dates: 04-11-2023 and 14-12-2023\n",
      "\n",
      "Consecutive Dates: 17-04-2010 and 18-09-2010\n",
      "Consecutive Dates: 18-09-2010 and 27-10-2010\n",
      "Consecutive Dates: 27-10-2010 and 27-11-2010\n",
      "Consecutive Dates: 27-11-2010 and 12-09-2017\n",
      "Consecutive Dates: 12-09-2017 and 12-10-2017\n",
      "Consecutive Dates: 12-10-2017 and 27-10-2017\n",
      "Consecutive Dates: 27-10-2017 and 22-12-2017\n",
      "Consecutive Dates: 22-12-2017 and 25-01-2018\n",
      "Consecutive Dates: 25-01-2018 and 10-03-2018\n",
      "Consecutive Dates: 10-03-2018 and 24-04-2018\n",
      "Consecutive Dates: 24-04-2018 and 21-05-2018\n",
      "Consecutive Dates: 21-05-2018 and 04-07-2018\n",
      "Consecutive Dates: 04-07-2018 and 13-08-2018\n",
      "Consecutive Dates: 13-08-2018 and 12-09-2018\n",
      "Consecutive Dates: 12-09-2018 and 06-10-2018\n",
      "Consecutive Dates: 06-10-2018 and 14-11-2018\n",
      "Consecutive Dates: 14-11-2018 and 21-12-2018\n",
      "Consecutive Dates: 21-12-2018 and 28-01-2019\n",
      "Consecutive Dates: 28-01-2019 and 15-03-2019\n",
      "Consecutive Dates: 15-03-2019 and 24-04-2019\n",
      "Consecutive Dates: 24-04-2019 and 31-05-2019\n",
      "Consecutive Dates: 31-05-2019 and 09-07-2019\n",
      "Consecutive Dates: 09-07-2019 and 26-08-2019\n",
      "Consecutive Dates: 26-08-2019 and 15-10-2019\n",
      "Consecutive Dates: 15-10-2019 and 30-12-2019\n",
      "Consecutive Dates: 30-12-2019 and 02-03-2020\n",
      "Consecutive Dates: 02-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 25-05-2020\n",
      "Consecutive Dates: 25-05-2020 and 12-08-2020\n",
      "Consecutive Dates: 12-08-2020 and 08-10-2020\n",
      "Consecutive Dates: 08-10-2020 and 30-10-2020\n",
      "Consecutive Dates: 30-10-2020 and 09-01-2021\n",
      "Consecutive Dates: 09-01-2021 and 08-02-2021\n",
      "Consecutive Dates: 08-02-2021 and 08-03-2021\n",
      "Consecutive Dates: 08-03-2021 and 08-04-2021\n",
      "Consecutive Dates: 08-04-2021 and 05-05-2021\n",
      "Consecutive Dates: 05-05-2021 and 21-06-2021\n",
      "Consecutive Dates: 21-06-2021 and 28-09-2021\n",
      "Consecutive Dates: 28-09-2021 and 03-12-2021\n",
      "Consecutive Dates: 03-12-2021 and 27-01-2022\n",
      "Consecutive Dates: 27-01-2022 and 17-04-2022\n",
      "Consecutive Dates: 17-04-2022 and 09-05-2022\n",
      "Consecutive Dates: 09-05-2022 and 13-07-2022\n",
      "Consecutive Dates: 13-07-2022 and 13-09-2022\n",
      "Consecutive Dates: 13-09-2022 and 14-11-2022\n",
      "Consecutive Dates: 14-11-2022 and 27-01-2023\n",
      "Consecutive Dates: 27-01-2023 and 18-03-2023\n",
      "Consecutive Dates: 18-03-2023 and 29-06-2023\n",
      "Consecutive Dates: 29-06-2023 and 24-07-2023\n",
      "Consecutive Dates: 24-07-2023 and 02-09-2023\n",
      "Consecutive Dates: 02-09-2023 and 29-09-2023\n",
      "Consecutive Dates: 29-09-2023 and 14-11-2023\n",
      "Consecutive Dates: 14-11-2023 and 20-12-2023\n",
      "\n",
      "Consecutive Dates: 06-08-2011 and 14-08-2019\n",
      "Consecutive Dates: 14-08-2019 and 15-06-2020\n",
      "Consecutive Dates: 15-06-2020 and 18-01-2021\n",
      "Consecutive Dates: 18-01-2021 and 24-02-2021\n",
      "Consecutive Dates: 24-02-2021 and 01-03-2021\n",
      "Consecutive Dates: 01-03-2021 and 08-03-2021\n",
      "Consecutive Dates: 08-03-2021 and 30-04-2021\n",
      "Consecutive Dates: 30-04-2021 and 02-06-2021\n",
      "Consecutive Dates: 02-06-2021 and 03-06-2021\n",
      "Consecutive Dates: 03-06-2021 and 18-06-2021\n",
      "\n",
      "Consecutive Dates: 16-05-2018 and 15-06-2018\n",
      "Consecutive Dates: 15-06-2018 and 16-07-2018\n",
      "Consecutive Dates: 16-07-2018 and 16-08-2018\n",
      "Consecutive Dates: 16-08-2018 and 15-09-2018\n",
      "Consecutive Dates: 15-09-2018 and 15-11-2018\n",
      "Consecutive Dates: 15-11-2018 and 05-03-2019\n",
      "Consecutive Dates: 05-03-2019 and 03-04-2019\n",
      "Consecutive Dates: 03-04-2019 and 02-05-2019\n",
      "Consecutive Dates: 02-05-2019 and 27-05-2019\n",
      "Consecutive Dates: 27-05-2019 and 27-06-2019\n",
      "Consecutive Dates: 27-06-2019 and 27-07-2019\n",
      "Consecutive Dates: 27-07-2019 and 27-08-2019\n",
      "Consecutive Dates: 27-08-2019 and 31-08-2019\n",
      "Consecutive Dates: 31-08-2019 and 13-09-2019\n",
      "Consecutive Dates: 13-09-2019 and 26-10-2019\n",
      "Consecutive Dates: 26-10-2019 and 30-11-2019\n",
      "Consecutive Dates: 30-11-2019 and 27-12-2019\n",
      "Consecutive Dates: 27-12-2019 and 27-01-2020\n",
      "Consecutive Dates: 27-01-2020 and 29-02-2020\n",
      "Consecutive Dates: 29-02-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 16-12-2020\n",
      "Consecutive Dates: 16-12-2020 and 03-05-2022\n",
      "Consecutive Dates: 03-05-2022 and 19-05-2022\n",
      "Consecutive Dates: 19-05-2022 and 17-06-2022\n",
      "Consecutive Dates: 17-06-2022 and 16-07-2022\n",
      "Consecutive Dates: 16-07-2022 and 09-08-2022\n",
      "Consecutive Dates: 09-08-2022 and 03-09-2022\n",
      "Consecutive Dates: 03-09-2022 and 03-10-2022\n",
      "Consecutive Dates: 03-10-2022 and 02-11-2022\n",
      "Consecutive Dates: 02-11-2022 and 06-12-2022\n",
      "Consecutive Dates: 06-12-2022 and 04-01-2023\n",
      "Consecutive Dates: 04-01-2023 and 09-02-2023\n",
      "Consecutive Dates: 09-02-2023 and 09-03-2023\n",
      "Consecutive Dates: 09-03-2023 and 03-04-2023\n",
      "Consecutive Dates: 03-04-2023 and 24-04-2023\n",
      "Consecutive Dates: 24-04-2023 and 05-06-2023\n",
      "Consecutive Dates: 05-06-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 06-09-2023\n",
      "Consecutive Dates: 06-09-2023 and 05-10-2023\n",
      "Consecutive Dates: 05-10-2023 and 04-11-2023\n",
      "Consecutive Dates: 04-11-2023 and 04-12-2023\n",
      "\n",
      "Consecutive Dates: 15-12-2007 and 12-01-2008\n",
      "Consecutive Dates: 12-01-2008 and 02-02-2008\n",
      "Consecutive Dates: 02-02-2008 and 11-12-2010\n",
      "Consecutive Dates: 11-12-2010 and 13-03-2013\n",
      "Consecutive Dates: 13-03-2013 and 13-04-2013\n",
      "Consecutive Dates: 13-04-2013 and 11-05-2013\n",
      "Consecutive Dates: 11-05-2013 and 12-06-2013\n",
      "Consecutive Dates: 12-06-2013 and 13-07-2013\n",
      "Consecutive Dates: 13-07-2013 and 14-08-2013\n",
      "Consecutive Dates: 14-08-2013 and 19-08-2013\n",
      "Consecutive Dates: 19-08-2013 and 14-09-2013\n",
      "Consecutive Dates: 14-09-2013 and 17-10-2013\n",
      "Consecutive Dates: 17-10-2013 and 16-11-2013\n",
      "Consecutive Dates: 16-11-2013 and 18-12-2013\n",
      "Consecutive Dates: 18-12-2013 and 18-01-2014\n",
      "Consecutive Dates: 18-01-2014 and 19-02-2014\n",
      "Consecutive Dates: 19-02-2014 and 23-04-2014\n",
      "Consecutive Dates: 23-04-2014 and 24-05-2014\n",
      "Consecutive Dates: 24-05-2014 and 28-06-2014\n",
      "Consecutive Dates: 28-06-2014 and 30-07-2014\n",
      "Consecutive Dates: 30-07-2014 and 30-08-2014\n",
      "Consecutive Dates: 30-08-2014 and 01-10-2014\n",
      "Consecutive Dates: 01-10-2014 and 29-10-2014\n",
      "Consecutive Dates: 29-10-2014 and 29-11-2014\n",
      "Consecutive Dates: 29-11-2014 and 31-12-2014\n",
      "Consecutive Dates: 31-12-2014 and 03-02-2015\n",
      "Consecutive Dates: 03-02-2015 and 07-03-2015\n",
      "Consecutive Dates: 07-03-2015 and 09-06-2015\n",
      "Consecutive Dates: 09-06-2015 and 11-07-2015\n",
      "Consecutive Dates: 11-07-2015 and 14-08-2015\n",
      "Consecutive Dates: 14-08-2015 and 29-09-2015\n",
      "Consecutive Dates: 29-09-2015 and 03-11-2015\n",
      "Consecutive Dates: 03-11-2015 and 05-12-2015\n",
      "Consecutive Dates: 05-12-2015 and 05-01-2016\n",
      "Consecutive Dates: 05-01-2016 and 08-01-2016\n",
      "Consecutive Dates: 08-01-2016 and 16-02-2016\n",
      "Consecutive Dates: 16-02-2016 and 21-03-2016\n",
      "Consecutive Dates: 21-03-2016 and 23-04-2016\n",
      "Consecutive Dates: 23-04-2016 and 31-05-2016\n",
      "Consecutive Dates: 31-05-2016 and 11-07-2016\n",
      "Consecutive Dates: 11-07-2016 and 09-08-2016\n",
      "Consecutive Dates: 09-08-2016 and 10-09-2016\n",
      "Consecutive Dates: 10-09-2016 and 22-10-2016\n",
      "Consecutive Dates: 22-10-2016 and 07-01-2017\n",
      "Consecutive Dates: 07-01-2017 and 14-03-2017\n",
      "Consecutive Dates: 14-03-2017 and 06-05-2017\n",
      "Consecutive Dates: 06-05-2017 and 07-07-2017\n",
      "Consecutive Dates: 07-07-2017 and 08-08-2017\n",
      "Consecutive Dates: 08-08-2017 and 12-09-2017\n",
      "Consecutive Dates: 12-09-2017 and 14-10-2017\n",
      "Consecutive Dates: 14-10-2017 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 20-03-2018\n",
      "Consecutive Dates: 20-03-2018 and 02-05-2018\n",
      "Consecutive Dates: 02-05-2018 and 08-06-2018\n",
      "Consecutive Dates: 08-06-2018 and 20-07-2018\n",
      "Consecutive Dates: 20-07-2018 and 28-12-2018\n",
      "Consecutive Dates: 28-12-2018 and 08-01-2019\n",
      "Consecutive Dates: 08-01-2019 and 25-01-2019\n",
      "Consecutive Dates: 25-01-2019 and 15-03-2019\n",
      "Consecutive Dates: 15-03-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 07-06-2019\n",
      "Consecutive Dates: 07-06-2019 and 11-07-2019\n",
      "Consecutive Dates: 11-07-2019 and 13-08-2019\n",
      "Consecutive Dates: 13-08-2019 and 03-10-2019\n",
      "Consecutive Dates: 03-10-2019 and 07-11-2019\n",
      "Consecutive Dates: 07-11-2019 and 04-01-2020\n",
      "Consecutive Dates: 04-01-2020 and 24-03-2020\n",
      "Consecutive Dates: 24-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 11-07-2020\n",
      "Consecutive Dates: 11-07-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 28-08-2021\n",
      "Consecutive Dates: 28-08-2021 and 25-09-2021\n",
      "Consecutive Dates: 25-09-2021 and 26-10-2021\n",
      "Consecutive Dates: 26-10-2021 and 30-10-2021\n",
      "Consecutive Dates: 30-10-2021 and 03-11-2021\n",
      "Consecutive Dates: 03-11-2021 and 10-11-2021\n",
      "Consecutive Dates: 10-11-2021 and 27-11-2021\n",
      "Consecutive Dates: 27-11-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 28-01-2022\n",
      "Consecutive Dates: 28-01-2022 and 28-02-2022\n",
      "Consecutive Dates: 28-02-2022 and 28-03-2022\n",
      "Consecutive Dates: 28-03-2022 and 28-04-2022\n",
      "Consecutive Dates: 28-04-2022 and 28-05-2022\n",
      "Consecutive Dates: 28-05-2022 and 29-06-2022\n",
      "Consecutive Dates: 29-06-2022 and 28-07-2022\n",
      "Consecutive Dates: 28-07-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 09-11-2022\n",
      "Consecutive Dates: 09-11-2022 and 14-12-2022\n",
      "Consecutive Dates: 14-12-2022 and 19-01-2023\n",
      "Consecutive Dates: 19-01-2023 and 20-02-2023\n",
      "Consecutive Dates: 20-02-2023 and 04-04-2023\n",
      "Consecutive Dates: 04-04-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 06-06-2023\n",
      "Consecutive Dates: 06-06-2023 and 06-07-2023\n",
      "Consecutive Dates: 06-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 11-10-2023\n",
      "Consecutive Dates: 11-10-2023 and 20-11-2023\n",
      "Consecutive Dates: 20-11-2023 and 18-12-2023\n",
      "\n",
      "Consecutive Dates: 17-07-2020 and 05-07-2021\n",
      "Consecutive Dates: 05-07-2021 and 16-08-2021\n",
      "Consecutive Dates: 16-08-2021 and 17-09-2021\n",
      "Consecutive Dates: 17-09-2021 and 06-11-2021\n",
      "Consecutive Dates: 06-11-2021 and 08-12-2021\n",
      "Consecutive Dates: 08-12-2021 and 02-02-2022\n",
      "Consecutive Dates: 02-02-2022 and 28-02-2022\n",
      "\n",
      "Consecutive Dates: 12-01-2008 and 02-02-2010\n",
      "Consecutive Dates: 02-02-2010 and 11-12-2010\n",
      "Consecutive Dates: 11-12-2010 and 13-03-2013\n",
      "Consecutive Dates: 13-03-2013 and 13-04-2013\n",
      "Consecutive Dates: 13-04-2013 and 11-05-2013\n",
      "Consecutive Dates: 11-05-2013 and 12-06-2013\n",
      "Consecutive Dates: 12-06-2013 and 13-07-2013\n",
      "Consecutive Dates: 13-07-2013 and 14-08-2013\n",
      "Consecutive Dates: 14-08-2013 and 19-08-2013\n",
      "Consecutive Dates: 19-08-2013 and 14-09-2013\n",
      "Consecutive Dates: 14-09-2013 and 17-10-2013\n",
      "Consecutive Dates: 17-10-2013 and 14-09-2013\n",
      "Consecutive Dates: 14-09-2013 and 17-10-2013\n",
      "Consecutive Dates: 17-10-2013 and 16-11-2013\n",
      "Consecutive Dates: 16-11-2013 and 18-01-2014\n",
      "Consecutive Dates: 18-01-2014 and 19-02-2014\n",
      "Consecutive Dates: 19-02-2014 and 24-05-2014\n",
      "Consecutive Dates: 24-05-2014 and 23-06-2014\n",
      "Consecutive Dates: 23-06-2014 and 30-07-2014\n",
      "Consecutive Dates: 30-07-2014 and 30-08-2014\n",
      "Consecutive Dates: 30-08-2014 and 01-10-2014\n",
      "Consecutive Dates: 01-10-2014 and 29-10-2014\n",
      "Consecutive Dates: 29-10-2014 and 29-11-2014\n",
      "Consecutive Dates: 29-11-2014 and 31-12-2014\n",
      "Consecutive Dates: 31-12-2014 and 03-01-2015\n",
      "Consecutive Dates: 03-01-2015 and 07-03-2015\n",
      "Consecutive Dates: 07-03-2015 and 18-04-2015\n",
      "Consecutive Dates: 18-04-2015 and 09-06-2015\n",
      "Consecutive Dates: 09-06-2015 and 11-07-2015\n",
      "Consecutive Dates: 11-07-2015 and 14-08-2015\n",
      "Consecutive Dates: 14-08-2015 and 29-09-2015\n",
      "Consecutive Dates: 29-09-2015 and 03-11-2015\n",
      "Consecutive Dates: 03-11-2015 and 05-12-2015\n",
      "Consecutive Dates: 05-12-2015 and 05-01-2016\n",
      "Consecutive Dates: 05-01-2016 and 08-01-2016\n",
      "Consecutive Dates: 08-01-2016 and 16-02-2016\n",
      "Consecutive Dates: 16-02-2016 and 21-03-2016\n",
      "Consecutive Dates: 21-03-2016 and 23-04-2016\n",
      "Consecutive Dates: 23-04-2016 and 31-05-2016\n",
      "Consecutive Dates: 31-05-2016 and 11-07-2016\n",
      "Consecutive Dates: 11-07-2016 and 09-08-2016\n",
      "Consecutive Dates: 09-08-2016 and 10-05-2016\n",
      "Consecutive Dates: 10-05-2016 and 22-10-2016\n",
      "Consecutive Dates: 22-10-2016 and 07-01-2017\n",
      "Consecutive Dates: 07-01-2017 and 14-03-2017\n",
      "Consecutive Dates: 14-03-2017 and 06-05-2017\n",
      "Consecutive Dates: 06-05-2017 and 07-07-2017\n",
      "Consecutive Dates: 07-07-2017 and 08-08-2017\n",
      "Consecutive Dates: 08-08-2017 and 12-09-2017\n",
      "Consecutive Dates: 12-09-2017 and 14-10-2017\n",
      "Consecutive Dates: 14-10-2017 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 20-03-2018\n",
      "Consecutive Dates: 20-03-2018 and 02-05-2018\n",
      "Consecutive Dates: 02-05-2018 and 08-06-2018\n",
      "Consecutive Dates: 08-06-2018 and 20-07-2018\n",
      "Consecutive Dates: 20-07-2018 and 28-12-2018\n",
      "Consecutive Dates: 28-12-2018 and 08-01-2018\n",
      "Consecutive Dates: 08-01-2018 and 25-01-2019\n",
      "Consecutive Dates: 25-01-2019 and 15-03-2019\n",
      "Consecutive Dates: 15-03-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 07-06-2019\n",
      "Consecutive Dates: 07-06-2019 and 11-07-2019\n",
      "Consecutive Dates: 11-07-2019 and 13-08-2019\n",
      "Consecutive Dates: 13-08-2019 and 03-10-2019\n",
      "Consecutive Dates: 03-10-2019 and 07-11-2019\n",
      "Consecutive Dates: 07-11-2019 and 04-01-2020\n",
      "Consecutive Dates: 04-01-2020 and 24-03-2020\n",
      "Consecutive Dates: 24-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 11-07-2020\n",
      "Consecutive Dates: 11-07-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 08-03-2021\n",
      "Consecutive Dates: 08-03-2021 and 28-08-2021\n",
      "Consecutive Dates: 28-08-2021 and 25-09-2021\n",
      "Consecutive Dates: 25-09-2021 and 26-10-2021\n",
      "Consecutive Dates: 26-10-2021 and 30-10-2021\n",
      "Consecutive Dates: 30-10-2021 and 03-11-2021\n",
      "Consecutive Dates: 03-11-2021 and 10-11-2021\n",
      "Consecutive Dates: 10-11-2021 and 27-11-2021\n",
      "Consecutive Dates: 27-11-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 28-01-2022\n",
      "Consecutive Dates: 28-01-2022 and 28-02-2022\n",
      "Consecutive Dates: 28-02-2022 and 28-03-2022\n",
      "Consecutive Dates: 28-03-2022 and 28-04-2022\n",
      "Consecutive Dates: 28-04-2022 and 28-05-2022\n",
      "Consecutive Dates: 28-05-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 28-07-2022\n",
      "Consecutive Dates: 28-07-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 09-11-2022\n",
      "Consecutive Dates: 09-11-2022 and 14-12-2022\n",
      "Consecutive Dates: 14-12-2022 and 19-01-2023\n",
      "Consecutive Dates: 19-01-2023 and 20-02-2022\n",
      "Consecutive Dates: 20-02-2022 and 04-04-2023\n",
      "Consecutive Dates: 04-04-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 06-06-2023\n",
      "Consecutive Dates: 06-06-2023 and 06-07-2023\n",
      "Consecutive Dates: 06-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 11-10-2023\n",
      "Consecutive Dates: 11-10-2023 and 20-11-2023\n",
      "Consecutive Dates: 20-11-2023 and 18-12-2023\n",
      "\n",
      "Consecutive Dates: 07-10-2020 and 06-11-2020\n",
      "Consecutive Dates: 06-11-2020 and 27-11-2020\n",
      "Consecutive Dates: 27-11-2020 and 11-01-2021\n",
      "Consecutive Dates: 11-01-2021 and 04-02-2021\n",
      "Consecutive Dates: 04-02-2021 and 03-03-2021\n",
      "Consecutive Dates: 03-03-2021 and 26-04-2021\n",
      "Consecutive Dates: 26-04-2021 and 18-05-2021\n",
      "Consecutive Dates: 18-05-2021 and 23-06-2021\n",
      "Consecutive Dates: 23-06-2021 and 06-07-2021\n",
      "Consecutive Dates: 06-07-2021 and 27-08-2021\n",
      "Consecutive Dates: 27-08-2021 and 20-09-2021\n",
      "Consecutive Dates: 20-09-2021 and 19-10-2021\n",
      "Consecutive Dates: 19-10-2021 and 13-11-2021\n",
      "Consecutive Dates: 13-11-2021 and 27-11-2021\n",
      "Consecutive Dates: 27-11-2021 and 11-12-2021\n",
      "Consecutive Dates: 11-12-2021 and 14-01-2022\n",
      "Consecutive Dates: 14-01-2022 and 18-02-2022\n",
      "Consecutive Dates: 18-02-2022 and 21-03-2022\n",
      "Consecutive Dates: 21-03-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 02-06-2022\n",
      "Consecutive Dates: 02-06-2022 and 05-07-2022\n",
      "Consecutive Dates: 05-07-2022 and 29-07-2022\n",
      "Consecutive Dates: 29-07-2022 and 08-09-2022\n",
      "Consecutive Dates: 08-09-2022 and 07-10-2022\n",
      "Consecutive Dates: 07-10-2022 and 05-11-2022\n",
      "Consecutive Dates: 05-11-2022 and 05-12-2022\n",
      "Consecutive Dates: 05-12-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 28-02-2023\n",
      "Consecutive Dates: 28-02-2023 and 18-03-2023\n",
      "Consecutive Dates: 18-03-2023 and 22-05-2023\n",
      "Consecutive Dates: 22-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 03-08-2023\n",
      "Consecutive Dates: 03-08-2023 and 09-09-2023\n",
      "Consecutive Dates: 09-09-2023 and 30-10-2023\n",
      "Consecutive Dates: 30-10-2023 and 25-11-2023\n",
      "\n",
      "Consecutive Dates: 15-12-2021 and 12-03-2022\n",
      "Consecutive Dates: 12-03-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 01-08-2022\n",
      "Consecutive Dates: 01-08-2022 and 19-08-2022\n",
      "Consecutive Dates: 19-08-2022 and 30-12-2022\n",
      "Consecutive Dates: 30-12-2022 and 14-02-2023\n",
      "Consecutive Dates: 14-02-2023 and 21-03-2023\n",
      "Consecutive Dates: 21-03-2023 and 06-05-2023\n",
      "Consecutive Dates: 06-05-2023 and 19-07-2023\n",
      "Consecutive Dates: 19-07-2023 and 16-09-2023\n",
      "Consecutive Dates: 16-09-2023 and 03-11-2023\n",
      "Consecutive Dates: 03-11-2023 and 21-12-2023\n",
      "\n",
      "Consecutive Dates: 02-08-2021 and 07-10-2021\n",
      "Consecutive Dates: 07-10-2021 and 08-11-2021\n",
      "Consecutive Dates: 08-11-2021 and 13-12-2021\n",
      "Consecutive Dates: 13-12-2021 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 03-02-2022\n",
      "Consecutive Dates: 03-02-2022 and 25-02-2022\n",
      "Consecutive Dates: 25-02-2022 and 31-03-2022\n",
      "Consecutive Dates: 31-03-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 11-06-2022\n",
      "Consecutive Dates: 11-06-2022 and 14-07-2022\n",
      "Consecutive Dates: 14-07-2022 and 17-08-2022\n",
      "Consecutive Dates: 17-08-2022 and 16-09-2022\n",
      "Consecutive Dates: 16-09-2022 and 19-10-2022\n",
      "Consecutive Dates: 19-10-2022 and 19-11-2022\n",
      "Consecutive Dates: 19-11-2022 and 21-12-2022\n",
      "Consecutive Dates: 21-12-2022 and 23-01-2023\n",
      "Consecutive Dates: 23-01-2023 and 23-02-2022\n",
      "Consecutive Dates: 23-02-2022 and 24-03-2023\n",
      "Consecutive Dates: 24-03-2023 and 24-04-2023\n",
      "Consecutive Dates: 24-04-2023 and 24-05-2023\n",
      "Consecutive Dates: 24-05-2023 and 27-06-2023\n",
      "Consecutive Dates: 27-06-2023 and 26-07-2023\n",
      "Consecutive Dates: 26-07-2023 and 26-08-2023\n",
      "Consecutive Dates: 26-08-2023 and 30-09-2023\n",
      "Consecutive Dates: 30-09-2023 and 27-10-2023\n",
      "\n",
      "Consecutive Dates: 01-04-2022 and 04-05-2022\n",
      "Consecutive Dates: 04-05-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 23-05-2022\n",
      "Consecutive Dates: 23-05-2022 and 26-09-2022\n",
      "Consecutive Dates: 26-09-2022 and 09-12-2022\n",
      "Consecutive Dates: 09-12-2022 and 16-12-2022\n",
      "Consecutive Dates: 16-12-2022 and 23-12-2022\n",
      "Consecutive Dates: 23-12-2022 and 11-07-2023\n",
      "\n",
      "Consecutive Dates: 05-02-2022 and 05-05-2022\n",
      "\n",
      "Consecutive Dates: 12-01-2019 and 01-02-2019\n",
      "Consecutive Dates: 01-02-2019 and 21-12-2021\n",
      "Consecutive Dates: 21-12-2021 and 19-01-2022\n",
      "Consecutive Dates: 19-01-2022 and 12-02-2022\n",
      "Consecutive Dates: 12-02-2022 and 16-03-2022\n",
      "Consecutive Dates: 16-03-2022 and 05-05-2022\n",
      "\n",
      "Consecutive Dates: 17-06-2109 and 23-07-2019\n",
      "Consecutive Dates: 23-07-2019 and 27-08-2019\n",
      "Consecutive Dates: 27-08-2019 and 24-09-2019\n",
      "Consecutive Dates: 24-09-2019 and 26-10-2019\n",
      "Consecutive Dates: 26-10-2019 and 25-11-2019\n",
      "Consecutive Dates: 25-11-2019 and 26-12-2019\n",
      "Consecutive Dates: 26-12-2019 and 27-01-2020\n",
      "Consecutive Dates: 27-01-2020 and 13-03-2020\n",
      "Consecutive Dates: 13-03-2020 and 23-04-2020\n",
      "Consecutive Dates: 23-04-2020 and 19-05-2020\n",
      "Consecutive Dates: 19-05-2020 and 19-06-2020\n",
      "Consecutive Dates: 19-06-2020 and 22-07-2020\n",
      "Consecutive Dates: 22-07-2020 and 25-07-2020\n",
      "Consecutive Dates: 25-07-2020 and 14-10-2020\n",
      "Consecutive Dates: 14-10-2020 and 17-12-2020\n",
      "Consecutive Dates: 17-12-2020 and 18-01-2021\n",
      "Consecutive Dates: 18-01-2021 and 16-02-2021\n",
      "Consecutive Dates: 16-02-2021 and 19-03-2021\n",
      "Consecutive Dates: 19-03-2021 and 20-04-2021\n",
      "Consecutive Dates: 20-04-2021 and 20-05-2021\n",
      "Consecutive Dates: 20-05-2021 and 01-11-2021\n",
      "Consecutive Dates: 01-11-2021 and 24-11-2021\n",
      "Consecutive Dates: 24-11-2021 and 28-01-2022\n",
      "Consecutive Dates: 28-01-2022 and 08-04-2022\n",
      "Consecutive Dates: 08-04-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 10-06-2022\n",
      "Consecutive Dates: 10-06-2022 and 13-07-2022\n",
      "Consecutive Dates: 13-07-2022 and 05-09-2022\n",
      "Consecutive Dates: 05-09-2022 and 07-10-2022\n",
      "Consecutive Dates: 07-10-2022 and 10-11-2022\n",
      "Consecutive Dates: 10-11-2022 and 14-12-2022\n",
      "Consecutive Dates: 14-12-2022 and 13-01-2023\n",
      "Consecutive Dates: 13-01-2023 and 13-02-2023\n",
      "Consecutive Dates: 13-02-2023 and 13-03-2023\n",
      "Consecutive Dates: 13-03-2023 and 21-04-2023\n",
      "Consecutive Dates: 21-04-2023 and 23-05-2023\n",
      "Consecutive Dates: 23-05-2023 and 27-06-2023\n",
      "Consecutive Dates: 27-06-2023 and 01-08-2023\n",
      "Consecutive Dates: 01-08-2023 and 31-08-2023\n",
      "Consecutive Dates: 31-08-2023 and 10-10-2023\n",
      "Consecutive Dates: 10-10-2023 and 17-11-2023\n",
      "\n",
      "Consecutive Dates: 04-04-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 04-06-2022\n",
      "Consecutive Dates: 04-06-2022 and 05-07-2022\n",
      "Consecutive Dates: 05-07-2022 and 04-08-2022\n",
      "Consecutive Dates: 04-08-2022 and 05-09-2022\n",
      "Consecutive Dates: 05-09-2022 and 10-10-2022\n",
      "Consecutive Dates: 10-10-2022 and 15-11-2022\n",
      "Consecutive Dates: 15-11-2022 and 18-02-2023\n",
      "Consecutive Dates: 18-02-2023 and 17-03-2023\n",
      "Consecutive Dates: 17-03-2023 and 17-07-2023\n",
      "Consecutive Dates: 17-07-2023 and 28-08-2023\n",
      "Consecutive Dates: 28-08-2023 and 05-10-2023\n",
      "Consecutive Dates: 05-10-2023 and 01-11-2023\n",
      "Consecutive Dates: 01-11-2023 and 16-12-2023\n",
      "\n",
      "Consecutive Dates: 15-11-2021 and 18-01-2022\n",
      "Consecutive Dates: 18-01-2022 and 23-07-2022\n",
      "Consecutive Dates: 23-07-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 16-11-2022\n",
      "Consecutive Dates: 16-11-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 31-10-2023\n",
      "Consecutive Dates: 31-10-2023 and 29-12-2023\n",
      "\n",
      "Consecutive Dates: 11-01-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 22-11-2022\n",
      "Consecutive Dates: 22-11-2022 and 24-03-2023\n",
      "Consecutive Dates: 24-03-2023 and 12-06-2023\n",
      "Consecutive Dates: 12-06-2023 and 11-09-2023\n",
      "Consecutive Dates: 11-09-2023 and 16-10-2023\n",
      "Consecutive Dates: 16-10-2023 and 06-12-2023\n",
      "\n",
      "Consecutive Dates: 02-08-2021 and 07-10-2021\n",
      "Consecutive Dates: 07-10-2021 and 08-11-2021\n",
      "Consecutive Dates: 08-11-2021 and 13-12-2021\n",
      "Consecutive Dates: 13-12-2021 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 03-02-2022\n",
      "Consecutive Dates: 03-02-2022 and 25-02-2022\n",
      "Consecutive Dates: 25-02-2022 and 31-03-2022\n",
      "Consecutive Dates: 31-03-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 11-06-2022\n",
      "Consecutive Dates: 11-06-2022 and 14-07-2022\n",
      "Consecutive Dates: 14-07-2022 and 17-08-2022\n",
      "Consecutive Dates: 17-08-2022 and 16-09-2022\n",
      "Consecutive Dates: 16-09-2022 and 19-10-2022\n",
      "Consecutive Dates: 19-10-2022 and 19-11-2022\n",
      "Consecutive Dates: 19-11-2022 and 21-12-2022\n",
      "Consecutive Dates: 21-12-2022 and 23-01-2023\n",
      "Consecutive Dates: 23-01-2023 and 23-02-2022\n",
      "Consecutive Dates: 23-02-2022 and 24-03-2023\n",
      "Consecutive Dates: 24-03-2023 and 24-04-2023\n",
      "Consecutive Dates: 24-04-2023 and 24-05-2023\n",
      "Consecutive Dates: 24-05-2023 and 27-06-2023\n",
      "Consecutive Dates: 27-06-2023 and 26-07-2023\n",
      "Consecutive Dates: 26-07-2023 and 26-08-2023\n",
      "Consecutive Dates: 26-08-2023 and 30-09-2023\n",
      "Consecutive Dates: 30-09-2023 and 27-10-2023\n",
      "Consecutive Dates: 27-10-2023 and 30-11-2023\n",
      "\n",
      "Consecutive Dates: 29-01-2021 and 31-12-2021\n",
      "Consecutive Dates: 31-12-2021 and 31-01-2022\n",
      "Consecutive Dates: 31-01-2022 and 07-03-2022\n",
      "Consecutive Dates: 07-03-2022 and 08-04-2022\n",
      "Consecutive Dates: 08-04-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 09-06-2022\n",
      "Consecutive Dates: 09-06-2022 and 03-09-2022\n",
      "Consecutive Dates: 03-09-2022 and 07-11-2022\n",
      "Consecutive Dates: 07-11-2022 and 09-12-2022\n",
      "Consecutive Dates: 09-12-2022 and 14-02-2023\n",
      "Consecutive Dates: 14-02-2023 and 24-04-2023\n",
      "Consecutive Dates: 24-04-2023 and 11-07-2023\n",
      "\n",
      "Consecutive Dates: 26-05-2018 and 02-06-2018\n",
      "Consecutive Dates: 02-06-2018 and 02-07-2018\n",
      "Consecutive Dates: 02-07-2018 and 31-07-2018\n",
      "Consecutive Dates: 31-07-2018 and 31-08-2018\n",
      "Consecutive Dates: 31-08-2018 and 28-09-2018\n",
      "Consecutive Dates: 28-09-2018 and 29-10-2018\n",
      "Consecutive Dates: 29-10-2018 and 26-11-2018\n",
      "Consecutive Dates: 26-11-2018 and 24-12-2018\n",
      "Consecutive Dates: 24-12-2018 and 23-01-2019\n",
      "Consecutive Dates: 23-01-2019 and 25-02-2019\n",
      "Consecutive Dates: 25-02-2019 and 23-03-2019\n",
      "Consecutive Dates: 23-03-2019 and 26-04-2019\n",
      "Consecutive Dates: 26-04-2019 and 06-06-2019\n",
      "Consecutive Dates: 06-06-2019 and 21-08-2019\n",
      "Consecutive Dates: 21-08-2019 and 18-11-2019\n",
      "Consecutive Dates: 18-11-2019 and 04-01-2020\n",
      "Consecutive Dates: 04-01-2020 and 28-01-2020\n",
      "Consecutive Dates: 28-01-2020 and 23-02-2021\n",
      "Consecutive Dates: 23-02-2021 and 20-03-2021\n",
      "Consecutive Dates: 20-03-2021 and 13-04-2021\n",
      "Consecutive Dates: 13-04-2021 and 10-09-2021\n",
      "Consecutive Dates: 10-09-2021 and 23-10-2021\n",
      "Consecutive Dates: 23-10-2021 and 25-11-2021\n",
      "Consecutive Dates: 25-11-2021 and 08-02-2022\n",
      "Consecutive Dates: 08-02-2022 and 11-03-2022\n",
      "Consecutive Dates: 11-03-2022 and 13-04-2022\n",
      "Consecutive Dates: 13-04-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 04-06-2022\n",
      "Consecutive Dates: 04-06-2022 and 08-07-2022\n",
      "Consecutive Dates: 08-07-2022 and 10-09-2022\n",
      "Consecutive Dates: 10-09-2022 and 11-10-2022\n",
      "Consecutive Dates: 11-10-2022 and 12-11-2022\n",
      "Consecutive Dates: 12-11-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 10-04-2023\n",
      "Consecutive Dates: 10-04-2023 and 21-06-2023\n",
      "Consecutive Dates: 21-06-2023 and 26-08-2023\n",
      "Consecutive Dates: 26-08-2023 and 23-11-2023\n",
      "\n",
      "Consecutive Dates: 05-05-2022 and 27-06-2022\n",
      "Consecutive Dates: 27-06-2022 and 18-11-2022\n",
      "Consecutive Dates: 18-11-2022 and 14-03-2023\n",
      "Consecutive Dates: 14-03-2023 and 26-04-2023\n",
      "\n",
      "Consecutive Dates: 20-05-2020 and 23-06-2020\n",
      "Consecutive Dates: 23-06-2020 and 29-07-2020\n",
      "Consecutive Dates: 29-07-2020 and 09-09-2020\n",
      "Consecutive Dates: 09-09-2020 and 10-10-2020\n",
      "Consecutive Dates: 10-10-2020 and 12-11-2020\n",
      "Consecutive Dates: 12-11-2020 and 12-01-2021\n",
      "Consecutive Dates: 12-01-2021 and 17-02-2021\n",
      "Consecutive Dates: 17-02-2021 and 26-03-2021\n",
      "Consecutive Dates: 26-03-2021 and 19-04-2021\n",
      "Consecutive Dates: 19-04-2021 and 01-06-2021\n",
      "Consecutive Dates: 01-06-2021 and 29-06-2021\n",
      "Consecutive Dates: 29-06-2021 and 27-07-2021\n",
      "Consecutive Dates: 27-07-2021 and 16-08-2021\n",
      "Consecutive Dates: 16-08-2021 and 04-10-2021\n",
      "Consecutive Dates: 04-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 15-02-2022\n",
      "Consecutive Dates: 15-02-2022 and 18-03-2022\n",
      "Consecutive Dates: 18-03-2022 and 18-04-2022\n",
      "Consecutive Dates: 18-04-2022 and 19-05-2022\n",
      "Consecutive Dates: 19-05-2022 and 27-06-2022\n",
      "Consecutive Dates: 27-06-2022 and 12-09-2022\n",
      "Consecutive Dates: 12-09-2022 and 22-10-2022\n",
      "Consecutive Dates: 22-10-2022 and 31-01-2023\n",
      "Consecutive Dates: 31-01-2023 and 04-04-2023\n",
      "Consecutive Dates: 04-04-2023 and 30-06-2023\n",
      "\n",
      "Consecutive Dates: 05-05-2022 and 02-06-2022\n",
      "Consecutive Dates: 02-06-2022 and 30-12-2022\n",
      "Consecutive Dates: 30-12-2022 and 05-01-2023\n",
      "Consecutive Dates: 05-01-2023 and 12-06-2023\n",
      "Consecutive Dates: 12-06-2023 and 20-06-2023\n",
      "\n",
      "Consecutive Dates: 08-09-2021 and 12-11-2021\n",
      "Consecutive Dates: 12-11-2021 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 09-08-2022\n",
      "Consecutive Dates: 09-08-2022 and 07-10-2022\n",
      "Consecutive Dates: 07-10-2022 and 13-12-2022\n",
      "Consecutive Dates: 13-12-2022 and 24-03-2023\n",
      "Consecutive Dates: 24-03-2023 and 26-06-2023\n",
      "Consecutive Dates: 26-06-2023 and 12-10-2023\n",
      "\n",
      "Consecutive Dates: 28-11-2020 and 11-11-2021\n",
      "Consecutive Dates: 11-11-2021 and 16-11-2021\n",
      "Consecutive Dates: 16-11-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 12-07-2022\n",
      "Consecutive Dates: 12-07-2022 and 03-03-2023\n",
      "Consecutive Dates: 03-03-2023 and 16-03-2023\n",
      "Consecutive Dates: 16-03-2023 and 06-04-2023\n",
      "\n",
      "Consecutive Dates: 03-01-2022 and 31-01-2022\n",
      "Consecutive Dates: 31-01-2022 and 11-03-2022\n",
      "Consecutive Dates: 11-03-2022 and 26-04-2022\n",
      "Consecutive Dates: 26-04-2022 and 13-06-2022\n",
      "Consecutive Dates: 13-06-2022 and 25-07-2022\n",
      "Consecutive Dates: 25-07-2022 and 05-09-2022\n",
      "Consecutive Dates: 05-09-2022 and 28-10-2022\n",
      "Consecutive Dates: 28-10-2022 and 24-01-2023\n",
      "\n",
      "Consecutive Dates: 28-12-2020 and 08-01-2021\n",
      "Consecutive Dates: 08-01-2021 and 20-02-2021\n",
      "Consecutive Dates: 20-02-2021 and 20-03-2021\n",
      "Consecutive Dates: 20-03-2021 and 20-04-2021\n",
      "Consecutive Dates: 20-04-2021 and 02-09-2021\n",
      "Consecutive Dates: 02-09-2021 and 01-11-2021\n",
      "Consecutive Dates: 01-11-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 02-03-2022\n",
      "Consecutive Dates: 02-03-2022 and 02-05-2022\n",
      "Consecutive Dates: 02-05-2022 and 31-05-2022\n",
      "Consecutive Dates: 31-05-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 28-07-2022\n",
      "Consecutive Dates: 28-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 22-09-2022\n",
      "Consecutive Dates: 22-09-2022 and 21-10-2022\n",
      "Consecutive Dates: 21-10-2022 and 21-12-2022\n",
      "Consecutive Dates: 21-12-2022 and 23-01-2023\n",
      "Consecutive Dates: 23-01-2023 and 18-02-2023\n",
      "Consecutive Dates: 18-02-2023 and 24-03-2023\n",
      "Consecutive Dates: 24-03-2023 and 21-04-2023\n",
      "Consecutive Dates: 21-04-2023 and 23-05-2023\n",
      "Consecutive Dates: 23-05-2023 and 22-06-2023\n",
      "Consecutive Dates: 22-06-2023 and 22-07-2023\n",
      "Consecutive Dates: 22-07-2023 and 21-08-2023\n",
      "Consecutive Dates: 21-08-2023 and 22-09-2023\n",
      "Consecutive Dates: 22-09-2023 and 21-10-2023\n",
      "Consecutive Dates: 21-10-2023 and 21-11-2023\n",
      "Consecutive Dates: 21-11-2023 and 21-12-2023\n",
      "Consecutive Dates: 21-12-2023 and 19-01-2024\n",
      "\n",
      "Consecutive Dates: 04-01-2021 and 13-03-2021\n",
      "Consecutive Dates: 13-03-2021 and 11-09-2021\n",
      "Consecutive Dates: 11-09-2021 and 25-10-2021\n",
      "Consecutive Dates: 25-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 21-04-2022\n",
      "Consecutive Dates: 21-04-2022 and 23-06-2022\n",
      "Consecutive Dates: 23-06-2022 and 22-08-2022\n",
      "Consecutive Dates: 22-08-2022 and 24-10-2022\n",
      "Consecutive Dates: 24-10-2022 and 09-12-2022\n",
      "Consecutive Dates: 09-12-2022 and 16-01-2023\n",
      "Consecutive Dates: 16-01-2023 and 31-03-2023\n",
      "Consecutive Dates: 31-03-2023 and 17-05-2023\n",
      "Consecutive Dates: 17-05-2023 and 03-07-2023\n",
      "Consecutive Dates: 03-07-2023 and 21-08-2023\n",
      "Consecutive Dates: 21-08-2023 and 13-10-2023\n",
      "Consecutive Dates: 13-10-2023 and 28-11-2023\n",
      "\n",
      "Consecutive Dates: 30-12-2020 and 30-01-2021\n",
      "Consecutive Dates: 30-01-2021 and 02-03-2021\n",
      "Consecutive Dates: 02-03-2021 and 02-04-2021\n",
      "Consecutive Dates: 02-04-2021 and 03-05-2021\n",
      "Consecutive Dates: 03-05-2021 and 03-06-2021\n",
      "Consecutive Dates: 03-06-2021 and 03-07-2021\n",
      "Consecutive Dates: 03-07-2021 and 03-08-2021\n",
      "Consecutive Dates: 03-08-2021 and 03-09-2021\n",
      "Consecutive Dates: 03-09-2021 and 03-11-2021\n",
      "Consecutive Dates: 03-11-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 01-04-2022\n",
      "Consecutive Dates: 01-04-2022 and 11-06-2022\n",
      "Consecutive Dates: 11-06-2022 and 06-12-2022\n",
      "Consecutive Dates: 06-12-2022 and 09-02-2023\n",
      "Consecutive Dates: 09-02-2023 and 29-05-2023\n",
      "Consecutive Dates: 29-05-2023 and 19-09-2023\n",
      "Consecutive Dates: 19-09-2023 and 16-01-2024\n",
      "\n",
      "Consecutive Dates: 26-10-2020 and 21-12-2020\n",
      "Consecutive Dates: 21-12-2020 and 07-01-2021\n",
      "Consecutive Dates: 07-01-2021 and 22-01-2021\n",
      "Consecutive Dates: 22-01-2021 and 29-01-2021\n",
      "Consecutive Dates: 29-01-2021 and 08-02-2021\n",
      "Consecutive Dates: 08-02-2021 and 11-02-2021\n",
      "Consecutive Dates: 11-02-2021 and 22-02-2021\n",
      "Consecutive Dates: 22-02-2021 and 24-09-2021\n",
      "Consecutive Dates: 24-09-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 10-01-2022\n",
      "Consecutive Dates: 10-01-2022 and 22-07-2022\n",
      "Consecutive Dates: 22-07-2022 and 25-09-2023\n",
      "\n",
      "Consecutive Dates: 17-12-2021 and 03-01-2022\n",
      "\n",
      "Consecutive Dates: 03-01-2022 and 05-03-2022\n",
      "\n",
      "Consecutive Dates: 21-08-2020 and 20-10-2020\n",
      "Consecutive Dates: 20-10-2020 and 19-12-2020\n",
      "Consecutive Dates: 19-12-2020 and 25-01-2021\n",
      "Consecutive Dates: 25-01-2021 and 23-02-2021\n",
      "Consecutive Dates: 23-02-2021 and 23-03-2021\n",
      "Consecutive Dates: 23-03-2021 and 20-04-2021\n",
      "Consecutive Dates: 20-04-2021 and 20-05-2021\n",
      "Consecutive Dates: 20-05-2021 and 19-06-2021\n",
      "Consecutive Dates: 19-06-2021 and 23-07-2021\n",
      "Consecutive Dates: 23-07-2021 and 24-08-2021\n",
      "Consecutive Dates: 24-08-2021 and 05-10-2021\n",
      "Consecutive Dates: 05-10-2021 and 23-11-2021\n",
      "Consecutive Dates: 23-11-2021 and 23-12-2021\n",
      "Consecutive Dates: 23-12-2021 and 24-01-2022\n",
      "Consecutive Dates: 24-01-2022 and 24-02-2022\n",
      "Consecutive Dates: 24-02-2022 and 10-05-2022\n",
      "Consecutive Dates: 10-05-2022 and 07-07-2022\n",
      "Consecutive Dates: 07-07-2022 and 08-08-2022\n",
      "Consecutive Dates: 08-08-2022 and 07-09-2022\n",
      "Consecutive Dates: 07-09-2022 and 11-10-2022\n",
      "Consecutive Dates: 11-10-2022 and 22-11-2022\n",
      "Consecutive Dates: 22-11-2022 and 03-01-2023\n",
      "Consecutive Dates: 03-01-2023 and 06-02-2023\n",
      "Consecutive Dates: 06-02-2023 and 22-03-2023\n",
      "Consecutive Dates: 22-03-2023 and 01-05-2023\n",
      "Consecutive Dates: 01-05-2023 and 30-05-2023\n",
      "Consecutive Dates: 30-05-2023 and 05-07-2023\n",
      "Consecutive Dates: 05-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 12-09-2023\n",
      "Consecutive Dates: 12-09-2023 and 27-10-2023\n",
      "Consecutive Dates: 27-10-2023 and 27-11-2023\n",
      "\n",
      "Consecutive Dates: 25-06-2021 and 26-06-2021\n",
      "Consecutive Dates: 26-06-2021 and 20-07-2021\n",
      "Consecutive Dates: 20-07-2021 and 24-09-2021\n",
      "Consecutive Dates: 24-09-2021 and 14-10-2021\n",
      "Consecutive Dates: 14-10-2021 and 06-11-2021\n",
      "Consecutive Dates: 06-11-2021 and 06-12-2021\n",
      "Consecutive Dates: 06-12-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 04-03-2022\n",
      "Consecutive Dates: 04-03-2022 and 02-05-2022\n",
      "Consecutive Dates: 02-05-2022 and 06-06-2022\n",
      "Consecutive Dates: 06-06-2022 and 01-07-2022\n",
      "Consecutive Dates: 01-07-2022 and 25-07-2022\n",
      "Consecutive Dates: 25-07-2022 and 10-09-2022\n",
      "Consecutive Dates: 10-09-2022 and 10-10-2022\n",
      "Consecutive Dates: 10-10-2022 and 08-11-2022\n",
      "Consecutive Dates: 08-11-2022 and 02-12-2022\n",
      "Consecutive Dates: 02-12-2022 and 05-01-2023\n",
      "Consecutive Dates: 05-01-2023 and 21-02-2023\n",
      "Consecutive Dates: 21-02-2023 and 30-03-2023\n",
      "Consecutive Dates: 30-03-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 01-06-2023\n",
      "Consecutive Dates: 01-06-2023 and 07-07-2023\n",
      "Consecutive Dates: 07-07-2023 and 02-08-2023\n",
      "Consecutive Dates: 02-08-2023 and 04-09-2023\n",
      "Consecutive Dates: 04-09-2023 and 09-10-2023\n",
      "Consecutive Dates: 09-10-2023 and 06-11-2023\n",
      "Consecutive Dates: 06-11-2023 and 11-12-2023\n",
      "Consecutive Dates: 11-12-2023 and 10-01-2024\n",
      "\n",
      "\n",
      "Consecutive Dates: 25-03-2021 and 11-06-2021\n",
      "Consecutive Dates: 11-06-2021 and 03-08-2021\n",
      "Consecutive Dates: 03-08-2021 and 20-09-2021\n",
      "Consecutive Dates: 20-09-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 03-03-2022\n",
      "Consecutive Dates: 03-03-2022 and 10-03-2022\n",
      "Consecutive Dates: 10-03-2022 and 11-12-2023\n",
      "\n",
      "Consecutive Dates: 28-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 18-05-2022\n",
      "Consecutive Dates: 18-05-2022 and 20-06-2022\n",
      "Consecutive Dates: 20-06-2022 and 25-08-2022\n",
      "\n",
      "Consecutive Dates: 03-01-2022 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 21-01-2022\n",
      "\n",
      "Consecutive Dates: 26-10-2020 and 20-11-2020\n",
      "Consecutive Dates: 20-11-2020 and 21-12-2020\n",
      "Consecutive Dates: 21-12-2020 and 07-01-2021\n",
      "Consecutive Dates: 07-01-2021 and 22-01-2021\n",
      "Consecutive Dates: 22-01-2021 and 29-01-2021\n",
      "Consecutive Dates: 29-01-2021 and 08-02-2021\n",
      "Consecutive Dates: 08-02-2021 and 11-02-2021\n",
      "Consecutive Dates: 11-02-2021 and 22-02-2021\n",
      "Consecutive Dates: 22-02-2021 and 24-09-2021\n",
      "Consecutive Dates: 24-09-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 10-01-2022\n",
      "Consecutive Dates: 10-01-2022 and 22-07-2022\n",
      "Consecutive Dates: 22-07-2022 and 25-09-2023\n",
      "\n",
      "Consecutive Dates: 08-08-2017 and 05-09-2017\n",
      "Consecutive Dates: 05-09-2017 and 05-10-2017\n",
      "Consecutive Dates: 05-10-2017 and 30-10-2017\n",
      "Consecutive Dates: 30-10-2017 and 29-11-2017\n",
      "Consecutive Dates: 29-11-2017 and 28-12-2017\n",
      "Consecutive Dates: 28-12-2017 and 01-02-2018\n",
      "Consecutive Dates: 01-02-2018 and 13-02-2018\n",
      "Consecutive Dates: 13-02-2018 and 19-03-2018\n",
      "Consecutive Dates: 19-03-2018 and 17-04-2018\n",
      "Consecutive Dates: 17-04-2018 and 15-05-2018\n",
      "Consecutive Dates: 15-05-2018 and 09-06-2018\n",
      "Consecutive Dates: 09-06-2018 and 10-07-2018\n",
      "Consecutive Dates: 10-07-2018 and 06-08-2018\n",
      "Consecutive Dates: 06-08-2018 and 05-09-2018\n",
      "Consecutive Dates: 05-09-2018 and 28-09-2018\n",
      "Consecutive Dates: 28-09-2018 and 29-10-2018\n",
      "Consecutive Dates: 29-10-2018 and 30-11-2018\n",
      "Consecutive Dates: 30-11-2018 and 27-12-2018\n",
      "Consecutive Dates: 27-12-2018 and 02-02-2019\n",
      "Consecutive Dates: 02-02-2019 and 05-04-2019\n",
      "Consecutive Dates: 05-04-2019 and 03-05-2019\n",
      "Consecutive Dates: 03-05-2019 and 27-05-2019\n",
      "Consecutive Dates: 27-05-2019 and 18-06-2019\n",
      "Consecutive Dates: 18-06-2019 and 15-07-2019\n",
      "Consecutive Dates: 15-07-2019 and 17-08-2019\n",
      "Consecutive Dates: 17-08-2019 and 07-09-2019\n",
      "Consecutive Dates: 07-09-2019 and 03-10-2019\n",
      "Consecutive Dates: 03-10-2019 and 06-11-2019\n",
      "Consecutive Dates: 06-11-2019 and 06-12-2019\n",
      "Consecutive Dates: 06-12-2019 and 04-01-2020\n",
      "Consecutive Dates: 04-01-2020 and 04-02-2020\n",
      "Consecutive Dates: 04-02-2020 and 07-03-2020\n",
      "Consecutive Dates: 07-03-2020 and 03-07-2020\n",
      "Consecutive Dates: 03-07-2020 and 28-08-2020\n",
      "Consecutive Dates: 28-08-2020 and 27-11-2020\n",
      "Consecutive Dates: 27-11-2020 and 05-02-2021\n",
      "Consecutive Dates: 05-02-2021 and 09-04-2021\n",
      "Consecutive Dates: 09-04-2021 and 03-08-2021\n",
      "Consecutive Dates: 03-08-2021 and 22-10-2021\n",
      "Consecutive Dates: 22-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 06-05-2022\n",
      "Consecutive Dates: 06-05-2022 and 30-07-2022\n",
      "Consecutive Dates: 30-07-2022 and 21-10-2022\n",
      "Consecutive Dates: 21-10-2022 and 27-01-2023\n",
      "Consecutive Dates: 27-01-2023 and 18-04-2023\n",
      "Consecutive Dates: 18-04-2023 and 25-10-2023\n",
      "Consecutive Dates: 25-10-2023 and 02-02-2024\n",
      "\n",
      "Consecutive Dates: 17-05-2021 and 18-06-2021\n",
      "Consecutive Dates: 18-06-2021 and 13-09-2021\n",
      "Consecutive Dates: 13-09-2021 and 28-09-2021\n",
      "Consecutive Dates: 28-09-2021 and 11-10-2021\n",
      "Consecutive Dates: 11-10-2021 and 05-11-2021\n",
      "Consecutive Dates: 05-11-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 01-02-2022\n",
      "Consecutive Dates: 01-02-2022 and 28-02-2022\n",
      "Consecutive Dates: 28-02-2022 and 29-04-2022\n",
      "Consecutive Dates: 29-04-2022 and 30-05-2022\n",
      "Consecutive Dates: 30-05-2022 and 01-07-2022\n",
      "Consecutive Dates: 01-07-2022 and 01-08-2022\n",
      "Consecutive Dates: 01-08-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 01-11-2022\n",
      "Consecutive Dates: 01-11-2022 and 02-12-2022\n",
      "Consecutive Dates: 02-12-2022 and 03-01-2023\n",
      "Consecutive Dates: 03-01-2023 and 06-02-2023\n",
      "Consecutive Dates: 06-02-2023 and 21-03-2023\n",
      "Consecutive Dates: 21-03-2023 and 02-05-2023\n",
      "Consecutive Dates: 02-05-2023 and 11-08-2023\n",
      "Consecutive Dates: 11-08-2023 and 22-09-2023\n",
      "Consecutive Dates: 22-09-2023 and 01-11-2023\n",
      "Consecutive Dates: 01-11-2023 and 09-01-2024\n",
      "\n",
      "Consecutive Dates: 21-08-2020 and 20-10-2020\n",
      "Consecutive Dates: 20-10-2020 and 20-11-2020\n",
      "Consecutive Dates: 20-11-2020 and 19-12-2020\n",
      "Consecutive Dates: 19-12-2020 and 25-01-2021\n",
      "Consecutive Dates: 25-01-2021 and 23-02-2021\n",
      "Consecutive Dates: 23-02-2021 and 23-03-2021\n",
      "Consecutive Dates: 23-03-2021 and 20-04-2021\n",
      "Consecutive Dates: 20-04-2021 and 20-05-2021\n",
      "Consecutive Dates: 20-05-2021 and 19-06-2021\n",
      "Consecutive Dates: 19-06-2021 and 23-07-2021\n",
      "Consecutive Dates: 23-07-2021 and 24-08-2021\n",
      "Consecutive Dates: 24-08-2021 and 05-10-2021\n",
      "Consecutive Dates: 05-10-2021 and 23-11-2021\n",
      "Consecutive Dates: 23-11-2021 and 23-12-2021\n",
      "Consecutive Dates: 23-12-2021 and 24-01-2022\n",
      "Consecutive Dates: 24-01-2022 and 24-02-2022\n",
      "Consecutive Dates: 24-02-2022 and 10-05-2022\n",
      "Consecutive Dates: 10-05-2022 and 07-07-2022\n",
      "Consecutive Dates: 07-07-2022 and 08-08-2022\n",
      "Consecutive Dates: 08-08-2022 and 07-09-2022\n",
      "Consecutive Dates: 07-09-2022 and 11-10-2022\n",
      "Consecutive Dates: 11-10-2022 and 22-11-2022\n",
      "Consecutive Dates: 22-11-2022 and 03-01-2023\n",
      "Consecutive Dates: 03-01-2023 and 06-02-2023\n",
      "Consecutive Dates: 06-02-2023 and 22-03-2023\n",
      "Consecutive Dates: 22-03-2023 and 01-05-2023\n",
      "Consecutive Dates: 01-05-2023 and 30-05-2023\n",
      "Consecutive Dates: 30-05-2023 and 05-07-2023\n",
      "Consecutive Dates: 05-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 12-09-2023\n",
      "Consecutive Dates: 12-09-2023 and 27-10-2023\n",
      "Consecutive Dates: 27-10-2023 and 27-11-2023\n",
      "\n",
      "Consecutive Dates: 03-01-2022 and 25-05-2022\n",
      "\n",
      "Consecutive Dates: 03-01-2022 and 22-06-2022\n",
      "Consecutive Dates: 22-06-2022 and 31-08-2022\n",
      "Consecutive Dates: 31-08-2022 and 21-03-2023\n",
      "Consecutive Dates: 21-03-2023 and 21-04-2023\n",
      "Consecutive Dates: 21-04-2023 and 22-05-2023\n",
      "Consecutive Dates: 22-05-2023 and 22-06-2023\n",
      "Consecutive Dates: 22-06-2023 and 20-07-2023\n",
      "Consecutive Dates: 20-07-2023 and 28-01-2023\n",
      "Consecutive Dates: 28-01-2023 and 21-09-2023\n",
      "\n",
      "Consecutive Dates: 01-11-2021 and 01-12-2021\n",
      "Consecutive Dates: 01-12-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 31-01-2022\n",
      "Consecutive Dates: 31-01-2022 and 08-03-2022\n",
      "Consecutive Dates: 08-03-2022 and 09-04-2022\n",
      "Consecutive Dates: 09-04-2022 and 08-08-2022\n",
      "Consecutive Dates: 08-08-2022 and 10-09-2022\n",
      "Consecutive Dates: 10-09-2022 and 07-10-2022\n",
      "Consecutive Dates: 07-10-2022 and 08-11-2022\n",
      "Consecutive Dates: 08-11-2022 and 10-12-2022\n",
      "Consecutive Dates: 10-12-2022 and 11-01-2023\n",
      "Consecutive Dates: 11-01-2023 and 08-02-2023\n",
      "Consecutive Dates: 08-02-2023 and 09-03-2023\n",
      "Consecutive Dates: 09-03-2023 and 08-04-2023\n",
      "Consecutive Dates: 08-04-2023 and 13-05-2023\n",
      "Consecutive Dates: 13-05-2023 and 03-06-2023\n",
      "Consecutive Dates: 03-06-2023 and 18-07-2023\n",
      "Consecutive Dates: 18-07-2023 and 22-08-2023\n",
      "\n",
      "Consecutive Dates: 13-07-2021 and 13-08-2021\n",
      "Consecutive Dates: 13-08-2021 and 14-09-2021\n",
      "Consecutive Dates: 14-09-2021 and 19-10-2021\n",
      "Consecutive Dates: 19-10-2021 and 22-10-2021\n",
      "Consecutive Dates: 22-10-2021 and 26-10-2021\n",
      "Consecutive Dates: 26-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 15-02-2022\n",
      "Consecutive Dates: 15-02-2022 and 17-02-2022\n",
      "Consecutive Dates: 17-02-2022 and 25-03-2022\n",
      "Consecutive Dates: 25-03-2022 and 31-03-2022\n",
      "Consecutive Dates: 31-03-2022 and 30-05-2022\n",
      "Consecutive Dates: 30-05-2022 and 22-07-2022\n",
      "Consecutive Dates: 22-07-2022 and 23-07-2022\n",
      "Consecutive Dates: 23-07-2022 and 25-07-2022\n",
      "Consecutive Dates: 25-07-2022 and 26-07-2022\n",
      "Consecutive Dates: 26-07-2022 and 17-10-2022\n",
      "Consecutive Dates: 17-10-2022 and 26-12-2022\n",
      "Consecutive Dates: 26-12-2022 and 10-02-2023\n",
      "Consecutive Dates: 10-02-2023 and 15-05-2023\n",
      "Consecutive Dates: 15-05-2023 and 27-06-2023\n",
      "\n",
      "Consecutive Dates: 03-01-2022 and 03-02-2022\n",
      "Consecutive Dates: 03-02-2022 and 03-03-2022\n",
      "Consecutive Dates: 03-03-2022 and 13-04-2022\n",
      "Consecutive Dates: 13-04-2022 and 15-09-2023\n",
      "Consecutive Dates: 15-09-2023 and 06-11-2023\n",
      "\n",
      "\n",
      "Consecutive Dates: 19-07-2021 and 21-09-2021\n",
      "Consecutive Dates: 21-09-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 16-07-2022\n",
      "Consecutive Dates: 16-07-2022 and 11-08-2022\n",
      "Consecutive Dates: 11-08-2022 and 07-09-2022\n",
      "Consecutive Dates: 07-09-2022 and 08-10-2022\n",
      "Consecutive Dates: 08-10-2022 and 06-12-2022\n",
      "Consecutive Dates: 06-12-2022 and 07-01-2023\n",
      "Consecutive Dates: 07-01-2023 and 11-07-2023\n",
      "Consecutive Dates: 11-07-2023 and 11-01-2024\n",
      "Consecutive Dates: 11-01-2024 and 09-02-2024\n",
      "\n",
      "Consecutive Dates: 19-01-2022 and 16-02-2022\n",
      "Consecutive Dates: 16-02-2022 and 06-05-2022\n",
      "Consecutive Dates: 06-05-2022 and 23-06-2022\n",
      "Consecutive Dates: 23-06-2022 and 26-07-2022\n",
      "Consecutive Dates: 26-07-2022 and 15-09-2022\n",
      "Consecutive Dates: 15-09-2022 and 14-11-2022\n",
      "Consecutive Dates: 14-11-2022 and 31-12-2022\n",
      "Consecutive Dates: 31-12-2022 and 02-02-2023\n",
      "Consecutive Dates: 02-02-2023 and 04-03-2023\n",
      "Consecutive Dates: 04-03-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 29-05-2023\n",
      "\n",
      "Consecutive Dates: 16-11-2021 and 03-01-2022\n",
      "\n",
      "\n",
      "Consecutive Dates: 09-06-2018 and 13-07-2018\n",
      "Consecutive Dates: 13-07-2018 and 11-08-2018\n",
      "Consecutive Dates: 11-08-2018 and 11-09-2018\n",
      "Consecutive Dates: 11-09-2018 and 04-10-2018\n",
      "Consecutive Dates: 04-10-2018 and 05-11-2018\n",
      "Consecutive Dates: 05-11-2018 and 06-12-2018\n",
      "Consecutive Dates: 06-12-2018 and 10-06-2019\n",
      "Consecutive Dates: 10-06-2019 and 10-07-2019\n",
      "Consecutive Dates: 10-07-2019 and 07-08-2019\n",
      "Consecutive Dates: 07-08-2019 and 21-08-2019\n",
      "Consecutive Dates: 21-08-2019 and 01-10-2019\n",
      "Consecutive Dates: 01-10-2019 and 26-10-2019\n",
      "Consecutive Dates: 26-10-2019 and 04-12-2019\n",
      "Consecutive Dates: 04-12-2019 and 06-01-2020\n",
      "Consecutive Dates: 06-01-2020 and 01-02-2020\n",
      "Consecutive Dates: 01-02-2020 and 13-03-2020\n",
      "Consecutive Dates: 13-03-2020 and 12-06-2020\n",
      "Consecutive Dates: 12-06-2020 and 04-08-2020\n",
      "Consecutive Dates: 04-08-2020 and 07-09-2020\n",
      "Consecutive Dates: 07-09-2020 and 04-11-2020\n",
      "Consecutive Dates: 04-11-2020 and 25-12-2020\n",
      "Consecutive Dates: 25-12-2020 and 11-02-2021\n",
      "Consecutive Dates: 11-02-2021 and 17-03-2021\n",
      "Consecutive Dates: 17-03-2021 and 22-04-2021\n",
      "Consecutive Dates: 22-04-2021 and 17-08-2021\n",
      "Consecutive Dates: 17-08-2021 and 21-09-2021\n",
      "Consecutive Dates: 21-09-2021 and 25-10-2021\n",
      "Consecutive Dates: 25-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 17-03-2022\n",
      "Consecutive Dates: 17-03-2022 and 14-04-2022\n",
      "Consecutive Dates: 14-04-2022 and 12-05-2022\n",
      "Consecutive Dates: 12-05-2022 and 27-07-2022\n",
      "Consecutive Dates: 27-07-2022 and 05-09-2022\n",
      "Consecutive Dates: 05-09-2022 and 01-10-2022\n",
      "Consecutive Dates: 01-10-2022 and 27-01-2023\n",
      "Consecutive Dates: 27-01-2023 and 24-02-2023\n",
      "Consecutive Dates: 24-02-2023 and 25-03-2023\n",
      "Consecutive Dates: 25-03-2023 and 17-04-2023\n",
      "Consecutive Dates: 17-04-2023 and 15-07-2023\n",
      "Consecutive Dates: 15-07-2023 and 26-10-2023\n",
      "\n",
      "\n",
      "Consecutive Dates: 30-09-2014 and 07-11-2014\n",
      "Consecutive Dates: 07-11-2014 and 02-12-2014\n",
      "Consecutive Dates: 02-12-2014 and 06-01-2015\n",
      "Consecutive Dates: 06-01-2015 and 05-02-2015\n",
      "Consecutive Dates: 05-02-2015 and 07-03-2015\n",
      "Consecutive Dates: 07-03-2015 and 07-04-2015\n",
      "Consecutive Dates: 07-04-2015 and 09-05-2015\n",
      "Consecutive Dates: 09-05-2015 and 08-06-2015\n",
      "Consecutive Dates: 08-06-2015 and 08-07-2015\n",
      "Consecutive Dates: 08-07-2015 and 06-08-2015\n",
      "Consecutive Dates: 06-08-2015 and 04-09-2015\n",
      "Consecutive Dates: 04-09-2015 and 05-10-2015\n",
      "Consecutive Dates: 05-10-2015 and 02-11-2015\n",
      "Consecutive Dates: 02-11-2015 and 17-12-2015\n",
      "Consecutive Dates: 17-12-2015 and 16-01-2016\n",
      "Consecutive Dates: 16-01-2016 and 13-02-2016\n",
      "Consecutive Dates: 13-02-2016 and 14-03-2016\n",
      "Consecutive Dates: 14-03-2016 and 12-05-2016\n",
      "Consecutive Dates: 12-05-2016 and 11-06-2016\n",
      "Consecutive Dates: 11-06-2016 and 12-07-2016\n",
      "Consecutive Dates: 12-07-2016 and 11-08-2016\n",
      "Consecutive Dates: 11-08-2016 and 10-09-2016\n",
      "Consecutive Dates: 10-09-2016 and 27-09-2016\n",
      "Consecutive Dates: 27-09-2016 and 24-10-2016\n",
      "Consecutive Dates: 24-10-2016 and 24-11-2016\n",
      "Consecutive Dates: 24-11-2016 and 22-12-2016\n",
      "Consecutive Dates: 22-12-2016 and 21-01-2017\n",
      "Consecutive Dates: 21-01-2017 and 21-02-2017\n",
      "Consecutive Dates: 21-02-2017 and 23-03-2017\n",
      "Consecutive Dates: 23-03-2017 and 22-04-2017\n",
      "Consecutive Dates: 22-04-2017 and 22-05-2017\n",
      "Consecutive Dates: 22-05-2017 and 24-06-2017\n",
      "Consecutive Dates: 24-06-2017 and 27-07-2017\n",
      "Consecutive Dates: 27-07-2017 and 26-08-2017\n",
      "Consecutive Dates: 26-08-2017 and 25-09-2017\n",
      "Consecutive Dates: 25-09-2017 and 25-10-2017\n",
      "Consecutive Dates: 25-10-2017 and 23-11-2017\n",
      "Consecutive Dates: 23-11-2017 and 23-12-2017\n",
      "Consecutive Dates: 23-12-2017 and 23-01-2018\n",
      "Consecutive Dates: 23-01-2018 and 20-02-2018\n",
      "Consecutive Dates: 20-02-2018 and 26-03-2018\n",
      "Consecutive Dates: 26-03-2018 and 24-04-2018\n",
      "Consecutive Dates: 24-04-2018 and 24-05-2018\n",
      "Consecutive Dates: 24-05-2018 and 06-06-2018\n",
      "Consecutive Dates: 06-06-2018 and 05-07-2018\n",
      "Consecutive Dates: 05-07-2018 and 04-08-2018\n",
      "Consecutive Dates: 04-08-2018 and 18-09-2018\n",
      "Consecutive Dates: 18-09-2018 and 16-10-2018\n",
      "Consecutive Dates: 16-10-2018 and 15-11-2018\n",
      "Consecutive Dates: 15-11-2018 and 17-12-2018\n",
      "Consecutive Dates: 17-12-2018 and 15-01-2019\n",
      "Consecutive Dates: 15-01-2019 and 16-02-2019\n",
      "Consecutive Dates: 16-02-2019 and 18-03-2019\n",
      "Consecutive Dates: 18-03-2019 and 16-04-2019\n",
      "Consecutive Dates: 16-04-2019 and 16-05-2019\n",
      "Consecutive Dates: 16-05-2019 and 15-06-2019\n",
      "Consecutive Dates: 15-06-2019 and 16-07-2019\n",
      "Consecutive Dates: 16-07-2019 and 14-08-2019\n",
      "Consecutive Dates: 14-08-2019 and 12-09-2019\n",
      "Consecutive Dates: 12-09-2019 and 14-10-2019\n",
      "Consecutive Dates: 14-10-2019 and 12-11-2019\n",
      "Consecutive Dates: 12-11-2019 and 16-12-2019\n",
      "Consecutive Dates: 16-12-2019 and 15-01-2020\n",
      "Consecutive Dates: 15-01-2020 and 15-02-2020\n",
      "Consecutive Dates: 15-02-2020 and 16-03-2020\n",
      "Consecutive Dates: 16-03-2020 and 24-04-2020\n",
      "Consecutive Dates: 24-04-2020 and 18-06-2020\n",
      "Consecutive Dates: 18-06-2020 and 21-07-2020\n",
      "Consecutive Dates: 21-07-2020 and 28-08-2020\n",
      "Consecutive Dates: 28-08-2020 and 28-09-2020\n",
      "Consecutive Dates: 28-09-2020 and 21-12-2020\n",
      "Consecutive Dates: 21-12-2020 and 04-09-2021\n",
      "Consecutive Dates: 04-09-2021 and 11-10-2021\n",
      "Consecutive Dates: 11-10-2021 and 01-11-2021\n",
      "Consecutive Dates: 01-11-2021 and 03-12-2021\n",
      "Consecutive Dates: 03-12-2021 and 10-01-2022\n",
      "Consecutive Dates: 10-01-2022 and 11-02-2022\n",
      "Consecutive Dates: 11-02-2022 and 11-03-2022\n",
      "Consecutive Dates: 11-03-2022 and 15-04-2022\n",
      "Consecutive Dates: 15-04-2022 and 15-05-2022\n",
      "Consecutive Dates: 15-05-2022 and 18-06-2022\n",
      "Consecutive Dates: 18-06-2022 and 20-07-2022\n",
      "Consecutive Dates: 20-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 13-10-2022\n",
      "\n",
      "Consecutive Dates: 16-10-2019 and 15-11-2019\n",
      "Consecutive Dates: 15-11-2019 and 15-12-2019\n",
      "Consecutive Dates: 15-12-2019 and 13-01-2020\n",
      "Consecutive Dates: 13-01-2020 and 11-02-2020\n",
      "Consecutive Dates: 11-02-2020 and 13-03-2020\n",
      "Consecutive Dates: 13-03-2020 and 15-05-1010\n",
      "Consecutive Dates: 15-05-1010 and 17-04-2020\n",
      "Consecutive Dates: 17-04-2020 and 15-06-2020\n",
      "Consecutive Dates: 15-06-2020 and 13-08-2020\n",
      "Consecutive Dates: 13-08-2020 and 22-09-2020\n",
      "Consecutive Dates: 22-09-2020 and 27-11-2020\n",
      "Consecutive Dates: 27-11-2020 and 04-01-2021\n",
      "Consecutive Dates: 04-01-2021 and 28-01-2021\n",
      "Consecutive Dates: 28-01-2021 and 24-02-2021\n",
      "Consecutive Dates: 24-02-2021 and 24-03-2021\n",
      "Consecutive Dates: 24-03-2021 and 30-04-2021\n",
      "Consecutive Dates: 30-04-2021 and 29-05-2021\n",
      "Consecutive Dates: 29-05-2021 and 19-06-2021\n",
      "Consecutive Dates: 19-06-2021 and 02-08-2021\n",
      "Consecutive Dates: 02-08-2021 and 02-09-2021\n",
      "Consecutive Dates: 02-09-2021 and 04-10-2021\n",
      "Consecutive Dates: 04-10-2021 and 03-11-2021\n",
      "Consecutive Dates: 03-11-2021 and 06-12-2021\n",
      "Consecutive Dates: 06-12-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 02-02-2022\n",
      "Consecutive Dates: 02-02-2022 and 05-03-2022\n",
      "Consecutive Dates: 05-03-2022 and 04-04-2022\n",
      "Consecutive Dates: 04-04-2022 and 07-05-2022\n",
      "Consecutive Dates: 07-05-2022 and 04-06-2022\n",
      "Consecutive Dates: 04-06-2022 and 09-07-2022\n",
      "Consecutive Dates: 09-07-2022 and 16-08-2022\n",
      "Consecutive Dates: 16-08-2022 and 14-09-2022\n",
      "Consecutive Dates: 14-09-2022 and 16-10-2022\n",
      "Consecutive Dates: 16-10-2022 and 25-11-2022\n",
      "Consecutive Dates: 25-11-2022 and 30-12-2022\n",
      "Consecutive Dates: 30-12-2022 and 28-01-2023\n",
      "Consecutive Dates: 28-01-2023 and 11-03-2023\n",
      "Consecutive Dates: 11-03-2023 and 18-04-2023\n",
      "Consecutive Dates: 18-04-2023 and 23-05-2023\n",
      "Consecutive Dates: 23-05-2023 and 21-06-2023\n",
      "Consecutive Dates: 21-06-2023 and 21-07-2023\n",
      "Consecutive Dates: 21-07-2023 and 29-08-2023\n",
      "Consecutive Dates: 29-08-2023 and 28-09-2023\n",
      "Consecutive Dates: 28-09-2023 and 27-10-2023\n",
      "Consecutive Dates: 27-10-2023 and 28-11-2023\n",
      "Consecutive Dates: 28-11-2023 and 29-12-2023\n",
      "\n",
      "Consecutive Dates: 03-11-2022 and 03-01-2023\n",
      "Consecutive Dates: 03-01-2023 and 02-03-2023\n",
      "Consecutive Dates: 02-03-2023 and 25-04-2023\n",
      "\n",
      "Consecutive Dates: 26-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 27-09-2022\n",
      "Consecutive Dates: 27-09-2022 and 18-04-2023\n",
      "Consecutive Dates: 18-04-2023 and 04-05-2023\n",
      "\n",
      "Consecutive Dates: 01-07-2022 and 01-08-2022\n",
      "Consecutive Dates: 01-08-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 01-10-2022\n",
      "Consecutive Dates: 01-10-2022 and 01-11-2022\n",
      "Consecutive Dates: 01-11-2022 and 09-01-2023\n",
      "Consecutive Dates: 09-01-2023 and 14-02-2023\n",
      "\n",
      "Consecutive Dates: 26-08-2022 and 24-09-2022\n",
      "Consecutive Dates: 24-09-2022 and 01-11-2022\n",
      "\n",
      "Consecutive Dates: 22-12-2021 and 24-01-2022\n",
      "Consecutive Dates: 24-01-2022 and 25-02-2022\n",
      "Consecutive Dates: 25-02-2022 and 26-03-2022\n",
      "Consecutive Dates: 26-03-2022 and 25-05-2022\n",
      "Consecutive Dates: 25-05-2022 and 25-06-2022\n",
      "Consecutive Dates: 25-06-2022 and 27-07-2022\n",
      "Consecutive Dates: 27-07-2022 and 26-08-2022\n",
      "\n",
      "Consecutive Dates: 27-07-2015 and 30-09-2015\n",
      "Consecutive Dates: 30-09-2015 and 05-11-2015\n",
      "Consecutive Dates: 05-11-2015 and 10-12-2015\n",
      "Consecutive Dates: 10-12-2015 and 12-01-2016\n",
      "Consecutive Dates: 12-01-2016 and 11-02-2016\n",
      "Consecutive Dates: 11-02-2016 and 18-05-2016\n",
      "Consecutive Dates: 18-05-2016 and 11-11-2016\n",
      "Consecutive Dates: 11-11-2016 and 21-12-2016\n",
      "Consecutive Dates: 21-12-2016 and 25-01-2017\n",
      "Consecutive Dates: 25-01-2017 and 27-02-2017\n",
      "Consecutive Dates: 27-02-2017 and 03-04-2017\n",
      "Consecutive Dates: 03-04-2017 and 09-05-2017\n",
      "Consecutive Dates: 09-05-2017 and 21-06-2017\n",
      "Consecutive Dates: 21-06-2017 and 03-08-2017\n",
      "Consecutive Dates: 03-08-2017 and 18-09-2017\n",
      "Consecutive Dates: 18-09-2017 and 29-11-2017\n",
      "Consecutive Dates: 29-11-2017 and 03-01-2018\n",
      "Consecutive Dates: 03-01-2018 and 09-02-2018\n",
      "Consecutive Dates: 09-02-2018 and 27-03-2018\n",
      "Consecutive Dates: 27-03-2018 and 26-04-2018\n",
      "Consecutive Dates: 26-04-2018 and 08-06-2018\n",
      "Consecutive Dates: 08-06-2018 and 24-07-2018\n",
      "Consecutive Dates: 24-07-2018 and 12-09-2018\n",
      "Consecutive Dates: 12-09-2018 and 24-10-2018\n",
      "Consecutive Dates: 24-10-2018 and 10-12-2018\n",
      "Consecutive Dates: 10-12-2018 and 25-01-2019\n",
      "Consecutive Dates: 25-01-2019 and 26-03-2019\n",
      "Consecutive Dates: 26-03-2019 and 06-06-2019\n",
      "Consecutive Dates: 06-06-2019 and 26-07-2019\n",
      "Consecutive Dates: 26-07-2019 and 03-09-2019\n",
      "Consecutive Dates: 03-09-2019 and 24-10-2019\n",
      "Consecutive Dates: 24-10-2019 and 18-11-2019\n",
      "Consecutive Dates: 18-11-2019 and 30-12-2019\n",
      "Consecutive Dates: 30-12-2019 and 04-02-2020\n",
      "Consecutive Dates: 04-02-2020 and 05-02-2020\n",
      "Consecutive Dates: 05-02-2020 and 06-05-2020\n",
      "Consecutive Dates: 06-05-2020 and 02-06-2020\n",
      "Consecutive Dates: 02-06-2020 and 25-08-2020\n",
      "Consecutive Dates: 25-08-2020 and 29-10-2020\n",
      "Consecutive Dates: 29-10-2020 and 19-12-2020\n",
      "Consecutive Dates: 19-12-2020 and 21-01-2021\n",
      "Consecutive Dates: 21-01-2021 and 23-03-2021\n",
      "Consecutive Dates: 23-03-2021 and 30-06-2021\n",
      "Consecutive Dates: 30-06-2021 and 19-10-2021\n",
      "Consecutive Dates: 19-10-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 31-03-2022\n",
      "Consecutive Dates: 31-03-2022 and 05-07-2022\n",
      "Consecutive Dates: 05-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 26-09-2022\n",
      "Consecutive Dates: 26-09-2022 and 03-11-2022\n",
      "Consecutive Dates: 03-11-2022 and 01-12-2022\n",
      "Consecutive Dates: 01-12-2022 and 02-01-2023\n",
      "Consecutive Dates: 02-01-2023 and 07-02-2023\n",
      "Consecutive Dates: 07-02-2023 and 16-03-2023\n",
      "Consecutive Dates: 16-03-2023 and 25-04-2023\n",
      "Consecutive Dates: 25-04-2023 and 05-06-2023\n",
      "Consecutive Dates: 05-06-2023 and 31-07-2023\n",
      "Consecutive Dates: 31-07-2023 and 10-10-2023\n",
      "Consecutive Dates: 10-10-2023 and 02-12-2023\n",
      "Consecutive Dates: 02-12-2023 and 27-01-2024\n",
      "\n",
      "Consecutive Dates: 09-10-2015 and 12-11-2015\n",
      "Consecutive Dates: 12-11-2015 and 11-01-2015\n",
      "Consecutive Dates: 11-01-2015 and 09-01-2016\n",
      "Consecutive Dates: 09-01-2016 and 06-02-2016\n",
      "Consecutive Dates: 06-02-2016 and 07-03-2016\n",
      "Consecutive Dates: 07-03-2016 and 09-04-2016\n",
      "Consecutive Dates: 09-04-2016 and 30-04-2016\n",
      "Consecutive Dates: 30-04-2016 and 14-05-2016\n",
      "Consecutive Dates: 14-05-2016 and 22-06-2016\n",
      "Consecutive Dates: 22-06-2016 and 26-07-2016\n",
      "Consecutive Dates: 26-07-2016 and 20-08-2016\n",
      "Consecutive Dates: 20-08-2016 and 06-10-2016\n",
      "Consecutive Dates: 06-10-2016 and 07-11-2016\n",
      "Consecutive Dates: 07-11-2016 and 09-12-2016\n",
      "Consecutive Dates: 09-12-2016 and 23-01-2017\n",
      "Consecutive Dates: 23-01-2017 and 20-02-2017\n",
      "Consecutive Dates: 20-02-2017 and 30-03-2017\n",
      "Consecutive Dates: 30-03-2017 and 28-04-2017\n",
      "Consecutive Dates: 28-04-2017 and 10-06-2017\n",
      "Consecutive Dates: 10-06-2017 and 04-07-2017\n",
      "Consecutive Dates: 04-07-2017 and 01-08-2017\n",
      "Consecutive Dates: 01-08-2017 and 30-08-2017\n",
      "Consecutive Dates: 30-08-2017 and 04-10-2017\n",
      "Consecutive Dates: 04-10-2017 and 27-11-2017\n",
      "Consecutive Dates: 27-11-2017 and 26-12-2017\n",
      "Consecutive Dates: 26-12-2017 and 01-02-2018\n",
      "Consecutive Dates: 01-02-2018 and 07-03-2018\n",
      "Consecutive Dates: 07-03-2018 and 11-04-2018\n",
      "Consecutive Dates: 11-04-2018 and 22-05-2018\n",
      "Consecutive Dates: 22-05-2018 and 25-06-2018\n",
      "Consecutive Dates: 25-06-2018 and 09-08-2018\n",
      "Consecutive Dates: 09-08-2018 and 13-09-2018\n",
      "Consecutive Dates: 13-09-2018 and 13-10-2018\n",
      "Consecutive Dates: 13-10-2018 and 08-11-2018\n",
      "Consecutive Dates: 08-11-2018 and 19-12-2018\n",
      "Consecutive Dates: 19-12-2018 and 17-01-2019\n",
      "Consecutive Dates: 17-01-2019 and 15-02-2019\n",
      "Consecutive Dates: 15-02-2019 and 16-02-2019\n",
      "Consecutive Dates: 16-02-2019 and 20-04-2019\n",
      "Consecutive Dates: 20-04-2019 and 22-05-2019\n",
      "Consecutive Dates: 22-05-2019 and 26-06-2019\n",
      "Consecutive Dates: 26-06-2019 and 29-07-2019\n",
      "Consecutive Dates: 29-07-2019 and 27-08-2019\n",
      "Consecutive Dates: 27-08-2019 and 05-10-2019\n",
      "Consecutive Dates: 05-10-2019 and 05-11-2019\n",
      "Consecutive Dates: 05-11-2019 and 17-12-2019\n",
      "Consecutive Dates: 17-12-2019 and 14-01-2020\n",
      "Consecutive Dates: 14-01-2020 and 19-02-2020\n",
      "Consecutive Dates: 19-02-2020 and 20-03-2020\n",
      "Consecutive Dates: 20-03-2020 and 08-05-2020\n",
      "Consecutive Dates: 08-05-2020 and 05-06-2020\n",
      "Consecutive Dates: 05-06-2020 and 26-09-2020\n",
      "Consecutive Dates: 26-09-2020 and 20-10-2020\n",
      "Consecutive Dates: 20-10-2020 and 24-11-2020\n",
      "Consecutive Dates: 24-11-2020 and 24-12-2020\n",
      "Consecutive Dates: 24-12-2020 and 01-02-2021\n",
      "Consecutive Dates: 01-02-2021 and 08-03-2021\n",
      "Consecutive Dates: 08-03-2021 and 16-04-2021\n",
      "Consecutive Dates: 16-04-2021 and 23-06-2021\n",
      "Consecutive Dates: 23-06-2021 and 20-07-2021\n",
      "Consecutive Dates: 20-07-2021 and 25-08-2021\n",
      "Consecutive Dates: 25-08-2021 and 18-09-2021\n",
      "Consecutive Dates: 18-09-2021 and 26-10-2021\n",
      "Consecutive Dates: 26-10-2021 and 25-11-2021\n",
      "Consecutive Dates: 25-11-2021 and 21-12-2021\n",
      "Consecutive Dates: 21-12-2021 and 20-01-2022\n",
      "Consecutive Dates: 20-01-2022 and 15-02-2022\n",
      "Consecutive Dates: 15-02-2022 and 15-03-2022\n",
      "Consecutive Dates: 15-03-2022 and 22-04-2022\n",
      "Consecutive Dates: 22-04-2022 and 23-05-2022\n",
      "Consecutive Dates: 23-05-2022 and 19-07-2022\n",
      "Consecutive Dates: 19-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 28-09-2022\n",
      "Consecutive Dates: 28-09-2022 and 06-12-2022\n",
      "Consecutive Dates: 06-12-2022 and 24-01-2023\n",
      "Consecutive Dates: 24-01-2023 and 16-03-2023\n",
      "Consecutive Dates: 16-03-2023 and 24-04-2023\n",
      "Consecutive Dates: 24-04-2023 and 07-06-2023\n",
      "Consecutive Dates: 07-06-2023 and 27-07-2023\n",
      "Consecutive Dates: 27-07-2023 and 11-09-2023\n",
      "Consecutive Dates: 11-09-2023 and 31-10-2023\n",
      "Consecutive Dates: 31-10-2023 and 08-01-2024\n",
      "\n",
      "Consecutive Dates: 26-02-2021 and 06-04-2021\n",
      "Consecutive Dates: 06-04-2021 and 01-10-2021\n",
      "Consecutive Dates: 01-10-2021 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 14-10-2022\n",
      "\n",
      "Consecutive Dates: 30-09-2014 and 07-11-2014\n",
      "Consecutive Dates: 07-11-2014 and 02-12-2014\n",
      "Consecutive Dates: 02-12-2014 and 06-01-2015\n",
      "Consecutive Dates: 06-01-2015 and 05-02-2015\n",
      "Consecutive Dates: 05-02-2015 and 07-03-2015\n",
      "Consecutive Dates: 07-03-2015 and 07-04-2015\n",
      "Consecutive Dates: 07-04-2015 and 09-05-2015\n",
      "Consecutive Dates: 09-05-2015 and 08-06-2015\n",
      "Consecutive Dates: 08-06-2015 and 08-07-2015\n",
      "Consecutive Dates: 08-07-2015 and 06-08-2015\n",
      "Consecutive Dates: 06-08-2015 and 04-09-2015\n",
      "Consecutive Dates: 04-09-2015 and 05-10-2015\n",
      "Consecutive Dates: 05-10-2015 and 02-11-2015\n",
      "Consecutive Dates: 02-11-2015 and 17-12-2015\n",
      "Consecutive Dates: 17-12-2015 and 16-01-2016\n",
      "Consecutive Dates: 16-01-2016 and 13-02-2016\n",
      "Consecutive Dates: 13-02-2016 and 14-03-2016\n",
      "Consecutive Dates: 14-03-2016 and 12-05-2016\n",
      "Consecutive Dates: 12-05-2016 and 11-06-2016\n",
      "Consecutive Dates: 11-06-2016 and 12-07-2016\n",
      "Consecutive Dates: 12-07-2016 and 11-08-2016\n",
      "Consecutive Dates: 11-08-2016 and 10-09-2016\n",
      "Consecutive Dates: 10-09-2016 and 27-09-2016\n",
      "Consecutive Dates: 27-09-2016 and 24-10-2016\n",
      "Consecutive Dates: 24-10-2016 and 24-11-2016\n",
      "Consecutive Dates: 24-11-2016 and 22-12-2016\n",
      "Consecutive Dates: 22-12-2016 and 21-01-2017\n",
      "Consecutive Dates: 21-01-2017 and 21-02-2017\n",
      "Consecutive Dates: 21-02-2017 and 23-03-2017\n",
      "Consecutive Dates: 23-03-2017 and 22-04-2017\n",
      "Consecutive Dates: 22-04-2017 and 22-05-2017\n",
      "Consecutive Dates: 22-05-2017 and 24-06-2017\n",
      "Consecutive Dates: 24-06-2017 and 27-07-2017\n",
      "Consecutive Dates: 27-07-2017 and 26-08-2017\n",
      "Consecutive Dates: 26-08-2017 and 25-09-2017\n",
      "Consecutive Dates: 25-09-2017 and 25-10-2017\n",
      "Consecutive Dates: 25-10-2017 and 23-11-2017\n",
      "Consecutive Dates: 23-11-2017 and 23-12-2017\n",
      "Consecutive Dates: 23-12-2017 and 23-01-2018\n",
      "Consecutive Dates: 23-01-2018 and 20-02-2018\n",
      "Consecutive Dates: 20-02-2018 and 26-03-2018\n",
      "Consecutive Dates: 26-03-2018 and 24-04-2018\n",
      "Consecutive Dates: 24-04-2018 and 24-05-2018\n",
      "Consecutive Dates: 24-05-2018 and 06-06-2018\n",
      "Consecutive Dates: 06-06-2018 and 05-07-2018\n",
      "Consecutive Dates: 05-07-2018 and 04-08-2018\n",
      "Consecutive Dates: 04-08-2018 and 18-09-2018\n",
      "Consecutive Dates: 18-09-2018 and 16-10-2018\n",
      "Consecutive Dates: 16-10-2018 and 15-11-2018\n",
      "Consecutive Dates: 15-11-2018 and 17-12-2018\n",
      "Consecutive Dates: 17-12-2018 and 15-01-2019\n",
      "Consecutive Dates: 15-01-2019 and 16-02-2019\n",
      "Consecutive Dates: 16-02-2019 and 18-03-2019\n",
      "Consecutive Dates: 18-03-2019 and 16-04-2019\n",
      "Consecutive Dates: 16-04-2019 and 16-05-2019\n",
      "Consecutive Dates: 16-05-2019 and 15-06-2019\n",
      "Consecutive Dates: 15-06-2019 and 16-07-2019\n",
      "Consecutive Dates: 16-07-2019 and 14-08-2019\n",
      "Consecutive Dates: 14-08-2019 and 12-09-2019\n",
      "Consecutive Dates: 12-09-2019 and 14-10-2019\n",
      "Consecutive Dates: 14-10-2019 and 12-11-2019\n",
      "Consecutive Dates: 12-11-2019 and 16-12-2019\n",
      "Consecutive Dates: 16-12-2019 and 15-01-2020\n",
      "Consecutive Dates: 15-01-2020 and 15-02-2020\n",
      "Consecutive Dates: 15-02-2020 and 16-03-2020\n",
      "Consecutive Dates: 16-03-2020 and 24-04-2020\n",
      "Consecutive Dates: 24-04-2020 and 18-06-2020\n",
      "Consecutive Dates: 18-06-2020 and 21-07-2020\n",
      "Consecutive Dates: 21-07-2020 and 28-08-2020\n",
      "Consecutive Dates: 28-08-2020 and 28-09-2020\n",
      "Consecutive Dates: 28-09-2020 and 20-11-2020\n",
      "Consecutive Dates: 20-11-2020 and 21-12-2020\n",
      "Consecutive Dates: 21-12-2020 and 04-09-2021\n",
      "Consecutive Dates: 04-09-2021 and 11-10-2021\n",
      "Consecutive Dates: 11-10-2021 and 01-11-2021\n",
      "Consecutive Dates: 01-11-2021 and 03-12-2021\n",
      "Consecutive Dates: 03-12-2021 and 10-01-2022\n",
      "Consecutive Dates: 10-01-2022 and 11-02-2022\n",
      "Consecutive Dates: 11-02-2022 and 11-03-2022\n",
      "Consecutive Dates: 11-03-2022 and 15-04-2022\n",
      "Consecutive Dates: 15-04-2022 and 15-05-2022\n",
      "Consecutive Dates: 15-05-2022 and 18-06-2022\n",
      "Consecutive Dates: 18-06-2022 and 20-07-2022\n",
      "Consecutive Dates: 20-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 13-10-2022\n",
      "\n",
      "Consecutive Dates: 16-05-2020 and 16-06-2020\n",
      "Consecutive Dates: 16-06-2020 and 09-01-2021\n",
      "Consecutive Dates: 09-01-2021 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 12-06-2023\n",
      "Consecutive Dates: 12-06-2023 and 24-07-2023\n",
      "Consecutive Dates: 24-07-2023 and 23-08-2023\n",
      "\n",
      "Consecutive Dates: 31-05-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 04-11-2022\n",
      "Consecutive Dates: 04-11-2022 and 09-12-2022\n",
      "\n",
      "Consecutive Dates: 30-06-2022 and 04-07-2022\n",
      "Consecutive Dates: 04-07-2022 and 29-07-2022\n",
      "Consecutive Dates: 29-07-2022 and 05-08-2022\n",
      "Consecutive Dates: 05-08-2022 and 19-08-2022\n",
      "Consecutive Dates: 19-08-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 11-10-2022\n",
      "Consecutive Dates: 11-10-2022 and 13-10-2022\n",
      "Consecutive Dates: 13-10-2022 and 11-11-2022\n",
      "Consecutive Dates: 11-11-2022 and 07-02-2023\n",
      "Consecutive Dates: 07-02-2023 and 24-03-2023\n",
      "Consecutive Dates: 24-03-2023 and 23-06-2023\n",
      "Consecutive Dates: 23-06-2023 and 14-07-2023\n",
      "Consecutive Dates: 14-07-2023 and 28-07-2023\n",
      "Consecutive Dates: 28-07-2023 and 15-09-2023\n",
      "\n",
      "Consecutive Dates: 26-08-2022 and 24-09-2022\n",
      "Consecutive Dates: 24-09-2022 and 26-10-2022\n",
      "Consecutive Dates: 26-10-2022 and 18-11-2022\n",
      "Consecutive Dates: 18-11-2022 and 21-07-2023\n",
      "Consecutive Dates: 21-07-2023 and 18-08-2023\n",
      "\n",
      "Consecutive Dates: 07-06-2019 and 21-06-2019\n",
      "Consecutive Dates: 21-06-2019 and 22-07-2019\n",
      "Consecutive Dates: 22-07-2019 and 22-08-2019\n",
      "Consecutive Dates: 22-08-2019 and 11-11-2019\n",
      "Consecutive Dates: 11-11-2019 and 09-12-2019\n",
      "Consecutive Dates: 09-12-2019 and 06-01-2020\n",
      "Consecutive Dates: 06-01-2020 and 05-03-2021\n",
      "Consecutive Dates: 05-03-2021 and 12-03-2021\n",
      "Consecutive Dates: 12-03-2021 and 20-04-2021\n",
      "Consecutive Dates: 20-04-2021 and 11-05-2021\n",
      "Consecutive Dates: 11-05-2021 and 09-08-2021\n",
      "Consecutive Dates: 09-08-2021 and 22-10-2021\n",
      "Consecutive Dates: 22-10-2021 and 14-02-2022\n",
      "Consecutive Dates: 14-02-2022 and 06-05-2022\n",
      "Consecutive Dates: 06-05-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 31-10-2022\n",
      "Consecutive Dates: 31-10-2022 and 23-01-2023\n",
      "Consecutive Dates: 23-01-2023 and 07-04-2023\n",
      "Consecutive Dates: 07-04-2023 and 30-06-2023\n",
      "Consecutive Dates: 30-06-2023 and 29-09-2023\n",
      "Consecutive Dates: 29-09-2023 and 01-12-2023\n",
      "Consecutive Dates: 01-12-2023 and 05-02-2024\n",
      "\n",
      "Consecutive Dates: 07-08-2022 and 17-08-2022\n",
      "Consecutive Dates: 17-08-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 21-09-2022\n",
      "Consecutive Dates: 21-09-2022 and 11-11-2022\n",
      "Consecutive Dates: 11-11-2022 and 18-11-2022\n",
      "Consecutive Dates: 18-11-2022 and 25-11-2022\n",
      "Consecutive Dates: 25-11-2022 and 02-12-2022\n",
      "Consecutive Dates: 02-12-2022 and 09-12-2022\n",
      "Consecutive Dates: 09-12-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 13-01-2023\n",
      "Consecutive Dates: 13-01-2023 and 19-01-2023\n",
      "Consecutive Dates: 19-01-2023 and 31-01-2023\n",
      "Consecutive Dates: 31-01-2023 and 07-02-2023\n",
      "Consecutive Dates: 07-02-2023 and 24-02-2023\n",
      "Consecutive Dates: 24-02-2023 and 01-04-2023\n",
      "Consecutive Dates: 01-04-2023 and 28-04-2023\n",
      "Consecutive Dates: 28-04-2023 and 30-05-2023\n",
      "Consecutive Dates: 30-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 29-07-2023\n",
      "Consecutive Dates: 29-07-2023 and 31-08-2023\n",
      "Consecutive Dates: 31-08-2023 and 28-09-2023\n",
      "Consecutive Dates: 28-09-2023 and 30-10-2023\n",
      "Consecutive Dates: 30-10-2023 and 25-11-2023\n",
      "Consecutive Dates: 25-11-2023 and 21-12-2023\n",
      "Consecutive Dates: 21-12-2023 and 29-01-2024\n",
      "\n",
      "Consecutive Dates: 28-03-2022 and 13-07-2022\n",
      "Consecutive Dates: 13-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 11-10-2022\n",
      "Consecutive Dates: 11-10-2022 and 15-05-2023\n",
      "Consecutive Dates: 15-05-2023 and 31-07-2023\n",
      "Consecutive Dates: 31-07-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 03-10-2023\n",
      "Consecutive Dates: 03-10-2023 and 01-11-2023\n",
      "Consecutive Dates: 01-11-2023 and 04-12-2023\n",
      "\n",
      "Consecutive Dates: 08-06-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 19-12-2022\n",
      "Consecutive Dates: 19-12-2022 and 23-01-2023\n",
      "Consecutive Dates: 23-01-2023 and 02-11-2023\n",
      "\n",
      "Consecutive Dates: 28-08-2021 and 15-07-2022\n",
      "Consecutive Dates: 15-07-2022 and 17-08-2022\n",
      "\n",
      "Consecutive Dates: 29-06-2020 and 21-08-2020\n",
      "Consecutive Dates: 21-08-2020 and 30-08-2020\n",
      "Consecutive Dates: 30-08-2020 and 31-10-2020\n",
      "Consecutive Dates: 31-10-2020 and 03-12-2020\n",
      "Consecutive Dates: 03-12-2020 and 04-01-2021\n",
      "Consecutive Dates: 04-01-2021 and 19-01-2021\n",
      "Consecutive Dates: 19-01-2021 and 02-02-2021\n",
      "Consecutive Dates: 02-02-2021 and 10-03-2021\n",
      "Consecutive Dates: 10-03-2021 and 12-04-2021\n",
      "Consecutive Dates: 12-04-2021 and 28-08-2021\n",
      "Consecutive Dates: 28-08-2021 and 22-10-2021\n",
      "Consecutive Dates: 22-10-2021 and 24-11-2021\n",
      "Consecutive Dates: 24-11-2021 and 07-02-2022\n",
      "Consecutive Dates: 07-02-2022 and 17-02-2022\n",
      "Consecutive Dates: 17-02-2022 and 25-02-2022\n",
      "Consecutive Dates: 25-02-2022 and 07-03-2022\n",
      "Consecutive Dates: 07-03-2022 and 04-04-2022\n",
      "Consecutive Dates: 04-04-2022 and 21-06-2022\n",
      "Consecutive Dates: 21-06-2022 and 24-08-2022\n",
      "Consecutive Dates: 24-08-2022 and 24-09-2022\n",
      "Consecutive Dates: 24-09-2022 and 16-11-2022\n",
      "\n",
      "Consecutive Dates: 16-05-2019 and 14-08-2019\n",
      "Consecutive Dates: 14-08-2019 and 03-02-2020\n",
      "Consecutive Dates: 03-02-2020 and 06-02-2020\n",
      "Consecutive Dates: 06-02-2020 and 19-06-2020\n",
      "Consecutive Dates: 19-06-2020 and 17-07-2020\n",
      "Consecutive Dates: 17-07-2020 and 21-08-2020\n",
      "Consecutive Dates: 21-08-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 19-12-2020\n",
      "Consecutive Dates: 19-12-2020 and 18-02-2021\n",
      "Consecutive Dates: 18-02-2021 and 27-02-2021\n",
      "Consecutive Dates: 27-02-2021 and 28-08-2021\n",
      "Consecutive Dates: 28-08-2021 and 29-10-2021\n",
      "Consecutive Dates: 29-10-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 21-03-2022\n",
      "Consecutive Dates: 21-03-2022 and 25-05-2022\n",
      "Consecutive Dates: 25-05-2022 and 02-07-2022\n",
      "Consecutive Dates: 02-07-2022 and 13-08-2022\n",
      "Consecutive Dates: 13-08-2022 and 13-09-2022\n",
      "Consecutive Dates: 13-09-2022 and 12-10-2022\n",
      "Consecutive Dates: 12-10-2022 and 12-11-2022\n",
      "Consecutive Dates: 12-11-2022 and 13-12-2022\n",
      "Consecutive Dates: 13-12-2022 and 12-01-2023\n",
      "Consecutive Dates: 12-01-2023 and 08-02-2023\n",
      "Consecutive Dates: 08-02-2023 and 05-08-2023\n",
      "\n",
      "Consecutive Dates: 16-05-2018 and 15-06-2018\n",
      "Consecutive Dates: 15-06-2018 and 16-07-2018\n",
      "Consecutive Dates: 16-07-2018 and 16-08-2018\n",
      "Consecutive Dates: 16-08-2018 and 15-09-2018\n",
      "Consecutive Dates: 15-09-2018 and 15-11-2018\n",
      "Consecutive Dates: 15-11-2018 and 05-03-2019\n",
      "Consecutive Dates: 05-03-2019 and 03-04-2019\n",
      "Consecutive Dates: 03-04-2019 and 02-05-2019\n",
      "Consecutive Dates: 02-05-2019 and 27-05-2019\n",
      "Consecutive Dates: 27-05-2019 and 27-06-2019\n",
      "Consecutive Dates: 27-06-2019 and 27-07-2019\n",
      "Consecutive Dates: 27-07-2019 and 27-08-2019\n",
      "Consecutive Dates: 27-08-2019 and 31-08-2019\n",
      "Consecutive Dates: 31-08-2019 and 13-09-2019\n",
      "Consecutive Dates: 13-09-2019 and 26-10-2019\n",
      "Consecutive Dates: 26-10-2019 and 27-12-2019\n",
      "Consecutive Dates: 27-12-2019 and 27-01-2020\n",
      "Consecutive Dates: 27-01-2020 and 29-02-2020\n",
      "Consecutive Dates: 29-02-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 16-12-2020\n",
      "Consecutive Dates: 16-12-2020 and 03-05-2022\n",
      "Consecutive Dates: 03-05-2022 and 19-05-2022\n",
      "Consecutive Dates: 19-05-2022 and 17-06-2022\n",
      "Consecutive Dates: 17-06-2022 and 16-07-2022\n",
      "Consecutive Dates: 16-07-2022 and 09-08-2022\n",
      "Consecutive Dates: 09-08-2022 and 03-09-2022\n",
      "Consecutive Dates: 03-09-2022 and 03-10-2022\n",
      "Consecutive Dates: 03-10-2022 and 02-11-2022\n",
      "Consecutive Dates: 02-11-2022 and 06-12-2022\n",
      "Consecutive Dates: 06-12-2022 and 04-01-2023\n",
      "Consecutive Dates: 04-01-2023 and 09-02-2023\n",
      "Consecutive Dates: 09-02-2023 and 09-03-2023\n",
      "Consecutive Dates: 09-03-2023 and 03-04-2023\n",
      "Consecutive Dates: 03-04-2023 and 24-04-2023\n",
      "Consecutive Dates: 24-04-2023 and 05-06-2023\n",
      "Consecutive Dates: 05-06-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 06-09-2023\n",
      "Consecutive Dates: 06-09-2023 and 05-10-2023\n",
      "Consecutive Dates: 05-10-2023 and 04-11-2023\n",
      "Consecutive Dates: 04-11-2023 and 04-12-2023\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for i in df2['frequency of follow up at lgb (to write down follow-up dates)']:\n",
    "    print()\n",
    "    k=k+1\n",
    "    a = extract_consecutive_dates(i)\n",
    "    for pair in a:\n",
    "        #um = sum +  calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\n",
    "        #rint(sum)\n",
    "        print(f\"Consecutive Dates: {pair[0].strftime('%d-%m-%Y')} and {pair[1].strftime('%d-%m-%Y')}\")\n",
    "        \n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "694c45e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days between 29-07-2019 and 24-06-2019: 35 days\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def calculate_days_difference(date1_str, date2_str, date_format=\"%d-%m-%Y\"):\n",
    "    date1 = datetime.strptime(date1_str, date_format)\n",
    "    date2 = datetime.strptime(date2_str, date_format)\n",
    "\n",
    "    days_difference = abs((date2 - date1).days)\n",
    "\n",
    "    return days_difference\n",
    "\n",
    "date2_str = \"24-06-2019\"\n",
    "date1_str = \"29-07-2019\"\n",
    "result = calculate_days_difference(date1_str, date2_str)\n",
    "\n",
    "print(f\"Number of days between {date1_str} and {date2_str}: {result} days\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7a312260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consecutive Dates: 24-06-2019 and 29-07-2019\n",
      "Consecutive Dates: 29-07-2019 and 09-09-2019\n",
      "Consecutive Dates: 09-09-2019 and 21-10-2019\n",
      "Consecutive Dates: 21-10-2019 and 17-12-2019\n",
      "Consecutive Dates: 17-12-2019 and 18-01-2020\n",
      "Consecutive Dates: 18-01-2020 and 02-03-2020\n",
      "Consecutive Dates: 02-03-2020 and 02-05-2020\n",
      "Consecutive Dates: 02-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 28-08-2020\n",
      "Consecutive Dates: 28-08-2020 and 17-11-2020\n",
      "Consecutive Dates: 17-11-2020 and 21-01-2021\n",
      "577\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sum_days' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [140], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsecutive Dates: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     df2\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_days\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msum_days\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(k)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sum_days' is not defined"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for i in df2['frequency of follow up at lgb (to write down follow-up dates)']:\n",
    "    print()\n",
    "    k=k+1\n",
    "    a = extract_consecutive_dates(i)\n",
    "    sum = 0\n",
    "    for pair in a:\n",
    "        b = calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\n",
    "        sum=sum+b\n",
    "        print(f\"Consecutive Dates: {pair[0].strftime('%d-%m-%Y')} and {pair[1].strftime('%d-%m-%Y')}\")\n",
    "    print(sum)\n",
    "    df2.at[i, 'total_days'] = sum_days\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1dcdecee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'total_days'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'total_days'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [141], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_days\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'total_days'"
     ]
    }
   ],
   "source": [
    "for i in df2['total_days']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5a2be172",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['total_days'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [142], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_days\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5388\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5240\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5249\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5251\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5386\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5390\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5394\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5395\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5396\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6975\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6975\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6976\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['total_days'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df2 = df2.drop('total_days', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "29650458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consecutive Dates: 24-06-2019 and 29-07-2019\n",
      "Consecutive Dates: 29-07-2019 and 09-09-2019\n",
      "Consecutive Dates: 09-09-2019 and 21-10-2019\n",
      "Consecutive Dates: 21-10-2019 and 17-12-2019\n",
      "Consecutive Dates: 17-12-2019 and 18-01-2020\n",
      "Consecutive Dates: 18-01-2020 and 02-03-2020\n",
      "Consecutive Dates: 02-03-2020 and 02-05-2020\n",
      "Consecutive Dates: 02-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 28-08-2020\n",
      "Consecutive Dates: 28-08-2020 and 17-11-2020\n",
      "Consecutive Dates: 17-11-2020 and 21-01-2021\n",
      "577\n",
      "\n",
      "Consecutive Dates: 31-03-2014 and 29-04-2014\n",
      "Consecutive Dates: 29-04-2014 and 29-05-2014\n",
      "Consecutive Dates: 29-05-2014 and 04-07-2014\n",
      "Consecutive Dates: 04-07-2014 and 25-08-2014\n",
      "Consecutive Dates: 25-08-2014 and 01-02-2016\n",
      "Consecutive Dates: 01-02-2016 and 30-03-2016\n",
      "Consecutive Dates: 30-03-2016 and 29-04-2016\n",
      "Consecutive Dates: 29-04-2016 and 03-06-2016\n",
      "Consecutive Dates: 03-06-2016 and 28-08-2016\n",
      "Consecutive Dates: 28-08-2016 and 08-08-2016\n",
      "Consecutive Dates: 08-08-2016 and 08-09-2016\n",
      "Consecutive Dates: 08-09-2016 and 05-10-2016\n",
      "Consecutive Dates: 05-10-2016 and 09-11-2016\n",
      "Consecutive Dates: 09-11-2016 and 16-12-2016\n",
      "Consecutive Dates: 16-12-2016 and 23-01-2017\n",
      "Consecutive Dates: 23-01-2017 and 22-02-2017\n",
      "Consecutive Dates: 22-02-2017 and 10-03-2017\n",
      "Consecutive Dates: 10-03-2017 and 21-04-2017\n",
      "Consecutive Dates: 21-04-2017 and 25-05-2017\n",
      "Consecutive Dates: 25-05-2017 and 22-06-2017\n",
      "Consecutive Dates: 22-06-2017 and 20-07-2017\n",
      "Consecutive Dates: 20-07-2017 and 03-10-2017\n",
      "Consecutive Dates: 03-10-2017 and 02-11-2017\n",
      "Consecutive Dates: 02-11-2017 and 06-01-2018\n",
      "Consecutive Dates: 06-01-2018 and 05-02-2018\n",
      "Consecutive Dates: 05-02-2018 and 08-03-2018\n",
      "Consecutive Dates: 08-03-2018 and 07-04-2018\n",
      "Consecutive Dates: 07-04-2018 and 05-05-2018\n",
      "Consecutive Dates: 05-05-2018 and 07-06-2018\n",
      "Consecutive Dates: 07-06-2018 and 09-08-2018\n",
      "Consecutive Dates: 09-08-2018 and 12-09-2018\n",
      "Consecutive Dates: 12-09-2018 and 09-10-2018\n",
      "Consecutive Dates: 09-10-2018 and 12-11-2018\n",
      "Consecutive Dates: 12-11-2018 and 19-12-2018\n",
      "Consecutive Dates: 19-12-2018 and 17-01-2019\n",
      "Consecutive Dates: 17-01-2019 and 13-06-2019\n",
      "Consecutive Dates: 13-06-2019 and 13-07-2019\n",
      "Consecutive Dates: 13-07-2019 and 17-08-2019\n",
      "Consecutive Dates: 17-08-2019 and 17-08-2019\n",
      "Consecutive Dates: 17-08-2019 and 20-10-2019\n",
      "Consecutive Dates: 20-10-2019 and 03-01-2020\n",
      "Consecutive Dates: 03-01-2020 and 06-03-2020\n",
      "Consecutive Dates: 06-03-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 02-04-2021\n",
      "Consecutive Dates: 02-04-2021 and 10-05-2021\n",
      "Consecutive Dates: 10-05-2021 and 06-08-2021\n",
      "Consecutive Dates: 06-08-2021 and 07-09-2021\n",
      "Consecutive Dates: 07-09-2021 and 13-11-2021\n",
      "Consecutive Dates: 13-11-2021 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 19-03-2022\n",
      "Consecutive Dates: 19-03-2022 and 30-05-2022\n",
      "Consecutive Dates: 30-05-2022 and 04-07-2022\n",
      "Consecutive Dates: 04-07-2022 and 09-08-2022\n",
      "Consecutive Dates: 09-08-2022 and 13-09-2022\n",
      "Consecutive Dates: 13-09-2022 and 27-10-2022\n",
      "Consecutive Dates: 27-10-2022 and 28-11-2022\n",
      "Consecutive Dates: 28-11-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 13-02-2023\n",
      "Consecutive Dates: 13-02-2023 and 22-03-2023\n",
      "Consecutive Dates: 22-03-2023 and 26-04-2023\n",
      "Consecutive Dates: 26-04-2023 and 05-06-2023\n",
      "Consecutive Dates: 05-06-2023 and 17-07-2023\n",
      "Consecutive Dates: 17-07-2023 and 24-08-2023\n",
      "Consecutive Dates: 24-08-2023 and 25-09-2023\n",
      "Consecutive Dates: 25-09-2023 and 06-11-2023\n",
      "3547\n",
      "\n",
      "Consecutive Dates: 31-03-2014 and 29-04-2014\n",
      "Consecutive Dates: 29-04-2014 and 29-05-2014\n",
      "Consecutive Dates: 29-05-2014 and 04-07-2014\n",
      "Consecutive Dates: 04-07-2014 and 25-08-2014\n",
      "Consecutive Dates: 25-08-2014 and 01-02-2016\n",
      "Consecutive Dates: 01-02-2016 and 30-03-2016\n",
      "Consecutive Dates: 30-03-2016 and 29-04-2016\n",
      "Consecutive Dates: 29-04-2016 and 03-06-2016\n",
      "Consecutive Dates: 03-06-2016 and 28-08-2016\n",
      "Consecutive Dates: 28-08-2016 and 08-08-2016\n",
      "Consecutive Dates: 08-08-2016 and 08-09-2016\n",
      "Consecutive Dates: 08-09-2016 and 05-10-2016\n",
      "Consecutive Dates: 05-10-2016 and 09-11-2016\n",
      "Consecutive Dates: 09-11-2016 and 16-12-2016\n",
      "Consecutive Dates: 16-12-2016 and 23-01-2017\n",
      "Consecutive Dates: 23-01-2017 and 22-02-2017\n",
      "Consecutive Dates: 22-02-2017 and 10-03-2017\n",
      "Consecutive Dates: 10-03-2017 and 21-04-2017\n",
      "Consecutive Dates: 21-04-2017 and 25-05-2017\n",
      "Consecutive Dates: 25-05-2017 and 22-06-2017\n",
      "Consecutive Dates: 22-06-2017 and 20-07-2017\n",
      "Consecutive Dates: 20-07-2017 and 03-10-2017\n",
      "Consecutive Dates: 03-10-2017 and 02-11-2017\n",
      "Consecutive Dates: 02-11-2017 and 06-01-2018\n",
      "Consecutive Dates: 06-01-2018 and 05-02-2018\n",
      "Consecutive Dates: 05-02-2018 and 08-03-2018\n",
      "Consecutive Dates: 08-03-2018 and 07-04-2018\n",
      "Consecutive Dates: 07-04-2018 and 05-05-2018\n",
      "Consecutive Dates: 05-05-2018 and 07-06-2018\n",
      "Consecutive Dates: 07-06-2018 and 09-08-2018\n",
      "Consecutive Dates: 09-08-2018 and 12-09-2018\n",
      "Consecutive Dates: 12-09-2018 and 09-10-2018\n",
      "Consecutive Dates: 09-10-2018 and 12-11-2018\n",
      "Consecutive Dates: 12-11-2018 and 19-12-2018\n",
      "Consecutive Dates: 19-12-2018 and 17-01-2019\n",
      "Consecutive Dates: 17-01-2019 and 13-06-2019\n",
      "Consecutive Dates: 13-06-2019 and 13-07-2019\n",
      "Consecutive Dates: 13-07-2019 and 17-08-2019\n",
      "Consecutive Dates: 17-08-2019 and 17-08-2019\n",
      "Consecutive Dates: 17-08-2019 and 20-10-2019\n",
      "Consecutive Dates: 20-10-2019 and 30-11-2019\n",
      "Consecutive Dates: 30-11-2019 and 03-01-2020\n",
      "Consecutive Dates: 03-01-2020 and 06-03-2020\n",
      "Consecutive Dates: 06-03-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 02-04-2021\n",
      "Consecutive Dates: 02-04-2021 and 10-05-2021\n",
      "Consecutive Dates: 10-05-2021 and 06-08-2021\n",
      "Consecutive Dates: 06-08-2021 and 07-09-2021\n",
      "Consecutive Dates: 07-09-2021 and 13-11-2021\n",
      "Consecutive Dates: 13-11-2021 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 19-03-2022\n",
      "Consecutive Dates: 19-03-2022 and 30-05-2022\n",
      "Consecutive Dates: 30-05-2022 and 04-07-2022\n",
      "Consecutive Dates: 04-07-2022 and 09-08-2022\n",
      "Consecutive Dates: 09-08-2022 and 13-09-2022\n",
      "Consecutive Dates: 13-09-2022 and 27-10-2022\n",
      "Consecutive Dates: 27-10-2022 and 28-11-2022\n",
      "Consecutive Dates: 28-11-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 13-02-2023\n",
      "Consecutive Dates: 13-02-2023 and 22-03-2023\n",
      "Consecutive Dates: 22-03-2023 and 26-04-2023\n",
      "Consecutive Dates: 26-04-2023 and 05-06-2023\n",
      "Consecutive Dates: 05-06-2023 and 17-07-2023\n",
      "Consecutive Dates: 17-07-2023 and 24-08-2023\n",
      "Consecutive Dates: 24-08-2023 and 25-09-2023\n",
      "Consecutive Dates: 25-09-2023 and 06-11-2023\n",
      "3547\n",
      "\n",
      "Consecutive Dates: 22-06-2020 and 30-09-2020\n",
      "100\n",
      "\n",
      "Consecutive Dates: 10-06-2015 and 22-06-2015\n",
      "Consecutive Dates: 22-06-2015 and 15-07-2015\n",
      "Consecutive Dates: 15-07-2015 and 29-07-2015\n",
      "Consecutive Dates: 29-07-2015 and 26-05-2015\n",
      "Consecutive Dates: 26-05-2015 and 23-09-2015\n",
      "Consecutive Dates: 23-09-2015 and 21-10-2015\n",
      "Consecutive Dates: 21-10-2015 and 11-11-2015\n",
      "Consecutive Dates: 11-11-2015 and 21-12-2015\n",
      "Consecutive Dates: 21-12-2015 and 25-01-2016\n",
      "Consecutive Dates: 25-01-2016 and 16-03-2016\n",
      "Consecutive Dates: 16-03-2016 and 18-05-2016\n",
      "Consecutive Dates: 18-05-2016 and 20-07-2016\n",
      "Consecutive Dates: 20-07-2016 and 07-09-2016\n",
      "Consecutive Dates: 07-09-2016 and 26-10-2016\n",
      "Consecutive Dates: 26-10-2016 and 28-12-2016\n",
      "Consecutive Dates: 28-12-2016 and 27-01-2017\n",
      "Consecutive Dates: 27-01-2017 and 22-02-2017\n",
      "Consecutive Dates: 22-02-2017 and 17-03-2017\n",
      "Consecutive Dates: 17-03-2017 and 14-04-2017\n",
      "Consecutive Dates: 14-04-2017 and 12-05-2017\n",
      "Consecutive Dates: 12-05-2017 and 26-06-2017\n",
      "Consecutive Dates: 26-06-2017 and 13-09-2017\n",
      "Consecutive Dates: 13-09-2017 and 11-10-2017\n",
      "Consecutive Dates: 11-10-2017 and 15-11-2017\n",
      "Consecutive Dates: 15-11-2017 and 15-12-2017\n",
      "Consecutive Dates: 15-12-2017 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 02-04-2018\n",
      "Consecutive Dates: 02-04-2018 and 09-05-2018\n",
      "Consecutive Dates: 09-05-2018 and 31-05-2018\n",
      "Consecutive Dates: 31-05-2018 and 27-06-2018\n",
      "Consecutive Dates: 27-06-2018 and 04-08-2018\n",
      "Consecutive Dates: 04-08-2018 and 24-09-2018\n",
      "Consecutive Dates: 24-09-2018 and 05-11-2018\n",
      "Consecutive Dates: 05-11-2018 and 14-12-2018\n",
      "Consecutive Dates: 14-12-2018 and 15-01-2019\n",
      "Consecutive Dates: 15-01-2019 and 12-02-2019\n",
      "Consecutive Dates: 12-02-2019 and 12-04-2019\n",
      "Consecutive Dates: 12-04-2019 and 25-05-2019\n",
      "Consecutive Dates: 25-05-2019 and 16-07-2019\n",
      "Consecutive Dates: 16-07-2019 and 20-08-2019\n",
      "Consecutive Dates: 20-08-2019 and 21-09-2019\n",
      "Consecutive Dates: 21-09-2019 and 21-10-2019\n",
      "Consecutive Dates: 21-10-2019 and 18-11-2019\n",
      "Consecutive Dates: 18-11-2019 and 20-12-2019\n",
      "Consecutive Dates: 20-12-2019 and 25-01-2020\n",
      "Consecutive Dates: 25-01-2020 and 24-02-2020\n",
      "Consecutive Dates: 24-02-2020 and 20-03-2020\n",
      "Consecutive Dates: 20-03-2020 and 19-05-2020\n",
      "Consecutive Dates: 19-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 28-07-2020\n",
      "Consecutive Dates: 28-07-2020 and 20-10-2020\n",
      "Consecutive Dates: 20-10-2020 and 01-11-2020\n",
      "Consecutive Dates: 01-11-2020 and 22-12-2020\n",
      "Consecutive Dates: 22-12-2020 and 19-01-2021\n",
      "Consecutive Dates: 19-01-2021 and 19-02-2021\n",
      "Consecutive Dates: 19-02-2021 and 19-03-2021\n",
      "Consecutive Dates: 19-03-2021 and 12-04-2021\n",
      "Consecutive Dates: 12-04-2021 and 08-05-2021\n",
      "Consecutive Dates: 08-05-2021 and 19-07-2021\n",
      "Consecutive Dates: 19-07-2021 and 13-08-2021\n",
      "Consecutive Dates: 13-08-2021 and 11-10-2021\n",
      "Consecutive Dates: 11-10-2021 and 16-11-2021\n",
      "Consecutive Dates: 16-11-2021 and 17-12-2021\n",
      "Consecutive Dates: 17-12-2021 and 11-01-2022\n",
      "Consecutive Dates: 11-01-2022 and 15-03-2021\n",
      "Consecutive Dates: 15-03-2021 and 12-04-2022\n",
      "Consecutive Dates: 12-04-2022 and 13-06-2022\n",
      "Consecutive Dates: 13-06-2022 and 16-07-2022\n",
      "Consecutive Dates: 16-07-2022 and 16-08-2022\n",
      "Consecutive Dates: 16-08-2022 and 14-11-2022\n",
      "Consecutive Dates: 14-11-2022 and 24-01-2023\n",
      "Consecutive Dates: 24-01-2023 and 28-02-2023\n",
      "Consecutive Dates: 28-02-2023 and 01-04-2023\n",
      "Consecutive Dates: 01-04-2023 and 29-05-2023\n",
      "Consecutive Dates: 29-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 18-08-2023\n",
      "Consecutive Dates: 18-08-2023 and 26-09-2023\n",
      "Consecutive Dates: 26-09-2023 and 07-11-2023\n",
      "3804\n",
      "\n",
      "Consecutive Dates: 10-06-2015 and 22-06-2015\n",
      "Consecutive Dates: 22-06-2015 and 15-07-2015\n",
      "Consecutive Dates: 15-07-2015 and 29-07-2015\n",
      "Consecutive Dates: 29-07-2015 and 26-05-2015\n",
      "Consecutive Dates: 26-05-2015 and 23-09-2015\n",
      "Consecutive Dates: 23-09-2015 and 21-10-2015\n",
      "Consecutive Dates: 21-10-2015 and 11-11-2015\n",
      "Consecutive Dates: 11-11-2015 and 21-12-2015\n",
      "Consecutive Dates: 21-12-2015 and 25-01-2016\n",
      "Consecutive Dates: 25-01-2016 and 16-03-2016\n",
      "Consecutive Dates: 16-03-2016 and 18-05-2016\n",
      "Consecutive Dates: 18-05-2016 and 20-07-2016\n",
      "Consecutive Dates: 20-07-2016 and 07-09-2016\n",
      "Consecutive Dates: 07-09-2016 and 26-10-2016\n",
      "Consecutive Dates: 26-10-2016 and 28-12-2016\n",
      "Consecutive Dates: 28-12-2016 and 27-01-2017\n",
      "Consecutive Dates: 27-01-2017 and 22-02-2017\n",
      "Consecutive Dates: 22-02-2017 and 17-03-2017\n",
      "Consecutive Dates: 17-03-2017 and 14-04-2017\n",
      "Consecutive Dates: 14-04-2017 and 12-05-2017\n",
      "Consecutive Dates: 12-05-2017 and 26-06-2017\n",
      "Consecutive Dates: 26-06-2017 and 13-09-2017\n",
      "Consecutive Dates: 13-09-2017 and 11-10-2017\n",
      "Consecutive Dates: 11-10-2017 and 15-11-2017\n",
      "Consecutive Dates: 15-11-2017 and 15-12-2017\n",
      "Consecutive Dates: 15-12-2017 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 02-04-2018\n",
      "Consecutive Dates: 02-04-2018 and 09-05-2018\n",
      "Consecutive Dates: 09-05-2018 and 31-05-2018\n",
      "Consecutive Dates: 31-05-2018 and 27-06-2018\n",
      "Consecutive Dates: 27-06-2018 and 04-08-2018\n",
      "Consecutive Dates: 04-08-2018 and 24-09-2018\n",
      "Consecutive Dates: 24-09-2018 and 05-11-2018\n",
      "Consecutive Dates: 05-11-2018 and 14-12-2018\n",
      "Consecutive Dates: 14-12-2018 and 15-01-2019\n",
      "Consecutive Dates: 15-01-2019 and 12-02-2019\n",
      "Consecutive Dates: 12-02-2019 and 12-04-2019\n",
      "Consecutive Dates: 12-04-2019 and 25-05-2019\n",
      "Consecutive Dates: 25-05-2019 and 16-07-2019\n",
      "Consecutive Dates: 16-07-2019 and 20-08-2019\n",
      "Consecutive Dates: 20-08-2019 and 21-09-2019\n",
      "Consecutive Dates: 21-09-2019 and 21-10-2019\n",
      "Consecutive Dates: 21-10-2019 and 18-11-2019\n",
      "Consecutive Dates: 18-11-2019 and 20-12-2019\n",
      "Consecutive Dates: 20-12-2019 and 25-01-2020\n",
      "Consecutive Dates: 25-01-2020 and 24-02-2020\n",
      "Consecutive Dates: 24-02-2020 and 20-03-2020\n",
      "Consecutive Dates: 20-03-2020 and 19-05-2020\n",
      "Consecutive Dates: 19-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 28-07-2020\n",
      "Consecutive Dates: 28-07-2020 and 20-10-2020\n",
      "Consecutive Dates: 20-10-2020 and 22-12-2020\n",
      "Consecutive Dates: 22-12-2020 and 19-01-2021\n",
      "Consecutive Dates: 19-01-2021 and 19-02-2021\n",
      "Consecutive Dates: 19-02-2021 and 19-03-2021\n",
      "Consecutive Dates: 19-03-2021 and 12-04-2021\n",
      "Consecutive Dates: 12-04-2021 and 08-05-2021\n",
      "Consecutive Dates: 08-05-2021 and 19-07-2021\n",
      "Consecutive Dates: 19-07-2021 and 13-08-2021\n",
      "Consecutive Dates: 13-08-2021 and 11-10-2021\n",
      "Consecutive Dates: 11-10-2021 and 16-11-2021\n",
      "Consecutive Dates: 16-11-2021 and 17-12-2021\n",
      "Consecutive Dates: 17-12-2021 and 11-01-2022\n",
      "Consecutive Dates: 11-01-2022 and 15-03-2021\n",
      "Consecutive Dates: 15-03-2021 and 12-04-2022\n",
      "Consecutive Dates: 12-04-2022 and 13-06-2022\n",
      "Consecutive Dates: 13-06-2022 and 16-07-2022\n",
      "Consecutive Dates: 16-07-2022 and 16-08-2022\n",
      "Consecutive Dates: 16-08-2022 and 14-11-2022\n",
      "Consecutive Dates: 14-11-2022 and 24-01-2023\n",
      "Consecutive Dates: 24-01-2023 and 28-02-2023\n",
      "Consecutive Dates: 28-02-2023 and 01-04-2023\n",
      "Consecutive Dates: 01-04-2023 and 29-05-2023\n",
      "Consecutive Dates: 29-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 18-08-2023\n",
      "Consecutive Dates: 18-08-2023 and 26-09-2023\n",
      "Consecutive Dates: 26-09-2023 and 07-11-2023\n",
      "3804\n",
      "\n",
      "Consecutive Dates: 08-06-2016 and 18-07-2016\n",
      "Consecutive Dates: 18-07-2016 and 19-08-2016\n",
      "Consecutive Dates: 19-08-2016 and 14-09-2016\n",
      "Consecutive Dates: 14-09-2016 and 04-10-2016\n",
      "Consecutive Dates: 04-10-2016 and 09-11-2016\n",
      "Consecutive Dates: 09-11-2016 and 09-01-2017\n",
      "Consecutive Dates: 09-01-2017 and 10-02-2017\n",
      "Consecutive Dates: 10-02-2017 and 11-03-2017\n",
      "Consecutive Dates: 11-03-2017 and 10-04-2017\n",
      "Consecutive Dates: 10-04-2017 and 11-05-2017\n",
      "Consecutive Dates: 11-05-2017 and 10-06-2017\n",
      "Consecutive Dates: 10-06-2017 and 08-07-2017\n",
      "Consecutive Dates: 08-07-2017 and 05-08-2017\n",
      "Consecutive Dates: 05-08-2017 and 04-09-2017\n",
      "Consecutive Dates: 04-09-2017 and 14-10-2017\n",
      "Consecutive Dates: 14-10-2017 and 04-12-2017\n",
      "Consecutive Dates: 04-12-2017 and 02-01-2018\n",
      "Consecutive Dates: 02-01-2018 and 02-02-2018\n",
      "Consecutive Dates: 02-02-2018 and 03-03-2018\n",
      "Consecutive Dates: 03-03-2018 and 04-04-2018\n",
      "Consecutive Dates: 04-04-2018 and 02-05-2018\n",
      "Consecutive Dates: 02-05-2018 and 02-06-2018\n",
      "Consecutive Dates: 02-06-2018 and 02-07-2018\n",
      "Consecutive Dates: 02-07-2018 and 31-07-2018\n",
      "Consecutive Dates: 31-07-2018 and 30-08-2018\n",
      "Consecutive Dates: 30-08-2018 and 28-09-2018\n",
      "Consecutive Dates: 28-09-2018 and 28-11-2018\n",
      "Consecutive Dates: 28-11-2018 and 27-12-2018\n",
      "Consecutive Dates: 27-12-2018 and 25-01-2019\n",
      "Consecutive Dates: 25-01-2019 and 26-02-2019\n",
      "Consecutive Dates: 26-02-2019 and 26-03-2019\n",
      "Consecutive Dates: 26-03-2019 and 24-04-2019\n",
      "Consecutive Dates: 24-04-2019 and 27-05-2019\n",
      "Consecutive Dates: 27-05-2019 and 27-06-2019\n",
      "Consecutive Dates: 27-06-2019 and 27-08-2019\n",
      "Consecutive Dates: 27-08-2019 and 25-09-2019\n",
      "Consecutive Dates: 25-09-2019 and 25-10-2019\n",
      "Consecutive Dates: 25-10-2019 and 25-11-2019\n",
      "Consecutive Dates: 25-11-2019 and 24-12-2019\n",
      "Consecutive Dates: 24-12-2019 and 21-01-2020\n",
      "Consecutive Dates: 21-01-2020 and 22-02-2020\n",
      "Consecutive Dates: 22-02-2020 and 23-03-2020\n",
      "Consecutive Dates: 23-03-2020 and 21-04-2020\n",
      "Consecutive Dates: 21-04-2020 and 22-05-2020\n",
      "Consecutive Dates: 22-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 09-01-2021\n",
      "Consecutive Dates: 09-01-2021 and 03-03-2021\n",
      "Consecutive Dates: 03-03-2021 and 12-04-2021\n",
      "Consecutive Dates: 12-04-2021 and 14-06-2021\n",
      "Consecutive Dates: 14-06-2021 and 08-08-2021\n",
      "Consecutive Dates: 08-08-2021 and 14-09-2021\n",
      "Consecutive Dates: 14-09-2021 and 16-10-2021\n",
      "Consecutive Dates: 16-10-2021 and 16-11-2021\n",
      "Consecutive Dates: 16-11-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 04-02-2022\n",
      "Consecutive Dates: 04-02-2022 and 05-03-2022\n",
      "Consecutive Dates: 05-03-2022 and 05-04-2022\n",
      "Consecutive Dates: 05-04-2022 and 20-05-2022\n",
      "Consecutive Dates: 20-05-2022 and 06-07-2022\n",
      "Consecutive Dates: 06-07-2022 and 03-08-2022\n",
      "Consecutive Dates: 03-08-2022 and 02-09-2022\n",
      "Consecutive Dates: 02-09-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 02-11-2022\n",
      "Consecutive Dates: 02-11-2022 and 08-12-2022\n",
      "Consecutive Dates: 08-12-2022 and 28-12-2023\n",
      "Consecutive Dates: 28-12-2023 and 04-02-2023\n",
      "Consecutive Dates: 04-02-2023 and 04-03-2023\n",
      "Consecutive Dates: 04-03-2023 and 04-05-2023\n",
      "Consecutive Dates: 04-05-2023 and 27-05-2023\n",
      "Consecutive Dates: 27-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 01-08-2023\n",
      "Consecutive Dates: 01-08-2023 and 02-09-2023\n",
      "Consecutive Dates: 02-09-2023 and 03-10-2023\n",
      "Consecutive Dates: 03-10-2023 and 01-11-2023\n",
      "3356\n",
      "\n",
      "0\n",
      "\n",
      "Consecutive Dates: 27-12-2019 and 17-03-2020\n",
      "Consecutive Dates: 17-03-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 14-12-2020\n",
      "Consecutive Dates: 14-12-2020 and 22-01-2021\n",
      "Consecutive Dates: 22-01-2021 and 06-11-2023\n",
      "1410\n",
      "\n",
      "Consecutive Dates: 27-02-2020 and 22-06-2020\n",
      "116\n",
      "\n",
      "Consecutive Dates: 14-02-2020 and 22-06-2022\n",
      "859\n",
      "\n",
      "Consecutive Dates: 08-03-2018 and 13-06-2019\n",
      "Consecutive Dates: 13-06-2019 and 28-06-2019\n",
      "Consecutive Dates: 28-06-2019 and 22-06-2022\n",
      "Consecutive Dates: 22-06-2022 and 26-11-2020\n",
      "Consecutive Dates: 26-11-2020 and 11-08-2022\n",
      "Consecutive Dates: 11-08-2022 and 06-07-2023\n",
      "3092\n",
      "\n",
      "0\n",
      "\n",
      "Consecutive Dates: 15-10-2012 and 09-01-2013\n",
      "Consecutive Dates: 09-01-2013 and 04-02-2013\n",
      "Consecutive Dates: 04-02-2013 and 07-03-2013\n",
      "Consecutive Dates: 07-03-2013 and 05-04-2013\n",
      "Consecutive Dates: 05-04-2013 and 06-05-2013\n",
      "Consecutive Dates: 06-05-2013 and 05-06-2013\n",
      "Consecutive Dates: 05-06-2013 and 04-07-2013\n",
      "Consecutive Dates: 04-07-2013 and 03-08-2013\n",
      "Consecutive Dates: 03-08-2013 and 02-09-2013\n",
      "Consecutive Dates: 02-09-2013 and 03-10-2013\n",
      "Consecutive Dates: 03-10-2013 and 02-11-2013\n",
      "Consecutive Dates: 02-11-2013 and 21-11-2013\n",
      "Consecutive Dates: 21-11-2013 and 11-03-2015\n",
      "Consecutive Dates: 11-03-2015 and 03-04-2015\n",
      "Consecutive Dates: 03-04-2015 and 22-04-2015\n",
      "Consecutive Dates: 22-04-2015 and 14-05-2015\n",
      "Consecutive Dates: 14-05-2015 and 05-06-2015\n",
      "Consecutive Dates: 05-06-2015 and 13-07-2015\n",
      "Consecutive Dates: 13-07-2015 and 19-08-2015\n",
      "Consecutive Dates: 19-08-2015 and 22-09-2015\n",
      "Consecutive Dates: 22-09-2015 and 21-10-2015\n",
      "Consecutive Dates: 21-10-2015 and 20-11-2015\n",
      "Consecutive Dates: 20-11-2015 and 19-01-2016\n",
      "Consecutive Dates: 19-01-2016 and 18-02-2016\n",
      "Consecutive Dates: 18-02-2016 and 03-03-2016\n",
      "Consecutive Dates: 03-03-2016 and 02-04-2019\n",
      "Consecutive Dates: 02-04-2019 and 06-05-2016\n",
      "Consecutive Dates: 06-05-2016 and 07-03-2017\n",
      "Consecutive Dates: 07-03-2017 and 13-04-2017\n",
      "Consecutive Dates: 13-04-2017 and 17-05-2017\n",
      "Consecutive Dates: 17-05-2017 and 19-06-2017\n",
      "Consecutive Dates: 19-06-2017 and 20-07-2017\n",
      "Consecutive Dates: 20-07-2017 and 16-08-2017\n",
      "Consecutive Dates: 16-08-2017 and 13-09-2017\n",
      "Consecutive Dates: 13-09-2017 and 14-10-2017\n",
      "Consecutive Dates: 14-10-2017 and 28-10-2017\n",
      "Consecutive Dates: 28-10-2017 and 28-11-2017\n",
      "Consecutive Dates: 28-11-2017 and 30-12-2017\n",
      "Consecutive Dates: 30-12-2017 and 31-01-2018\n",
      "Consecutive Dates: 31-01-2018 and 05-03-2018\n",
      "Consecutive Dates: 05-03-2018 and 04-04-2018\n",
      "Consecutive Dates: 04-04-2018 and 12-04-2018\n",
      "Consecutive Dates: 12-04-2018 and 02-05-2018\n",
      "Consecutive Dates: 02-05-2018 and 28-05-2018\n",
      "Consecutive Dates: 28-05-2018 and 02-07-2018\n",
      "Consecutive Dates: 02-07-2018 and 31-07-2018\n",
      "Consecutive Dates: 31-07-2018 and 30-08-2018\n",
      "Consecutive Dates: 30-08-2018 and 29-10-2018\n",
      "Consecutive Dates: 29-10-2018 and 28-11-2018\n",
      "Consecutive Dates: 28-11-2018 and 29-12-2018\n",
      "Consecutive Dates: 29-12-2018 and 29-01-2019\n",
      "Consecutive Dates: 29-01-2019 and 28-02-2019\n",
      "Consecutive Dates: 28-02-2019 and 29-03-2019\n",
      "Consecutive Dates: 29-03-2019 and 27-04-2019\n",
      "Consecutive Dates: 27-04-2019 and 27-05-2019\n",
      "Consecutive Dates: 27-05-2019 and 26-06-2019\n",
      "Consecutive Dates: 26-06-2019 and 25-07-2019\n",
      "Consecutive Dates: 25-07-2019 and 26-08-2019\n",
      "Consecutive Dates: 26-08-2019 and 25-09-2019\n",
      "Consecutive Dates: 25-09-2019 and 26-10-2019\n",
      "Consecutive Dates: 26-10-2019 and 22-11-2019\n",
      "Consecutive Dates: 22-11-2019 and 25-12-2019\n",
      "Consecutive Dates: 25-12-2019 and 20-01-2020\n",
      "Consecutive Dates: 20-01-2020 and 22-02-2020\n",
      "Consecutive Dates: 22-02-2020 and 21-04-2020\n",
      "Consecutive Dates: 21-04-2020 and 22-05-2020\n",
      "Consecutive Dates: 22-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 16-11-2020\n",
      "Consecutive Dates: 16-11-2020 and 11-01-2021\n",
      "Consecutive Dates: 11-01-2021 and 21-03-2021\n",
      "Consecutive Dates: 21-03-2021 and 12-06-2023\n",
      "Consecutive Dates: 12-06-2023 and 30-07-2023\n",
      "Consecutive Dates: 30-07-2023 and 04-08-2023\n",
      "Consecutive Dates: 04-08-2023 and 18-08-2023\n",
      "Consecutive Dates: 18-08-2023 and 19-09-2023\n",
      "Consecutive Dates: 19-09-2023 and 18-10-2023\n",
      "6142\n",
      "\n",
      "Consecutive Dates: 07-03-2019 and 24-01-2020\n",
      "Consecutive Dates: 24-01-2020 and 04-02-2020\n",
      "Consecutive Dates: 04-02-2020 and 03-03-2020\n",
      "Consecutive Dates: 03-03-2020 and 14-05-2020\n",
      "Consecutive Dates: 14-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 28-09-2020\n",
      "Consecutive Dates: 28-09-2020 and 20-02-2021\n",
      "Consecutive Dates: 20-02-2021 and 17-05-2021\n",
      "Consecutive Dates: 17-05-2021 and 19-08-2021\n",
      "Consecutive Dates: 19-08-2021 and 06-07-2022\n",
      "Consecutive Dates: 06-07-2022 and 14-08-2023\n",
      "1621\n",
      "\n",
      "Consecutive Dates: 30-08-2018 and 03-10-2018\n",
      "Consecutive Dates: 03-10-2018 and 17-11-2018\n",
      "Consecutive Dates: 17-11-2018 and 20-12-2018\n",
      "Consecutive Dates: 20-12-2018 and 31-01-2019\n",
      "Consecutive Dates: 31-01-2019 and 15-03-2019\n",
      "Consecutive Dates: 15-03-2019 and 01-05-2019\n",
      "Consecutive Dates: 01-05-2019 and 29-06-2019\n",
      "Consecutive Dates: 29-06-2019 and 25-09-2019\n",
      "Consecutive Dates: 25-09-2019 and 21-10-2019\n",
      "Consecutive Dates: 21-10-2019 and 05-12-2019\n",
      "Consecutive Dates: 05-12-2019 and 24-01-2020\n",
      "Consecutive Dates: 24-01-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 06-10-2020\n",
      "Consecutive Dates: 06-10-2020 and 23-11-2020\n",
      "Consecutive Dates: 23-11-2020 and 09-03-2021\n",
      "Consecutive Dates: 09-03-2021 and 11-05-2021\n",
      "Consecutive Dates: 11-05-2021 and 28-07-2021\n",
      "Consecutive Dates: 28-07-2021 and 04-10-2021\n",
      "Consecutive Dates: 04-10-2021 and 26-11-2021\n",
      "Consecutive Dates: 26-11-2021 and 29-01-2022\n",
      "Consecutive Dates: 29-01-2022 and 10-03-2022\n",
      "Consecutive Dates: 10-03-2022 and 20-04-2022\n",
      "Consecutive Dates: 20-04-2022 and 26-05-2022\n",
      "Consecutive Dates: 26-05-2022 and 18-07-2022\n",
      "Consecutive Dates: 18-07-2022 and 07-09-2022\n",
      "Consecutive Dates: 07-09-2022 and 10-10-2022\n",
      "Consecutive Dates: 10-10-2022 and 23-11-2022\n",
      "Consecutive Dates: 23-11-2022 and 04-01-2023\n",
      "Consecutive Dates: 04-01-2023 and 02-03-2023\n",
      "Consecutive Dates: 02-03-2023 and 20-04-2023\n",
      "Consecutive Dates: 20-04-2023 and 09-06-2023\n",
      "Consecutive Dates: 09-06-2023 and 04-08-2023\n",
      "Consecutive Dates: 04-08-2023 and 23-09-2023\n",
      "Consecutive Dates: 23-09-2023 and 04-11-2023\n",
      "1892\n",
      "\n",
      "Consecutive Dates: 22-06-2020 and 31-08-2020\n",
      "Consecutive Dates: 31-08-2020 and 14-09-2020\n",
      "Consecutive Dates: 14-09-2020 and 28-10-2020\n",
      "Consecutive Dates: 28-10-2020 and 12-03-2020\n",
      "Consecutive Dates: 12-03-2020 and 19-03-2021\n",
      "730\n",
      "\n",
      "Consecutive Dates: 08-12-2020 and 16-10-2021\n",
      "Consecutive Dates: 16-10-2021 and 13-12-2021\n",
      "Consecutive Dates: 13-12-2021 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 16-07-2021\n",
      "Consecutive Dates: 16-07-2021 and 16-08-2021\n",
      "Consecutive Dates: 16-08-2021 and 13-09-2021\n",
      "Consecutive Dates: 13-09-2021 and 14-05-2022\n",
      "Consecutive Dates: 14-05-2022 and 15-06-2022\n",
      "Consecutive Dates: 15-06-2022 and 15-07-2022\n",
      "Consecutive Dates: 15-07-2022 and 16-02-2022\n",
      "Consecutive Dates: 16-02-2022 and 15-03-2022\n",
      "Consecutive Dates: 15-03-2022 and 18-04-2022\n",
      "Consecutive Dates: 18-04-2022 and 12-10-2022\n",
      "Consecutive Dates: 12-10-2022 and 11-11-2022\n",
      "Consecutive Dates: 11-11-2022 and 13-12-2022\n",
      "Consecutive Dates: 13-12-2022 and 09-01-2023\n",
      "Consecutive Dates: 09-01-2023 and 12-08-2022\n",
      "Consecutive Dates: 12-08-2022 and 12-09-2022\n",
      "Consecutive Dates: 12-09-2022 and 10-04-2023\n",
      "Consecutive Dates: 10-04-2023 and 08-05-2023\n",
      "Consecutive Dates: 08-05-2023 and 10-06-2023\n",
      "Consecutive Dates: 10-06-2023 and 08-07-2023\n",
      "Consecutive Dates: 08-07-2023 and 11-02-2023\n",
      "Consecutive Dates: 11-02-2023 and 04-03-2023\n",
      "Consecutive Dates: 04-03-2023 and 05-08-2023\n",
      "Consecutive Dates: 05-08-2023 and 29-08-2023\n",
      "Consecutive Dates: 29-08-2023 and 07-10-2023\n",
      "Consecutive Dates: 07-10-2023 and 04-11-2023\n",
      "2323\n",
      "\n",
      "Consecutive Dates: 08-12-2020 and 16-10-2021\n",
      "Consecutive Dates: 16-10-2021 and 10-11-2021\n",
      "Consecutive Dates: 10-11-2021 and 13-12-2021\n",
      "Consecutive Dates: 13-12-2021 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 16-07-2021\n",
      "Consecutive Dates: 16-07-2021 and 16-08-2021\n",
      "Consecutive Dates: 16-08-2021 and 13-09-2021\n",
      "Consecutive Dates: 13-09-2021 and 14-05-2022\n",
      "Consecutive Dates: 14-05-2022 and 15-06-2022\n",
      "Consecutive Dates: 15-06-2022 and 15-07-2022\n",
      "Consecutive Dates: 15-07-2022 and 16-02-2022\n",
      "Consecutive Dates: 16-02-2022 and 15-03-2022\n",
      "Consecutive Dates: 15-03-2022 and 18-04-2022\n",
      "Consecutive Dates: 18-04-2022 and 12-10-2022\n",
      "Consecutive Dates: 12-10-2022 and 11-11-2022\n",
      "Consecutive Dates: 11-11-2022 and 13-12-2022\n",
      "Consecutive Dates: 13-12-2022 and 09-01-2023\n",
      "Consecutive Dates: 09-01-2023 and 12-08-2022\n",
      "Consecutive Dates: 12-08-2022 and 12-09-2022\n",
      "Consecutive Dates: 12-09-2022 and 10-04-2023\n",
      "Consecutive Dates: 10-04-2023 and 08-05-2023\n",
      "Consecutive Dates: 08-05-2023 and 10-06-2023\n",
      "Consecutive Dates: 10-06-2023 and 08-07-2023\n",
      "Consecutive Dates: 08-07-2023 and 11-02-2023\n",
      "Consecutive Dates: 11-02-2023 and 04-03-2023\n",
      "Consecutive Dates: 04-03-2023 and 05-08-2023\n",
      "Consecutive Dates: 05-08-2023 and 29-08-2023\n",
      "Consecutive Dates: 29-08-2023 and 07-10-2023\n",
      "Consecutive Dates: 07-10-2023 and 04-11-2023\n",
      "2323\n",
      "\n",
      "Consecutive Dates: 03-07-2017 and 11-09-2017\n",
      "Consecutive Dates: 11-09-2017 and 19-03-2018\n",
      "Consecutive Dates: 19-03-2018 and 04-05-2018\n",
      "Consecutive Dates: 04-05-2018 and 20-06-2018\n",
      "Consecutive Dates: 20-06-2018 and 03-08-2018\n",
      "Consecutive Dates: 03-08-2018 and 18-09-2018\n",
      "Consecutive Dates: 18-09-2018 and 09-10-2018\n",
      "Consecutive Dates: 09-10-2018 and 28-11-2018\n",
      "Consecutive Dates: 28-11-2018 and 07-02-2019\n",
      "Consecutive Dates: 07-02-2019 and 13-04-2019\n",
      "Consecutive Dates: 13-04-2019 and 23-05-2019\n",
      "Consecutive Dates: 23-05-2019 and 09-07-2019\n",
      "Consecutive Dates: 09-07-2019 and 15-11-2019\n",
      "Consecutive Dates: 15-11-2019 and 04-10-2019\n",
      "Consecutive Dates: 04-10-2019 and 15-11-2019\n",
      "Consecutive Dates: 15-11-2019 and 17-12-2019\n",
      "Consecutive Dates: 17-12-2019 and 23-01-2020\n",
      "Consecutive Dates: 23-01-2020 and 04-03-2020\n",
      "Consecutive Dates: 04-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 26-09-2020\n",
      "Consecutive Dates: 26-09-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 29-12-2020\n",
      "Consecutive Dates: 29-12-2020 and 04-02-2021\n",
      "Consecutive Dates: 04-02-2021 and 06-03-2021\n",
      "Consecutive Dates: 06-03-2021 and 12-04-2021\n",
      "Consecutive Dates: 12-04-2021 and 29-05-2021\n",
      "Consecutive Dates: 29-05-2021 and 09-07-2021\n",
      "Consecutive Dates: 09-07-2021 and 27-08-2021\n",
      "Consecutive Dates: 27-08-2021 and 06-10-2021\n",
      "Consecutive Dates: 06-10-2021 and 17-11-2021\n",
      "Consecutive Dates: 17-11-2021 and 23-12-2021\n",
      "Consecutive Dates: 23-12-2021 and 12-01-2022\n",
      "Consecutive Dates: 12-01-2022 and 05-02-2022\n",
      "Consecutive Dates: 05-02-2022 and 19-02-2022\n",
      "Consecutive Dates: 19-02-2022 and 22-03-2022\n",
      "Consecutive Dates: 22-03-2022 and 02-05-2022\n",
      "Consecutive Dates: 02-05-2022 and 13-06-2022\n",
      "Consecutive Dates: 13-06-2022 and 16-07-2022\n",
      "Consecutive Dates: 16-07-2022 and 23-08-2022\n",
      "Consecutive Dates: 23-08-2022 and 16-08-2022\n",
      "Consecutive Dates: 16-08-2022 and 26-09-2022\n",
      "Consecutive Dates: 26-09-2022 and 05-10-2022\n",
      "Consecutive Dates: 05-10-2022 and 28-10-2022\n",
      "Consecutive Dates: 28-10-2022 and 08-11-2022\n",
      "Consecutive Dates: 08-11-2022 and 07-02-2023\n",
      "Consecutive Dates: 07-02-2023 and 05-04-2023\n",
      "Consecutive Dates: 05-04-2023 and 29-05-2023\n",
      "Consecutive Dates: 29-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 18-07-2023\n",
      "Consecutive Dates: 18-07-2023 and 15-09-2023\n",
      "2363\n",
      "\n",
      "Consecutive Dates: 05-06-2014 and 27-06-2014\n",
      "Consecutive Dates: 27-06-2014 and 30-07-2014\n",
      "Consecutive Dates: 30-07-2014 and 02-09-2014\n",
      "Consecutive Dates: 02-09-2014 and 08-10-2014\n",
      "Consecutive Dates: 08-10-2014 and 14-11-2017\n",
      "Consecutive Dates: 14-11-2017 and 30-12-2014\n",
      "Consecutive Dates: 30-12-2014 and 27-02-2015\n",
      "Consecutive Dates: 27-02-2015 and 03-04-2015\n",
      "Consecutive Dates: 03-04-2015 and 09-05-2015\n",
      "Consecutive Dates: 09-05-2015 and 25-06-2015\n",
      "Consecutive Dates: 25-06-2015 and 31-07-2015\n",
      "Consecutive Dates: 31-07-2015 and 01-10-2015\n",
      "Consecutive Dates: 01-10-2015 and 09-11-2015\n",
      "Consecutive Dates: 09-11-2015 and 01-01-2016\n",
      "Consecutive Dates: 01-01-2016 and 12-02-2016\n",
      "Consecutive Dates: 12-02-2016 and 18-03-2016\n",
      "Consecutive Dates: 18-03-2016 and 19-04-2016\n",
      "Consecutive Dates: 19-04-2016 and 07-05-2016\n",
      "Consecutive Dates: 07-05-2016 and 04-06-2016\n",
      "Consecutive Dates: 04-06-2016 and 11-07-2016\n",
      "Consecutive Dates: 11-07-2016 and 05-08-2016\n",
      "Consecutive Dates: 05-08-2016 and 03-09-2016\n",
      "Consecutive Dates: 03-09-2016 and 13-10-2016\n",
      "Consecutive Dates: 13-10-2016 and 09-11-2016\n",
      "Consecutive Dates: 09-11-2016 and 07-12-2016\n",
      "Consecutive Dates: 07-12-2016 and 02-01-2017\n",
      "Consecutive Dates: 02-01-2017 and 01-02-2017\n",
      "Consecutive Dates: 01-02-2017 and 03-03-2017\n",
      "Consecutive Dates: 03-03-2017 and 31-03-2017\n",
      "Consecutive Dates: 31-03-2017 and 10-05-2017\n",
      "Consecutive Dates: 10-05-2017 and 03-06-2017\n",
      "Consecutive Dates: 03-06-2017 and 04-07-2017\n",
      "Consecutive Dates: 04-07-2017 and 08-09-2017\n",
      "Consecutive Dates: 08-09-2017 and 29-06-2018\n",
      "Consecutive Dates: 29-06-2018 and 09-08-2018\n",
      "Consecutive Dates: 09-08-2018 and 18-09-2018\n",
      "Consecutive Dates: 18-09-2018 and 20-10-2018\n",
      "Consecutive Dates: 20-10-2018 and 23-11-2018\n",
      "Consecutive Dates: 23-11-2018 and 09-02-2019\n",
      "Consecutive Dates: 09-02-2019 and 02-04-2019\n",
      "Consecutive Dates: 02-04-2019 and 27-05-2019\n",
      "Consecutive Dates: 27-05-2019 and 18-06-2019\n",
      "Consecutive Dates: 18-06-2019 and 19-06-2019\n",
      "Consecutive Dates: 19-06-2019 and 26-07-2019\n",
      "Consecutive Dates: 26-07-2019 and 09-09-2019\n",
      "Consecutive Dates: 09-09-2019 and 10-10-2019\n",
      "Consecutive Dates: 10-10-2019 and 16-11-2019\n",
      "Consecutive Dates: 16-11-2019 and 26-11-2019\n",
      "Consecutive Dates: 26-11-2019 and 24-12-2019\n",
      "Consecutive Dates: 24-12-2019 and 04-02-2020\n",
      "Consecutive Dates: 04-02-2020 and 19-03-2020\n",
      "Consecutive Dates: 19-03-2020 and 18-05-2020\n",
      "Consecutive Dates: 18-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 15-10-2020\n",
      "Consecutive Dates: 15-10-2020 and 16-11-2020\n",
      "Consecutive Dates: 16-11-2020 and 17-12-2020\n",
      "Consecutive Dates: 17-12-2020 and 16-01-2021\n",
      "Consecutive Dates: 16-01-2021 and 25-02-2021\n",
      "Consecutive Dates: 25-02-2021 and 19-05-2021\n",
      "Consecutive Dates: 19-05-2021 and 31-07-2021\n",
      "Consecutive Dates: 31-07-2021 and 13-11-2021\n",
      "Consecutive Dates: 13-11-2021 and 20-12-2021\n",
      "Consecutive Dates: 20-12-2021 and 10-01-2022\n",
      "Consecutive Dates: 10-01-2022 and 09-03-2022\n",
      "Consecutive Dates: 09-03-2022 and 12-04-2022\n",
      "Consecutive Dates: 12-04-2022 and 20-06-2022\n",
      "Consecutive Dates: 20-06-2022 and 25-08-2022\n",
      "Consecutive Dates: 25-08-2022 and 09-11-2022\n",
      "Consecutive Dates: 09-11-2022 and 15-02-2023\n",
      "Consecutive Dates: 15-02-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 24-08-2023\n",
      "5467\n",
      "\n",
      "Consecutive Dates: 23-11-2015 and 28-12-2015\n",
      "Consecutive Dates: 28-12-2015 and 15-02-2016\n",
      "Consecutive Dates: 15-02-2016 and 11-04-2016\n",
      "Consecutive Dates: 11-04-2016 and 25-05-2016\n",
      "Consecutive Dates: 25-05-2016 and 24-06-2016\n",
      "Consecutive Dates: 24-06-2016 and 06-07-2016\n",
      "Consecutive Dates: 06-07-2016 and 03-08-2016\n",
      "Consecutive Dates: 03-08-2016 and 08-09-2016\n",
      "Consecutive Dates: 08-09-2016 and 13-10-2016\n",
      "Consecutive Dates: 13-10-2016 and 12-12-2016\n",
      "Consecutive Dates: 12-12-2016 and 18-01-2017\n",
      "Consecutive Dates: 18-01-2017 and 02-03-2017\n",
      "Consecutive Dates: 02-03-2017 and 10-04-2017\n",
      "Consecutive Dates: 10-04-2017 and 03-05-2017\n",
      "Consecutive Dates: 03-05-2017 and 29-05-2017\n",
      "Consecutive Dates: 29-05-2017 and 05-06-2017\n",
      "Consecutive Dates: 05-06-2017 and 03-07-2017\n",
      "Consecutive Dates: 03-07-2017 and 02-08-2017\n",
      "Consecutive Dates: 02-08-2017 and 04-09-2017\n",
      "Consecutive Dates: 04-09-2017 and 06-11-2017\n",
      "Consecutive Dates: 06-11-2017 and 04-12-2017\n",
      "Consecutive Dates: 04-12-2017 and 05-01-2018\n",
      "Consecutive Dates: 05-01-2018 and 14-02-2018\n",
      "Consecutive Dates: 14-02-2018 and 02-04-2018\n",
      "Consecutive Dates: 02-04-2018 and 01-06-2018\n",
      "Consecutive Dates: 01-06-2018 and 02-06-2018\n",
      "Consecutive Dates: 02-06-2018 and 04-07-2018\n",
      "Consecutive Dates: 04-07-2018 and 02-08-2018\n",
      "Consecutive Dates: 02-08-2018 and 06-09-2018\n",
      "Consecutive Dates: 06-09-2018 and 09-10-2018\n",
      "Consecutive Dates: 09-10-2018 and 07-11-2018\n",
      "Consecutive Dates: 07-11-2018 and 10-01-2019\n",
      "Consecutive Dates: 10-01-2019 and 11-02-2019\n",
      "Consecutive Dates: 11-02-2019 and 18-03-2019\n",
      "Consecutive Dates: 18-03-2019 and 26-04-2019\n",
      "Consecutive Dates: 26-04-2019 and 28-05-2019\n",
      "Consecutive Dates: 28-05-2019 and 18-06-2019\n",
      "Consecutive Dates: 18-06-2019 and 28-08-2019\n",
      "Consecutive Dates: 28-08-2019 and 04-10-2019\n",
      "Consecutive Dates: 04-10-2019 and 08-11-2019\n",
      "Consecutive Dates: 08-11-2019 and 11-12-2019\n",
      "Consecutive Dates: 11-12-2019 and 16-01-2020\n",
      "Consecutive Dates: 16-01-2020 and 15-02-2020\n",
      "Consecutive Dates: 15-02-2020 and 29-02-2020\n",
      "Consecutive Dates: 29-02-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 05-05-2020\n",
      "Consecutive Dates: 05-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 21-07-2020\n",
      "Consecutive Dates: 21-07-2020 and 29-08-2020\n",
      "Consecutive Dates: 29-08-2020 and 21-10-2020\n",
      "Consecutive Dates: 21-10-2020 and 15-11-2020\n",
      "Consecutive Dates: 15-11-2020 and 22-12-2020\n",
      "Consecutive Dates: 22-12-2020 and 22-01-2021\n",
      "Consecutive Dates: 22-01-2021 and 06-03-2021\n",
      "Consecutive Dates: 06-03-2021 and 02-04-2021\n",
      "Consecutive Dates: 02-04-2021 and 08-05-2021\n",
      "Consecutive Dates: 08-05-2021 and 25-01-2022\n",
      "Consecutive Dates: 25-01-2022 and 23-08-2022\n",
      "Consecutive Dates: 23-08-2022 and 19-12-2022\n",
      "Consecutive Dates: 19-12-2022 and 24-07-2023\n",
      "Consecutive Dates: 24-07-2023 and 05-10-2023\n",
      "2873\n",
      "\n",
      "Consecutive Dates: 23-11-2015 and 28-12-2015\n",
      "Consecutive Dates: 28-12-2015 and 15-02-2016\n",
      "Consecutive Dates: 15-02-2016 and 11-04-2016\n",
      "Consecutive Dates: 11-04-2016 and 25-05-2016\n",
      "Consecutive Dates: 25-05-2016 and 24-06-2016\n",
      "Consecutive Dates: 24-06-2016 and 06-07-2016\n",
      "Consecutive Dates: 06-07-2016 and 03-08-2016\n",
      "Consecutive Dates: 03-08-2016 and 08-09-2016\n",
      "Consecutive Dates: 08-09-2016 and 13-10-2016\n",
      "Consecutive Dates: 13-10-2016 and 10-11-2016\n",
      "Consecutive Dates: 10-11-2016 and 12-12-2016\n",
      "Consecutive Dates: 12-12-2016 and 18-01-2017\n",
      "Consecutive Dates: 18-01-2017 and 02-03-2017\n",
      "Consecutive Dates: 02-03-2017 and 10-04-2017\n",
      "Consecutive Dates: 10-04-2017 and 03-05-2017\n",
      "Consecutive Dates: 03-05-2017 and 29-05-2017\n",
      "Consecutive Dates: 29-05-2017 and 05-06-2017\n",
      "Consecutive Dates: 05-06-2017 and 03-07-2017\n",
      "Consecutive Dates: 03-07-2017 and 02-08-2017\n",
      "Consecutive Dates: 02-08-2017 and 04-09-2017\n",
      "Consecutive Dates: 04-09-2017 and 06-11-2017\n",
      "Consecutive Dates: 06-11-2017 and 04-12-2017\n",
      "Consecutive Dates: 04-12-2017 and 05-01-2018\n",
      "Consecutive Dates: 05-01-2018 and 14-02-2018\n",
      "Consecutive Dates: 14-02-2018 and 02-04-2018\n",
      "Consecutive Dates: 02-04-2018 and 01-06-2018\n",
      "Consecutive Dates: 01-06-2018 and 02-06-2018\n",
      "Consecutive Dates: 02-06-2018 and 04-07-2018\n",
      "Consecutive Dates: 04-07-2018 and 02-08-2018\n",
      "Consecutive Dates: 02-08-2018 and 06-09-2018\n",
      "Consecutive Dates: 06-09-2018 and 09-10-2018\n",
      "Consecutive Dates: 09-10-2018 and 07-11-2018\n",
      "Consecutive Dates: 07-11-2018 and 10-01-2019\n",
      "Consecutive Dates: 10-01-2019 and 11-02-2019\n",
      "Consecutive Dates: 11-02-2019 and 18-03-2019\n",
      "Consecutive Dates: 18-03-2019 and 26-04-2019\n",
      "Consecutive Dates: 26-04-2019 and 28-05-2019\n",
      "Consecutive Dates: 28-05-2019 and 18-06-2019\n",
      "Consecutive Dates: 18-06-2019 and 28-08-2019\n",
      "Consecutive Dates: 28-08-2019 and 04-10-2019\n",
      "Consecutive Dates: 04-10-2019 and 08-11-2019\n",
      "Consecutive Dates: 08-11-2019 and 11-12-2019\n",
      "Consecutive Dates: 11-12-2019 and 16-01-2020\n",
      "Consecutive Dates: 16-01-2020 and 15-02-2020\n",
      "Consecutive Dates: 15-02-2020 and 29-02-2020\n",
      "Consecutive Dates: 29-02-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 05-05-2020\n",
      "Consecutive Dates: 05-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 21-07-2020\n",
      "Consecutive Dates: 21-07-2020 and 29-08-2020\n",
      "Consecutive Dates: 29-08-2020 and 21-10-2020\n",
      "Consecutive Dates: 21-10-2020 and 15-11-2020\n",
      "Consecutive Dates: 15-11-2020 and 22-12-2020\n",
      "Consecutive Dates: 22-12-2020 and 22-01-2021\n",
      "Consecutive Dates: 22-01-2021 and 06-03-2021\n",
      "Consecutive Dates: 06-03-2021 and 02-04-2021\n",
      "Consecutive Dates: 02-04-2021 and 08-05-2021\n",
      "Consecutive Dates: 08-05-2021 and 25-01-2022\n",
      "Consecutive Dates: 25-01-2022 and 23-08-2022\n",
      "Consecutive Dates: 23-08-2022 and 19-12-2022\n",
      "Consecutive Dates: 19-12-2022 and 24-07-2023\n",
      "Consecutive Dates: 24-07-2023 and 05-10-2023\n",
      "2873\n",
      "\n",
      "Consecutive Dates: 13-06-2018 and 18-08-2018\n",
      "Consecutive Dates: 18-08-2018 and 23-08-2018\n",
      "Consecutive Dates: 23-08-2018 and 19-09-2018\n",
      "Consecutive Dates: 19-09-2018 and 24-10-2018\n",
      "Consecutive Dates: 24-10-2018 and 20-02-2019\n",
      "Consecutive Dates: 20-02-2019 and 13-03-2019\n",
      "Consecutive Dates: 13-03-2019 and 06-04-2019\n",
      "Consecutive Dates: 06-04-2019 and 25-05-2019\n",
      "Consecutive Dates: 25-05-2019 and 31-07-2019\n",
      "Consecutive Dates: 31-07-2019 and 13-09-2019\n",
      "Consecutive Dates: 13-09-2019 and 08-10-2019\n",
      "Consecutive Dates: 08-10-2019 and 17-12-2019\n",
      "Consecutive Dates: 17-12-2019 and 07-01-2020\n",
      "Consecutive Dates: 07-01-2020 and 13-03-2020\n",
      "Consecutive Dates: 13-03-2020 and 11-05-2020\n",
      "Consecutive Dates: 11-05-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 11-09-2020\n",
      "Consecutive Dates: 11-09-2020 and 23-01-2021\n",
      "Consecutive Dates: 23-01-2021 and 24-03-2021\n",
      "Consecutive Dates: 24-03-2021 and 14-04-2021\n",
      "Consecutive Dates: 14-04-2021 and 12-06-2021\n",
      "Consecutive Dates: 12-06-2021 and 14-06-2021\n",
      "Consecutive Dates: 14-06-2021 and 20-08-2021\n",
      "Consecutive Dates: 20-08-2021 and 10-09-2021\n",
      "Consecutive Dates: 10-09-2021 and 28-09-2021\n",
      "Consecutive Dates: 28-09-2021 and 16-11-2021\n",
      "Consecutive Dates: 16-11-2021 and 01-12-2021\n",
      "Consecutive Dates: 01-12-2021 and 03-12-2021\n",
      "Consecutive Dates: 03-12-2021 and 17-12-2021\n",
      "Consecutive Dates: 17-12-2021 and 31-12-2021\n",
      "Consecutive Dates: 31-12-2021 and 18-02-2022\n",
      "Consecutive Dates: 18-02-2022 and 22-02-2022\n",
      "Consecutive Dates: 22-02-2022 and 11-03-2022\n",
      "Consecutive Dates: 11-03-2022 and 25-03-2022\n",
      "Consecutive Dates: 25-03-2022 and 23-04-2022\n",
      "Consecutive Dates: 23-04-2022 and 01-07-2022\n",
      "Consecutive Dates: 01-07-2022 and 13-08-2022\n",
      "Consecutive Dates: 13-08-2022 and 31-12-2022\n",
      "Consecutive Dates: 31-12-2022 and 12-05-2023\n",
      "Consecutive Dates: 12-05-2023 and 09-06-2023\n",
      "Consecutive Dates: 09-06-2023 and 27-07-2023\n",
      "1870\n",
      "\n",
      "Consecutive Dates: 17-03-2020 and 15-06-2020\n",
      "Consecutive Dates: 15-06-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 24-06-2020\n",
      "Consecutive Dates: 24-06-2020 and 01-07-2020\n",
      "Consecutive Dates: 01-07-2020 and 03-08-2020\n",
      "Consecutive Dates: 03-08-2020 and 24-08-2020\n",
      "160\n",
      "\n",
      "Consecutive Dates: 04-01-2020 and 06-02-2020\n",
      "Consecutive Dates: 06-02-2020 and 11-03-2020\n",
      "Consecutive Dates: 11-03-2020 and 22-06-2020\n",
      "Consecutive Dates: 22-06-2020 and 27-08-2020\n",
      "Consecutive Dates: 27-08-2020 and 30-10-2020\n",
      "Consecutive Dates: 30-10-2020 and 07-01-2021\n",
      "Consecutive Dates: 07-01-2021 and 24-02-2021\n",
      "Consecutive Dates: 24-02-2021 and 02-02-2022\n",
      "760\n",
      "\n",
      "Consecutive Dates: 21-11-2016 and 21-12-2016\n",
      "Consecutive Dates: 21-12-2016 and 21-01-2017\n",
      "Consecutive Dates: 21-01-2017 and 28-02-2017\n",
      "Consecutive Dates: 28-02-2017 and 31-03-2017\n",
      "Consecutive Dates: 31-03-2017 and 02-05-2017\n",
      "Consecutive Dates: 02-05-2017 and 01-06-2017\n",
      "Consecutive Dates: 01-06-2017 and 05-07-2017\n",
      "Consecutive Dates: 05-07-2017 and 12-08-2017\n",
      "Consecutive Dates: 12-08-2017 and 08-09-2017\n",
      "Consecutive Dates: 08-09-2017 and 18-10-2017\n",
      "Consecutive Dates: 18-10-2017 and 21-11-2017\n",
      "Consecutive Dates: 21-11-2017 and 28-12-2017\n",
      "Consecutive Dates: 28-12-2017 and 31-01-2018\n",
      "Consecutive Dates: 31-01-2018 and 21-03-2018\n",
      "Consecutive Dates: 21-03-2018 and 23-04-2018\n",
      "Consecutive Dates: 23-04-2018 and 31-05-2018\n",
      "Consecutive Dates: 31-05-2018 and 06-06-2018\n",
      "Consecutive Dates: 06-06-2018 and 03-07-2018\n",
      "Consecutive Dates: 03-07-2018 and 25-09-2018\n",
      "Consecutive Dates: 25-09-2018 and 05-11-2018\n",
      "Consecutive Dates: 05-11-2018 and 18-12-2018\n",
      "Consecutive Dates: 18-12-2018 and 29-01-2019\n",
      "Consecutive Dates: 29-01-2019 and 06-03-2019\n",
      "Consecutive Dates: 06-03-2019 and 03-04-2019\n",
      "Consecutive Dates: 03-04-2019 and 19-04-2019\n",
      "Consecutive Dates: 19-04-2019 and 25-05-2019\n",
      "Consecutive Dates: 25-05-2019 and 29-06-2019\n",
      "Consecutive Dates: 29-06-2019 and 09-08-2019\n",
      "Consecutive Dates: 09-08-2019 and 24-09-2019\n",
      "Consecutive Dates: 24-09-2019 and 29-10-2019\n",
      "Consecutive Dates: 29-10-2019 and 01-12-2019\n",
      "Consecutive Dates: 01-12-2019 and 06-01-2020\n",
      "Consecutive Dates: 06-01-2020 and 14-02-2020\n",
      "Consecutive Dates: 14-02-2020 and 12-06-2020\n",
      "Consecutive Dates: 12-06-2020 and 30-10-2020\n",
      "Consecutive Dates: 30-10-2020 and 11-12-2020\n",
      "Consecutive Dates: 11-12-2020 and 18-01-2021\n",
      "Consecutive Dates: 18-01-2021 and 19-03-2021\n",
      "Consecutive Dates: 19-03-2021 and 13-04-2021\n",
      "Consecutive Dates: 13-04-2021 and 03-08-2021\n",
      "Consecutive Dates: 03-08-2021 and 06-11-2021\n",
      "Consecutive Dates: 06-11-2021 and 11-12-2021\n",
      "Consecutive Dates: 11-12-2021 and 04-02-2022\n",
      "Consecutive Dates: 04-02-2022 and 14-06-2022\n",
      "Consecutive Dates: 14-06-2022 and 20-07-2022\n",
      "Consecutive Dates: 20-07-2022 and 24-08-2022\n",
      "Consecutive Dates: 24-08-2022 and 12-11-2022\n",
      "Consecutive Dates: 12-11-2022 and 04-01-2023\n",
      "Consecutive Dates: 04-01-2023 and 18-05-2023\n",
      "2369\n",
      "\n",
      "Consecutive Dates: 23-09-2017 and 23-10-2017\n",
      "Consecutive Dates: 23-10-2017 and 24-11-2017\n",
      "Consecutive Dates: 24-11-2017 and 05-10-2018\n",
      "Consecutive Dates: 05-10-2018 and 22-09-2021\n",
      "Consecutive Dates: 22-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 13-01-2022\n",
      "1573\n",
      "\n",
      "Consecutive Dates: 19-07-2017 and 15-09-2017\n",
      "Consecutive Dates: 15-09-2017 and 13-11-2017\n",
      "Consecutive Dates: 13-11-2017 and 13-06-2019\n",
      "Consecutive Dates: 13-06-2019 and 18-07-2019\n",
      "Consecutive Dates: 18-07-2019 and 21-11-2019\n",
      "Consecutive Dates: 21-11-2019 and 31-12-2019\n",
      "Consecutive Dates: 31-12-2019 and 11-03-2020\n",
      "Consecutive Dates: 11-03-2020 and 23-10-2020\n",
      "Consecutive Dates: 23-10-2020 and 05-04-2021\n",
      "Consecutive Dates: 05-04-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 11-10-2022\n",
      "Consecutive Dates: 11-10-2022 and 23-06-2023\n",
      "Consecutive Dates: 23-06-2023 and 26-07-2023\n",
      "Consecutive Dates: 26-07-2023 and 28-08-2023\n",
      "Consecutive Dates: 28-08-2023 and 10-10-2023\n",
      "Consecutive Dates: 10-10-2023 and 17-11-2023\n",
      "2312\n",
      "\n",
      "Consecutive Dates: 21-11-2014 and 17-12-2014\n",
      "Consecutive Dates: 17-12-2014 and 15-01-2015\n",
      "Consecutive Dates: 15-01-2015 and 14-02-2015\n",
      "Consecutive Dates: 14-02-2015 and 24-03-2015\n",
      "Consecutive Dates: 24-03-2015 and 13-04-2015\n",
      "Consecutive Dates: 13-04-2015 and 04-05-2015\n",
      "Consecutive Dates: 04-05-2015 and 04-06-2015\n",
      "Consecutive Dates: 04-06-2015 and 23-07-2015\n",
      "Consecutive Dates: 23-07-2015 and 06-08-2015\n",
      "Consecutive Dates: 06-08-2015 and 07-09-2015\n",
      "Consecutive Dates: 07-09-2015 and 03-10-2015\n",
      "Consecutive Dates: 03-10-2015 and 03-11-2015\n",
      "Consecutive Dates: 03-11-2015 and 07-12-2015\n",
      "Consecutive Dates: 07-12-2015 and 24-01-2016\n",
      "Consecutive Dates: 24-01-2016 and 30-01-2016\n",
      "Consecutive Dates: 30-01-2016 and 04-03-2016\n",
      "Consecutive Dates: 04-03-2016 and 05-04-2016\n",
      "Consecutive Dates: 05-04-2016 and 07-05-2016\n",
      "Consecutive Dates: 07-05-2016 and 06-06-2016\n",
      "Consecutive Dates: 06-06-2016 and 30-06-2016\n",
      "Consecutive Dates: 30-06-2016 and 30-07-2016\n",
      "Consecutive Dates: 30-07-2016 and 05-09-2016\n",
      "Consecutive Dates: 05-09-2016 and 23-09-2016\n",
      "Consecutive Dates: 23-09-2016 and 24-10-2016\n",
      "Consecutive Dates: 24-10-2016 and 07-12-2016\n",
      "Consecutive Dates: 07-12-2016 and 30-01-2017\n",
      "Consecutive Dates: 30-01-2017 and 07-03-2017\n",
      "Consecutive Dates: 07-03-2017 and 20-04-2017\n",
      "Consecutive Dates: 20-04-2017 and 17-07-2019\n",
      "Consecutive Dates: 17-07-2019 and 21-09-2019\n",
      "Consecutive Dates: 21-09-2019 and 21-09-2019\n",
      "Consecutive Dates: 21-09-2019 and 19-10-2019\n",
      "Consecutive Dates: 19-10-2019 and 22-11-2019\n",
      "Consecutive Dates: 22-11-2019 and 23-12-2019\n",
      "Consecutive Dates: 23-12-2019 and 22-01-2020\n",
      "Consecutive Dates: 22-01-2020 and 19-02-2020\n",
      "Consecutive Dates: 19-02-2020 and 13-03-2020\n",
      "Consecutive Dates: 13-03-2020 and 23-04-2020\n",
      "Consecutive Dates: 23-04-2020 and 16-06-2020\n",
      "Consecutive Dates: 16-06-2020 and 01-08-2020\n",
      "Consecutive Dates: 01-08-2020 and 02-09-2020\n",
      "Consecutive Dates: 02-09-2020 and 27-11-2020\n",
      "Consecutive Dates: 27-11-2020 and 25-12-2020\n",
      "Consecutive Dates: 25-12-2020 and 04-02-2021\n",
      "Consecutive Dates: 04-02-2021 and 25-02-2021\n",
      "Consecutive Dates: 25-02-2021 and 01-04-2021\n",
      "Consecutive Dates: 01-04-2021 and 22-04-2021\n",
      "Consecutive Dates: 22-04-2021 and 08-05-2021\n",
      "Consecutive Dates: 08-05-2021 and 11-06-2021\n",
      "Consecutive Dates: 11-06-2021 and 19-07-2021\n",
      "Consecutive Dates: 19-07-2021 and 17-08-2021\n",
      "Consecutive Dates: 17-08-2021 and 25-09-2021\n",
      "Consecutive Dates: 25-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 03-12-2021\n",
      "Consecutive Dates: 03-12-2021 and 03-02-2022\n",
      "Consecutive Dates: 03-02-2022 and 10-03-2022\n",
      "Consecutive Dates: 10-03-2022 and 14-04-2022\n",
      "Consecutive Dates: 14-04-2022 and 06-05-2022\n",
      "Consecutive Dates: 06-05-2022 and 08-06-2022\n",
      "Consecutive Dates: 08-06-2022 and 09-07-2022\n",
      "Consecutive Dates: 09-07-2022 and 17-08-2022\n",
      "Consecutive Dates: 17-08-2022 and 23-09-2022\n",
      "Consecutive Dates: 23-09-2022 and 02-11-2022\n",
      "Consecutive Dates: 02-11-2022 and 09-12-2022\n",
      "Consecutive Dates: 09-12-2022 and 30-12-2022\n",
      "Consecutive Dates: 30-12-2022 and 13-03-2023\n",
      "Consecutive Dates: 13-03-2023 and 01-04-2023\n",
      "Consecutive Dates: 01-04-2023 and 04-05-2023\n",
      "Consecutive Dates: 04-05-2023 and 18-05-2023\n",
      "3100\n",
      "\n",
      "Consecutive Dates: 28-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 18-05-2022\n",
      "Consecutive Dates: 18-05-2022 and 20-06-2022\n",
      "Consecutive Dates: 20-06-2022 and 25-08-2022\n",
      "301\n",
      "\n",
      "Consecutive Dates: 21-04-2016 and 16-05-2016\n",
      "Consecutive Dates: 16-05-2016 and 23-05-2017\n",
      "Consecutive Dates: 23-05-2017 and 24-07-2017\n",
      "Consecutive Dates: 24-07-2017 and 19-02-2018\n",
      "Consecutive Dates: 19-02-2018 and 26-03-2018\n",
      "Consecutive Dates: 26-03-2018 and 30-11-2018\n",
      "Consecutive Dates: 30-11-2018 and 12-01-2019\n",
      "Consecutive Dates: 12-01-2019 and 02-01-2019\n",
      "Consecutive Dates: 02-01-2019 and 20-02-2020\n",
      "Consecutive Dates: 20-02-2020 and 15-06-2020\n",
      "Consecutive Dates: 15-06-2020 and 11-02-2021\n",
      "Consecutive Dates: 11-02-2021 and 07-10-2021\n",
      "Consecutive Dates: 07-10-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 03-12-2021\n",
      "Consecutive Dates: 03-12-2021 and 30-12-2021\n",
      "Consecutive Dates: 30-12-2021 and 17-02-2022\n",
      "Consecutive Dates: 17-02-2022 and 24-03-2022\n",
      "Consecutive Dates: 24-03-2022 and 12-05-2022\n",
      "Consecutive Dates: 12-05-2022 and 29-08-2022\n",
      "Consecutive Dates: 29-08-2022 and 06-10-2022\n",
      "Consecutive Dates: 06-10-2022 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 16-11-2023\n",
      "Consecutive Dates: 16-11-2023 and 27-11-2023\n",
      "2796\n",
      "\n",
      "Consecutive Dates: 25-03-2019 and 22-04-2019\n",
      "Consecutive Dates: 22-04-2019 and 21-05-2019\n",
      "Consecutive Dates: 21-05-2019 and 28-06-2019\n",
      "Consecutive Dates: 28-06-2019 and 09-08-2019\n",
      "Consecutive Dates: 09-08-2019 and 09-09-2019\n",
      "Consecutive Dates: 09-09-2019 and 11-10-2019\n",
      "Consecutive Dates: 11-10-2019 and 05-11-2019\n",
      "Consecutive Dates: 05-11-2019 and 04-12-2019\n",
      "Consecutive Dates: 04-12-2019 and 06-01-2019\n",
      "Consecutive Dates: 06-01-2019 and 10-02-2020\n",
      "Consecutive Dates: 10-02-2020 and 06-07-2020\n",
      "Consecutive Dates: 06-07-2020 and 24-11-2020\n",
      "Consecutive Dates: 24-11-2020 and 12-01-2021\n",
      "Consecutive Dates: 12-01-2021 and 26-04-2021\n",
      "Consecutive Dates: 26-04-2021 and 30-07-2021\n",
      "Consecutive Dates: 30-07-2021 and 28-09-2021\n",
      "Consecutive Dates: 28-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 25-02-2022\n",
      "Consecutive Dates: 25-02-2022 and 25-04-2022\n",
      "Consecutive Dates: 25-04-2022 and 25-05-2022\n",
      "Consecutive Dates: 25-05-2022 and 27-06-2022\n",
      "Consecutive Dates: 27-06-2022 and 27-07-2022\n",
      "Consecutive Dates: 27-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 02-11-2022\n",
      "Consecutive Dates: 02-11-2022 and 02-01-2023\n",
      "Consecutive Dates: 02-01-2023 and 27-02-2023\n",
      "Consecutive Dates: 27-02-2023 and 17-04-2023\n",
      "Consecutive Dates: 17-04-2023 and 29-05-2023\n",
      "Consecutive Dates: 29-05-2023 and 27-06-2023\n",
      "Consecutive Dates: 27-06-2023 and 27-09-2023\n",
      "Consecutive Dates: 27-09-2023 and 25-10-2023\n",
      "Consecutive Dates: 25-10-2023 and 27-11-2023\n",
      "2372\n",
      "\n",
      "Consecutive Dates: 28-08-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 27-12-2021\n",
      "Consecutive Dates: 27-12-2021 and 27-01-2022\n",
      "Consecutive Dates: 27-01-2022 and 25-04-2022\n",
      "Consecutive Dates: 25-04-2022 and 27-06-2022\n",
      "Consecutive Dates: 27-06-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 26-10-2022\n",
      "Consecutive Dates: 26-10-2022 and 18-11-2022\n",
      "Consecutive Dates: 18-11-2022 and 10-04-2023\n",
      "Consecutive Dates: 10-04-2023 and 19-10-2023\n",
      "782\n",
      "\n",
      "Consecutive Dates: 28-10-2021 and 29-11-2021\n",
      "Consecutive Dates: 29-11-2021 and 05-01-2022\n",
      "Consecutive Dates: 05-01-2022 and 05-09-2022\n",
      "Consecutive Dates: 05-09-2022 and 09-03-2022\n",
      "Consecutive Dates: 09-03-2022 and 09-04-2022\n",
      "523\n",
      "\n",
      "Consecutive Dates: 30-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 13-12-2021\n",
      "Consecutive Dates: 13-12-2021 and 29-01-2021\n",
      "392\n",
      "\n",
      "Consecutive Dates: 30-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 06-02-2023\n",
      "494\n",
      "\n",
      "Consecutive Dates: 08-09-2021 and 20-09-2021\n",
      "Consecutive Dates: 20-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 17-02-2022\n",
      "Consecutive Dates: 17-02-2022 and 04-09-2023\n",
      "Consecutive Dates: 04-09-2023 and 12-09-2023\n",
      "734\n",
      "\n",
      "Consecutive Dates: 05-07-2021 and 03-09-2021\n",
      "Consecutive Dates: 03-09-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 02-12-2021\n",
      "Consecutive Dates: 02-12-2021 and 31-01-2022\n",
      "Consecutive Dates: 31-01-2022 and 31-03-2022\n",
      "Consecutive Dates: 31-03-2022 and 31-05-2022\n",
      "Consecutive Dates: 31-05-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 29-12-2022\n",
      "Consecutive Dates: 29-12-2022 and 13-02-2023\n",
      "Consecutive Dates: 13-02-2023 and 02-06-2023\n",
      "Consecutive Dates: 02-06-2023 and 25-07-2023\n",
      "750\n",
      "\n",
      "Consecutive Dates: 03-05-2021 and 12-07-2021\n",
      "Consecutive Dates: 12-07-2021 and 28-10-2021\n",
      "Consecutive Dates: 28-10-2021 and 24-01-2022\n",
      "Consecutive Dates: 24-01-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 21-07-2022\n",
      "444\n",
      "\n",
      "Consecutive Dates: 08-11-2021 and 30-12-2021\n",
      "Consecutive Dates: 30-12-2021 and 29-01-2022\n",
      "Consecutive Dates: 29-01-2022 and 01-03-2022\n",
      "Consecutive Dates: 01-03-2022 and 31-03-2022\n",
      "Consecutive Dates: 31-03-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 11-06-2022\n",
      "Consecutive Dates: 11-06-2022 and 05-07-2022\n",
      "Consecutive Dates: 05-07-2022 and 04-08-2022\n",
      "Consecutive Dates: 04-08-2022 and 05-09-2022\n",
      "Consecutive Dates: 05-09-2022 and 10-10-2022\n",
      "Consecutive Dates: 10-10-2022 and 05-12-2022\n",
      "Consecutive Dates: 05-12-2022 and 14-01-2023\n",
      "Consecutive Dates: 14-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 27-03-2023\n",
      "Consecutive Dates: 27-03-2023 and 06-05-2023\n",
      "Consecutive Dates: 06-05-2023 and 10-06-2025\n",
      "1310\n",
      "\n",
      "Consecutive Dates: 18-07-2022 and 15-09-2022\n",
      "Consecutive Dates: 15-09-2022 and 06-10-2022\n",
      "Consecutive Dates: 06-10-2022 and 14-10-2022\n",
      "Consecutive Dates: 14-10-2022 and 16-11-2022\n",
      "Consecutive Dates: 16-11-2022 and 21-11-2022\n",
      "Consecutive Dates: 21-11-2022 and 17-12-2022\n",
      "Consecutive Dates: 17-12-2022 and 13-01-2023\n",
      "Consecutive Dates: 13-01-2023 and 18-01-2023\n",
      "Consecutive Dates: 18-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 15-03-2023\n",
      "Consecutive Dates: 15-03-2023 and 17-04-2023\n",
      "Consecutive Dates: 17-04-2023 and 07-06-2023\n",
      "Consecutive Dates: 07-06-2023 and 31-07-2023\n",
      "Consecutive Dates: 31-07-2023 and 11-08-2023\n",
      "Consecutive Dates: 11-08-2023 and 19-08-2023\n",
      "Consecutive Dates: 19-08-2023 and 20-09-2023\n",
      "Consecutive Dates: 20-09-2023 and 18-10-2023\n",
      "Consecutive Dates: 18-10-2023 and 04-11-2023\n",
      "Consecutive Dates: 04-11-2023 and 02-12-2023\n",
      "502\n",
      "\n",
      "Consecutive Dates: 21-07-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 18-05-2023\n",
      "Consecutive Dates: 18-05-2023 and 05-10-2023\n",
      "441\n",
      "\n",
      "0\n",
      "\n",
      "Consecutive Dates: 05-04-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 02-06-2022\n",
      "Consecutive Dates: 02-06-2022 and 01-07-2022\n",
      "Consecutive Dates: 01-07-2022 and 15-07-2022\n",
      "Consecutive Dates: 15-07-2022 and 26-07-2022\n",
      "Consecutive Dates: 26-07-2022 and 04-08-2022\n",
      "Consecutive Dates: 04-08-2022 and 11-08-2022\n",
      "Consecutive Dates: 11-08-2022 and 18-08-2022\n",
      "Consecutive Dates: 18-08-2022 and 25-08-2022\n",
      "Consecutive Dates: 25-08-2022 and 06-09-2022\n",
      "Consecutive Dates: 06-09-2022 and 13-10-2022\n",
      "Consecutive Dates: 13-10-2022 and 24-12-2022\n",
      "Consecutive Dates: 24-12-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 05-05-2023\n",
      "Consecutive Dates: 05-05-2023 and 28-07-2023\n",
      "Consecutive Dates: 28-07-2023 and 18-10-2023\n",
      "561\n",
      "\n",
      "Consecutive Dates: 16-01-2023 and 16-03-2023\n",
      "59\n",
      "\n",
      "Consecutive Dates: 02-02-2021 and 08-05-2021\n",
      "Consecutive Dates: 08-05-2021 and 14-09-2021\n",
      "Consecutive Dates: 14-09-2021 and 05-04-2021\n",
      "Consecutive Dates: 05-04-2021 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 24-08-2022\n",
      "Consecutive Dates: 24-08-2022 and 31-10-2022\n",
      "Consecutive Dates: 31-10-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 08-05-2023\n",
      "Consecutive Dates: 08-05-2023 and 11-07-2023\n",
      "Consecutive Dates: 11-07-2023 and 01-11-2023\n",
      "1326\n",
      "\n",
      "Consecutive Dates: 14-03-2019 and 23-12-2019\n",
      "Consecutive Dates: 23-12-2019 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 25-06-2022\n",
      "Consecutive Dates: 25-06-2022 and 29-08-2022\n",
      "Consecutive Dates: 29-08-2022 and 31-10-2022\n",
      "1327\n",
      "\n",
      "Consecutive Dates: 05-04-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 02-06-2022\n",
      "Consecutive Dates: 02-06-2022 and 01-07-2022\n",
      "Consecutive Dates: 01-07-2022 and 15-07-2022\n",
      "Consecutive Dates: 15-07-2022 and 26-07-2022\n",
      "Consecutive Dates: 26-07-2022 and 04-08-2022\n",
      "Consecutive Dates: 04-08-2022 and 11-08-2022\n",
      "Consecutive Dates: 11-08-2022 and 18-08-2022\n",
      "Consecutive Dates: 18-08-2022 and 25-08-2022\n",
      "Consecutive Dates: 25-08-2022 and 06-09-2022\n",
      "Consecutive Dates: 06-09-2022 and 13-10-2022\n",
      "Consecutive Dates: 13-10-2022 and 10-11-2022\n",
      "Consecutive Dates: 10-11-2022 and 24-12-2022\n",
      "Consecutive Dates: 24-12-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 05-05-2023\n",
      "Consecutive Dates: 05-05-2023 and 28-07-2023\n",
      "Consecutive Dates: 28-07-2023 and 18-10-2023\n",
      "561\n",
      "\n",
      "Consecutive Dates: 17-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 03-03-2023\n",
      "Consecutive Dates: 03-03-2023 and 03-04-2023\n",
      "Consecutive Dates: 03-04-2023 and 19-05-2023\n",
      "Consecutive Dates: 19-05-2023 and 24-06-2023\n",
      "Consecutive Dates: 24-06-2023 and 29-07-2023\n",
      "Consecutive Dates: 29-07-2023 and 07-09-2023\n",
      "233\n",
      "\n",
      "Consecutive Dates: 16-02-2023 and 27-03-2023\n",
      "Consecutive Dates: 27-03-2023 and 15-05-2023\n",
      "88\n",
      "\n",
      "Consecutive Dates: 16-02-2023 and 06-03-2023\n",
      "Consecutive Dates: 06-03-2023 and 22-03-2023\n",
      "Consecutive Dates: 22-03-2023 and 31-03-2023\n",
      "Consecutive Dates: 31-03-2023 and 28-04-2023\n",
      "Consecutive Dates: 28-04-2023 and 16-06-2023\n",
      "Consecutive Dates: 16-06-2023 and 01-09-2023\n",
      "Consecutive Dates: 01-09-2023 and 24-10-2023\n",
      "250\n",
      "\n",
      "Consecutive Dates: 28-12-2020 and 13-04-2021\n",
      "Consecutive Dates: 13-04-2021 and 25-07-2022\n",
      "Consecutive Dates: 25-07-2022 and 16-02-2023\n",
      "780\n",
      "\n",
      "Consecutive Dates: 16-02-2023 and 10-03-2023\n",
      "Consecutive Dates: 10-03-2023 and 17-04-2023\n",
      "Consecutive Dates: 17-04-2023 and 05-06-2023\n",
      "109\n",
      "\n",
      "Consecutive Dates: 15-09-2022 and 17-11-2022\n",
      "Consecutive Dates: 17-11-2022 and 20-12-2022\n",
      "Consecutive Dates: 20-12-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 18-04-2023\n",
      "Consecutive Dates: 18-04-2023 and 27-07-2023\n",
      "315\n",
      "\n",
      "Consecutive Dates: 20-05-2017 and 21-06-2017\n",
      "Consecutive Dates: 21-06-2017 and 25-08-2018\n",
      "Consecutive Dates: 25-08-2018 and 01-09-2018\n",
      "Consecutive Dates: 01-09-2018 and 12-09-2018\n",
      "Consecutive Dates: 12-09-2018 and 22-10-2018\n",
      "Consecutive Dates: 22-10-2018 and 23-11-2018\n",
      "Consecutive Dates: 23-11-2018 and 31-12-2018\n",
      "Consecutive Dates: 31-12-2018 and 16-02-2019\n",
      "Consecutive Dates: 16-02-2019 and 22-03-2019\n",
      "Consecutive Dates: 22-03-2019 and 03-07-2019\n",
      "Consecutive Dates: 03-07-2019 and 03-08-2019\n",
      "Consecutive Dates: 03-08-2019 and 11-09-2019\n",
      "Consecutive Dates: 11-09-2019 and 15-10-2019\n",
      "Consecutive Dates: 15-10-2019 and 15-11-2019\n",
      "Consecutive Dates: 15-11-2019 and 23-12-2019\n",
      "Consecutive Dates: 23-12-2019 and 31-01-2020\n",
      "Consecutive Dates: 31-01-2020 and 22-02-2020\n",
      "Consecutive Dates: 22-02-2020 and 09-03-2020\n",
      "Consecutive Dates: 09-03-2020 and 23-04-2020\n",
      "Consecutive Dates: 23-04-2020 and 15-06-2020\n",
      "Consecutive Dates: 15-06-2020 and 18-08-2020\n",
      "Consecutive Dates: 18-08-2020 and 17-10-2020\n",
      "Consecutive Dates: 17-10-2020 and 03-12-2020\n",
      "Consecutive Dates: 03-12-2020 and 28-12-2020\n",
      "Consecutive Dates: 28-12-2020 and 25-01-2021\n",
      "Consecutive Dates: 25-01-2021 and 25-02-2021\n",
      "Consecutive Dates: 25-02-2021 and 07-04-2021\n",
      "Consecutive Dates: 07-04-2021 and 19-06-2021\n",
      "Consecutive Dates: 19-06-2021 and 04-08-2021\n",
      "Consecutive Dates: 04-08-2021 and 06-09-2021\n",
      "Consecutive Dates: 06-09-2021 and 13-10-2021\n",
      "Consecutive Dates: 13-10-2021 and 17-11-2021\n",
      "Consecutive Dates: 17-11-2021 and 30-12-2021\n",
      "Consecutive Dates: 30-12-2021 and 19-02-2022\n",
      "Consecutive Dates: 19-02-2022 and 24-03-2022\n",
      "Consecutive Dates: 24-03-2022 and 21-04-2022\n",
      "Consecutive Dates: 21-04-2022 and 26-05-2022\n",
      "Consecutive Dates: 26-05-2022 and 02-06-2022\n",
      "Consecutive Dates: 02-06-2022 and 09-08-2022\n",
      "Consecutive Dates: 09-08-2022 and 22-09-2022\n",
      "Consecutive Dates: 22-09-2022 and 17-11-2022\n",
      "Consecutive Dates: 17-11-2022 and 07-01-2023\n",
      "Consecutive Dates: 07-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 21-03-2023\n",
      "Consecutive Dates: 21-03-2023 and 29-04-2023\n",
      "Consecutive Dates: 29-04-2023 and 26-08-2023\n",
      "Consecutive Dates: 26-08-2023 and 07-10-2023\n",
      "Consecutive Dates: 07-10-2023 and 04-12-2023\n",
      "2389\n",
      "\n",
      "Consecutive Dates: 08-07-2022 and 08-08-2022\n",
      "Consecutive Dates: 08-08-2022 and 08-09-2022\n",
      "Consecutive Dates: 08-09-2022 and 18-10-2022\n",
      "Consecutive Dates: 18-10-2022 and 14-11-2022\n",
      "Consecutive Dates: 14-11-2022 and 12-12-2022\n",
      "Consecutive Dates: 12-12-2022 and 11-01-2023\n",
      "Consecutive Dates: 11-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 04-04-2023\n",
      "Consecutive Dates: 04-04-2023 and 17-06-2023\n",
      "Consecutive Dates: 17-06-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 27-11-2023\n",
      "507\n",
      "\n",
      "Consecutive Dates: 24-04-2017 and 16-05-2017\n",
      "Consecutive Dates: 16-05-2017 and 08-10-2018\n",
      "Consecutive Dates: 08-10-2018 and 07-11-2018\n",
      "Consecutive Dates: 07-11-2018 and 10-12-2018\n",
      "Consecutive Dates: 10-12-2018 and 12-01-2019\n",
      "Consecutive Dates: 12-01-2019 and 28-03-2019\n",
      "Consecutive Dates: 28-03-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 30-05-2019\n",
      "Consecutive Dates: 30-05-2019 and 01-07-2019\n",
      "Consecutive Dates: 01-07-2019 and 05-08-2019\n",
      "Consecutive Dates: 05-08-2019 and 07-09-2019\n",
      "Consecutive Dates: 07-09-2019 and 07-10-2019\n",
      "Consecutive Dates: 07-10-2019 and 11-11-2019\n",
      "Consecutive Dates: 11-11-2019 and 18-12-2019\n",
      "Consecutive Dates: 18-12-2019 and 20-01-2020\n",
      "Consecutive Dates: 20-01-2020 and 17-02-2020\n",
      "Consecutive Dates: 17-02-2020 and 17-03-2020\n",
      "Consecutive Dates: 17-03-2020 and 18-06-2020\n",
      "Consecutive Dates: 18-06-2020 and 16-09-2020\n",
      "Consecutive Dates: 16-09-2020 and 28-12-2020\n",
      "Consecutive Dates: 28-12-2020 and 02-01-2021\n",
      "Consecutive Dates: 02-01-2021 and 02-02-2021\n",
      "Consecutive Dates: 02-02-2021 and 22-03-2021\n",
      "Consecutive Dates: 22-03-2021 and 26-04-2021\n",
      "Consecutive Dates: 26-04-2021 and 08-06-2022\n",
      "Consecutive Dates: 08-06-2022 and 08-07-2022\n",
      "Consecutive Dates: 08-07-2022 and 11-08-2022\n",
      "Consecutive Dates: 11-08-2022 and 09-09-2022\n",
      "Consecutive Dates: 09-09-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 25-03-2023\n",
      "Consecutive Dates: 25-03-2023 and 26-04-2023\n",
      "Consecutive Dates: 26-04-2023 and 30-05-2023\n",
      "Consecutive Dates: 30-05-2023 and 01-07-2023\n",
      "Consecutive Dates: 01-07-2023 and 05-08-2023\n",
      "Consecutive Dates: 05-08-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 25-10-2023\n",
      "2375\n",
      "\n",
      "Consecutive Dates: 21-05-2022 and 01-06-2022\n",
      "Consecutive Dates: 01-06-2022 and 22-06-2022\n",
      "Consecutive Dates: 22-06-2022 and 21-07-2022\n",
      "Consecutive Dates: 21-07-2022 and 27-08-2022\n",
      "Consecutive Dates: 27-08-2022 and 30-07-2022\n",
      "Consecutive Dates: 30-07-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 01-11-2022\n",
      "Consecutive Dates: 01-11-2022 and 02-12-2022\n",
      "Consecutive Dates: 02-12-2022 and 06-01-2023\n",
      "Consecutive Dates: 06-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 23-03-2023\n",
      "Consecutive Dates: 23-03-2023 and 29-04-2023\n",
      "Consecutive Dates: 29-04-2023 and 10-06-2023\n",
      "Consecutive Dates: 10-06-2023 and 17-07-2023\n",
      "Consecutive Dates: 17-07-2023 and 28-08-2023\n",
      "Consecutive Dates: 28-08-2023 and 09-10-2023\n",
      "Consecutive Dates: 09-10-2023 and 27-11-2023\n",
      "611\n",
      "\n",
      "Consecutive Dates: 16-02-2023 and 16-03-2023\n",
      "Consecutive Dates: 16-03-2023 and 17-04-2023\n",
      "Consecutive Dates: 17-04-2023 and 15-05-2023\n",
      "88\n",
      "\n",
      "0\n",
      "\n",
      "Consecutive Dates: 24-04-2017 and 16-05-2017\n",
      "Consecutive Dates: 16-05-2017 and 08-10-2018\n",
      "Consecutive Dates: 08-10-2018 and 07-11-2018\n",
      "Consecutive Dates: 07-11-2018 and 10-12-2018\n",
      "Consecutive Dates: 10-12-2018 and 12-01-2019\n",
      "Consecutive Dates: 12-01-2019 and 28-03-2019\n",
      "Consecutive Dates: 28-03-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 30-05-2019\n",
      "Consecutive Dates: 30-05-2019 and 01-07-2019\n",
      "Consecutive Dates: 01-07-2019 and 05-08-2019\n",
      "Consecutive Dates: 05-08-2019 and 07-09-2019\n",
      "Consecutive Dates: 07-09-2019 and 07-10-2019\n",
      "Consecutive Dates: 07-10-2019 and 11-11-2019\n",
      "Consecutive Dates: 11-11-2019 and 18-12-2019\n",
      "Consecutive Dates: 18-12-2019 and 20-01-2020\n",
      "Consecutive Dates: 20-01-2020 and 17-02-2020\n",
      "Consecutive Dates: 17-02-2020 and 17-03-2020\n",
      "Consecutive Dates: 17-03-2020 and 18-06-2020\n",
      "Consecutive Dates: 18-06-2020 and 16-09-2020\n",
      "Consecutive Dates: 16-09-2020 and 10-11-2020\n",
      "Consecutive Dates: 10-11-2020 and 28-12-2020\n",
      "Consecutive Dates: 28-12-2020 and 02-01-2021\n",
      "Consecutive Dates: 02-01-2021 and 02-02-2021\n",
      "Consecutive Dates: 02-02-2021 and 22-03-2021\n",
      "Consecutive Dates: 22-03-2021 and 26-04-2021\n",
      "Consecutive Dates: 26-04-2021 and 08-06-2022\n",
      "Consecutive Dates: 08-06-2022 and 08-07-2022\n",
      "Consecutive Dates: 08-07-2022 and 11-08-2022\n",
      "Consecutive Dates: 11-08-2022 and 09-09-2022\n",
      "Consecutive Dates: 09-09-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 30-11-2022\n",
      "Consecutive Dates: 30-11-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 25-03-2023\n",
      "Consecutive Dates: 25-03-2023 and 26-04-2023\n",
      "Consecutive Dates: 26-04-2023 and 30-05-2023\n",
      "Consecutive Dates: 30-05-2023 and 01-07-2023\n",
      "Consecutive Dates: 01-07-2023 and 05-08-2023\n",
      "Consecutive Dates: 05-08-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 25-10-2023\n",
      "2375\n",
      "\n",
      "Consecutive Dates: 16-02-2023 and 03-03-2023\n",
      "Consecutive Dates: 03-03-2023 and 13-06-2023\n",
      "117\n",
      "\n",
      "Consecutive Dates: 29-12-2017 and 11-01-2022\n",
      "Consecutive Dates: 11-01-2022 and 12-01-2022\n",
      "Consecutive Dates: 12-01-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 18-02-2023\n",
      "1877\n",
      "\n",
      "Consecutive Dates: 04-05-2022 and 21-06-2022\n",
      "Consecutive Dates: 21-06-2022 and 21-07-2022\n",
      "Consecutive Dates: 21-07-2022 and 20-08-2022\n",
      "Consecutive Dates: 20-08-2022 and 17-10-2022\n",
      "Consecutive Dates: 17-10-2022 and 16-11-2022\n",
      "Consecutive Dates: 16-11-2022 and 19-12-2022\n",
      "Consecutive Dates: 19-12-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 18-03-2023\n",
      "Consecutive Dates: 18-03-2023 and 18-04-2023\n",
      "Consecutive Dates: 18-04-2023 and 16-05-2023\n",
      "Consecutive Dates: 16-05-2023 and 16-06-2023\n",
      "Consecutive Dates: 16-06-2023 and 13-07-2023\n",
      "Consecutive Dates: 13-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 31-08-2023\n",
      "Consecutive Dates: 31-08-2023 and 01-11-2023\n",
      "Consecutive Dates: 01-11-2023 and 02-12-2023\n",
      "577\n",
      "\n",
      "Consecutive Dates: 22-09-2022 and 20-10-2022\n",
      "Consecutive Dates: 20-10-2022 and 17-11-2022\n",
      "Consecutive Dates: 17-11-2022 and 21-12-2022\n",
      "Consecutive Dates: 21-12-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 07-04-2023\n",
      "Consecutive Dates: 07-04-2023 and 18-07-2023\n",
      "Consecutive Dates: 18-07-2023 and 17-08-2023\n",
      "Consecutive Dates: 17-08-2023 and 13-10-2023\n",
      "386\n",
      "\n",
      "Consecutive Dates: 11-01-2018 and 08-02-2019\n",
      "Consecutive Dates: 08-02-2019 and 10-03-2019\n",
      "Consecutive Dates: 10-03-2019 and 06-04-2019\n",
      "Consecutive Dates: 06-04-2019 and 04-05-2019\n",
      "Consecutive Dates: 04-05-2019 and 13-07-2019\n",
      "Consecutive Dates: 13-07-2019 and 11-02-2020\n",
      "Consecutive Dates: 11-02-2020 and 02-05-2022\n",
      "Consecutive Dates: 02-05-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 20-04-2023\n",
      "1925\n",
      "\n",
      "Consecutive Dates: 28-01-2019 and 02-03-2019\n",
      "Consecutive Dates: 02-03-2019 and 09-04-2019\n",
      "Consecutive Dates: 09-04-2019 and 29-05-2019\n",
      "Consecutive Dates: 29-05-2019 and 02-09-2019\n",
      "Consecutive Dates: 02-09-2019 and 30-09-2019\n",
      "Consecutive Dates: 30-09-2019 and 27-11-2019\n",
      "Consecutive Dates: 27-11-2019 and 24-12-2019\n",
      "Consecutive Dates: 24-12-2019 and 31-01-2020\n",
      "Consecutive Dates: 31-01-2020 and 04-02-2020\n",
      "Consecutive Dates: 04-02-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 09-06-2020\n",
      "Consecutive Dates: 09-06-2020 and 08-10-2020\n",
      "Consecutive Dates: 08-10-2020 and 27-11-2020\n",
      "Consecutive Dates: 27-11-2020 and 28-12-2020\n",
      "Consecutive Dates: 28-12-2020 and 29-01-2021\n",
      "Consecutive Dates: 29-01-2021 and 27-02-2021\n",
      "Consecutive Dates: 27-02-2021 and 30-03-2021\n",
      "Consecutive Dates: 30-03-2021 and 04-05-2021\n",
      "Consecutive Dates: 04-05-2021 and 11-06-2021\n",
      "Consecutive Dates: 11-06-2021 and 09-08-2021\n",
      "Consecutive Dates: 09-08-2021 and 07-10-2021\n",
      "Consecutive Dates: 07-10-2021 and 15-12-2021\n",
      "Consecutive Dates: 15-12-2021 and 04-02-2022\n",
      "Consecutive Dates: 04-02-2022 and 16-03-2022\n",
      "Consecutive Dates: 16-03-2022 and 21-04-2022\n",
      "Consecutive Dates: 21-04-2022 and 03-06-2022\n",
      "Consecutive Dates: 03-06-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 04-08-2022\n",
      "Consecutive Dates: 04-08-2022 and 29-09-2022\n",
      "Consecutive Dates: 29-09-2022 and 01-11-2022\n",
      "Consecutive Dates: 01-11-2022 and 15-12-2022\n",
      "Consecutive Dates: 15-12-2022 and 14-01-2023\n",
      "Consecutive Dates: 14-01-2023 and 25-02-2023\n",
      "Consecutive Dates: 25-02-2023 and 11-04-2023\n",
      "Consecutive Dates: 11-04-2023 and 25-05-2023\n",
      "Consecutive Dates: 25-05-2023 and 26-03-2023\n",
      "Consecutive Dates: 26-03-2023 and 25-07-2023\n",
      "Consecutive Dates: 25-07-2023 and 08-09-2023\n",
      "Consecutive Dates: 08-09-2023 and 06-10-2023\n",
      "Consecutive Dates: 06-10-2023 and 04-11-2023\n",
      "Consecutive Dates: 04-11-2023 and 14-12-2023\n",
      "1901\n",
      "\n",
      "Consecutive Dates: 13-05-2022 and 11-06-2022\n",
      "Consecutive Dates: 11-06-2022 and 15-07-2022\n",
      "Consecutive Dates: 15-07-2022 and 16-08-2022\n",
      "Consecutive Dates: 16-08-2022 and 17-01-2023\n",
      "Consecutive Dates: 17-01-2023 and 18-01-2023\n",
      "Consecutive Dates: 18-01-2023 and 16-02-2023\n",
      "279\n",
      "\n",
      "Consecutive Dates: 15-12-2007 and 12-01-2008\n",
      "Consecutive Dates: 12-01-2008 and 02-02-2008\n",
      "Consecutive Dates: 02-02-2008 and 11-12-2010\n",
      "Consecutive Dates: 11-12-2010 and 13-03-2013\n",
      "Consecutive Dates: 13-03-2013 and 13-04-2013\n",
      "Consecutive Dates: 13-04-2013 and 11-05-2013\n",
      "Consecutive Dates: 11-05-2013 and 12-06-2013\n",
      "Consecutive Dates: 12-06-2013 and 13-07-2013\n",
      "Consecutive Dates: 13-07-2013 and 14-08-2013\n",
      "Consecutive Dates: 14-08-2013 and 19-08-2013\n",
      "Consecutive Dates: 19-08-2013 and 14-09-2013\n",
      "Consecutive Dates: 14-09-2013 and 17-10-2013\n",
      "Consecutive Dates: 17-10-2013 and 16-11-2013\n",
      "Consecutive Dates: 16-11-2013 and 18-12-2013\n",
      "Consecutive Dates: 18-12-2013 and 18-01-2014\n",
      "Consecutive Dates: 18-01-2014 and 19-02-2014\n",
      "Consecutive Dates: 19-02-2014 and 23-04-2014\n",
      "Consecutive Dates: 23-04-2014 and 24-05-2014\n",
      "Consecutive Dates: 24-05-2014 and 28-06-2014\n",
      "Consecutive Dates: 28-06-2014 and 30-07-2014\n",
      "Consecutive Dates: 30-07-2014 and 30-08-2014\n",
      "Consecutive Dates: 30-08-2014 and 01-10-2014\n",
      "Consecutive Dates: 01-10-2014 and 29-10-2014\n",
      "Consecutive Dates: 29-10-2014 and 29-11-2014\n",
      "Consecutive Dates: 29-11-2014 and 31-12-2014\n",
      "Consecutive Dates: 31-12-2014 and 03-02-2015\n",
      "Consecutive Dates: 03-02-2015 and 07-03-2015\n",
      "Consecutive Dates: 07-03-2015 and 09-06-2015\n",
      "Consecutive Dates: 09-06-2015 and 11-07-2015\n",
      "Consecutive Dates: 11-07-2015 and 14-08-2015\n",
      "Consecutive Dates: 14-08-2015 and 29-09-2015\n",
      "Consecutive Dates: 29-09-2015 and 03-11-2015\n",
      "Consecutive Dates: 03-11-2015 and 05-12-2015\n",
      "Consecutive Dates: 05-12-2015 and 05-01-2016\n",
      "Consecutive Dates: 05-01-2016 and 08-01-2016\n",
      "Consecutive Dates: 08-01-2016 and 16-02-2016\n",
      "Consecutive Dates: 16-02-2016 and 21-03-2016\n",
      "Consecutive Dates: 21-03-2016 and 23-04-2016\n",
      "Consecutive Dates: 23-04-2016 and 31-05-2016\n",
      "Consecutive Dates: 31-05-2016 and 11-07-2016\n",
      "Consecutive Dates: 11-07-2016 and 09-08-2016\n",
      "Consecutive Dates: 09-08-2016 and 10-09-2016\n",
      "Consecutive Dates: 10-09-2016 and 22-10-2016\n",
      "Consecutive Dates: 22-10-2016 and 07-01-2017\n",
      "Consecutive Dates: 07-01-2017 and 14-03-2017\n",
      "Consecutive Dates: 14-03-2017 and 06-05-2017\n",
      "Consecutive Dates: 06-05-2017 and 07-07-2017\n",
      "Consecutive Dates: 07-07-2017 and 08-08-2017\n",
      "Consecutive Dates: 08-08-2017 and 12-09-2017\n",
      "Consecutive Dates: 12-09-2017 and 14-10-2017\n",
      "Consecutive Dates: 14-10-2017 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 20-03-2018\n",
      "Consecutive Dates: 20-03-2018 and 02-05-2018\n",
      "Consecutive Dates: 02-05-2018 and 08-06-2018\n",
      "Consecutive Dates: 08-06-2018 and 20-07-2018\n",
      "Consecutive Dates: 20-07-2018 and 28-12-2018\n",
      "Consecutive Dates: 28-12-2018 and 08-01-2019\n",
      "Consecutive Dates: 08-01-2019 and 25-01-2019\n",
      "Consecutive Dates: 25-01-2019 and 15-03-2019\n",
      "Consecutive Dates: 15-03-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 07-06-2019\n",
      "Consecutive Dates: 07-06-2019 and 11-07-2019\n",
      "Consecutive Dates: 11-07-2019 and 13-08-2019\n",
      "Consecutive Dates: 13-08-2019 and 03-10-2019\n",
      "Consecutive Dates: 03-10-2019 and 07-11-2019\n",
      "Consecutive Dates: 07-11-2019 and 04-01-2020\n",
      "Consecutive Dates: 04-01-2020 and 24-03-2020\n",
      "Consecutive Dates: 24-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 11-07-2020\n",
      "Consecutive Dates: 11-07-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 28-08-2021\n",
      "Consecutive Dates: 28-08-2021 and 25-09-2021\n",
      "Consecutive Dates: 25-09-2021 and 26-10-2021\n",
      "Consecutive Dates: 26-10-2021 and 30-10-2021\n",
      "Consecutive Dates: 30-10-2021 and 03-11-2021\n",
      "Consecutive Dates: 03-11-2021 and 27-11-2021\n",
      "Consecutive Dates: 27-11-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 28-01-2022\n",
      "Consecutive Dates: 28-01-2022 and 28-02-2022\n",
      "Consecutive Dates: 28-02-2022 and 28-03-2022\n",
      "Consecutive Dates: 28-03-2022 and 28-04-2022\n",
      "Consecutive Dates: 28-04-2022 and 28-05-2022\n",
      "Consecutive Dates: 28-05-2022 and 29-06-2022\n",
      "Consecutive Dates: 29-06-2022 and 28-07-2022\n",
      "Consecutive Dates: 28-07-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 09-11-2022\n",
      "Consecutive Dates: 09-11-2022 and 14-12-2022\n",
      "Consecutive Dates: 14-12-2022 and 19-01-2023\n",
      "Consecutive Dates: 19-01-2023 and 20-02-2023\n",
      "Consecutive Dates: 20-02-2023 and 04-04-2023\n",
      "Consecutive Dates: 04-04-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 06-06-2023\n",
      "Consecutive Dates: 06-06-2023 and 06-07-2023\n",
      "Consecutive Dates: 06-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 11-10-2023\n",
      "Consecutive Dates: 11-10-2023 and 18-12-2023\n",
      "5847\n",
      "\n",
      "Consecutive Dates: 27-11-2019 and 24-01-2020\n",
      "Consecutive Dates: 24-01-2020 and 03-03-2020\n",
      "Consecutive Dates: 03-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 16-06-2020\n",
      "Consecutive Dates: 16-06-2020 and 29-07-2020\n",
      "Consecutive Dates: 29-07-2020 and 03-11-2020\n",
      "Consecutive Dates: 03-11-2020 and 17-11-2020\n",
      "Consecutive Dates: 17-11-2020 and 29-12-2020\n",
      "Consecutive Dates: 29-12-2020 and 10-02-2021\n",
      "Consecutive Dates: 10-02-2021 and 16-03-2021\n",
      "Consecutive Dates: 16-03-2021 and 31-03-2021\n",
      "Consecutive Dates: 31-03-2021 and 30-03-2022\n",
      "Consecutive Dates: 30-03-2022 and 27-05-2022\n",
      "Consecutive Dates: 27-05-2022 and 08-07-2022\n",
      "Consecutive Dates: 08-07-2022 and 22-08-2022\n",
      "Consecutive Dates: 22-08-2022 and 27-09-2022\n",
      "Consecutive Dates: 27-09-2022 and 11-11-2022\n",
      "Consecutive Dates: 11-11-2022 and 14-12-2022\n",
      "Consecutive Dates: 14-12-2022 and 18-01-2023\n",
      "Consecutive Dates: 18-01-2023 and 28-02-2023\n",
      "Consecutive Dates: 28-02-2023 and 18-04-2023\n",
      "Consecutive Dates: 18-04-2023 and 20-07-2023\n",
      "Consecutive Dates: 20-07-2023 and 26-09-2023\n",
      "Consecutive Dates: 26-09-2023 and 06-12-2023\n",
      "1470\n",
      "\n",
      "Consecutive Dates: 12-01-2008 and 02-02-2010\n",
      "Consecutive Dates: 02-02-2010 and 11-12-2010\n",
      "Consecutive Dates: 11-12-2010 and 13-03-2013\n",
      "Consecutive Dates: 13-03-2013 and 13-04-2013\n",
      "Consecutive Dates: 13-04-2013 and 11-05-2013\n",
      "Consecutive Dates: 11-05-2013 and 12-06-2013\n",
      "Consecutive Dates: 12-06-2013 and 13-07-2013\n",
      "Consecutive Dates: 13-07-2013 and 14-08-2013\n",
      "Consecutive Dates: 14-08-2013 and 19-08-2013\n",
      "Consecutive Dates: 19-08-2013 and 14-09-2013\n",
      "Consecutive Dates: 14-09-2013 and 17-10-2013\n",
      "Consecutive Dates: 17-10-2013 and 14-09-2013\n",
      "Consecutive Dates: 14-09-2013 and 17-10-2013\n",
      "Consecutive Dates: 17-10-2013 and 16-11-2013\n",
      "Consecutive Dates: 16-11-2013 and 18-01-2014\n",
      "Consecutive Dates: 18-01-2014 and 19-02-2014\n",
      "Consecutive Dates: 19-02-2014 and 24-05-2014\n",
      "Consecutive Dates: 24-05-2014 and 23-06-2014\n",
      "Consecutive Dates: 23-06-2014 and 30-07-2014\n",
      "Consecutive Dates: 30-07-2014 and 30-08-2014\n",
      "Consecutive Dates: 30-08-2014 and 01-10-2014\n",
      "Consecutive Dates: 01-10-2014 and 29-10-2014\n",
      "Consecutive Dates: 29-10-2014 and 29-11-2014\n",
      "Consecutive Dates: 29-11-2014 and 31-12-2014\n",
      "Consecutive Dates: 31-12-2014 and 03-01-2015\n",
      "Consecutive Dates: 03-01-2015 and 07-03-2015\n",
      "Consecutive Dates: 07-03-2015 and 18-04-2015\n",
      "Consecutive Dates: 18-04-2015 and 09-06-2015\n",
      "Consecutive Dates: 09-06-2015 and 11-07-2015\n",
      "Consecutive Dates: 11-07-2015 and 14-08-2015\n",
      "Consecutive Dates: 14-08-2015 and 29-09-2015\n",
      "Consecutive Dates: 29-09-2015 and 03-11-2015\n",
      "Consecutive Dates: 03-11-2015 and 05-12-2015\n",
      "Consecutive Dates: 05-12-2015 and 05-01-2016\n",
      "Consecutive Dates: 05-01-2016 and 08-01-2016\n",
      "Consecutive Dates: 08-01-2016 and 16-02-2016\n",
      "Consecutive Dates: 16-02-2016 and 21-03-2016\n",
      "Consecutive Dates: 21-03-2016 and 23-04-2016\n",
      "Consecutive Dates: 23-04-2016 and 31-05-2016\n",
      "Consecutive Dates: 31-05-2016 and 11-07-2016\n",
      "Consecutive Dates: 11-07-2016 and 09-08-2016\n",
      "Consecutive Dates: 09-08-2016 and 10-05-2016\n",
      "Consecutive Dates: 10-05-2016 and 22-10-2016\n",
      "Consecutive Dates: 22-10-2016 and 07-01-2017\n",
      "Consecutive Dates: 07-01-2017 and 14-03-2017\n",
      "Consecutive Dates: 14-03-2017 and 06-05-2017\n",
      "Consecutive Dates: 06-05-2017 and 07-07-2017\n",
      "Consecutive Dates: 07-07-2017 and 08-08-2017\n",
      "Consecutive Dates: 08-08-2017 and 12-09-2017\n",
      "Consecutive Dates: 12-09-2017 and 14-10-2017\n",
      "Consecutive Dates: 14-10-2017 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 20-03-2018\n",
      "Consecutive Dates: 20-03-2018 and 02-05-2018\n",
      "Consecutive Dates: 02-05-2018 and 08-06-2018\n",
      "Consecutive Dates: 08-06-2018 and 20-07-2018\n",
      "Consecutive Dates: 20-07-2018 and 28-12-2018\n",
      "Consecutive Dates: 28-12-2018 and 08-01-2018\n",
      "Consecutive Dates: 08-01-2018 and 25-01-2019\n",
      "Consecutive Dates: 25-01-2019 and 15-03-2019\n",
      "Consecutive Dates: 15-03-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 07-06-2019\n",
      "Consecutive Dates: 07-06-2019 and 11-07-2019\n",
      "Consecutive Dates: 11-07-2019 and 13-08-2019\n",
      "Consecutive Dates: 13-08-2019 and 03-10-2019\n",
      "Consecutive Dates: 03-10-2019 and 07-11-2019\n",
      "Consecutive Dates: 07-11-2019 and 04-01-2020\n",
      "Consecutive Dates: 04-01-2020 and 24-03-2020\n",
      "Consecutive Dates: 24-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 11-07-2020\n",
      "Consecutive Dates: 11-07-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 08-03-2021\n",
      "Consecutive Dates: 08-03-2021 and 28-08-2021\n",
      "Consecutive Dates: 28-08-2021 and 25-09-2021\n",
      "Consecutive Dates: 25-09-2021 and 26-10-2021\n",
      "Consecutive Dates: 26-10-2021 and 30-10-2021\n",
      "Consecutive Dates: 30-10-2021 and 03-11-2021\n",
      "Consecutive Dates: 03-11-2021 and 27-11-2021\n",
      "Consecutive Dates: 27-11-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 28-01-2022\n",
      "Consecutive Dates: 28-01-2022 and 28-02-2022\n",
      "Consecutive Dates: 28-02-2022 and 28-03-2022\n",
      "Consecutive Dates: 28-03-2022 and 28-04-2022\n",
      "Consecutive Dates: 28-04-2022 and 28-05-2022\n",
      "Consecutive Dates: 28-05-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 28-07-2022\n",
      "Consecutive Dates: 28-07-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 09-11-2022\n",
      "Consecutive Dates: 09-11-2022 and 14-12-2022\n",
      "Consecutive Dates: 14-12-2022 and 19-01-2023\n",
      "Consecutive Dates: 19-01-2023 and 20-02-2022\n",
      "Consecutive Dates: 20-02-2022 and 04-04-2023\n",
      "Consecutive Dates: 04-04-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 06-06-2023\n",
      "Consecutive Dates: 06-06-2023 and 06-07-2023\n",
      "Consecutive Dates: 06-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 11-10-2023\n",
      "Consecutive Dates: 11-10-2023 and 18-12-2023\n",
      "7441\n",
      "\n",
      "Consecutive Dates: 28-01-2019 and 02-03-2019\n",
      "Consecutive Dates: 02-03-2019 and 09-04-2019\n",
      "Consecutive Dates: 09-04-2019 and 29-05-2019\n",
      "Consecutive Dates: 29-05-2019 and 02-09-2019\n",
      "Consecutive Dates: 02-09-2019 and 30-09-2019\n",
      "Consecutive Dates: 30-09-2019 and 27-11-2019\n",
      "Consecutive Dates: 27-11-2019 and 24-12-2019\n",
      "Consecutive Dates: 24-12-2019 and 31-01-2020\n",
      "Consecutive Dates: 31-01-2020 and 04-02-2020\n",
      "Consecutive Dates: 04-02-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 09-06-2020\n",
      "Consecutive Dates: 09-06-2020 and 08-10-2020\n",
      "Consecutive Dates: 08-10-2020 and 27-11-2020\n",
      "Consecutive Dates: 27-11-2020 and 28-12-2020\n",
      "Consecutive Dates: 28-12-2020 and 29-01-2021\n",
      "Consecutive Dates: 29-01-2021 and 27-02-2021\n",
      "Consecutive Dates: 27-02-2021 and 30-03-2021\n",
      "Consecutive Dates: 30-03-2021 and 04-05-2021\n",
      "Consecutive Dates: 04-05-2021 and 11-06-2021\n",
      "Consecutive Dates: 11-06-2021 and 09-08-2021\n",
      "Consecutive Dates: 09-08-2021 and 07-10-2021\n",
      "Consecutive Dates: 07-10-2021 and 10-11-2021\n",
      "Consecutive Dates: 10-11-2021 and 15-12-2021\n",
      "Consecutive Dates: 15-12-2021 and 04-02-2022\n",
      "Consecutive Dates: 04-02-2022 and 16-03-2022\n",
      "Consecutive Dates: 16-03-2022 and 21-04-2022\n",
      "Consecutive Dates: 21-04-2022 and 03-06-2022\n",
      "Consecutive Dates: 03-06-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 04-08-2022\n",
      "Consecutive Dates: 04-08-2022 and 29-09-2022\n",
      "Consecutive Dates: 29-09-2022 and 01-11-2022\n",
      "Consecutive Dates: 01-11-2022 and 15-12-2022\n",
      "Consecutive Dates: 15-12-2022 and 14-01-2023\n",
      "Consecutive Dates: 14-01-2023 and 25-02-2023\n",
      "Consecutive Dates: 25-02-2023 and 11-04-2023\n",
      "Consecutive Dates: 11-04-2023 and 25-05-2023\n",
      "Consecutive Dates: 25-05-2023 and 26-03-2023\n",
      "Consecutive Dates: 26-03-2023 and 25-07-2023\n",
      "Consecutive Dates: 25-07-2023 and 08-09-2023\n",
      "Consecutive Dates: 08-09-2023 and 06-10-2023\n",
      "Consecutive Dates: 06-10-2023 and 04-11-2023\n",
      "Consecutive Dates: 04-11-2023 and 14-12-2023\n",
      "1901\n",
      "\n",
      "Consecutive Dates: 17-04-2010 and 18-09-2010\n",
      "Consecutive Dates: 18-09-2010 and 27-10-2010\n",
      "Consecutive Dates: 27-10-2010 and 27-11-2010\n",
      "Consecutive Dates: 27-11-2010 and 12-09-2017\n",
      "Consecutive Dates: 12-09-2017 and 12-10-2017\n",
      "Consecutive Dates: 12-10-2017 and 27-10-2017\n",
      "Consecutive Dates: 27-10-2017 and 22-12-2017\n",
      "Consecutive Dates: 22-12-2017 and 25-01-2018\n",
      "Consecutive Dates: 25-01-2018 and 10-03-2018\n",
      "Consecutive Dates: 10-03-2018 and 24-04-2018\n",
      "Consecutive Dates: 24-04-2018 and 21-05-2018\n",
      "Consecutive Dates: 21-05-2018 and 04-07-2018\n",
      "Consecutive Dates: 04-07-2018 and 13-08-2018\n",
      "Consecutive Dates: 13-08-2018 and 12-09-2018\n",
      "Consecutive Dates: 12-09-2018 and 06-10-2018\n",
      "Consecutive Dates: 06-10-2018 and 14-11-2018\n",
      "Consecutive Dates: 14-11-2018 and 21-12-2018\n",
      "Consecutive Dates: 21-12-2018 and 28-01-2019\n",
      "Consecutive Dates: 28-01-2019 and 15-03-2019\n",
      "Consecutive Dates: 15-03-2019 and 24-04-2019\n",
      "Consecutive Dates: 24-04-2019 and 31-05-2019\n",
      "Consecutive Dates: 31-05-2019 and 09-07-2019\n",
      "Consecutive Dates: 09-07-2019 and 26-08-2019\n",
      "Consecutive Dates: 26-08-2019 and 15-10-2019\n",
      "Consecutive Dates: 15-10-2019 and 30-12-2019\n",
      "Consecutive Dates: 30-12-2019 and 02-03-2020\n",
      "Consecutive Dates: 02-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 25-05-2020\n",
      "Consecutive Dates: 25-05-2020 and 12-08-2020\n",
      "Consecutive Dates: 12-08-2020 and 08-10-2020\n",
      "Consecutive Dates: 08-10-2020 and 30-10-2020\n",
      "Consecutive Dates: 30-10-2020 and 09-01-2021\n",
      "Consecutive Dates: 09-01-2021 and 08-02-2021\n",
      "Consecutive Dates: 08-02-2021 and 08-03-2021\n",
      "Consecutive Dates: 08-03-2021 and 08-04-2021\n",
      "Consecutive Dates: 08-04-2021 and 05-05-2021\n",
      "Consecutive Dates: 05-05-2021 and 21-06-2021\n",
      "Consecutive Dates: 21-06-2021 and 28-09-2021\n",
      "Consecutive Dates: 28-09-2021 and 03-12-2021\n",
      "Consecutive Dates: 03-12-2021 and 27-01-2022\n",
      "Consecutive Dates: 27-01-2022 and 17-04-2022\n",
      "Consecutive Dates: 17-04-2022 and 09-05-2022\n",
      "Consecutive Dates: 09-05-2022 and 13-07-2022\n",
      "Consecutive Dates: 13-07-2022 and 13-09-2022\n",
      "Consecutive Dates: 13-09-2022 and 14-11-2022\n",
      "Consecutive Dates: 14-11-2022 and 27-01-2023\n",
      "Consecutive Dates: 27-01-2023 and 18-03-2023\n",
      "Consecutive Dates: 18-03-2023 and 29-06-2023\n",
      "Consecutive Dates: 29-06-2023 and 24-07-2023\n",
      "Consecutive Dates: 24-07-2023 and 02-09-2023\n",
      "Consecutive Dates: 02-09-2023 and 29-09-2023\n",
      "Consecutive Dates: 29-09-2023 and 14-11-2023\n",
      "Consecutive Dates: 14-11-2023 and 20-12-2023\n",
      "4995\n",
      "\n",
      "Consecutive Dates: 06-08-2011 and 14-08-2019\n",
      "Consecutive Dates: 14-08-2019 and 15-06-2020\n",
      "Consecutive Dates: 15-06-2020 and 18-01-2021\n",
      "Consecutive Dates: 18-01-2021 and 24-02-2021\n",
      "Consecutive Dates: 24-02-2021 and 01-03-2021\n",
      "Consecutive Dates: 01-03-2021 and 08-03-2021\n",
      "Consecutive Dates: 08-03-2021 and 30-04-2021\n",
      "Consecutive Dates: 30-04-2021 and 02-06-2021\n",
      "Consecutive Dates: 02-06-2021 and 03-06-2021\n",
      "Consecutive Dates: 03-06-2021 and 18-06-2021\n",
      "3604\n",
      "\n",
      "Consecutive Dates: 16-05-2018 and 15-06-2018\n",
      "Consecutive Dates: 15-06-2018 and 16-07-2018\n",
      "Consecutive Dates: 16-07-2018 and 16-08-2018\n",
      "Consecutive Dates: 16-08-2018 and 15-09-2018\n",
      "Consecutive Dates: 15-09-2018 and 15-11-2018\n",
      "Consecutive Dates: 15-11-2018 and 05-03-2019\n",
      "Consecutive Dates: 05-03-2019 and 03-04-2019\n",
      "Consecutive Dates: 03-04-2019 and 02-05-2019\n",
      "Consecutive Dates: 02-05-2019 and 27-05-2019\n",
      "Consecutive Dates: 27-05-2019 and 27-06-2019\n",
      "Consecutive Dates: 27-06-2019 and 27-07-2019\n",
      "Consecutive Dates: 27-07-2019 and 27-08-2019\n",
      "Consecutive Dates: 27-08-2019 and 31-08-2019\n",
      "Consecutive Dates: 31-08-2019 and 13-09-2019\n",
      "Consecutive Dates: 13-09-2019 and 26-10-2019\n",
      "Consecutive Dates: 26-10-2019 and 30-11-2019\n",
      "Consecutive Dates: 30-11-2019 and 27-12-2019\n",
      "Consecutive Dates: 27-12-2019 and 27-01-2020\n",
      "Consecutive Dates: 27-01-2020 and 29-02-2020\n",
      "Consecutive Dates: 29-02-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 16-12-2020\n",
      "Consecutive Dates: 16-12-2020 and 03-05-2022\n",
      "Consecutive Dates: 03-05-2022 and 19-05-2022\n",
      "Consecutive Dates: 19-05-2022 and 17-06-2022\n",
      "Consecutive Dates: 17-06-2022 and 16-07-2022\n",
      "Consecutive Dates: 16-07-2022 and 09-08-2022\n",
      "Consecutive Dates: 09-08-2022 and 03-09-2022\n",
      "Consecutive Dates: 03-09-2022 and 03-10-2022\n",
      "Consecutive Dates: 03-10-2022 and 02-11-2022\n",
      "Consecutive Dates: 02-11-2022 and 06-12-2022\n",
      "Consecutive Dates: 06-12-2022 and 04-01-2023\n",
      "Consecutive Dates: 04-01-2023 and 09-02-2023\n",
      "Consecutive Dates: 09-02-2023 and 09-03-2023\n",
      "Consecutive Dates: 09-03-2023 and 03-04-2023\n",
      "Consecutive Dates: 03-04-2023 and 24-04-2023\n",
      "Consecutive Dates: 24-04-2023 and 05-06-2023\n",
      "Consecutive Dates: 05-06-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 06-09-2023\n",
      "Consecutive Dates: 06-09-2023 and 05-10-2023\n",
      "Consecutive Dates: 05-10-2023 and 04-11-2023\n",
      "Consecutive Dates: 04-11-2023 and 04-12-2023\n",
      "2028\n",
      "\n",
      "Consecutive Dates: 15-12-2007 and 12-01-2008\n",
      "Consecutive Dates: 12-01-2008 and 02-02-2008\n",
      "Consecutive Dates: 02-02-2008 and 11-12-2010\n",
      "Consecutive Dates: 11-12-2010 and 13-03-2013\n",
      "Consecutive Dates: 13-03-2013 and 13-04-2013\n",
      "Consecutive Dates: 13-04-2013 and 11-05-2013\n",
      "Consecutive Dates: 11-05-2013 and 12-06-2013\n",
      "Consecutive Dates: 12-06-2013 and 13-07-2013\n",
      "Consecutive Dates: 13-07-2013 and 14-08-2013\n",
      "Consecutive Dates: 14-08-2013 and 19-08-2013\n",
      "Consecutive Dates: 19-08-2013 and 14-09-2013\n",
      "Consecutive Dates: 14-09-2013 and 17-10-2013\n",
      "Consecutive Dates: 17-10-2013 and 16-11-2013\n",
      "Consecutive Dates: 16-11-2013 and 18-12-2013\n",
      "Consecutive Dates: 18-12-2013 and 18-01-2014\n",
      "Consecutive Dates: 18-01-2014 and 19-02-2014\n",
      "Consecutive Dates: 19-02-2014 and 23-04-2014\n",
      "Consecutive Dates: 23-04-2014 and 24-05-2014\n",
      "Consecutive Dates: 24-05-2014 and 28-06-2014\n",
      "Consecutive Dates: 28-06-2014 and 30-07-2014\n",
      "Consecutive Dates: 30-07-2014 and 30-08-2014\n",
      "Consecutive Dates: 30-08-2014 and 01-10-2014\n",
      "Consecutive Dates: 01-10-2014 and 29-10-2014\n",
      "Consecutive Dates: 29-10-2014 and 29-11-2014\n",
      "Consecutive Dates: 29-11-2014 and 31-12-2014\n",
      "Consecutive Dates: 31-12-2014 and 03-02-2015\n",
      "Consecutive Dates: 03-02-2015 and 07-03-2015\n",
      "Consecutive Dates: 07-03-2015 and 09-06-2015\n",
      "Consecutive Dates: 09-06-2015 and 11-07-2015\n",
      "Consecutive Dates: 11-07-2015 and 14-08-2015\n",
      "Consecutive Dates: 14-08-2015 and 29-09-2015\n",
      "Consecutive Dates: 29-09-2015 and 03-11-2015\n",
      "Consecutive Dates: 03-11-2015 and 05-12-2015\n",
      "Consecutive Dates: 05-12-2015 and 05-01-2016\n",
      "Consecutive Dates: 05-01-2016 and 08-01-2016\n",
      "Consecutive Dates: 08-01-2016 and 16-02-2016\n",
      "Consecutive Dates: 16-02-2016 and 21-03-2016\n",
      "Consecutive Dates: 21-03-2016 and 23-04-2016\n",
      "Consecutive Dates: 23-04-2016 and 31-05-2016\n",
      "Consecutive Dates: 31-05-2016 and 11-07-2016\n",
      "Consecutive Dates: 11-07-2016 and 09-08-2016\n",
      "Consecutive Dates: 09-08-2016 and 10-09-2016\n",
      "Consecutive Dates: 10-09-2016 and 22-10-2016\n",
      "Consecutive Dates: 22-10-2016 and 07-01-2017\n",
      "Consecutive Dates: 07-01-2017 and 14-03-2017\n",
      "Consecutive Dates: 14-03-2017 and 06-05-2017\n",
      "Consecutive Dates: 06-05-2017 and 07-07-2017\n",
      "Consecutive Dates: 07-07-2017 and 08-08-2017\n",
      "Consecutive Dates: 08-08-2017 and 12-09-2017\n",
      "Consecutive Dates: 12-09-2017 and 14-10-2017\n",
      "Consecutive Dates: 14-10-2017 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 20-03-2018\n",
      "Consecutive Dates: 20-03-2018 and 02-05-2018\n",
      "Consecutive Dates: 02-05-2018 and 08-06-2018\n",
      "Consecutive Dates: 08-06-2018 and 20-07-2018\n",
      "Consecutive Dates: 20-07-2018 and 28-12-2018\n",
      "Consecutive Dates: 28-12-2018 and 08-01-2019\n",
      "Consecutive Dates: 08-01-2019 and 25-01-2019\n",
      "Consecutive Dates: 25-01-2019 and 15-03-2019\n",
      "Consecutive Dates: 15-03-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 07-06-2019\n",
      "Consecutive Dates: 07-06-2019 and 11-07-2019\n",
      "Consecutive Dates: 11-07-2019 and 13-08-2019\n",
      "Consecutive Dates: 13-08-2019 and 03-10-2019\n",
      "Consecutive Dates: 03-10-2019 and 07-11-2019\n",
      "Consecutive Dates: 07-11-2019 and 04-01-2020\n",
      "Consecutive Dates: 04-01-2020 and 24-03-2020\n",
      "Consecutive Dates: 24-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 11-07-2020\n",
      "Consecutive Dates: 11-07-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 28-08-2021\n",
      "Consecutive Dates: 28-08-2021 and 25-09-2021\n",
      "Consecutive Dates: 25-09-2021 and 26-10-2021\n",
      "Consecutive Dates: 26-10-2021 and 30-10-2021\n",
      "Consecutive Dates: 30-10-2021 and 03-11-2021\n",
      "Consecutive Dates: 03-11-2021 and 10-11-2021\n",
      "Consecutive Dates: 10-11-2021 and 27-11-2021\n",
      "Consecutive Dates: 27-11-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 28-01-2022\n",
      "Consecutive Dates: 28-01-2022 and 28-02-2022\n",
      "Consecutive Dates: 28-02-2022 and 28-03-2022\n",
      "Consecutive Dates: 28-03-2022 and 28-04-2022\n",
      "Consecutive Dates: 28-04-2022 and 28-05-2022\n",
      "Consecutive Dates: 28-05-2022 and 29-06-2022\n",
      "Consecutive Dates: 29-06-2022 and 28-07-2022\n",
      "Consecutive Dates: 28-07-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 09-11-2022\n",
      "Consecutive Dates: 09-11-2022 and 14-12-2022\n",
      "Consecutive Dates: 14-12-2022 and 19-01-2023\n",
      "Consecutive Dates: 19-01-2023 and 20-02-2023\n",
      "Consecutive Dates: 20-02-2023 and 04-04-2023\n",
      "Consecutive Dates: 04-04-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 06-06-2023\n",
      "Consecutive Dates: 06-06-2023 and 06-07-2023\n",
      "Consecutive Dates: 06-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 11-10-2023\n",
      "Consecutive Dates: 11-10-2023 and 20-11-2023\n",
      "Consecutive Dates: 20-11-2023 and 18-12-2023\n",
      "5847\n",
      "\n",
      "Consecutive Dates: 17-07-2020 and 05-07-2021\n",
      "Consecutive Dates: 05-07-2021 and 16-08-2021\n",
      "Consecutive Dates: 16-08-2021 and 17-09-2021\n",
      "Consecutive Dates: 17-09-2021 and 06-11-2021\n",
      "Consecutive Dates: 06-11-2021 and 08-12-2021\n",
      "Consecutive Dates: 08-12-2021 and 02-02-2022\n",
      "Consecutive Dates: 02-02-2022 and 28-02-2022\n",
      "591\n",
      "\n",
      "Consecutive Dates: 12-01-2008 and 02-02-2010\n",
      "Consecutive Dates: 02-02-2010 and 11-12-2010\n",
      "Consecutive Dates: 11-12-2010 and 13-03-2013\n",
      "Consecutive Dates: 13-03-2013 and 13-04-2013\n",
      "Consecutive Dates: 13-04-2013 and 11-05-2013\n",
      "Consecutive Dates: 11-05-2013 and 12-06-2013\n",
      "Consecutive Dates: 12-06-2013 and 13-07-2013\n",
      "Consecutive Dates: 13-07-2013 and 14-08-2013\n",
      "Consecutive Dates: 14-08-2013 and 19-08-2013\n",
      "Consecutive Dates: 19-08-2013 and 14-09-2013\n",
      "Consecutive Dates: 14-09-2013 and 17-10-2013\n",
      "Consecutive Dates: 17-10-2013 and 14-09-2013\n",
      "Consecutive Dates: 14-09-2013 and 17-10-2013\n",
      "Consecutive Dates: 17-10-2013 and 16-11-2013\n",
      "Consecutive Dates: 16-11-2013 and 18-01-2014\n",
      "Consecutive Dates: 18-01-2014 and 19-02-2014\n",
      "Consecutive Dates: 19-02-2014 and 24-05-2014\n",
      "Consecutive Dates: 24-05-2014 and 23-06-2014\n",
      "Consecutive Dates: 23-06-2014 and 30-07-2014\n",
      "Consecutive Dates: 30-07-2014 and 30-08-2014\n",
      "Consecutive Dates: 30-08-2014 and 01-10-2014\n",
      "Consecutive Dates: 01-10-2014 and 29-10-2014\n",
      "Consecutive Dates: 29-10-2014 and 29-11-2014\n",
      "Consecutive Dates: 29-11-2014 and 31-12-2014\n",
      "Consecutive Dates: 31-12-2014 and 03-01-2015\n",
      "Consecutive Dates: 03-01-2015 and 07-03-2015\n",
      "Consecutive Dates: 07-03-2015 and 18-04-2015\n",
      "Consecutive Dates: 18-04-2015 and 09-06-2015\n",
      "Consecutive Dates: 09-06-2015 and 11-07-2015\n",
      "Consecutive Dates: 11-07-2015 and 14-08-2015\n",
      "Consecutive Dates: 14-08-2015 and 29-09-2015\n",
      "Consecutive Dates: 29-09-2015 and 03-11-2015\n",
      "Consecutive Dates: 03-11-2015 and 05-12-2015\n",
      "Consecutive Dates: 05-12-2015 and 05-01-2016\n",
      "Consecutive Dates: 05-01-2016 and 08-01-2016\n",
      "Consecutive Dates: 08-01-2016 and 16-02-2016\n",
      "Consecutive Dates: 16-02-2016 and 21-03-2016\n",
      "Consecutive Dates: 21-03-2016 and 23-04-2016\n",
      "Consecutive Dates: 23-04-2016 and 31-05-2016\n",
      "Consecutive Dates: 31-05-2016 and 11-07-2016\n",
      "Consecutive Dates: 11-07-2016 and 09-08-2016\n",
      "Consecutive Dates: 09-08-2016 and 10-05-2016\n",
      "Consecutive Dates: 10-05-2016 and 22-10-2016\n",
      "Consecutive Dates: 22-10-2016 and 07-01-2017\n",
      "Consecutive Dates: 07-01-2017 and 14-03-2017\n",
      "Consecutive Dates: 14-03-2017 and 06-05-2017\n",
      "Consecutive Dates: 06-05-2017 and 07-07-2017\n",
      "Consecutive Dates: 07-07-2017 and 08-08-2017\n",
      "Consecutive Dates: 08-08-2017 and 12-09-2017\n",
      "Consecutive Dates: 12-09-2017 and 14-10-2017\n",
      "Consecutive Dates: 14-10-2017 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 07-02-2018\n",
      "Consecutive Dates: 07-02-2018 and 20-03-2018\n",
      "Consecutive Dates: 20-03-2018 and 02-05-2018\n",
      "Consecutive Dates: 02-05-2018 and 08-06-2018\n",
      "Consecutive Dates: 08-06-2018 and 20-07-2018\n",
      "Consecutive Dates: 20-07-2018 and 28-12-2018\n",
      "Consecutive Dates: 28-12-2018 and 08-01-2018\n",
      "Consecutive Dates: 08-01-2018 and 25-01-2019\n",
      "Consecutive Dates: 25-01-2019 and 15-03-2019\n",
      "Consecutive Dates: 15-03-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 30-04-2019\n",
      "Consecutive Dates: 30-04-2019 and 07-06-2019\n",
      "Consecutive Dates: 07-06-2019 and 11-07-2019\n",
      "Consecutive Dates: 11-07-2019 and 13-08-2019\n",
      "Consecutive Dates: 13-08-2019 and 03-10-2019\n",
      "Consecutive Dates: 03-10-2019 and 07-11-2019\n",
      "Consecutive Dates: 07-11-2019 and 04-01-2020\n",
      "Consecutive Dates: 04-01-2020 and 24-03-2020\n",
      "Consecutive Dates: 24-03-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 11-07-2020\n",
      "Consecutive Dates: 11-07-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 08-03-2021\n",
      "Consecutive Dates: 08-03-2021 and 28-08-2021\n",
      "Consecutive Dates: 28-08-2021 and 25-09-2021\n",
      "Consecutive Dates: 25-09-2021 and 26-10-2021\n",
      "Consecutive Dates: 26-10-2021 and 30-10-2021\n",
      "Consecutive Dates: 30-10-2021 and 03-11-2021\n",
      "Consecutive Dates: 03-11-2021 and 10-11-2021\n",
      "Consecutive Dates: 10-11-2021 and 27-11-2021\n",
      "Consecutive Dates: 27-11-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 28-01-2022\n",
      "Consecutive Dates: 28-01-2022 and 28-02-2022\n",
      "Consecutive Dates: 28-02-2022 and 28-03-2022\n",
      "Consecutive Dates: 28-03-2022 and 28-04-2022\n",
      "Consecutive Dates: 28-04-2022 and 28-05-2022\n",
      "Consecutive Dates: 28-05-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 28-07-2022\n",
      "Consecutive Dates: 28-07-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 09-11-2022\n",
      "Consecutive Dates: 09-11-2022 and 14-12-2022\n",
      "Consecutive Dates: 14-12-2022 and 19-01-2023\n",
      "Consecutive Dates: 19-01-2023 and 20-02-2022\n",
      "Consecutive Dates: 20-02-2022 and 04-04-2023\n",
      "Consecutive Dates: 04-04-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 06-06-2023\n",
      "Consecutive Dates: 06-06-2023 and 06-07-2023\n",
      "Consecutive Dates: 06-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 11-10-2023\n",
      "Consecutive Dates: 11-10-2023 and 20-11-2023\n",
      "Consecutive Dates: 20-11-2023 and 18-12-2023\n",
      "7441\n",
      "\n",
      "Consecutive Dates: 07-10-2020 and 06-11-2020\n",
      "Consecutive Dates: 06-11-2020 and 27-11-2020\n",
      "Consecutive Dates: 27-11-2020 and 11-01-2021\n",
      "Consecutive Dates: 11-01-2021 and 04-02-2021\n",
      "Consecutive Dates: 04-02-2021 and 03-03-2021\n",
      "Consecutive Dates: 03-03-2021 and 26-04-2021\n",
      "Consecutive Dates: 26-04-2021 and 18-05-2021\n",
      "Consecutive Dates: 18-05-2021 and 23-06-2021\n",
      "Consecutive Dates: 23-06-2021 and 06-07-2021\n",
      "Consecutive Dates: 06-07-2021 and 27-08-2021\n",
      "Consecutive Dates: 27-08-2021 and 20-09-2021\n",
      "Consecutive Dates: 20-09-2021 and 19-10-2021\n",
      "Consecutive Dates: 19-10-2021 and 13-11-2021\n",
      "Consecutive Dates: 13-11-2021 and 27-11-2021\n",
      "Consecutive Dates: 27-11-2021 and 11-12-2021\n",
      "Consecutive Dates: 11-12-2021 and 14-01-2022\n",
      "Consecutive Dates: 14-01-2022 and 18-02-2022\n",
      "Consecutive Dates: 18-02-2022 and 21-03-2022\n",
      "Consecutive Dates: 21-03-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 02-06-2022\n",
      "Consecutive Dates: 02-06-2022 and 05-07-2022\n",
      "Consecutive Dates: 05-07-2022 and 29-07-2022\n",
      "Consecutive Dates: 29-07-2022 and 08-09-2022\n",
      "Consecutive Dates: 08-09-2022 and 07-10-2022\n",
      "Consecutive Dates: 07-10-2022 and 05-11-2022\n",
      "Consecutive Dates: 05-11-2022 and 05-12-2022\n",
      "Consecutive Dates: 05-12-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 28-02-2023\n",
      "Consecutive Dates: 28-02-2023 and 18-03-2023\n",
      "Consecutive Dates: 18-03-2023 and 22-05-2023\n",
      "Consecutive Dates: 22-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 03-08-2023\n",
      "Consecutive Dates: 03-08-2023 and 09-09-2023\n",
      "Consecutive Dates: 09-09-2023 and 30-10-2023\n",
      "Consecutive Dates: 30-10-2023 and 25-11-2023\n",
      "1144\n",
      "\n",
      "Consecutive Dates: 15-12-2021 and 12-03-2022\n",
      "Consecutive Dates: 12-03-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 01-08-2022\n",
      "Consecutive Dates: 01-08-2022 and 19-08-2022\n",
      "Consecutive Dates: 19-08-2022 and 30-12-2022\n",
      "Consecutive Dates: 30-12-2022 and 14-02-2023\n",
      "Consecutive Dates: 14-02-2023 and 21-03-2023\n",
      "Consecutive Dates: 21-03-2023 and 06-05-2023\n",
      "Consecutive Dates: 06-05-2023 and 19-07-2023\n",
      "Consecutive Dates: 19-07-2023 and 16-09-2023\n",
      "Consecutive Dates: 16-09-2023 and 03-11-2023\n",
      "Consecutive Dates: 03-11-2023 and 21-12-2023\n",
      "736\n",
      "\n",
      "Consecutive Dates: 02-08-2021 and 07-10-2021\n",
      "Consecutive Dates: 07-10-2021 and 08-11-2021\n",
      "Consecutive Dates: 08-11-2021 and 13-12-2021\n",
      "Consecutive Dates: 13-12-2021 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 03-02-2022\n",
      "Consecutive Dates: 03-02-2022 and 25-02-2022\n",
      "Consecutive Dates: 25-02-2022 and 31-03-2022\n",
      "Consecutive Dates: 31-03-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 11-06-2022\n",
      "Consecutive Dates: 11-06-2022 and 14-07-2022\n",
      "Consecutive Dates: 14-07-2022 and 17-08-2022\n",
      "Consecutive Dates: 17-08-2022 and 16-09-2022\n",
      "Consecutive Dates: 16-09-2022 and 19-10-2022\n",
      "Consecutive Dates: 19-10-2022 and 19-11-2022\n",
      "Consecutive Dates: 19-11-2022 and 21-12-2022\n",
      "Consecutive Dates: 21-12-2022 and 23-01-2023\n",
      "Consecutive Dates: 23-01-2023 and 23-02-2022\n",
      "Consecutive Dates: 23-02-2022 and 24-03-2023\n",
      "Consecutive Dates: 24-03-2023 and 24-04-2023\n",
      "Consecutive Dates: 24-04-2023 and 24-05-2023\n",
      "Consecutive Dates: 24-05-2023 and 27-06-2023\n",
      "Consecutive Dates: 27-06-2023 and 26-07-2023\n",
      "Consecutive Dates: 26-07-2023 and 26-08-2023\n",
      "Consecutive Dates: 26-08-2023 and 30-09-2023\n",
      "Consecutive Dates: 30-09-2023 and 27-10-2023\n",
      "1484\n",
      "\n",
      "Consecutive Dates: 01-04-2022 and 04-05-2022\n",
      "Consecutive Dates: 04-05-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 23-05-2022\n",
      "Consecutive Dates: 23-05-2022 and 26-09-2022\n",
      "Consecutive Dates: 26-09-2022 and 09-12-2022\n",
      "Consecutive Dates: 09-12-2022 and 16-12-2022\n",
      "Consecutive Dates: 16-12-2022 and 23-12-2022\n",
      "Consecutive Dates: 23-12-2022 and 11-07-2023\n",
      "466\n",
      "\n",
      "Consecutive Dates: 05-02-2022 and 05-05-2022\n",
      "89\n",
      "\n",
      "Consecutive Dates: 12-01-2019 and 01-02-2019\n",
      "Consecutive Dates: 01-02-2019 and 21-12-2021\n",
      "Consecutive Dates: 21-12-2021 and 19-01-2022\n",
      "Consecutive Dates: 19-01-2022 and 12-02-2022\n",
      "Consecutive Dates: 12-02-2022 and 16-03-2022\n",
      "Consecutive Dates: 16-03-2022 and 05-05-2022\n",
      "1209\n",
      "\n",
      "Consecutive Dates: 17-06-2109 and 23-07-2019\n",
      "Consecutive Dates: 23-07-2019 and 27-08-2019\n",
      "Consecutive Dates: 27-08-2019 and 24-09-2019\n",
      "Consecutive Dates: 24-09-2019 and 26-10-2019\n",
      "Consecutive Dates: 26-10-2019 and 25-11-2019\n",
      "Consecutive Dates: 25-11-2019 and 26-12-2019\n",
      "Consecutive Dates: 26-12-2019 and 27-01-2020\n",
      "Consecutive Dates: 27-01-2020 and 13-03-2020\n",
      "Consecutive Dates: 13-03-2020 and 23-04-2020\n",
      "Consecutive Dates: 23-04-2020 and 19-05-2020\n",
      "Consecutive Dates: 19-05-2020 and 19-06-2020\n",
      "Consecutive Dates: 19-06-2020 and 22-07-2020\n",
      "Consecutive Dates: 22-07-2020 and 25-07-2020\n",
      "Consecutive Dates: 25-07-2020 and 14-10-2020\n",
      "Consecutive Dates: 14-10-2020 and 17-12-2020\n",
      "Consecutive Dates: 17-12-2020 and 18-01-2021\n",
      "Consecutive Dates: 18-01-2021 and 16-02-2021\n",
      "Consecutive Dates: 16-02-2021 and 19-03-2021\n",
      "Consecutive Dates: 19-03-2021 and 20-04-2021\n",
      "Consecutive Dates: 20-04-2021 and 20-05-2021\n",
      "Consecutive Dates: 20-05-2021 and 01-11-2021\n",
      "Consecutive Dates: 01-11-2021 and 24-11-2021\n",
      "Consecutive Dates: 24-11-2021 and 28-01-2022\n",
      "Consecutive Dates: 28-01-2022 and 08-04-2022\n",
      "Consecutive Dates: 08-04-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 10-06-2022\n",
      "Consecutive Dates: 10-06-2022 and 13-07-2022\n",
      "Consecutive Dates: 13-07-2022 and 05-09-2022\n",
      "Consecutive Dates: 05-09-2022 and 07-10-2022\n",
      "Consecutive Dates: 07-10-2022 and 10-11-2022\n",
      "Consecutive Dates: 10-11-2022 and 14-12-2022\n",
      "Consecutive Dates: 14-12-2022 and 13-01-2023\n",
      "Consecutive Dates: 13-01-2023 and 13-02-2023\n",
      "Consecutive Dates: 13-02-2023 and 13-03-2023\n",
      "Consecutive Dates: 13-03-2023 and 21-04-2023\n",
      "Consecutive Dates: 21-04-2023 and 23-05-2023\n",
      "Consecutive Dates: 23-05-2023 and 27-06-2023\n",
      "Consecutive Dates: 27-06-2023 and 01-08-2023\n",
      "Consecutive Dates: 01-08-2023 and 31-08-2023\n",
      "Consecutive Dates: 31-08-2023 and 10-10-2023\n",
      "Consecutive Dates: 10-10-2023 and 17-11-2023\n",
      "34414\n",
      "\n",
      "Consecutive Dates: 04-04-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 04-06-2022\n",
      "Consecutive Dates: 04-06-2022 and 05-07-2022\n",
      "Consecutive Dates: 05-07-2022 and 04-08-2022\n",
      "Consecutive Dates: 04-08-2022 and 05-09-2022\n",
      "Consecutive Dates: 05-09-2022 and 10-10-2022\n",
      "Consecutive Dates: 10-10-2022 and 15-11-2022\n",
      "Consecutive Dates: 15-11-2022 and 18-02-2023\n",
      "Consecutive Dates: 18-02-2023 and 17-03-2023\n",
      "Consecutive Dates: 17-03-2023 and 17-07-2023\n",
      "Consecutive Dates: 17-07-2023 and 28-08-2023\n",
      "Consecutive Dates: 28-08-2023 and 05-10-2023\n",
      "Consecutive Dates: 05-10-2023 and 01-11-2023\n",
      "Consecutive Dates: 01-11-2023 and 16-12-2023\n",
      "621\n",
      "\n",
      "Consecutive Dates: 15-11-2021 and 18-01-2022\n",
      "Consecutive Dates: 18-01-2022 and 23-07-2022\n",
      "Consecutive Dates: 23-07-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 16-11-2022\n",
      "Consecutive Dates: 16-11-2022 and 16-02-2023\n",
      "Consecutive Dates: 16-02-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 31-10-2023\n",
      "Consecutive Dates: 31-10-2023 and 29-12-2023\n",
      "774\n",
      "\n",
      "Consecutive Dates: 11-01-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 22-11-2022\n",
      "Consecutive Dates: 22-11-2022 and 24-03-2023\n",
      "Consecutive Dates: 24-03-2023 and 12-06-2023\n",
      "Consecutive Dates: 12-06-2023 and 11-09-2023\n",
      "Consecutive Dates: 11-09-2023 and 16-10-2023\n",
      "Consecutive Dates: 16-10-2023 and 06-12-2023\n",
      "694\n",
      "\n",
      "Consecutive Dates: 02-08-2021 and 07-10-2021\n",
      "Consecutive Dates: 07-10-2021 and 08-11-2021\n",
      "Consecutive Dates: 08-11-2021 and 13-12-2021\n",
      "Consecutive Dates: 13-12-2021 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 03-02-2022\n",
      "Consecutive Dates: 03-02-2022 and 25-02-2022\n",
      "Consecutive Dates: 25-02-2022 and 31-03-2022\n",
      "Consecutive Dates: 31-03-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 11-06-2022\n",
      "Consecutive Dates: 11-06-2022 and 14-07-2022\n",
      "Consecutive Dates: 14-07-2022 and 17-08-2022\n",
      "Consecutive Dates: 17-08-2022 and 16-09-2022\n",
      "Consecutive Dates: 16-09-2022 and 19-10-2022\n",
      "Consecutive Dates: 19-10-2022 and 19-11-2022\n",
      "Consecutive Dates: 19-11-2022 and 21-12-2022\n",
      "Consecutive Dates: 21-12-2022 and 23-01-2023\n",
      "Consecutive Dates: 23-01-2023 and 23-02-2022\n",
      "Consecutive Dates: 23-02-2022 and 24-03-2023\n",
      "Consecutive Dates: 24-03-2023 and 24-04-2023\n",
      "Consecutive Dates: 24-04-2023 and 24-05-2023\n",
      "Consecutive Dates: 24-05-2023 and 27-06-2023\n",
      "Consecutive Dates: 27-06-2023 and 26-07-2023\n",
      "Consecutive Dates: 26-07-2023 and 26-08-2023\n",
      "Consecutive Dates: 26-08-2023 and 30-09-2023\n",
      "Consecutive Dates: 30-09-2023 and 27-10-2023\n",
      "Consecutive Dates: 27-10-2023 and 30-11-2023\n",
      "1518\n",
      "\n",
      "Consecutive Dates: 29-01-2021 and 31-12-2021\n",
      "Consecutive Dates: 31-12-2021 and 31-01-2022\n",
      "Consecutive Dates: 31-01-2022 and 07-03-2022\n",
      "Consecutive Dates: 07-03-2022 and 08-04-2022\n",
      "Consecutive Dates: 08-04-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 09-06-2022\n",
      "Consecutive Dates: 09-06-2022 and 03-09-2022\n",
      "Consecutive Dates: 03-09-2022 and 07-11-2022\n",
      "Consecutive Dates: 07-11-2022 and 09-12-2022\n",
      "Consecutive Dates: 09-12-2022 and 14-02-2023\n",
      "Consecutive Dates: 14-02-2023 and 24-04-2023\n",
      "Consecutive Dates: 24-04-2023 and 11-07-2023\n",
      "893\n",
      "\n",
      "Consecutive Dates: 26-05-2018 and 02-06-2018\n",
      "Consecutive Dates: 02-06-2018 and 02-07-2018\n",
      "Consecutive Dates: 02-07-2018 and 31-07-2018\n",
      "Consecutive Dates: 31-07-2018 and 31-08-2018\n",
      "Consecutive Dates: 31-08-2018 and 28-09-2018\n",
      "Consecutive Dates: 28-09-2018 and 29-10-2018\n",
      "Consecutive Dates: 29-10-2018 and 26-11-2018\n",
      "Consecutive Dates: 26-11-2018 and 24-12-2018\n",
      "Consecutive Dates: 24-12-2018 and 23-01-2019\n",
      "Consecutive Dates: 23-01-2019 and 25-02-2019\n",
      "Consecutive Dates: 25-02-2019 and 23-03-2019\n",
      "Consecutive Dates: 23-03-2019 and 26-04-2019\n",
      "Consecutive Dates: 26-04-2019 and 06-06-2019\n",
      "Consecutive Dates: 06-06-2019 and 21-08-2019\n",
      "Consecutive Dates: 21-08-2019 and 18-11-2019\n",
      "Consecutive Dates: 18-11-2019 and 04-01-2020\n",
      "Consecutive Dates: 04-01-2020 and 28-01-2020\n",
      "Consecutive Dates: 28-01-2020 and 23-02-2021\n",
      "Consecutive Dates: 23-02-2021 and 20-03-2021\n",
      "Consecutive Dates: 20-03-2021 and 13-04-2021\n",
      "Consecutive Dates: 13-04-2021 and 10-09-2021\n",
      "Consecutive Dates: 10-09-2021 and 23-10-2021\n",
      "Consecutive Dates: 23-10-2021 and 25-11-2021\n",
      "Consecutive Dates: 25-11-2021 and 08-02-2022\n",
      "Consecutive Dates: 08-02-2022 and 11-03-2022\n",
      "Consecutive Dates: 11-03-2022 and 13-04-2022\n",
      "Consecutive Dates: 13-04-2022 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 04-06-2022\n",
      "Consecutive Dates: 04-06-2022 and 08-07-2022\n",
      "Consecutive Dates: 08-07-2022 and 10-09-2022\n",
      "Consecutive Dates: 10-09-2022 and 11-10-2022\n",
      "Consecutive Dates: 11-10-2022 and 12-11-2022\n",
      "Consecutive Dates: 12-11-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 10-04-2023\n",
      "Consecutive Dates: 10-04-2023 and 21-06-2023\n",
      "Consecutive Dates: 21-06-2023 and 26-08-2023\n",
      "Consecutive Dates: 26-08-2023 and 23-11-2023\n",
      "2007\n",
      "\n",
      "Consecutive Dates: 05-05-2022 and 27-06-2022\n",
      "Consecutive Dates: 27-06-2022 and 18-11-2022\n",
      "Consecutive Dates: 18-11-2022 and 14-03-2023\n",
      "Consecutive Dates: 14-03-2023 and 26-04-2023\n",
      "356\n",
      "\n",
      "Consecutive Dates: 20-05-2020 and 23-06-2020\n",
      "Consecutive Dates: 23-06-2020 and 29-07-2020\n",
      "Consecutive Dates: 29-07-2020 and 09-09-2020\n",
      "Consecutive Dates: 09-09-2020 and 10-10-2020\n",
      "Consecutive Dates: 10-10-2020 and 12-11-2020\n",
      "Consecutive Dates: 12-11-2020 and 12-01-2021\n",
      "Consecutive Dates: 12-01-2021 and 17-02-2021\n",
      "Consecutive Dates: 17-02-2021 and 26-03-2021\n",
      "Consecutive Dates: 26-03-2021 and 19-04-2021\n",
      "Consecutive Dates: 19-04-2021 and 01-06-2021\n",
      "Consecutive Dates: 01-06-2021 and 29-06-2021\n",
      "Consecutive Dates: 29-06-2021 and 27-07-2021\n",
      "Consecutive Dates: 27-07-2021 and 16-08-2021\n",
      "Consecutive Dates: 16-08-2021 and 04-10-2021\n",
      "Consecutive Dates: 04-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 15-02-2022\n",
      "Consecutive Dates: 15-02-2022 and 18-03-2022\n",
      "Consecutive Dates: 18-03-2022 and 18-04-2022\n",
      "Consecutive Dates: 18-04-2022 and 19-05-2022\n",
      "Consecutive Dates: 19-05-2022 and 27-06-2022\n",
      "Consecutive Dates: 27-06-2022 and 12-09-2022\n",
      "Consecutive Dates: 12-09-2022 and 22-10-2022\n",
      "Consecutive Dates: 22-10-2022 and 31-01-2023\n",
      "Consecutive Dates: 31-01-2023 and 04-04-2023\n",
      "Consecutive Dates: 04-04-2023 and 30-06-2023\n",
      "1136\n",
      "\n",
      "Consecutive Dates: 05-05-2022 and 02-06-2022\n",
      "Consecutive Dates: 02-06-2022 and 30-12-2022\n",
      "Consecutive Dates: 30-12-2022 and 05-01-2023\n",
      "Consecutive Dates: 05-01-2023 and 12-06-2023\n",
      "Consecutive Dates: 12-06-2023 and 20-06-2023\n",
      "411\n",
      "\n",
      "Consecutive Dates: 08-09-2021 and 12-11-2021\n",
      "Consecutive Dates: 12-11-2021 and 05-05-2022\n",
      "Consecutive Dates: 05-05-2022 and 09-08-2022\n",
      "Consecutive Dates: 09-08-2022 and 07-10-2022\n",
      "Consecutive Dates: 07-10-2022 and 13-12-2022\n",
      "Consecutive Dates: 13-12-2022 and 24-03-2023\n",
      "Consecutive Dates: 24-03-2023 and 26-06-2023\n",
      "Consecutive Dates: 26-06-2023 and 12-10-2023\n",
      "764\n",
      "\n",
      "Consecutive Dates: 28-11-2020 and 11-11-2021\n",
      "Consecutive Dates: 11-11-2021 and 16-11-2021\n",
      "Consecutive Dates: 16-11-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 12-07-2022\n",
      "Consecutive Dates: 12-07-2022 and 03-03-2023\n",
      "Consecutive Dates: 03-03-2023 and 16-03-2023\n",
      "Consecutive Dates: 16-03-2023 and 06-04-2023\n",
      "859\n",
      "\n",
      "Consecutive Dates: 03-01-2022 and 31-01-2022\n",
      "Consecutive Dates: 31-01-2022 and 11-03-2022\n",
      "Consecutive Dates: 11-03-2022 and 26-04-2022\n",
      "Consecutive Dates: 26-04-2022 and 13-06-2022\n",
      "Consecutive Dates: 13-06-2022 and 25-07-2022\n",
      "Consecutive Dates: 25-07-2022 and 05-09-2022\n",
      "Consecutive Dates: 05-09-2022 and 28-10-2022\n",
      "Consecutive Dates: 28-10-2022 and 24-01-2023\n",
      "386\n",
      "\n",
      "Consecutive Dates: 28-12-2020 and 08-01-2021\n",
      "Consecutive Dates: 08-01-2021 and 20-02-2021\n",
      "Consecutive Dates: 20-02-2021 and 20-03-2021\n",
      "Consecutive Dates: 20-03-2021 and 20-04-2021\n",
      "Consecutive Dates: 20-04-2021 and 02-09-2021\n",
      "Consecutive Dates: 02-09-2021 and 01-11-2021\n",
      "Consecutive Dates: 01-11-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 02-03-2022\n",
      "Consecutive Dates: 02-03-2022 and 02-05-2022\n",
      "Consecutive Dates: 02-05-2022 and 31-05-2022\n",
      "Consecutive Dates: 31-05-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 28-07-2022\n",
      "Consecutive Dates: 28-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 22-09-2022\n",
      "Consecutive Dates: 22-09-2022 and 21-10-2022\n",
      "Consecutive Dates: 21-10-2022 and 21-12-2022\n",
      "Consecutive Dates: 21-12-2022 and 23-01-2023\n",
      "Consecutive Dates: 23-01-2023 and 18-02-2023\n",
      "Consecutive Dates: 18-02-2023 and 24-03-2023\n",
      "Consecutive Dates: 24-03-2023 and 21-04-2023\n",
      "Consecutive Dates: 21-04-2023 and 23-05-2023\n",
      "Consecutive Dates: 23-05-2023 and 22-06-2023\n",
      "Consecutive Dates: 22-06-2023 and 22-07-2023\n",
      "Consecutive Dates: 22-07-2023 and 21-08-2023\n",
      "Consecutive Dates: 21-08-2023 and 22-09-2023\n",
      "Consecutive Dates: 22-09-2023 and 21-10-2023\n",
      "Consecutive Dates: 21-10-2023 and 21-11-2023\n",
      "Consecutive Dates: 21-11-2023 and 21-12-2023\n",
      "Consecutive Dates: 21-12-2023 and 19-01-2024\n",
      "1117\n",
      "\n",
      "Consecutive Dates: 04-01-2021 and 13-03-2021\n",
      "Consecutive Dates: 13-03-2021 and 11-09-2021\n",
      "Consecutive Dates: 11-09-2021 and 25-10-2021\n",
      "Consecutive Dates: 25-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 21-04-2022\n",
      "Consecutive Dates: 21-04-2022 and 23-06-2022\n",
      "Consecutive Dates: 23-06-2022 and 22-08-2022\n",
      "Consecutive Dates: 22-08-2022 and 24-10-2022\n",
      "Consecutive Dates: 24-10-2022 and 09-12-2022\n",
      "Consecutive Dates: 09-12-2022 and 16-01-2023\n",
      "Consecutive Dates: 16-01-2023 and 31-03-2023\n",
      "Consecutive Dates: 31-03-2023 and 17-05-2023\n",
      "Consecutive Dates: 17-05-2023 and 03-07-2023\n",
      "Consecutive Dates: 03-07-2023 and 21-08-2023\n",
      "Consecutive Dates: 21-08-2023 and 13-10-2023\n",
      "Consecutive Dates: 13-10-2023 and 28-11-2023\n",
      "1058\n",
      "\n",
      "Consecutive Dates: 30-12-2020 and 30-01-2021\n",
      "Consecutive Dates: 30-01-2021 and 02-03-2021\n",
      "Consecutive Dates: 02-03-2021 and 02-04-2021\n",
      "Consecutive Dates: 02-04-2021 and 03-05-2021\n",
      "Consecutive Dates: 03-05-2021 and 03-06-2021\n",
      "Consecutive Dates: 03-06-2021 and 03-07-2021\n",
      "Consecutive Dates: 03-07-2021 and 03-08-2021\n",
      "Consecutive Dates: 03-08-2021 and 03-09-2021\n",
      "Consecutive Dates: 03-09-2021 and 03-11-2021\n",
      "Consecutive Dates: 03-11-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 01-04-2022\n",
      "Consecutive Dates: 01-04-2022 and 11-06-2022\n",
      "Consecutive Dates: 11-06-2022 and 06-12-2022\n",
      "Consecutive Dates: 06-12-2022 and 09-02-2023\n",
      "Consecutive Dates: 09-02-2023 and 29-05-2023\n",
      "Consecutive Dates: 29-05-2023 and 19-09-2023\n",
      "Consecutive Dates: 19-09-2023 and 16-01-2024\n",
      "1112\n",
      "\n",
      "Consecutive Dates: 26-10-2020 and 21-12-2020\n",
      "Consecutive Dates: 21-12-2020 and 07-01-2021\n",
      "Consecutive Dates: 07-01-2021 and 22-01-2021\n",
      "Consecutive Dates: 22-01-2021 and 29-01-2021\n",
      "Consecutive Dates: 29-01-2021 and 08-02-2021\n",
      "Consecutive Dates: 08-02-2021 and 11-02-2021\n",
      "Consecutive Dates: 11-02-2021 and 22-02-2021\n",
      "Consecutive Dates: 22-02-2021 and 24-09-2021\n",
      "Consecutive Dates: 24-09-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 10-01-2022\n",
      "Consecutive Dates: 10-01-2022 and 22-07-2022\n",
      "Consecutive Dates: 22-07-2022 and 25-09-2023\n",
      "1064\n",
      "\n",
      "Consecutive Dates: 17-12-2021 and 03-01-2022\n",
      "17\n",
      "\n",
      "Consecutive Dates: 03-01-2022 and 05-03-2022\n",
      "61\n",
      "\n",
      "Consecutive Dates: 21-08-2020 and 20-10-2020\n",
      "Consecutive Dates: 20-10-2020 and 19-12-2020\n",
      "Consecutive Dates: 19-12-2020 and 25-01-2021\n",
      "Consecutive Dates: 25-01-2021 and 23-02-2021\n",
      "Consecutive Dates: 23-02-2021 and 23-03-2021\n",
      "Consecutive Dates: 23-03-2021 and 20-04-2021\n",
      "Consecutive Dates: 20-04-2021 and 20-05-2021\n",
      "Consecutive Dates: 20-05-2021 and 19-06-2021\n",
      "Consecutive Dates: 19-06-2021 and 23-07-2021\n",
      "Consecutive Dates: 23-07-2021 and 24-08-2021\n",
      "Consecutive Dates: 24-08-2021 and 05-10-2021\n",
      "Consecutive Dates: 05-10-2021 and 23-11-2021\n",
      "Consecutive Dates: 23-11-2021 and 23-12-2021\n",
      "Consecutive Dates: 23-12-2021 and 24-01-2022\n",
      "Consecutive Dates: 24-01-2022 and 24-02-2022\n",
      "Consecutive Dates: 24-02-2022 and 10-05-2022\n",
      "Consecutive Dates: 10-05-2022 and 07-07-2022\n",
      "Consecutive Dates: 07-07-2022 and 08-08-2022\n",
      "Consecutive Dates: 08-08-2022 and 07-09-2022\n",
      "Consecutive Dates: 07-09-2022 and 11-10-2022\n",
      "Consecutive Dates: 11-10-2022 and 22-11-2022\n",
      "Consecutive Dates: 22-11-2022 and 03-01-2023\n",
      "Consecutive Dates: 03-01-2023 and 06-02-2023\n",
      "Consecutive Dates: 06-02-2023 and 22-03-2023\n",
      "Consecutive Dates: 22-03-2023 and 01-05-2023\n",
      "Consecutive Dates: 01-05-2023 and 30-05-2023\n",
      "Consecutive Dates: 30-05-2023 and 05-07-2023\n",
      "Consecutive Dates: 05-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 12-09-2023\n",
      "Consecutive Dates: 12-09-2023 and 27-10-2023\n",
      "Consecutive Dates: 27-10-2023 and 27-11-2023\n",
      "1193\n",
      "\n",
      "Consecutive Dates: 25-06-2021 and 26-06-2021\n",
      "Consecutive Dates: 26-06-2021 and 20-07-2021\n",
      "Consecutive Dates: 20-07-2021 and 24-09-2021\n",
      "Consecutive Dates: 24-09-2021 and 14-10-2021\n",
      "Consecutive Dates: 14-10-2021 and 06-11-2021\n",
      "Consecutive Dates: 06-11-2021 and 06-12-2021\n",
      "Consecutive Dates: 06-12-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 04-03-2022\n",
      "Consecutive Dates: 04-03-2022 and 02-05-2022\n",
      "Consecutive Dates: 02-05-2022 and 06-06-2022\n",
      "Consecutive Dates: 06-06-2022 and 01-07-2022\n",
      "Consecutive Dates: 01-07-2022 and 25-07-2022\n",
      "Consecutive Dates: 25-07-2022 and 10-09-2022\n",
      "Consecutive Dates: 10-09-2022 and 10-10-2022\n",
      "Consecutive Dates: 10-10-2022 and 08-11-2022\n",
      "Consecutive Dates: 08-11-2022 and 02-12-2022\n",
      "Consecutive Dates: 02-12-2022 and 05-01-2023\n",
      "Consecutive Dates: 05-01-2023 and 21-02-2023\n",
      "Consecutive Dates: 21-02-2023 and 30-03-2023\n",
      "Consecutive Dates: 30-03-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 01-06-2023\n",
      "Consecutive Dates: 01-06-2023 and 07-07-2023\n",
      "Consecutive Dates: 07-07-2023 and 02-08-2023\n",
      "Consecutive Dates: 02-08-2023 and 04-09-2023\n",
      "Consecutive Dates: 04-09-2023 and 09-10-2023\n",
      "Consecutive Dates: 09-10-2023 and 06-11-2023\n",
      "Consecutive Dates: 06-11-2023 and 11-12-2023\n",
      "Consecutive Dates: 11-12-2023 and 10-01-2024\n",
      "929\n",
      "\n",
      "0\n",
      "\n",
      "Consecutive Dates: 25-03-2021 and 11-06-2021\n",
      "Consecutive Dates: 11-06-2021 and 03-08-2021\n",
      "Consecutive Dates: 03-08-2021 and 20-09-2021\n",
      "Consecutive Dates: 20-09-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 03-03-2022\n",
      "Consecutive Dates: 03-03-2022 and 10-03-2022\n",
      "Consecutive Dates: 10-03-2022 and 11-12-2023\n",
      "991\n",
      "\n",
      "Consecutive Dates: 28-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 18-05-2022\n",
      "Consecutive Dates: 18-05-2022 and 20-06-2022\n",
      "Consecutive Dates: 20-06-2022 and 25-08-2022\n",
      "301\n",
      "\n",
      "Consecutive Dates: 03-01-2022 and 17-01-2022\n",
      "Consecutive Dates: 17-01-2022 and 21-01-2022\n",
      "18\n",
      "\n",
      "Consecutive Dates: 26-10-2020 and 20-11-2020\n",
      "Consecutive Dates: 20-11-2020 and 21-12-2020\n",
      "Consecutive Dates: 21-12-2020 and 07-01-2021\n",
      "Consecutive Dates: 07-01-2021 and 22-01-2021\n",
      "Consecutive Dates: 22-01-2021 and 29-01-2021\n",
      "Consecutive Dates: 29-01-2021 and 08-02-2021\n",
      "Consecutive Dates: 08-02-2021 and 11-02-2021\n",
      "Consecutive Dates: 11-02-2021 and 22-02-2021\n",
      "Consecutive Dates: 22-02-2021 and 24-09-2021\n",
      "Consecutive Dates: 24-09-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 10-01-2022\n",
      "Consecutive Dates: 10-01-2022 and 22-07-2022\n",
      "Consecutive Dates: 22-07-2022 and 25-09-2023\n",
      "1064\n",
      "\n",
      "Consecutive Dates: 08-08-2017 and 05-09-2017\n",
      "Consecutive Dates: 05-09-2017 and 05-10-2017\n",
      "Consecutive Dates: 05-10-2017 and 30-10-2017\n",
      "Consecutive Dates: 30-10-2017 and 29-11-2017\n",
      "Consecutive Dates: 29-11-2017 and 28-12-2017\n",
      "Consecutive Dates: 28-12-2017 and 01-02-2018\n",
      "Consecutive Dates: 01-02-2018 and 13-02-2018\n",
      "Consecutive Dates: 13-02-2018 and 19-03-2018\n",
      "Consecutive Dates: 19-03-2018 and 17-04-2018\n",
      "Consecutive Dates: 17-04-2018 and 15-05-2018\n",
      "Consecutive Dates: 15-05-2018 and 09-06-2018\n",
      "Consecutive Dates: 09-06-2018 and 10-07-2018\n",
      "Consecutive Dates: 10-07-2018 and 06-08-2018\n",
      "Consecutive Dates: 06-08-2018 and 05-09-2018\n",
      "Consecutive Dates: 05-09-2018 and 28-09-2018\n",
      "Consecutive Dates: 28-09-2018 and 29-10-2018\n",
      "Consecutive Dates: 29-10-2018 and 30-11-2018\n",
      "Consecutive Dates: 30-11-2018 and 27-12-2018\n",
      "Consecutive Dates: 27-12-2018 and 02-02-2019\n",
      "Consecutive Dates: 02-02-2019 and 05-04-2019\n",
      "Consecutive Dates: 05-04-2019 and 03-05-2019\n",
      "Consecutive Dates: 03-05-2019 and 27-05-2019\n",
      "Consecutive Dates: 27-05-2019 and 18-06-2019\n",
      "Consecutive Dates: 18-06-2019 and 15-07-2019\n",
      "Consecutive Dates: 15-07-2019 and 17-08-2019\n",
      "Consecutive Dates: 17-08-2019 and 07-09-2019\n",
      "Consecutive Dates: 07-09-2019 and 03-10-2019\n",
      "Consecutive Dates: 03-10-2019 and 06-11-2019\n",
      "Consecutive Dates: 06-11-2019 and 06-12-2019\n",
      "Consecutive Dates: 06-12-2019 and 04-01-2020\n",
      "Consecutive Dates: 04-01-2020 and 04-02-2020\n",
      "Consecutive Dates: 04-02-2020 and 07-03-2020\n",
      "Consecutive Dates: 07-03-2020 and 03-07-2020\n",
      "Consecutive Dates: 03-07-2020 and 28-08-2020\n",
      "Consecutive Dates: 28-08-2020 and 27-11-2020\n",
      "Consecutive Dates: 27-11-2020 and 05-02-2021\n",
      "Consecutive Dates: 05-02-2021 and 09-04-2021\n",
      "Consecutive Dates: 09-04-2021 and 03-08-2021\n",
      "Consecutive Dates: 03-08-2021 and 22-10-2021\n",
      "Consecutive Dates: 22-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 06-05-2022\n",
      "Consecutive Dates: 06-05-2022 and 30-07-2022\n",
      "Consecutive Dates: 30-07-2022 and 21-10-2022\n",
      "Consecutive Dates: 21-10-2022 and 27-01-2023\n",
      "Consecutive Dates: 27-01-2023 and 18-04-2023\n",
      "Consecutive Dates: 18-04-2023 and 25-10-2023\n",
      "Consecutive Dates: 25-10-2023 and 02-02-2024\n",
      "2369\n",
      "\n",
      "Consecutive Dates: 17-05-2021 and 18-06-2021\n",
      "Consecutive Dates: 18-06-2021 and 13-09-2021\n",
      "Consecutive Dates: 13-09-2021 and 28-09-2021\n",
      "Consecutive Dates: 28-09-2021 and 11-10-2021\n",
      "Consecutive Dates: 11-10-2021 and 05-11-2021\n",
      "Consecutive Dates: 05-11-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 01-02-2022\n",
      "Consecutive Dates: 01-02-2022 and 28-02-2022\n",
      "Consecutive Dates: 28-02-2022 and 29-04-2022\n",
      "Consecutive Dates: 29-04-2022 and 30-05-2022\n",
      "Consecutive Dates: 30-05-2022 and 01-07-2022\n",
      "Consecutive Dates: 01-07-2022 and 01-08-2022\n",
      "Consecutive Dates: 01-08-2022 and 30-08-2022\n",
      "Consecutive Dates: 30-08-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 01-11-2022\n",
      "Consecutive Dates: 01-11-2022 and 02-12-2022\n",
      "Consecutive Dates: 02-12-2022 and 03-01-2023\n",
      "Consecutive Dates: 03-01-2023 and 06-02-2023\n",
      "Consecutive Dates: 06-02-2023 and 21-03-2023\n",
      "Consecutive Dates: 21-03-2023 and 02-05-2023\n",
      "Consecutive Dates: 02-05-2023 and 11-08-2023\n",
      "Consecutive Dates: 11-08-2023 and 22-09-2023\n",
      "Consecutive Dates: 22-09-2023 and 01-11-2023\n",
      "Consecutive Dates: 01-11-2023 and 09-01-2024\n",
      "967\n",
      "\n",
      "Consecutive Dates: 21-08-2020 and 20-10-2020\n",
      "Consecutive Dates: 20-10-2020 and 20-11-2020\n",
      "Consecutive Dates: 20-11-2020 and 19-12-2020\n",
      "Consecutive Dates: 19-12-2020 and 25-01-2021\n",
      "Consecutive Dates: 25-01-2021 and 23-02-2021\n",
      "Consecutive Dates: 23-02-2021 and 23-03-2021\n",
      "Consecutive Dates: 23-03-2021 and 20-04-2021\n",
      "Consecutive Dates: 20-04-2021 and 20-05-2021\n",
      "Consecutive Dates: 20-05-2021 and 19-06-2021\n",
      "Consecutive Dates: 19-06-2021 and 23-07-2021\n",
      "Consecutive Dates: 23-07-2021 and 24-08-2021\n",
      "Consecutive Dates: 24-08-2021 and 05-10-2021\n",
      "Consecutive Dates: 05-10-2021 and 23-11-2021\n",
      "Consecutive Dates: 23-11-2021 and 23-12-2021\n",
      "Consecutive Dates: 23-12-2021 and 24-01-2022\n",
      "Consecutive Dates: 24-01-2022 and 24-02-2022\n",
      "Consecutive Dates: 24-02-2022 and 10-05-2022\n",
      "Consecutive Dates: 10-05-2022 and 07-07-2022\n",
      "Consecutive Dates: 07-07-2022 and 08-08-2022\n",
      "Consecutive Dates: 08-08-2022 and 07-09-2022\n",
      "Consecutive Dates: 07-09-2022 and 11-10-2022\n",
      "Consecutive Dates: 11-10-2022 and 22-11-2022\n",
      "Consecutive Dates: 22-11-2022 and 03-01-2023\n",
      "Consecutive Dates: 03-01-2023 and 06-02-2023\n",
      "Consecutive Dates: 06-02-2023 and 22-03-2023\n",
      "Consecutive Dates: 22-03-2023 and 01-05-2023\n",
      "Consecutive Dates: 01-05-2023 and 30-05-2023\n",
      "Consecutive Dates: 30-05-2023 and 05-07-2023\n",
      "Consecutive Dates: 05-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 12-09-2023\n",
      "Consecutive Dates: 12-09-2023 and 27-10-2023\n",
      "Consecutive Dates: 27-10-2023 and 27-11-2023\n",
      "1193\n",
      "\n",
      "Consecutive Dates: 03-01-2022 and 25-05-2022\n",
      "142\n",
      "\n",
      "Consecutive Dates: 03-01-2022 and 22-06-2022\n",
      "Consecutive Dates: 22-06-2022 and 31-08-2022\n",
      "Consecutive Dates: 31-08-2022 and 21-03-2023\n",
      "Consecutive Dates: 21-03-2023 and 21-04-2023\n",
      "Consecutive Dates: 21-04-2023 and 22-05-2023\n",
      "Consecutive Dates: 22-05-2023 and 22-06-2023\n",
      "Consecutive Dates: 22-06-2023 and 20-07-2023\n",
      "Consecutive Dates: 20-07-2023 and 28-01-2023\n",
      "Consecutive Dates: 28-01-2023 and 21-09-2023\n",
      "972\n",
      "\n",
      "Consecutive Dates: 01-11-2021 and 01-12-2021\n",
      "Consecutive Dates: 01-12-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 31-01-2022\n",
      "Consecutive Dates: 31-01-2022 and 08-03-2022\n",
      "Consecutive Dates: 08-03-2022 and 09-04-2022\n",
      "Consecutive Dates: 09-04-2022 and 08-08-2022\n",
      "Consecutive Dates: 08-08-2022 and 10-09-2022\n",
      "Consecutive Dates: 10-09-2022 and 07-10-2022\n",
      "Consecutive Dates: 07-10-2022 and 08-11-2022\n",
      "Consecutive Dates: 08-11-2022 and 10-12-2022\n",
      "Consecutive Dates: 10-12-2022 and 11-01-2023\n",
      "Consecutive Dates: 11-01-2023 and 08-02-2023\n",
      "Consecutive Dates: 08-02-2023 and 09-03-2023\n",
      "Consecutive Dates: 09-03-2023 and 08-04-2023\n",
      "Consecutive Dates: 08-04-2023 and 13-05-2023\n",
      "Consecutive Dates: 13-05-2023 and 03-06-2023\n",
      "Consecutive Dates: 03-06-2023 and 18-07-2023\n",
      "Consecutive Dates: 18-07-2023 and 22-08-2023\n",
      "659\n",
      "\n",
      "Consecutive Dates: 13-07-2021 and 13-08-2021\n",
      "Consecutive Dates: 13-08-2021 and 14-09-2021\n",
      "Consecutive Dates: 14-09-2021 and 19-10-2021\n",
      "Consecutive Dates: 19-10-2021 and 22-10-2021\n",
      "Consecutive Dates: 22-10-2021 and 26-10-2021\n",
      "Consecutive Dates: 26-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 15-02-2022\n",
      "Consecutive Dates: 15-02-2022 and 17-02-2022\n",
      "Consecutive Dates: 17-02-2022 and 25-03-2022\n",
      "Consecutive Dates: 25-03-2022 and 31-03-2022\n",
      "Consecutive Dates: 31-03-2022 and 30-05-2022\n",
      "Consecutive Dates: 30-05-2022 and 22-07-2022\n",
      "Consecutive Dates: 22-07-2022 and 23-07-2022\n",
      "Consecutive Dates: 23-07-2022 and 25-07-2022\n",
      "Consecutive Dates: 25-07-2022 and 26-07-2022\n",
      "Consecutive Dates: 26-07-2022 and 17-10-2022\n",
      "Consecutive Dates: 17-10-2022 and 26-12-2022\n",
      "Consecutive Dates: 26-12-2022 and 10-02-2023\n",
      "Consecutive Dates: 10-02-2023 and 15-05-2023\n",
      "Consecutive Dates: 15-05-2023 and 27-06-2023\n",
      "714\n",
      "\n",
      "Consecutive Dates: 03-01-2022 and 03-02-2022\n",
      "Consecutive Dates: 03-02-2022 and 03-03-2022\n",
      "Consecutive Dates: 03-03-2022 and 13-04-2022\n",
      "Consecutive Dates: 13-04-2022 and 15-09-2023\n",
      "Consecutive Dates: 15-09-2023 and 06-11-2023\n",
      "672\n",
      "\n",
      "0\n",
      "\n",
      "Consecutive Dates: 19-07-2021 and 21-09-2021\n",
      "Consecutive Dates: 21-09-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 16-07-2022\n",
      "Consecutive Dates: 16-07-2022 and 11-08-2022\n",
      "Consecutive Dates: 11-08-2022 and 07-09-2022\n",
      "Consecutive Dates: 07-09-2022 and 08-10-2022\n",
      "Consecutive Dates: 08-10-2022 and 06-12-2022\n",
      "Consecutive Dates: 06-12-2022 and 07-01-2023\n",
      "Consecutive Dates: 07-01-2023 and 11-07-2023\n",
      "Consecutive Dates: 11-07-2023 and 11-01-2024\n",
      "Consecutive Dates: 11-01-2024 and 09-02-2024\n",
      "935\n",
      "\n",
      "Consecutive Dates: 19-01-2022 and 16-02-2022\n",
      "Consecutive Dates: 16-02-2022 and 06-05-2022\n",
      "Consecutive Dates: 06-05-2022 and 23-06-2022\n",
      "Consecutive Dates: 23-06-2022 and 26-07-2022\n",
      "Consecutive Dates: 26-07-2022 and 15-09-2022\n",
      "Consecutive Dates: 15-09-2022 and 14-11-2022\n",
      "Consecutive Dates: 14-11-2022 and 31-12-2022\n",
      "Consecutive Dates: 31-12-2022 and 02-02-2023\n",
      "Consecutive Dates: 02-02-2023 and 04-03-2023\n",
      "Consecutive Dates: 04-03-2023 and 03-05-2023\n",
      "Consecutive Dates: 03-05-2023 and 29-05-2023\n",
      "495\n",
      "\n",
      "Consecutive Dates: 16-11-2021 and 03-01-2022\n",
      "48\n",
      "\n",
      "0\n",
      "\n",
      "Consecutive Dates: 09-06-2018 and 13-07-2018\n",
      "Consecutive Dates: 13-07-2018 and 11-08-2018\n",
      "Consecutive Dates: 11-08-2018 and 11-09-2018\n",
      "Consecutive Dates: 11-09-2018 and 04-10-2018\n",
      "Consecutive Dates: 04-10-2018 and 05-11-2018\n",
      "Consecutive Dates: 05-11-2018 and 06-12-2018\n",
      "Consecutive Dates: 06-12-2018 and 10-06-2019\n",
      "Consecutive Dates: 10-06-2019 and 10-07-2019\n",
      "Consecutive Dates: 10-07-2019 and 07-08-2019\n",
      "Consecutive Dates: 07-08-2019 and 21-08-2019\n",
      "Consecutive Dates: 21-08-2019 and 01-10-2019\n",
      "Consecutive Dates: 01-10-2019 and 26-10-2019\n",
      "Consecutive Dates: 26-10-2019 and 04-12-2019\n",
      "Consecutive Dates: 04-12-2019 and 06-01-2020\n",
      "Consecutive Dates: 06-01-2020 and 01-02-2020\n",
      "Consecutive Dates: 01-02-2020 and 13-03-2020\n",
      "Consecutive Dates: 13-03-2020 and 12-06-2020\n",
      "Consecutive Dates: 12-06-2020 and 04-08-2020\n",
      "Consecutive Dates: 04-08-2020 and 07-09-2020\n",
      "Consecutive Dates: 07-09-2020 and 04-11-2020\n",
      "Consecutive Dates: 04-11-2020 and 25-12-2020\n",
      "Consecutive Dates: 25-12-2020 and 11-02-2021\n",
      "Consecutive Dates: 11-02-2021 and 17-03-2021\n",
      "Consecutive Dates: 17-03-2021 and 22-04-2021\n",
      "Consecutive Dates: 22-04-2021 and 17-08-2021\n",
      "Consecutive Dates: 17-08-2021 and 21-09-2021\n",
      "Consecutive Dates: 21-09-2021 and 25-10-2021\n",
      "Consecutive Dates: 25-10-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 17-03-2022\n",
      "Consecutive Dates: 17-03-2022 and 14-04-2022\n",
      "Consecutive Dates: 14-04-2022 and 12-05-2022\n",
      "Consecutive Dates: 12-05-2022 and 27-07-2022\n",
      "Consecutive Dates: 27-07-2022 and 05-09-2022\n",
      "Consecutive Dates: 05-09-2022 and 01-10-2022\n",
      "Consecutive Dates: 01-10-2022 and 27-01-2023\n",
      "Consecutive Dates: 27-01-2023 and 24-02-2023\n",
      "Consecutive Dates: 24-02-2023 and 25-03-2023\n",
      "Consecutive Dates: 25-03-2023 and 17-04-2023\n",
      "Consecutive Dates: 17-04-2023 and 15-07-2023\n",
      "Consecutive Dates: 15-07-2023 and 26-10-2023\n",
      "1965\n",
      "\n",
      "0\n",
      "\n",
      "Consecutive Dates: 30-09-2014 and 07-11-2014\n",
      "Consecutive Dates: 07-11-2014 and 02-12-2014\n",
      "Consecutive Dates: 02-12-2014 and 06-01-2015\n",
      "Consecutive Dates: 06-01-2015 and 05-02-2015\n",
      "Consecutive Dates: 05-02-2015 and 07-03-2015\n",
      "Consecutive Dates: 07-03-2015 and 07-04-2015\n",
      "Consecutive Dates: 07-04-2015 and 09-05-2015\n",
      "Consecutive Dates: 09-05-2015 and 08-06-2015\n",
      "Consecutive Dates: 08-06-2015 and 08-07-2015\n",
      "Consecutive Dates: 08-07-2015 and 06-08-2015\n",
      "Consecutive Dates: 06-08-2015 and 04-09-2015\n",
      "Consecutive Dates: 04-09-2015 and 05-10-2015\n",
      "Consecutive Dates: 05-10-2015 and 02-11-2015\n",
      "Consecutive Dates: 02-11-2015 and 17-12-2015\n",
      "Consecutive Dates: 17-12-2015 and 16-01-2016\n",
      "Consecutive Dates: 16-01-2016 and 13-02-2016\n",
      "Consecutive Dates: 13-02-2016 and 14-03-2016\n",
      "Consecutive Dates: 14-03-2016 and 12-05-2016\n",
      "Consecutive Dates: 12-05-2016 and 11-06-2016\n",
      "Consecutive Dates: 11-06-2016 and 12-07-2016\n",
      "Consecutive Dates: 12-07-2016 and 11-08-2016\n",
      "Consecutive Dates: 11-08-2016 and 10-09-2016\n",
      "Consecutive Dates: 10-09-2016 and 27-09-2016\n",
      "Consecutive Dates: 27-09-2016 and 24-10-2016\n",
      "Consecutive Dates: 24-10-2016 and 24-11-2016\n",
      "Consecutive Dates: 24-11-2016 and 22-12-2016\n",
      "Consecutive Dates: 22-12-2016 and 21-01-2017\n",
      "Consecutive Dates: 21-01-2017 and 21-02-2017\n",
      "Consecutive Dates: 21-02-2017 and 23-03-2017\n",
      "Consecutive Dates: 23-03-2017 and 22-04-2017\n",
      "Consecutive Dates: 22-04-2017 and 22-05-2017\n",
      "Consecutive Dates: 22-05-2017 and 24-06-2017\n",
      "Consecutive Dates: 24-06-2017 and 27-07-2017\n",
      "Consecutive Dates: 27-07-2017 and 26-08-2017\n",
      "Consecutive Dates: 26-08-2017 and 25-09-2017\n",
      "Consecutive Dates: 25-09-2017 and 25-10-2017\n",
      "Consecutive Dates: 25-10-2017 and 23-11-2017\n",
      "Consecutive Dates: 23-11-2017 and 23-12-2017\n",
      "Consecutive Dates: 23-12-2017 and 23-01-2018\n",
      "Consecutive Dates: 23-01-2018 and 20-02-2018\n",
      "Consecutive Dates: 20-02-2018 and 26-03-2018\n",
      "Consecutive Dates: 26-03-2018 and 24-04-2018\n",
      "Consecutive Dates: 24-04-2018 and 24-05-2018\n",
      "Consecutive Dates: 24-05-2018 and 06-06-2018\n",
      "Consecutive Dates: 06-06-2018 and 05-07-2018\n",
      "Consecutive Dates: 05-07-2018 and 04-08-2018\n",
      "Consecutive Dates: 04-08-2018 and 18-09-2018\n",
      "Consecutive Dates: 18-09-2018 and 16-10-2018\n",
      "Consecutive Dates: 16-10-2018 and 15-11-2018\n",
      "Consecutive Dates: 15-11-2018 and 17-12-2018\n",
      "Consecutive Dates: 17-12-2018 and 15-01-2019\n",
      "Consecutive Dates: 15-01-2019 and 16-02-2019\n",
      "Consecutive Dates: 16-02-2019 and 18-03-2019\n",
      "Consecutive Dates: 18-03-2019 and 16-04-2019\n",
      "Consecutive Dates: 16-04-2019 and 16-05-2019\n",
      "Consecutive Dates: 16-05-2019 and 15-06-2019\n",
      "Consecutive Dates: 15-06-2019 and 16-07-2019\n",
      "Consecutive Dates: 16-07-2019 and 14-08-2019\n",
      "Consecutive Dates: 14-08-2019 and 12-09-2019\n",
      "Consecutive Dates: 12-09-2019 and 14-10-2019\n",
      "Consecutive Dates: 14-10-2019 and 12-11-2019\n",
      "Consecutive Dates: 12-11-2019 and 16-12-2019\n",
      "Consecutive Dates: 16-12-2019 and 15-01-2020\n",
      "Consecutive Dates: 15-01-2020 and 15-02-2020\n",
      "Consecutive Dates: 15-02-2020 and 16-03-2020\n",
      "Consecutive Dates: 16-03-2020 and 24-04-2020\n",
      "Consecutive Dates: 24-04-2020 and 18-06-2020\n",
      "Consecutive Dates: 18-06-2020 and 21-07-2020\n",
      "Consecutive Dates: 21-07-2020 and 28-08-2020\n",
      "Consecutive Dates: 28-08-2020 and 28-09-2020\n",
      "Consecutive Dates: 28-09-2020 and 21-12-2020\n",
      "Consecutive Dates: 21-12-2020 and 04-09-2021\n",
      "Consecutive Dates: 04-09-2021 and 11-10-2021\n",
      "Consecutive Dates: 11-10-2021 and 01-11-2021\n",
      "Consecutive Dates: 01-11-2021 and 03-12-2021\n",
      "Consecutive Dates: 03-12-2021 and 10-01-2022\n",
      "Consecutive Dates: 10-01-2022 and 11-02-2022\n",
      "Consecutive Dates: 11-02-2022 and 11-03-2022\n",
      "Consecutive Dates: 11-03-2022 and 15-04-2022\n",
      "Consecutive Dates: 15-04-2022 and 15-05-2022\n",
      "Consecutive Dates: 15-05-2022 and 18-06-2022\n",
      "Consecutive Dates: 18-06-2022 and 20-07-2022\n",
      "Consecutive Dates: 20-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 13-10-2022\n",
      "2935\n",
      "\n",
      "Consecutive Dates: 16-10-2019 and 15-11-2019\n",
      "Consecutive Dates: 15-11-2019 and 15-12-2019\n",
      "Consecutive Dates: 15-12-2019 and 13-01-2020\n",
      "Consecutive Dates: 13-01-2020 and 11-02-2020\n",
      "Consecutive Dates: 11-02-2020 and 13-03-2020\n",
      "Consecutive Dates: 13-03-2020 and 15-05-1010\n",
      "Consecutive Dates: 15-05-1010 and 17-04-2020\n",
      "Consecutive Dates: 17-04-2020 and 15-06-2020\n",
      "Consecutive Dates: 15-06-2020 and 13-08-2020\n",
      "Consecutive Dates: 13-08-2020 and 22-09-2020\n",
      "Consecutive Dates: 22-09-2020 and 27-11-2020\n",
      "Consecutive Dates: 27-11-2020 and 04-01-2021\n",
      "Consecutive Dates: 04-01-2021 and 28-01-2021\n",
      "Consecutive Dates: 28-01-2021 and 24-02-2021\n",
      "Consecutive Dates: 24-02-2021 and 24-03-2021\n",
      "Consecutive Dates: 24-03-2021 and 30-04-2021\n",
      "Consecutive Dates: 30-04-2021 and 29-05-2021\n",
      "Consecutive Dates: 29-05-2021 and 19-06-2021\n",
      "Consecutive Dates: 19-06-2021 and 02-08-2021\n",
      "Consecutive Dates: 02-08-2021 and 02-09-2021\n",
      "Consecutive Dates: 02-09-2021 and 04-10-2021\n",
      "Consecutive Dates: 04-10-2021 and 03-11-2021\n",
      "Consecutive Dates: 03-11-2021 and 06-12-2021\n",
      "Consecutive Dates: 06-12-2021 and 03-01-2022\n",
      "Consecutive Dates: 03-01-2022 and 02-02-2022\n",
      "Consecutive Dates: 02-02-2022 and 05-03-2022\n",
      "Consecutive Dates: 05-03-2022 and 04-04-2022\n",
      "Consecutive Dates: 04-04-2022 and 07-05-2022\n",
      "Consecutive Dates: 07-05-2022 and 04-06-2022\n",
      "Consecutive Dates: 04-06-2022 and 09-07-2022\n",
      "Consecutive Dates: 09-07-2022 and 16-08-2022\n",
      "Consecutive Dates: 16-08-2022 and 14-09-2022\n",
      "Consecutive Dates: 14-09-2022 and 16-10-2022\n",
      "Consecutive Dates: 16-10-2022 and 25-11-2022\n",
      "Consecutive Dates: 25-11-2022 and 30-12-2022\n",
      "Consecutive Dates: 30-12-2022 and 28-01-2023\n",
      "Consecutive Dates: 28-01-2023 and 11-03-2023\n",
      "Consecutive Dates: 11-03-2023 and 18-04-2023\n",
      "Consecutive Dates: 18-04-2023 and 23-05-2023\n",
      "Consecutive Dates: 23-05-2023 and 21-06-2023\n",
      "Consecutive Dates: 21-06-2023 and 21-07-2023\n",
      "Consecutive Dates: 21-07-2023 and 29-08-2023\n",
      "Consecutive Dates: 29-08-2023 and 28-09-2023\n",
      "Consecutive Dates: 28-09-2023 and 27-10-2023\n",
      "Consecutive Dates: 27-10-2023 and 28-11-2023\n",
      "Consecutive Dates: 28-11-2023 and 29-12-2023\n",
      "739201\n",
      "\n",
      "Consecutive Dates: 03-11-2022 and 03-01-2023\n",
      "Consecutive Dates: 03-01-2023 and 02-03-2023\n",
      "Consecutive Dates: 02-03-2023 and 25-04-2023\n",
      "173\n",
      "\n",
      "Consecutive Dates: 26-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 27-09-2022\n",
      "Consecutive Dates: 27-09-2022 and 18-04-2023\n",
      "Consecutive Dates: 18-04-2023 and 04-05-2023\n",
      "282\n",
      "\n",
      "Consecutive Dates: 01-07-2022 and 01-08-2022\n",
      "Consecutive Dates: 01-08-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 01-10-2022\n",
      "Consecutive Dates: 01-10-2022 and 01-11-2022\n",
      "Consecutive Dates: 01-11-2022 and 09-01-2023\n",
      "Consecutive Dates: 09-01-2023 and 14-02-2023\n",
      "228\n",
      "\n",
      "Consecutive Dates: 26-08-2022 and 24-09-2022\n",
      "Consecutive Dates: 24-09-2022 and 01-11-2022\n",
      "67\n",
      "\n",
      "Consecutive Dates: 22-12-2021 and 24-01-2022\n",
      "Consecutive Dates: 24-01-2022 and 25-02-2022\n",
      "Consecutive Dates: 25-02-2022 and 26-03-2022\n",
      "Consecutive Dates: 26-03-2022 and 25-05-2022\n",
      "Consecutive Dates: 25-05-2022 and 25-06-2022\n",
      "Consecutive Dates: 25-06-2022 and 27-07-2022\n",
      "Consecutive Dates: 27-07-2022 and 26-08-2022\n",
      "247\n",
      "\n",
      "Consecutive Dates: 27-07-2015 and 30-09-2015\n",
      "Consecutive Dates: 30-09-2015 and 05-11-2015\n",
      "Consecutive Dates: 05-11-2015 and 10-12-2015\n",
      "Consecutive Dates: 10-12-2015 and 12-01-2016\n",
      "Consecutive Dates: 12-01-2016 and 11-02-2016\n",
      "Consecutive Dates: 11-02-2016 and 18-05-2016\n",
      "Consecutive Dates: 18-05-2016 and 11-11-2016\n",
      "Consecutive Dates: 11-11-2016 and 21-12-2016\n",
      "Consecutive Dates: 21-12-2016 and 25-01-2017\n",
      "Consecutive Dates: 25-01-2017 and 27-02-2017\n",
      "Consecutive Dates: 27-02-2017 and 03-04-2017\n",
      "Consecutive Dates: 03-04-2017 and 09-05-2017\n",
      "Consecutive Dates: 09-05-2017 and 21-06-2017\n",
      "Consecutive Dates: 21-06-2017 and 03-08-2017\n",
      "Consecutive Dates: 03-08-2017 and 18-09-2017\n",
      "Consecutive Dates: 18-09-2017 and 29-11-2017\n",
      "Consecutive Dates: 29-11-2017 and 03-01-2018\n",
      "Consecutive Dates: 03-01-2018 and 09-02-2018\n",
      "Consecutive Dates: 09-02-2018 and 27-03-2018\n",
      "Consecutive Dates: 27-03-2018 and 26-04-2018\n",
      "Consecutive Dates: 26-04-2018 and 08-06-2018\n",
      "Consecutive Dates: 08-06-2018 and 24-07-2018\n",
      "Consecutive Dates: 24-07-2018 and 12-09-2018\n",
      "Consecutive Dates: 12-09-2018 and 24-10-2018\n",
      "Consecutive Dates: 24-10-2018 and 10-12-2018\n",
      "Consecutive Dates: 10-12-2018 and 25-01-2019\n",
      "Consecutive Dates: 25-01-2019 and 26-03-2019\n",
      "Consecutive Dates: 26-03-2019 and 06-06-2019\n",
      "Consecutive Dates: 06-06-2019 and 26-07-2019\n",
      "Consecutive Dates: 26-07-2019 and 03-09-2019\n",
      "Consecutive Dates: 03-09-2019 and 24-10-2019\n",
      "Consecutive Dates: 24-10-2019 and 18-11-2019\n",
      "Consecutive Dates: 18-11-2019 and 30-12-2019\n",
      "Consecutive Dates: 30-12-2019 and 04-02-2020\n",
      "Consecutive Dates: 04-02-2020 and 05-02-2020\n",
      "Consecutive Dates: 05-02-2020 and 06-05-2020\n",
      "Consecutive Dates: 06-05-2020 and 02-06-2020\n",
      "Consecutive Dates: 02-06-2020 and 25-08-2020\n",
      "Consecutive Dates: 25-08-2020 and 29-10-2020\n",
      "Consecutive Dates: 29-10-2020 and 19-12-2020\n",
      "Consecutive Dates: 19-12-2020 and 21-01-2021\n",
      "Consecutive Dates: 21-01-2021 and 23-03-2021\n",
      "Consecutive Dates: 23-03-2021 and 30-06-2021\n",
      "Consecutive Dates: 30-06-2021 and 19-10-2021\n",
      "Consecutive Dates: 19-10-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 31-03-2022\n",
      "Consecutive Dates: 31-03-2022 and 05-07-2022\n",
      "Consecutive Dates: 05-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 26-09-2022\n",
      "Consecutive Dates: 26-09-2022 and 03-11-2022\n",
      "Consecutive Dates: 03-11-2022 and 01-12-2022\n",
      "Consecutive Dates: 01-12-2022 and 02-01-2023\n",
      "Consecutive Dates: 02-01-2023 and 07-02-2023\n",
      "Consecutive Dates: 07-02-2023 and 16-03-2023\n",
      "Consecutive Dates: 16-03-2023 and 25-04-2023\n",
      "Consecutive Dates: 25-04-2023 and 05-06-2023\n",
      "Consecutive Dates: 05-06-2023 and 31-07-2023\n",
      "Consecutive Dates: 31-07-2023 and 10-10-2023\n",
      "Consecutive Dates: 10-10-2023 and 02-12-2023\n",
      "Consecutive Dates: 02-12-2023 and 27-01-2024\n",
      "3106\n",
      "\n",
      "Consecutive Dates: 09-10-2015 and 12-11-2015\n",
      "Consecutive Dates: 12-11-2015 and 11-01-2015\n",
      "Consecutive Dates: 11-01-2015 and 09-01-2016\n",
      "Consecutive Dates: 09-01-2016 and 06-02-2016\n",
      "Consecutive Dates: 06-02-2016 and 07-03-2016\n",
      "Consecutive Dates: 07-03-2016 and 09-04-2016\n",
      "Consecutive Dates: 09-04-2016 and 30-04-2016\n",
      "Consecutive Dates: 30-04-2016 and 14-05-2016\n",
      "Consecutive Dates: 14-05-2016 and 22-06-2016\n",
      "Consecutive Dates: 22-06-2016 and 26-07-2016\n",
      "Consecutive Dates: 26-07-2016 and 20-08-2016\n",
      "Consecutive Dates: 20-08-2016 and 06-10-2016\n",
      "Consecutive Dates: 06-10-2016 and 07-11-2016\n",
      "Consecutive Dates: 07-11-2016 and 09-12-2016\n",
      "Consecutive Dates: 09-12-2016 and 23-01-2017\n",
      "Consecutive Dates: 23-01-2017 and 20-02-2017\n",
      "Consecutive Dates: 20-02-2017 and 30-03-2017\n",
      "Consecutive Dates: 30-03-2017 and 28-04-2017\n",
      "Consecutive Dates: 28-04-2017 and 10-06-2017\n",
      "Consecutive Dates: 10-06-2017 and 04-07-2017\n",
      "Consecutive Dates: 04-07-2017 and 01-08-2017\n",
      "Consecutive Dates: 01-08-2017 and 30-08-2017\n",
      "Consecutive Dates: 30-08-2017 and 04-10-2017\n",
      "Consecutive Dates: 04-10-2017 and 27-11-2017\n",
      "Consecutive Dates: 27-11-2017 and 26-12-2017\n",
      "Consecutive Dates: 26-12-2017 and 01-02-2018\n",
      "Consecutive Dates: 01-02-2018 and 07-03-2018\n",
      "Consecutive Dates: 07-03-2018 and 11-04-2018\n",
      "Consecutive Dates: 11-04-2018 and 22-05-2018\n",
      "Consecutive Dates: 22-05-2018 and 25-06-2018\n",
      "Consecutive Dates: 25-06-2018 and 09-08-2018\n",
      "Consecutive Dates: 09-08-2018 and 13-09-2018\n",
      "Consecutive Dates: 13-09-2018 and 13-10-2018\n",
      "Consecutive Dates: 13-10-2018 and 08-11-2018\n",
      "Consecutive Dates: 08-11-2018 and 19-12-2018\n",
      "Consecutive Dates: 19-12-2018 and 17-01-2019\n",
      "Consecutive Dates: 17-01-2019 and 15-02-2019\n",
      "Consecutive Dates: 15-02-2019 and 16-02-2019\n",
      "Consecutive Dates: 16-02-2019 and 20-04-2019\n",
      "Consecutive Dates: 20-04-2019 and 22-05-2019\n",
      "Consecutive Dates: 22-05-2019 and 26-06-2019\n",
      "Consecutive Dates: 26-06-2019 and 29-07-2019\n",
      "Consecutive Dates: 29-07-2019 and 27-08-2019\n",
      "Consecutive Dates: 27-08-2019 and 05-10-2019\n",
      "Consecutive Dates: 05-10-2019 and 05-11-2019\n",
      "Consecutive Dates: 05-11-2019 and 17-12-2019\n",
      "Consecutive Dates: 17-12-2019 and 14-01-2020\n",
      "Consecutive Dates: 14-01-2020 and 19-02-2020\n",
      "Consecutive Dates: 19-02-2020 and 20-03-2020\n",
      "Consecutive Dates: 20-03-2020 and 08-05-2020\n",
      "Consecutive Dates: 08-05-2020 and 05-06-2020\n",
      "Consecutive Dates: 05-06-2020 and 26-09-2020\n",
      "Consecutive Dates: 26-09-2020 and 20-10-2020\n",
      "Consecutive Dates: 20-10-2020 and 24-11-2020\n",
      "Consecutive Dates: 24-11-2020 and 24-12-2020\n",
      "Consecutive Dates: 24-12-2020 and 01-02-2021\n",
      "Consecutive Dates: 01-02-2021 and 08-03-2021\n",
      "Consecutive Dates: 08-03-2021 and 16-04-2021\n",
      "Consecutive Dates: 16-04-2021 and 23-06-2021\n",
      "Consecutive Dates: 23-06-2021 and 20-07-2021\n",
      "Consecutive Dates: 20-07-2021 and 25-08-2021\n",
      "Consecutive Dates: 25-08-2021 and 18-09-2021\n",
      "Consecutive Dates: 18-09-2021 and 26-10-2021\n",
      "Consecutive Dates: 26-10-2021 and 25-11-2021\n",
      "Consecutive Dates: 25-11-2021 and 21-12-2021\n",
      "Consecutive Dates: 21-12-2021 and 20-01-2022\n",
      "Consecutive Dates: 20-01-2022 and 15-02-2022\n",
      "Consecutive Dates: 15-02-2022 and 15-03-2022\n",
      "Consecutive Dates: 15-03-2022 and 22-04-2022\n",
      "Consecutive Dates: 22-04-2022 and 23-05-2022\n",
      "Consecutive Dates: 23-05-2022 and 19-07-2022\n",
      "Consecutive Dates: 19-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 28-09-2022\n",
      "Consecutive Dates: 28-09-2022 and 06-12-2022\n",
      "Consecutive Dates: 06-12-2022 and 24-01-2023\n",
      "Consecutive Dates: 24-01-2023 and 16-03-2023\n",
      "Consecutive Dates: 16-03-2023 and 24-04-2023\n",
      "Consecutive Dates: 24-04-2023 and 07-06-2023\n",
      "Consecutive Dates: 07-06-2023 and 27-07-2023\n",
      "Consecutive Dates: 27-07-2023 and 11-09-2023\n",
      "Consecutive Dates: 11-09-2023 and 31-10-2023\n",
      "Consecutive Dates: 31-10-2023 and 08-01-2024\n",
      "3623\n",
      "\n",
      "Consecutive Dates: 26-02-2021 and 06-04-2021\n",
      "Consecutive Dates: 06-04-2021 and 01-10-2021\n",
      "Consecutive Dates: 01-10-2021 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 14-10-2022\n",
      "595\n",
      "\n",
      "Consecutive Dates: 30-09-2014 and 07-11-2014\n",
      "Consecutive Dates: 07-11-2014 and 02-12-2014\n",
      "Consecutive Dates: 02-12-2014 and 06-01-2015\n",
      "Consecutive Dates: 06-01-2015 and 05-02-2015\n",
      "Consecutive Dates: 05-02-2015 and 07-03-2015\n",
      "Consecutive Dates: 07-03-2015 and 07-04-2015\n",
      "Consecutive Dates: 07-04-2015 and 09-05-2015\n",
      "Consecutive Dates: 09-05-2015 and 08-06-2015\n",
      "Consecutive Dates: 08-06-2015 and 08-07-2015\n",
      "Consecutive Dates: 08-07-2015 and 06-08-2015\n",
      "Consecutive Dates: 06-08-2015 and 04-09-2015\n",
      "Consecutive Dates: 04-09-2015 and 05-10-2015\n",
      "Consecutive Dates: 05-10-2015 and 02-11-2015\n",
      "Consecutive Dates: 02-11-2015 and 17-12-2015\n",
      "Consecutive Dates: 17-12-2015 and 16-01-2016\n",
      "Consecutive Dates: 16-01-2016 and 13-02-2016\n",
      "Consecutive Dates: 13-02-2016 and 14-03-2016\n",
      "Consecutive Dates: 14-03-2016 and 12-05-2016\n",
      "Consecutive Dates: 12-05-2016 and 11-06-2016\n",
      "Consecutive Dates: 11-06-2016 and 12-07-2016\n",
      "Consecutive Dates: 12-07-2016 and 11-08-2016\n",
      "Consecutive Dates: 11-08-2016 and 10-09-2016\n",
      "Consecutive Dates: 10-09-2016 and 27-09-2016\n",
      "Consecutive Dates: 27-09-2016 and 24-10-2016\n",
      "Consecutive Dates: 24-10-2016 and 24-11-2016\n",
      "Consecutive Dates: 24-11-2016 and 22-12-2016\n",
      "Consecutive Dates: 22-12-2016 and 21-01-2017\n",
      "Consecutive Dates: 21-01-2017 and 21-02-2017\n",
      "Consecutive Dates: 21-02-2017 and 23-03-2017\n",
      "Consecutive Dates: 23-03-2017 and 22-04-2017\n",
      "Consecutive Dates: 22-04-2017 and 22-05-2017\n",
      "Consecutive Dates: 22-05-2017 and 24-06-2017\n",
      "Consecutive Dates: 24-06-2017 and 27-07-2017\n",
      "Consecutive Dates: 27-07-2017 and 26-08-2017\n",
      "Consecutive Dates: 26-08-2017 and 25-09-2017\n",
      "Consecutive Dates: 25-09-2017 and 25-10-2017\n",
      "Consecutive Dates: 25-10-2017 and 23-11-2017\n",
      "Consecutive Dates: 23-11-2017 and 23-12-2017\n",
      "Consecutive Dates: 23-12-2017 and 23-01-2018\n",
      "Consecutive Dates: 23-01-2018 and 20-02-2018\n",
      "Consecutive Dates: 20-02-2018 and 26-03-2018\n",
      "Consecutive Dates: 26-03-2018 and 24-04-2018\n",
      "Consecutive Dates: 24-04-2018 and 24-05-2018\n",
      "Consecutive Dates: 24-05-2018 and 06-06-2018\n",
      "Consecutive Dates: 06-06-2018 and 05-07-2018\n",
      "Consecutive Dates: 05-07-2018 and 04-08-2018\n",
      "Consecutive Dates: 04-08-2018 and 18-09-2018\n",
      "Consecutive Dates: 18-09-2018 and 16-10-2018\n",
      "Consecutive Dates: 16-10-2018 and 15-11-2018\n",
      "Consecutive Dates: 15-11-2018 and 17-12-2018\n",
      "Consecutive Dates: 17-12-2018 and 15-01-2019\n",
      "Consecutive Dates: 15-01-2019 and 16-02-2019\n",
      "Consecutive Dates: 16-02-2019 and 18-03-2019\n",
      "Consecutive Dates: 18-03-2019 and 16-04-2019\n",
      "Consecutive Dates: 16-04-2019 and 16-05-2019\n",
      "Consecutive Dates: 16-05-2019 and 15-06-2019\n",
      "Consecutive Dates: 15-06-2019 and 16-07-2019\n",
      "Consecutive Dates: 16-07-2019 and 14-08-2019\n",
      "Consecutive Dates: 14-08-2019 and 12-09-2019\n",
      "Consecutive Dates: 12-09-2019 and 14-10-2019\n",
      "Consecutive Dates: 14-10-2019 and 12-11-2019\n",
      "Consecutive Dates: 12-11-2019 and 16-12-2019\n",
      "Consecutive Dates: 16-12-2019 and 15-01-2020\n",
      "Consecutive Dates: 15-01-2020 and 15-02-2020\n",
      "Consecutive Dates: 15-02-2020 and 16-03-2020\n",
      "Consecutive Dates: 16-03-2020 and 24-04-2020\n",
      "Consecutive Dates: 24-04-2020 and 18-06-2020\n",
      "Consecutive Dates: 18-06-2020 and 21-07-2020\n",
      "Consecutive Dates: 21-07-2020 and 28-08-2020\n",
      "Consecutive Dates: 28-08-2020 and 28-09-2020\n",
      "Consecutive Dates: 28-09-2020 and 20-11-2020\n",
      "Consecutive Dates: 20-11-2020 and 21-12-2020\n",
      "Consecutive Dates: 21-12-2020 and 04-09-2021\n",
      "Consecutive Dates: 04-09-2021 and 11-10-2021\n",
      "Consecutive Dates: 11-10-2021 and 01-11-2021\n",
      "Consecutive Dates: 01-11-2021 and 03-12-2021\n",
      "Consecutive Dates: 03-12-2021 and 10-01-2022\n",
      "Consecutive Dates: 10-01-2022 and 11-02-2022\n",
      "Consecutive Dates: 11-02-2022 and 11-03-2022\n",
      "Consecutive Dates: 11-03-2022 and 15-04-2022\n",
      "Consecutive Dates: 15-04-2022 and 15-05-2022\n",
      "Consecutive Dates: 15-05-2022 and 18-06-2022\n",
      "Consecutive Dates: 18-06-2022 and 20-07-2022\n",
      "Consecutive Dates: 20-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 13-10-2022\n",
      "2935\n",
      "\n",
      "Consecutive Dates: 16-05-2020 and 16-06-2020\n",
      "Consecutive Dates: 16-06-2020 and 09-01-2021\n",
      "Consecutive Dates: 09-01-2021 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 12-06-2023\n",
      "Consecutive Dates: 12-06-2023 and 24-07-2023\n",
      "Consecutive Dates: 24-07-2023 and 23-08-2023\n",
      "1194\n",
      "\n",
      "Consecutive Dates: 31-05-2022 and 28-06-2022\n",
      "Consecutive Dates: 28-06-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 30-09-2022\n",
      "Consecutive Dates: 30-09-2022 and 04-11-2022\n",
      "Consecutive Dates: 04-11-2022 and 09-12-2022\n",
      "192\n",
      "\n",
      "Consecutive Dates: 30-06-2022 and 04-07-2022\n",
      "Consecutive Dates: 04-07-2022 and 29-07-2022\n",
      "Consecutive Dates: 29-07-2022 and 05-08-2022\n",
      "Consecutive Dates: 05-08-2022 and 19-08-2022\n",
      "Consecutive Dates: 19-08-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 11-10-2022\n",
      "Consecutive Dates: 11-10-2022 and 13-10-2022\n",
      "Consecutive Dates: 13-10-2022 and 11-11-2022\n",
      "Consecutive Dates: 11-11-2022 and 07-02-2023\n",
      "Consecutive Dates: 07-02-2023 and 24-03-2023\n",
      "Consecutive Dates: 24-03-2023 and 23-06-2023\n",
      "Consecutive Dates: 23-06-2023 and 14-07-2023\n",
      "Consecutive Dates: 14-07-2023 and 28-07-2023\n",
      "Consecutive Dates: 28-07-2023 and 15-09-2023\n",
      "442\n",
      "\n",
      "Consecutive Dates: 26-08-2022 and 24-09-2022\n",
      "Consecutive Dates: 24-09-2022 and 26-10-2022\n",
      "Consecutive Dates: 26-10-2022 and 18-11-2022\n",
      "Consecutive Dates: 18-11-2022 and 21-07-2023\n",
      "Consecutive Dates: 21-07-2023 and 18-08-2023\n",
      "357\n",
      "\n",
      "Consecutive Dates: 07-06-2019 and 21-06-2019\n",
      "Consecutive Dates: 21-06-2019 and 22-07-2019\n",
      "Consecutive Dates: 22-07-2019 and 22-08-2019\n",
      "Consecutive Dates: 22-08-2019 and 11-11-2019\n",
      "Consecutive Dates: 11-11-2019 and 09-12-2019\n",
      "Consecutive Dates: 09-12-2019 and 06-01-2020\n",
      "Consecutive Dates: 06-01-2020 and 05-03-2021\n",
      "Consecutive Dates: 05-03-2021 and 12-03-2021\n",
      "Consecutive Dates: 12-03-2021 and 20-04-2021\n",
      "Consecutive Dates: 20-04-2021 and 11-05-2021\n",
      "Consecutive Dates: 11-05-2021 and 09-08-2021\n",
      "Consecutive Dates: 09-08-2021 and 22-10-2021\n",
      "Consecutive Dates: 22-10-2021 and 14-02-2022\n",
      "Consecutive Dates: 14-02-2022 and 06-05-2022\n",
      "Consecutive Dates: 06-05-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 31-10-2022\n",
      "Consecutive Dates: 31-10-2022 and 23-01-2023\n",
      "Consecutive Dates: 23-01-2023 and 07-04-2023\n",
      "Consecutive Dates: 07-04-2023 and 30-06-2023\n",
      "Consecutive Dates: 30-06-2023 and 29-09-2023\n",
      "Consecutive Dates: 29-09-2023 and 01-12-2023\n",
      "Consecutive Dates: 01-12-2023 and 05-02-2024\n",
      "1704\n",
      "\n",
      "Consecutive Dates: 07-08-2022 and 17-08-2022\n",
      "Consecutive Dates: 17-08-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 21-09-2022\n",
      "Consecutive Dates: 21-09-2022 and 11-11-2022\n",
      "Consecutive Dates: 11-11-2022 and 18-11-2022\n",
      "Consecutive Dates: 18-11-2022 and 25-11-2022\n",
      "Consecutive Dates: 25-11-2022 and 02-12-2022\n",
      "Consecutive Dates: 02-12-2022 and 09-12-2022\n",
      "Consecutive Dates: 09-12-2022 and 10-01-2023\n",
      "Consecutive Dates: 10-01-2023 and 13-01-2023\n",
      "Consecutive Dates: 13-01-2023 and 19-01-2023\n",
      "Consecutive Dates: 19-01-2023 and 31-01-2023\n",
      "Consecutive Dates: 31-01-2023 and 07-02-2023\n",
      "Consecutive Dates: 07-02-2023 and 24-02-2023\n",
      "Consecutive Dates: 24-02-2023 and 01-04-2023\n",
      "Consecutive Dates: 01-04-2023 and 28-04-2023\n",
      "Consecutive Dates: 28-04-2023 and 30-05-2023\n",
      "Consecutive Dates: 30-05-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 29-07-2023\n",
      "Consecutive Dates: 29-07-2023 and 31-08-2023\n",
      "Consecutive Dates: 31-08-2023 and 28-09-2023\n",
      "Consecutive Dates: 28-09-2023 and 30-10-2023\n",
      "Consecutive Dates: 30-10-2023 and 25-11-2023\n",
      "Consecutive Dates: 25-11-2023 and 21-12-2023\n",
      "Consecutive Dates: 21-12-2023 and 29-01-2024\n",
      "540\n",
      "\n",
      "Consecutive Dates: 28-03-2022 and 13-07-2022\n",
      "Consecutive Dates: 13-07-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 11-10-2022\n",
      "Consecutive Dates: 11-10-2022 and 15-05-2023\n",
      "Consecutive Dates: 15-05-2023 and 31-07-2023\n",
      "Consecutive Dates: 31-07-2023 and 07-09-2023\n",
      "Consecutive Dates: 07-09-2023 and 03-10-2023\n",
      "Consecutive Dates: 03-10-2023 and 01-11-2023\n",
      "Consecutive Dates: 01-11-2023 and 04-12-2023\n",
      "616\n",
      "\n",
      "Consecutive Dates: 08-06-2022 and 26-08-2022\n",
      "Consecutive Dates: 26-08-2022 and 19-12-2022\n",
      "Consecutive Dates: 19-12-2022 and 23-01-2023\n",
      "Consecutive Dates: 23-01-2023 and 02-11-2023\n",
      "512\n",
      "\n",
      "Consecutive Dates: 28-08-2021 and 15-07-2022\n",
      "Consecutive Dates: 15-07-2022 and 17-08-2022\n",
      "354\n",
      "\n",
      "Consecutive Dates: 29-06-2020 and 21-08-2020\n",
      "Consecutive Dates: 21-08-2020 and 30-08-2020\n",
      "Consecutive Dates: 30-08-2020 and 31-10-2020\n",
      "Consecutive Dates: 31-10-2020 and 03-12-2020\n",
      "Consecutive Dates: 03-12-2020 and 04-01-2021\n",
      "Consecutive Dates: 04-01-2021 and 19-01-2021\n",
      "Consecutive Dates: 19-01-2021 and 02-02-2021\n",
      "Consecutive Dates: 02-02-2021 and 10-03-2021\n",
      "Consecutive Dates: 10-03-2021 and 12-04-2021\n",
      "Consecutive Dates: 12-04-2021 and 28-08-2021\n",
      "Consecutive Dates: 28-08-2021 and 22-10-2021\n",
      "Consecutive Dates: 22-10-2021 and 24-11-2021\n",
      "Consecutive Dates: 24-11-2021 and 07-02-2022\n",
      "Consecutive Dates: 07-02-2022 and 17-02-2022\n",
      "Consecutive Dates: 17-02-2022 and 25-02-2022\n",
      "Consecutive Dates: 25-02-2022 and 07-03-2022\n",
      "Consecutive Dates: 07-03-2022 and 04-04-2022\n",
      "Consecutive Dates: 04-04-2022 and 21-06-2022\n",
      "Consecutive Dates: 21-06-2022 and 24-08-2022\n",
      "Consecutive Dates: 24-08-2022 and 24-09-2022\n",
      "Consecutive Dates: 24-09-2022 and 16-11-2022\n",
      "870\n",
      "\n",
      "Consecutive Dates: 16-05-2019 and 14-08-2019\n",
      "Consecutive Dates: 14-08-2019 and 03-02-2020\n",
      "Consecutive Dates: 03-02-2020 and 06-02-2020\n",
      "Consecutive Dates: 06-02-2020 and 19-06-2020\n",
      "Consecutive Dates: 19-06-2020 and 17-07-2020\n",
      "Consecutive Dates: 17-07-2020 and 21-08-2020\n",
      "Consecutive Dates: 21-08-2020 and 19-11-2020\n",
      "Consecutive Dates: 19-11-2020 and 19-12-2020\n",
      "Consecutive Dates: 19-12-2020 and 18-02-2021\n",
      "Consecutive Dates: 18-02-2021 and 27-02-2021\n",
      "Consecutive Dates: 27-02-2021 and 28-08-2021\n",
      "Consecutive Dates: 28-08-2021 and 29-10-2021\n",
      "Consecutive Dates: 29-10-2021 and 28-12-2021\n",
      "Consecutive Dates: 28-12-2021 and 21-03-2022\n",
      "Consecutive Dates: 21-03-2022 and 25-05-2022\n",
      "Consecutive Dates: 25-05-2022 and 02-07-2022\n",
      "Consecutive Dates: 02-07-2022 and 13-08-2022\n",
      "Consecutive Dates: 13-08-2022 and 13-09-2022\n",
      "Consecutive Dates: 13-09-2022 and 12-10-2022\n",
      "Consecutive Dates: 12-10-2022 and 12-11-2022\n",
      "Consecutive Dates: 12-11-2022 and 13-12-2022\n",
      "Consecutive Dates: 13-12-2022 and 12-01-2023\n",
      "Consecutive Dates: 12-01-2023 and 08-02-2023\n",
      "Consecutive Dates: 08-02-2023 and 05-08-2023\n",
      "1542\n",
      "\n",
      "Consecutive Dates: 16-05-2018 and 15-06-2018\n",
      "Consecutive Dates: 15-06-2018 and 16-07-2018\n",
      "Consecutive Dates: 16-07-2018 and 16-08-2018\n",
      "Consecutive Dates: 16-08-2018 and 15-09-2018\n",
      "Consecutive Dates: 15-09-2018 and 15-11-2018\n",
      "Consecutive Dates: 15-11-2018 and 05-03-2019\n",
      "Consecutive Dates: 05-03-2019 and 03-04-2019\n",
      "Consecutive Dates: 03-04-2019 and 02-05-2019\n",
      "Consecutive Dates: 02-05-2019 and 27-05-2019\n",
      "Consecutive Dates: 27-05-2019 and 27-06-2019\n",
      "Consecutive Dates: 27-06-2019 and 27-07-2019\n",
      "Consecutive Dates: 27-07-2019 and 27-08-2019\n",
      "Consecutive Dates: 27-08-2019 and 31-08-2019\n",
      "Consecutive Dates: 31-08-2019 and 13-09-2019\n",
      "Consecutive Dates: 13-09-2019 and 26-10-2019\n",
      "Consecutive Dates: 26-10-2019 and 27-12-2019\n",
      "Consecutive Dates: 27-12-2019 and 27-01-2020\n",
      "Consecutive Dates: 27-01-2020 and 29-02-2020\n",
      "Consecutive Dates: 29-02-2020 and 22-04-2020\n",
      "Consecutive Dates: 22-04-2020 and 16-12-2020\n",
      "Consecutive Dates: 16-12-2020 and 03-05-2022\n",
      "Consecutive Dates: 03-05-2022 and 19-05-2022\n",
      "Consecutive Dates: 19-05-2022 and 17-06-2022\n",
      "Consecutive Dates: 17-06-2022 and 16-07-2022\n",
      "Consecutive Dates: 16-07-2022 and 09-08-2022\n",
      "Consecutive Dates: 09-08-2022 and 03-09-2022\n",
      "Consecutive Dates: 03-09-2022 and 03-10-2022\n",
      "Consecutive Dates: 03-10-2022 and 02-11-2022\n",
      "Consecutive Dates: 02-11-2022 and 06-12-2022\n",
      "Consecutive Dates: 06-12-2022 and 04-01-2023\n",
      "Consecutive Dates: 04-01-2023 and 09-02-2023\n",
      "Consecutive Dates: 09-02-2023 and 09-03-2023\n",
      "Consecutive Dates: 09-03-2023 and 03-04-2023\n",
      "Consecutive Dates: 03-04-2023 and 24-04-2023\n",
      "Consecutive Dates: 24-04-2023 and 05-06-2023\n",
      "Consecutive Dates: 05-06-2023 and 04-07-2023\n",
      "Consecutive Dates: 04-07-2023 and 07-08-2023\n",
      "Consecutive Dates: 07-08-2023 and 06-09-2023\n",
      "Consecutive Dates: 06-09-2023 and 05-10-2023\n",
      "Consecutive Dates: 05-10-2023 and 04-11-2023\n",
      "Consecutive Dates: 04-11-2023 and 04-12-2023\n",
      "2028\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "day = []\n",
    "for i in df2['frequency of follow up at lgb (to write down follow-up dates)']:\n",
    "    print()\n",
    "    k=k+1\n",
    "    a = extract_consecutive_dates(i)\n",
    "    sum = 0\n",
    "    for pair in a:\n",
    "        b = calculate_days_difference(pair[0].strftime('%d-%m-%Y'), pair[1].strftime('%d-%m-%Y'), date_format=\"%d-%m-%Y\")\n",
    "        sum=sum+b\n",
    "        print(f\"Consecutive Dates: {pair[0].strftime('%d-%m-%Y')} and {pair[1].strftime('%d-%m-%Y')}\")\n",
    "    day.append(sum)\n",
    "    print(sum)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5835537d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'total_days'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'total_days'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [144], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_days\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'total_days'"
     ]
    }
   ],
   "source": [
    "for i in df2['total_days']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bc54f896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-06-2019,29-07-2019,09-09-2019,21-10-2019,17-12-2019,18-01-2020,02-03-2020,02-05-2020,22-06-2020,28-08-2020,17-11-2020,21-01-2021\n",
      "\n",
      "31-03-2014,29-04-2014,29-05-2014,04-07-2014,25-08-2014,01-02-2016,30-03-2016,29-04-2016,03-06-2016,28-08-2016,08-08-2016,08-09-2016,05-10-2016,09-11-2016,16-12-2016,23-01-2017,22-02-2017,10-03-2017,21-04-2017,25-05-2017,22-06-2017,20-07-2017,03-10-2017,02-11-2017,06-01-2018,05-02-2018,08-03-2018,07-04-2018,05-05-2018,07-06-2018,09-08-2018,12-09-2018,09-10-2018,12-11-2018,19-12-2018,17-01-2019,13-06-2019,13-07-2019,17-08-2019,17-08-2019,20-10-2019,301-11-2019,03-01-2020,06-03-2020,22-06-2020,02-04-2021,10-05-2021,06-08-2021,07-09-2021,13-11-2021,17-01-2022,19-03-2022,30-05-2022,04-07-2022,09-08-2022,13-09-2022,27-10-2022,28-11-2022,10-01-2023,13-02-2023,22-03-2023,26-04-2023,05-06-2023,17-07-2023,24-08-2023,25-09-2023,06-11-2023\n",
      "\n",
      "31-03-2014,29-04-2014,29-05-2014,04-07-2014,25-08-2014,01-02-2016,30-03-2016,29-04-2016,03-06-2016,28-08-2016,08-08-2016,08-09-2016,05-10-2016,09-11-2016,16-12-2016,23-01-2017,22-02-2017,10-03-2017,21-04-2017,25-05-2017,22-06-2017,20-07-2017,03-10-2017,02-11-2017,06-01-2018,05-02-2018,08-03-2018,07-04-2018,05-05-2018,07-06-2018,09-08-2018,12-09-2018,09-10-2018,12-11-2018,19-12-2018,17-01-2019,13-06-2019,13-07-2019,17-08-2019,17-08-2019,20-10-2019,30-11-2019,03-01-2020,06-03-2020,22-06-2020,02-04-2021,10-05-2021,06-08-2021,07-09-2021,13-11-2021,17-01-2022,19-03-2022,30-05-2022,04-07-2022,09-08-2022,13-09-2022,27-10-2022,28-11-2022,10-01-2023,13-02-2023,22-03-2023,26-04-2023,05-06-2023,17-07-2023,24-08-2023,25-09-2023,06-11-2023\n",
      "\n",
      "22-06-2020,30-09-2020\n",
      "\n",
      "10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,23-09-15,21-10-15,11-11-15,21-12-15,25-1-16,16-3-16,18-5-16,20-07-16,7-9-16,26-10-16,28-12-16,27-1-17,22-2-17,17-3-17,14-4-17,12-5-17,26-6-17,13-9-17,11-10-17,15-11-17,15-12-17,7-2-18,2-4-18,9-5-18,31-5-18,27-6-18,4-8-18,24-9-18,5-11-18,14-12-18,15-1-19,12-2-19,12-4-19,25-5-19,16-7-19,20-8-19,21-9-19,21-10-19,18-11-19,20-12-19,25-1-2020,24-2-2020,20-03-20,19-05-20,22-06-20,28-07-20,20-10-20,01-11-20,22-12-20,19-1-21,19-2-21,19-03-21,12-04-21,08-05-21,19-07-21,13-08-21,11-10-21,16-11-21,17-12-21,11-01-22,15-03-21,12-04-22,13-06-22,16-07-22,16-08-22,14-11-22,24-01-23,28-02-23,1-04-23,29-05-23,4-07-23,18-08-23,26-09-23,07-11-23\n",
      "\n",
      "10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,23-09-15,21-10-15,11-11-15,21-12-15,25-1-16,16-3-16,18-5-16,20-07-16,7-9-16,26-10-16,28-12-16,27-1-17,22-2-17,17-3-17,14-4-17,12-5-17,26-6-17,13-9-17,11-10-17,15-11-17,15-12-17,7-2-18,2-4-18,9-5-18,31-5-18,27-6-18,4-8-18,24-9-18,5-11-18,14-12-18,15-1-19,12-2-19,12-4-19,25-5-19,16-7-19,20-8-19,21-9-19,21-10-19,18-11-19,20-12-19,25-1-2020,24-2-2020,20-03-20,19-05-20,22-06-20,28-07-20,20-10-20,0-11-20,22-12-20,19-1-21,19-2-21,19-03-21,12-04-21,08-05-21,19-07-21,13-08-21,11-10-21,16-11-21,17-12-21,11-01-22,15-03-21,12-04-22,13-06-22,16-07-22,16-08-22,14-11-22,24-01-23,28-02-23,1-04-23,29-05-23,4-07-23,18-08-23,26-09-23,07-11-23\n",
      "\n",
      "8-6-2016,18-7-2016,19-8-2016,14-9-16,4-10-2016,9-11-2016,9-1-2017,10-2-2017,11-3-2017,10-4-2017,11-5-2017,10-6-2017,8-7-2017,5-8-2017,4-9-2017,14-10-2017,4-12-2017,2-1-2018,2-2-2018,3-3-2018,4-4-2018,2-5-2018,2-6-2018,2-7-2018,31-7-2018,30-8-2018,28-9-2018,29-19-2018,28-11-2018,27-12-2018,25-1-2019,26-2-2019,26-3-2019,24-4-2019,27-5-2019,27-6-2019,27-8-2019,25-9-2019,25-10-2019,25-11-2019,24-12-2019,21-1-2020,22-2-2020,23-3-2020,21-4-2020,22-5-2020,22-6-2020,9-1-2021,3-3-2021,12-4-2021,14-6-2021,8-8-2021,14-9-2021,16-10-2021,16-11-2021,3-1-2022,4-2-2022,5-3-2022,5-4-2022,20-5-2022,6-7-2022,3-8-2022,2-9-2022,30-9-2022,2-11-2022,8-12-2022,28-12-2023,4-2-2023,4-3-2023,4-5-2023,27-5-2023,4-7-2023,1-8-2023,2-9-2023,3-10-2023,1-11-2023\n",
      "\n",
      "nan\n",
      "\n",
      "27-12-2019,17-3-2020,22-06-2020,14-12-2020,22-01-2021,6-11-2023\n",
      "\n",
      "27-02-2020,22-06-2020\n",
      "\n",
      "14-02-2020,22-06-2022\n",
      "\n",
      "08-03-2018,13-06-2019,28-06-2019,22-06-2022,26-11-2020,11-08-2022,06-07-2023\n",
      "\n",
      "22.06.2020\n",
      "\n",
      "15-10-12,9-1-13,4-2-13,7-3-13,5-4-13,6-5-13,5-6-13,4-7-13,3-8-13,2-9-13,3-10-13,2-11-13,21-11-13,11-3-15,3-4-15,22-4-15,14-5-15,5-6-15,13-7-15,19-8-15,22-9-15,21-10-15,20-11-15,21-12,15,19-1-16,18-2-16,3-3-16,2-4-19,6-5-16,7-3-17,13-4-17,17-5-17,19-6-17,20-7-17,16-8-17,13-9-17,14-10-17,28-10-17,28-11-17,30-12-17,31-1-18,5-3-18,4-4-18,12-4-18,2-5-18,28-5-18,2-7-18,31-7-18,30-08-18,29-10-18,28-11-18,29-12-18,29-01-19,28-2-19,29-3-19,27-4-19,27-5-19,26-6-19,25-7-19,26-8-19,25-9-19,26-10-19,22-11-19,25-12-19,20-1-20,22-2-20,21-4-20,22-05-20,22-6-20,16-11-20,11-01-21,21-03-21,12-06-23,30-07-23,04-08-23,18-08-23,19-09-23,18-10-23\n",
      "\n",
      "07.03.2019,24.01.2020,04.02.2020,03.03.2020,14.05.2020,22.06.2020,28.09.2020,20.02.2021,17.05.2021,19.8.2021,06.07.2022,14.08.2023\n",
      "\n",
      "30-08-18,03-10-18,17-11-18,20-12-18,31-01-19,15-03-19,1-05-19,29-06-19,25-09-19,21-10-19,05-12-19,24-01-2020,22-06-2020,06-10-2020,23-11-2020,09-03-21,11-05-21,28-07-21,04-10-21,26-11-21,29-01-22,10-03-22,20-04-22,26-05-22,18-07-22,07-09-22,10-10-22,23-11-22,04-1-23,02-03-23,20-04-23,09-06-23,04-08-23,23-09-23,04-11-23\n",
      "\n",
      "22-06-2020,31-08-2020,14-09-2020,28-10-2020,201-11-2020,12-03-2020,19-03-2021\n",
      "\n",
      "08-12-2020,16-10-2021,101-11-2021,13-12-2021,17-01-2022,16-07-2021,16-08-2021,13-9-2021,14-5-2022,15-6-2022,15-7-2022,16-2-2022,15-3-2022,18-4-2022,12-10-2022,11-11-2022,13-12-2022,9-1-2023,12-8-2022,12-9-2022,10-4-2023,8-5-2023,10-6-2023,8-7-2023,11-2-2023,4-3-2023,5-8-2023,29-8-2023,7-10-2023,4-11-2023\n",
      "\n",
      "08-12-2020,16-10-2021,10-11-2021,13-12-2021,17-01-2022,16-07-2021,16-08-2021,13-9-2021,14-5-2022,15-6-2022,15-7-2022,16-2-2022,15-3-2022,18-4-2022,12-10-2022,11-11-2022,13-12-2022,9-1-2023,12-8-2022,12-9-2022,10-4-2023,8-5-2023,10-6-2023,8-7-2023,11-2-2023,4-3-2023,5-8-2023,29-8-2023,7-10-2023,4-11-2023\n",
      "\n",
      "03-07-17,11-09-17,19-03-18,04-05-18,20-06-18,03-08-18,18-09-18,09-10-18,28-11-18,07-02-19,13-04-19,23-05-19,09-07-19,15-11-19,04-10-19,15-11-19,17-12-19,23-01-2020,04-03-2020,22-04-2020,22-06-2020,26-09-2020,19-11-2020,29-12-2020,04-02-21,06-03-21,12-04-21,29-05-21,09-07-21,27-08-21,06-10-21,17-11-21,23-12-21,12-1-22,05-02-22,19-02-22,22-03-22,02-05-22,13-06-22,16-07-22,23-08-22,16-08-22,26-09-22,05-10-22,28-10-22,08-11-22,07-02-23,05-04-23,29-05-23,04-07-23,18-07-23,15-09-23,\n",
      "\n",
      "05-06-2014,27-06-2014,30-07-2014,02-09-2014,08-10-2014,14-11-2017,30-12-2014,27-02-2015,03-04-2015,09-05-2015,25-06-2015,31-07-2015,01-10-2015,09-11-2015,01-01-2016,12-02-2016,18-03-2016,19-04-2016,07-05-2016,04-06-2016,11-07-2016,05-08-2016,03-09-2016,13-10-2016,09-11-2016,07-12-2016,02-01-2017,01-02-2017,03-03-2017,31-03-2017,10-05-2017,03-06-2017,04-07-2017,08-09-2017,29-06-2018,09-08-2018,18-09-2018,20-10-2018,23-11-2018,301-11-2018,09-02-2019,02-04-2019,27-05-2019,18-06-2019,19-06-2019,26-07-2019,09-09-2019,10-10-2019,16-11-2019,26-11-2019,24-12-2019,04-02-2020,19-03-2020,18-05-2020,22-06-2020,15-10-2020,16-11-2020,17-12-2020,16-01-2021,25-02-2021,19-05-2021,31-07-2021,13-11-2021,20-12-2021,10-01-2022,09-03-2022,12-04-2022,20-06-2022,25-08-2022,09-11-2022,15-02-2023,03-05-2023,04-07-2023,24-08-2023\n",
      "\n",
      "23-11-2015,28-12-2015,15-02-2016,11-04-2016,25-05-2016,24-06-2016,06-07-2016,03-08-2016,08-09-2016,13-10-2016,101-11-2016,12-12-2016,18-01-2017,02-03-2017,10-04-2017,03-05-2017,29-05-2017,05-06-2017,03-07-2017,02-08-2017,04-09-2017,06-11-2017,04-12-2017,05-01-2018,14-02-2018,02-04-2018,01-06-2018,02-06-2018,04-07-2018,02-08-2018,06-09-2018,09-10-2018,07-11-2018,10-01-2019,11-02-2019,18-03-2019,26-04-2019,28-05-2019,18-06-2019,28-08-2019,04-10-2019,08-11-2019,11-12-2019,16-01-2020,15-02-2020,29-02-2020,22-04-2020,05-05-2020,22-06-2020,21-07-2020,29-08-2020,21-10-2020,15-11-2020,22-12-2020,22-01-2021,06-03-2021,02-04-2021,08-05-2021,25-01-2022,23-08-2022,19-12-2022,24-07-2023,05-10-2023\n",
      "\n",
      "23-11-2015,28-12-2015,15-02-2016,11-04-2016,25-05-2016,24-06-2016,06-07-2016,03-08-2016,08-09-2016,13-10-2016,10-11-2016,12-12-2016,18-01-2017,02-03-2017,10-04-2017,03-05-2017,29-05-2017,05-06-2017,03-07-2017,02-08-2017,04-09-2017,06-11-2017,04-12-2017,05-01-2018,14-02-2018,02-04-2018,01-06-2018,02-06-2018,04-07-2018,02-08-2018,06-09-2018,09-10-2018,07-11-2018,10-01-2019,11-02-2019,18-03-2019,26-04-2019,28-05-2019,18-06-2019,28-08-2019,04-10-2019,08-11-2019,11-12-2019,16-01-2020,15-02-2020,29-02-2020,22-04-2020,05-05-2020,22-06-2020,21-07-2020,29-08-2020,21-10-2020,15-11-2020,22-12-2020,22-01-2021,06-03-2021,02-04-2021,08-05-2021,25-01-2022,23-08-2022,19-12-2022,24-07-2023,05-10-2023\n",
      "\n",
      "13-06-2018,18-08-2018,23-08-2018,19-09-2018,24-10-2018,20-02-2019,13-03-2019,06-04-2019,25-05-2019,31-07-2019,13-09-2019,08-10-2019,17-12-2019,07-01-2020,13-03-2020,11-05-2020,22-06-2020,11-09-2020,23-01-2021,24-03-2021,14-04-2021,12-06-2021,14-06-2021,20-08-2021,10-09-2021,28-09-2021,16-11-2021,01-12-2021,03-12-2021,17-12-2021,31-12-2021,18-02-2022,22-02-2022,11-03-2022,25-03-2022,23-04-2022,01-07-2022,13-08-2022,31-12-2022,12-05-2023,09-06-2023,27-07-2023\n",
      "\n",
      "17-03-2020,15-06-2020,22-06-2020,24-06-2020,01-07-2020,03-08-2020,24-08-2020,\n",
      "\n",
      "04-01-2020,06-02-2020,11-03-2020,22-06-2020,27-08-2020,30-10-2020,07-01-2021,24-02-2021,02-02-2022\n",
      "\n",
      "21-11-2016,21-12-2016,21-1-2017,28-2-2017,31-3-2017,2-5-2017,1-6-2017,5-7-2017,12-8-2017,8-9-2017,18-10-2017,21-11-2017,28-12-2017,31-1-2018,21-3-2018,23-4-2018,31-5-2018,6-6-2018,3-7-2018,25-9-2018,5-11-2018,18-12-2018,29-1-2019,6-3-2019,3-4-2019,19-4-2019,25-5-2019,29-6-2019,9-8-2019,24-9-2019,29-10-2019,1-12-2019,6-1-2020,14-2-2020,12-6-2020,30-10-2020,11-12-2020,18-1-2021,19-3-2021,13-4-2021,3-8-2021,6-11-2021,11-12-2021,4-2-2022,14-6-2022,20-7-2022,24-8-2022,12-11-2022,4-1-2023,18-5-2023,21-6-2023-11-10-2023\n",
      "\n",
      "23.09.2017,23.10.2017,24.11.2017,05.10.2018,22.09.2021,28.10.2021,13.01.2022\n",
      "\n",
      "19.07.2017,15.09.2017,13.11.2017,13.06.2019,18.07.2019,21.11.2019,31.12.2019,11.03.2020,23.10.2020,05.04.2021,28.10.2021,11.10.2022,23.06.2023,26.07.2023,28.08.2023,10.10.2023,17.11.2023\n",
      "\n",
      "21-11-2014,17-12-2014,15-01-2015,14-02-2015,24-03-2015,13-04-2015,04-05-2015,04-06-2015,23-07-2015,06-08-2015,07-09-2015,03-10-2015,03-11-2015,07-12-2015,24-01-2016,30-01-2016,04-03-2016,05-04-2016,07-05-2016,06-06-2016,30-06-2016,30-07-2016,05-09-2016,23-09-2016,24-10-2016,07-12-2016,30-01-2017,07-03-2017,20-04-2017,17-07-2019,21-09-2019,21-09-2019,19-10-2019,22-11-2019,23-12-2019,22-01-2020,19-02-2020,13-03-2020,23-04-2020,16-06-2020,01-08-2020,02-09-2020,27-11-2020,25-12-2020,04-02-2021,25-02-2021,01-04-2021,22-04-2021,08-05-2021,11-06-2021,19-07-2021,17-08-2021,25-09-2021,28-10-2021,03-12-2021,-4-01-2022,03-02-2022,10-03-2022,14-04-2022,06-05-2022,08-06-2022,09-07-2022,17-08-2022,23-09-2022,02-11-2022,09-12-2022,30-12-2022,15-02,2023,13-03-2023,1-04-2023,04-05-2023,18-05-2023\n",
      "\n",
      "28-10-21,03-01-22,18-05-22,20-06-22,25-08-22\n",
      "\n",
      "21.04.2016,16.05.2016,23.05.2017,24.07.2017,19.02.2018,26.03.2018,30.11.2018,12.01.2019,02.01.2019,20.02.2020,15.06.2020,11.02.2021,07.10.2021,28.10.2021,03.12.2021,30.12.2021,17.02.2022,24.03.2022,12.05.2022,29.08.2022,06.10.2022,03.05.2023,16.11.2023,27.11.2023\n",
      "\n",
      "25-3-2019,22-4-2019,21-5-2019,28-6-2019,9-8-2019,9-9-2019,11-10-2019,5-11-2019,4-12-2019,6-1-2019,10-2-2020,6-7-2020,24-11-2020,12-1-2021,26-4-2021,30-7-2021,28-9-2021,28-10-2021,28-12-2021,25-2-2022,25-4-2022,25-5-2022,27-6-2022,27-7-2022,26-8-2022,2-11-2022,2-1-2023,27-2-2023,17-4-2023,29-5-2023,27-6-2023,27-9-2023,25-10-2023,27-11-2023\n",
      "\n",
      "28-08-21,28-10-21,27-12-21,27-1-22,25-04-22,27-06-22,26-08-22,26-10-22,18-11-22,10-04-23,19-10-23\n",
      "\n",
      "28-10-21,29-11-21,05-01-22,05-09-22,09-03-22,09-04-22\n",
      "\n",
      "30-09-21,28-10-21,13-12-21,29-01-21\n",
      "\n",
      "30-9-2021,28-10-2021,6-2-2023\n",
      "\n",
      "8.9.21,20.9.2021,28.10.2021,17.2.2022,4.9.2023,12.9.2023\n",
      "\n",
      "05-07-21,03-09-21,28-10-21,02-12-21,31-01-22,31-03-22,31-05-22,28-06-22,29-12-22,13-02-23,02-06-23,25-07-23\n",
      "\n",
      "3-5-2021,12-7-2021,28-10-2021,24-1-2022,5-5-2022,21-7-2022\n",
      "\n",
      "8-11-2021,301-11-2021,30-12-2021,29-1-2022,1-3-2022,31-3-2022,5-5-2022,11-6-2022,5-7-2022,4-8-2022,5-9-2022,10-10-2022,101-11-2022,5-12-2022,14-1-2023,16-2-2023,27-3-2023,6-5-2023,10-6-2025\n",
      "\n",
      "18-7-2022,27-7-202217-8-2022,15-9-2022,6-10-2022,14-10-2022,16-11-2022,21-11-2022,17-12-2022,13-1-2023,18-1-2023,16-2-2023,15-3-2023,17-4-2023,7-6-2023,31-7-2023,11-8-2023,19-8-2023,20-9-2023,18-10-2023,4-11-2023,2-12-2023\n",
      "\n",
      "21-7-2022,16-2-2023,18-5-2023,5-10-2023\n",
      "\n",
      "nan\n",
      "\n",
      "5-4-2022,5-5-2022,2-6-2022,1-7-2022,15-7-2022,26-7-2022,4-8-2022,11-8-2022,18-8-2022,25-8-2022,6-9-2022,13-10-2022,101-11-2022,24-12-2022,16-2-2023,5-5-2023,28-7-2023,18-10-2023\n",
      "\n",
      "16-1-2023,16-3-2023\n",
      "\n",
      "2-2-2021,8-5-2021,14-9-2021,5-4-2021,-5-5-2021,28-6-2022,24-8-2022,31-10-2022,16-2-2023,8-5-2023,11-7-2023,1-11-2023\n",
      "\n",
      "14-3-2019,23-12-2019,5-5-2022,25-6-2022,29-8-2022,31-10-2022,15-12-202216-2-2023\n",
      "\n",
      "5-4-2022,5-5-2022,2-6-2022,1-7-2022,15-7-2022,26-7-2022,4-8-2022,11-8-2022,18-8-2022,25-8-2022,6-9-2022,13-10-2022,10-11-2022,24-12-2022,16-2-2023,5-5-2023,28-7-2023,18-10-2023\n",
      "\n",
      "17-1-2023,16-2-2023,3-3-2023,3-4-2023,19-5-2023,24-6-2023,29-7-2023,7-9-2023\n",
      "\n",
      "16.02.2023,27.03.2023,15.05.2023\n",
      "\n",
      "16.02.2023,6.3.2023,22.3.2023,31.3.2023,28.4.2023,16.6.23,1.9.2023,24.10.2023\n",
      "\n",
      "28-12-2020,13-4-2021,25-7-2022,16-2-2023\n",
      "\n",
      "16.2.2023,10.3.2023,17.4.2023,5.6.2023\n",
      "\n",
      "15-9-2022,17-11-2022,20-12-2022,16-2-2023,18-4-2023,27-7-2023\n",
      "\n",
      "20-5-2017,21-6-2017,25-8-2018,1-9-2018,12-9-2018,22-10-2018,23-11-2018,31-12-2018,16-2-2019,22-3-2019,3-7-2019,3-8-2019,11-9-2019,15-10-2019,15-11-2019,23-12-2019,31-1-2020,22-2-2020,9-3-2020,23-4-2020,15-6-2020,18-8-2020,17-10-2020,3-12-2020,28-12-2020,25-1-2021,25-2-2021,7-4-2021,19-6-2021,4-8-2021,6-9-2021,13-10-2021,17-11-2021,30-12-2021,19-2-2022,24-3-2022,21-4-2022,26-5-2022,2-6-2022,9-8-2022,22-9-2022,17-11-2022,7-1-2023,16-2-2023,21-3-2023,29-4-2023,26-8-2023,7-10-2023,4-12-2023\n",
      "\n",
      "8-7-2022,8-8-2022,8-9-2022,18-10-2022,14-11-2022,12-12-2022,11-1-2023,16-2-2023,4-4-2023,17-6-2023,7-8-2023,27-11-2023\n",
      "\n",
      "24-4-2017,16-5-2017,8-10-2018,7-11-2018,10-12-2018,12-1-2019,28-3-2019,30-4-2019,30-5-2019,1-7-2019,5-8-2019,7-9-2019,7-10-2019,11-11-2019,18-12-2019,20-1-2020,17-2-2020,17-3-2020,18-6-2020,16-9-2020,101-11-2020,28-12-2020,2-1-2021,2-2-2021,22-3-2021,26-4-2021,8-6-2022,8-7-2022,11-8-2022,9-9-2022,30-9-2022,301-11-2022,10-1-2023,16-2-2023,25-3-2023,26-4-2023,30-5-2023,1-7-2023,5-8-2023,7-9-2023,25-10-2023\n",
      "\n",
      "21.5.2022,1.6.2022,22.6.2022,21.7.2022,27.8.2022,30.7.2022,30.9.2022,1.11.2022,2.12.2022,6.1.2023,16.2.2023,23.3.2023,29.4.2023,10.6.2023,17.7.2023,28.8.2023,9.10.2023,27.11.2023\n",
      "\n",
      "16.2.2023,16.3.2023,17.4.2023,15.5.2023\n",
      "\n",
      "nan\n",
      "\n",
      "24-4-2017,16-5-2017,8-10-2018,7-11-2018,10-12-2018,12-1-2019,28-3-2019,30-4-2019,30-5-2019,1-7-2019,5-8-2019,7-9-2019,7-10-2019,11-11-2019,18-12-2019,20-1-2020,17-2-2020,17-3-2020,18-6-2020,16-9-2020,10-11-2020,28-12-2020,2-1-2021,2-2-2021,22-3-2021,26-4-2021,8-6-2022,8-7-2022,11-8-2022,9-9-2022,30-9-2022,30-11-2022,10-1-2023,16-2-2023,25-3-2023,26-4-2023,30-5-2023,1-7-2023,5-8-2023,7-9-2023,25-10-2023\n",
      "\n",
      "16.2.2023,3.3.2023,13.6.2023\n",
      "\n",
      "29-12-2017,11-1-2022,12-1-2022,16-2-2023,18-2-2023\n",
      "\n",
      "4-5-2022,21-6-2022,21-7-2022,20-08-2022,17-10-2022,16-11-2022,19-12-2022,17-1-2-2023,16-2-2023,18-3-2023,18-4-2023,16-5-2023,16-6-2023,13-7-2023,7-8-2023,31-8-2023,1-11-2023,2-12-2023\n",
      "\n",
      "22-9-2022,20-10-2022,17-11-2022,21-12-2022,16-2-2023,7-4-2023,18-7-2023,17-8-2023,13-10-2023\n",
      "\n",
      "11-1-2018,8-2-2019,10-3-2019,6-4-2019,4-5-2019,13-7-2019,11-2-2020,2-5-2022,30-8-2022,29-92022,16-2-2023,20-4-2023\n",
      "\n",
      "28-1-2019,2-3-2019,9-4-2019,29-5-2019,2-9-2019,30-9-2019,27-11-2019,24-12-2019,31-1-2020,4-2-2020,22-4-2020,9-6-2020,8-10-2020,27-11-2020,28-12-2020,29-1-2021,27-2-2021,30-3-2021,4-5-2021,11-6-2021,9-8-2021,7-10-2021,101-11-2021,15-12-2021,4-2-2022,16-3-2022,21-4-2022,3-6-2022,28-6-2022,4-8-2022,29-9-2022,1-11-2022,15-12-2022,14-1-2023,25-2-2023,11-4-2023,25-5-2023,26-3-2023,25-7-2023,8-9-2023,6-10-2023,4-11-2023,14-12-2023\n",
      "\n",
      "13-5-2022,11-6-2022,15-7-2022,16-8-2022,17-1-2023,18-1-2023,16-2-2023\n",
      "\n",
      "15-12-2007,12-1-2008,2-2-2008,11-12-2010,13-3-2013,13-4-2013,11-5-2013,12-6-2013,13-7-2013,14-8-2013,19-8-2013,14-9-2013,17-10-2013,16-11-2013,18-12-2013,18-1-2014,19-2-2014,23-4-2014,24-5-2014,28-6-2014,30-7-2014,30-8-2014,1-10-2014,29-10-2014,29-11-2014,31-12-2014,3-2-2015,7-3-2015,9-6-2015,11-7-2015,14-8-2015,29-9-2015,3-11-2015,5-12-2015,5-1-2016,8-1-2016,16-2-2016,21-3-2016,23-4-2016,31-5-2016,11-7-2016,9-8-2016,10-9-2016,22-10-2016,7-1-2017,14-3-2017,6-5-2017,7-7-2017,8-8-2017,12-9-2017,14-10-2017,7-2-2018,20-3-2018,2-5-2018,8-6-2018,20-7-2018,28-12-2018,8-1-2019,25-1-2019,15-3-2019,30-4-2019,7-6-2019,11-7-2019,13-8-2019,3-10-2019,7-11-2019,4-1-2020,24-3-2020,22-4-2020,11-7-2020,19-11-2020,28-8-2021,25-9-2021,26-10-2021,30-10-2021,3-11-2021,101-11-2021,27-11-2021,28-12-2021,28-1-2022,28-2-2022,28-3-2022,28-4-2022,28-5-2022,29-6-2022,28-7-2022,30-8-2022,30-9-2022,9-11-2022,14-12-2022,19-1-2023,20-2-2023,4-4-2023,3-5-2023,6-6-2023,6-7-2023,7-8-2023,7-9-2023,11-10-2023,201-11-2023,18-12-2023\n",
      "\n",
      "27-11-2019,24-1-2020,3-3-2020,22-4-2020,16-6-2020,29-7-2020,3-11-2020,17-11-2020,29-12-2020,10-2-2021,16-3-2021,31-3-2021,30-3-2022,27-5-2022,8-7-2022,22-8-2022,27-9-2022,11-11-2022,14-12-2022,18-1-2023,28-2-2023,18-4-2023,20-7-2023,26-9-2023,6-12-2023\n",
      "\n",
      "12-1-2008,2-2-2010,11-12-2010,13-3-2013,13-4-2013,11-5-2013,12-6-2013,13-7-2013,14-8-2013,19-8-2013,14-9-2013,17-10-2013,14-9-2013,17-10-2013,16-11-2013,18-1-2014,19-2-2014,23-4,2014,24-5-2014,23-6-2014,30-7-2014,30-8-2014,1-10-2014,29-10-2014,29-11-2014,31-12-2014,3-1-2015,7-3-2015,18-4-2015,9-6-2015,11-7-2015,14-8-2015,29-9-2015,3-11-2015,5-12-2015,5-1-2016,8-1-2016,16-2-2016,21-3-2016,23-4-2016,31-5-2016,11-7-2016,9-8-2016,10-5-2016,22-10,22-10-2016,7-1-2017,14-3-2017,6-5-2017,7-7-2017,8-8-2017,12-9-2017,14-10-2017,7-2-2018,7-2-2018,20-3-2018,2-5-2018,8-6-2018,20-7-2018,28-12-2018,8-1-2018,25-1-2019,15-3-2019,30-4-2019,30-4-2019,7-6-2019,11-7-2019,13-8-2019,3-10-2019,7-11-2019,4-1-2020,24-3-2020,22-4-2020,11-7-2020,19-11-2020,19-11-2020,8-3-2021,28-8-2021,25-9-201,25-9-2021,26-10-2021,30-10-2021,3-11-2021,101-11-2021,27-11-2021,28-12-2021,28-1-2022,28-2-2022,28-3-2022,28-4-2022,28-5-2022,28-6-2022,28-7-2022,30-8-2022,30-9-2022,9-11-2022,14-12-2022,19-1-2023,20-2-2022,4-4-2023,3-5-2023,6-6-2023,6-7-2023,7-8-2023,7-9-2023,11-10-2023,201-11-2023,18-12-2023\n",
      "\n",
      "28-1-2019,2-3-2019,9-4-2019,29-5-2019,2-9-2019,30-9-2019,27-11-2019,24-12-2019,31-1-2020,4-2-2020,22-4-2020,9-6-2020,8-10-2020,27-11-2020,28-12-2020,29-1-2021,27-2-2021,30-3-2021,4-5-2021,11-6-2021,9-8-2021,7-10-2021,10-11-2021,15-12-2021,4-2-2022,16-3-2022,21-4-2022,3-6-2022,28-6-2022,4-8-2022,29-9-2022,1-11-2022,15-12-2022,14-1-2023,25-2-2023,11-4-2023,25-5-2023,26-3-2023,25-7-2023,8-9-2023,6-10-2023,4-11-2023,14-12-2023\n",
      "\n",
      "17-04-10,18-09-10,27-10-10,27-11-10,12-09-17,12-10-17,27-10-17,22-12-17,25-01-18,10-03-18,24-04-18,21-05-18,04-07-18,13-08-18,12-09-18,06-10-18,14-11-18,21-12-18,28-01-19,15-03-19,24-04-19,31-05-19,09-07-19,26-08-19,15-10-19,30-12-19,02-03-20,22-04-20,25-05-20,12-08-20,08-10-20,30-10-20,09-01-21,08-02-21,08-03-21,08-04-21,05-05-21,21-06-21,28-09-21,03-12-21,27-01-22,17-04-22,09-05-22,13-07-22,13-09-22,14-11-22,27-01-23,18-03-23,29-06-23,24-07-23,02-09-23,29-09-23,14-11-23,20-12-23\n",
      "\n",
      "6-8-2011,14-8-2019,15-6-2020,18-1-2021,24-2-2021,1-3-2021,8-3-2021,30-4-2021,2-6-2021,3-6-2021,18-6-2021\n",
      "\n",
      "16-5-2018,15-6-2018,16-7-2018,16-8-2018,15-09-2018,15-11-2018,5-3-2019,3-4-2019,2-5-2019,27-5-2019,27-6-2019,27-7-2019,27-8-2019,31-8-2019,13-9-2019,26-10-2019,30-11-2019,27-12-2019,27-1-2020,29-2-2020,22-4-2020,16-12-2020,3-5-2022,19-5-2022,17-6-2022,16-7-2022,9-8-2022,3-9-2022,3-10-2022,2-11-2022,6-12-2022,4-1-2023,9-2-2023,9-3-2023,3-4-2023,24-4-2023,5-6-2023,4-7-2023,7-8-2023,6-9-2023,5-10-2023,4-11-2023,4-12-2023\n",
      "\n",
      "15-12-2007,12-1-2008,2-2-2008,11-12-2010,13-3-2013,13-4-2013,11-5-2013,12-6-2013,13-7-2013,14-8-2013,19-8-2013,14-9-2013,17-10-2013,16-11-2013,18-12-2013,18-1-2014,19-2-2014,23-4-2014,24-5-2014,28-6-2014,30-7-2014,30-8-2014,1-10-2014,29-10-2014,29-11-2014,31-12-2014,3-2-2015,7-3-2015,9-6-2015,11-7-2015,14-8-2015,29-9-2015,3-11-2015,5-12-2015,5-1-2016,8-1-2016,16-2-2016,21-3-2016,23-4-2016,31-5-2016,11-7-2016,9-8-2016,10-9-2016,22-10-2016,7-1-2017,14-3-2017,6-5-2017,7-7-2017,8-8-2017,12-9-2017,14-10-2017,7-2-2018,20-3-2018,2-5-2018,8-6-2018,20-7-2018,28-12-2018,8-1-2019,25-1-2019,15-3-2019,30-4-2019,7-6-2019,11-7-2019,13-8-2019,3-10-2019,7-11-2019,4-1-2020,24-3-2020,22-4-2020,11-7-2020,19-11-2020,28-8-2021,25-9-2021,26-10-2021,30-10-2021,3-11-2021,10-11-2021,27-11-2021,28-12-2021,28-1-2022,28-2-2022,28-3-2022,28-4-2022,28-5-2022,29-6-2022,28-7-2022,30-8-2022,30-9-2022,9-11-2022,14-12-2022,19-1-2023,20-2-2023,4-4-2023,3-5-2023,6-6-2023,6-7-2023,7-8-2023,7-9-2023,11-10-2023,20-11-2023,18-12-2023\n",
      "\n",
      "17-7-2020,5-7-2021,16-8-2021,17-9-2021,6-11-2021,8-12-2021,2-2-2022,28-2-2022\n",
      "\n",
      "12-1-2008,2-2-2010,11-12-2010,13-3-2013,13-4-2013,11-5-2013,12-6-2013,13-7-2013,14-8-2013,19-8-2013,14-9-2013,17-10-2013,14-9-2013,17-10-2013,16-11-2013,18-1-2014,19-2-2014,23-4,2014,24-5-2014,23-6-2014,30-7-2014,30-8-2014,1-10-2014,29-10-2014,29-11-2014,31-12-2014,3-1-2015,7-3-2015,18-4-2015,9-6-2015,11-7-2015,14-8-2015,29-9-2015,3-11-2015,5-12-2015,5-1-2016,8-1-2016,16-2-2016,21-3-2016,23-4-2016,31-5-2016,11-7-2016,9-8-2016,10-5-2016,22-10,22-10-2016,7-1-2017,14-3-2017,6-5-2017,7-7-2017,8-8-2017,12-9-2017,14-10-2017,7-2-2018,7-2-2018,20-3-2018,2-5-2018,8-6-2018,20-7-2018,28-12-2018,8-1-2018,25-1-2019,15-3-2019,30-4-2019,30-4-2019,7-6-2019,11-7-2019,13-8-2019,3-10-2019,7-11-2019,4-1-2020,24-3-2020,22-4-2020,11-7-2020,19-11-2020,19-11-2020,8-3-2021,28-8-2021,25-9-201,25-9-2021,26-10-2021,30-10-2021,3-11-2021,10-11-2021,27-11-2021,28-12-2021,28-1-2022,28-2-2022,28-3-2022,28-4-2022,28-5-2022,28-6-2022,28-7-2022,30-8-2022,30-9-2022,9-11-2022,14-12-2022,19-1-2023,20-2-2022,4-4-2023,3-5-2023,6-6-2023,6-7-2023,7-8-2023,7-9-2023,11-10-2023,20-11-2023,18-12-2023\n",
      "\n",
      "7.10.2020,,6.11.2020,27.11.2020,11.1.2021,4.2.2021,3.3.2021,26.4.2021,18.5.2021,23.6.2021,6.7.2021,27.8.2021,20.9.2021,19.10.2021,13.11.2021,27.11.2021,11.12.2021,14.1.2022,18.2.2022,21.3.2022,5.5.2022,2.6.2022,5.7.2022,29.7.2022,8.9.2022,7.10.2022,5.11.2022,5.12.2022,10.1.2023,28.2.2023,18.3.2023,22.5.2023,4.7.2023,3.8.2023,9.9.2023,30.10.2023,25.11.2023\n",
      "\n",
      "15.12.2021,12.3.2022,5.5.2022,1.8.2022,19.8.2022,30.12.2022,14.2.2023,21.3.2023,6.5.2023,19.7.2023,16.9.2023,3.11.2023,21.12.2023\n",
      "\n",
      "2-8-2021,7-10-2021,8-11-2021,13-12-2021,17-1-2022,3-2-2022,25-2-2022,31-3-2022,5-5-2022,11-6-2022,14-7-2022,17-8-2022,16-9-2022,19-10-2022,19-11-2022,21-12-2022,23-1-2023,23-2-2022,24-3-2023,24-4-2023,24-5-2023,27-6-2023,26-7-2023,26-8-2023,30-9-2023,27-10-2023,301-11-2023\n",
      "\n",
      "1-4-2022,4-5-2022,5-5-2022,23-5-2022,26-9-2022,9-12-2022,16-12-2022,23-12-2022,11-7-2023\n",
      "\n",
      "5-2-2022,5-5-2022\n",
      "\n",
      "12.1.2019,1.2.2019,21.12.2021,19.1.2022,12.2.2022,16.3.2022,5.5.2022\n",
      "\n",
      "17.6.2109,23.7.2019,27.8.2019,24.9.2019,26.10.2019,25.11.2019,26.12.2019,27.1.2020,13.3.2020,23.4.2020,19.5.2020,19.6.2020,22.7.2020,25.7.2020,14.10.2020,17.12.2020,18.1.2021,16.2.2021,19.3.2021,20.4.2021,20.5.2021,1.11.2021,24.11.2021,28.1.2022,8.4.2022,5.5.2022,10.6.2022,13.7.2022,5.9.2022,7.10.2022,10.11.2022,14.12.2022,13.1.2023,13.2.2023,13.3.2023,21.4.2023,23.5.2023,27.6.2023,1.8.2023,31.8.2023,10.10.2023,17.11.2023\n",
      "\n",
      "4-4-2022,5-5-2022,4-6-2022,5-7-2022,4-8-2022,5-9-2022,10-10-2022,15-11-2022,18-2-2023,17-3-2023,17-7-2023,28-8-2023,5-10-2023,1-11-2023,16-12-2023\n",
      "\n",
      "15-11-2021,18-1-2022,23-7-2022,30-8-2022,16-11-2022,16-2-2023,3-5-2023,31-10-2023,29-12-2023\n",
      "\n",
      "11-1-2022,5-5-2022,22-11-2022,24-3-2023,12-6-2023,11-9-2023,16-10-2023,6-12-2023\n",
      "\n",
      "2-8-2021,7-10-2021,8-11-2021,13-12-2021,17-1-2022,3-2-2022,25-2-2022,31-3-2022,5-5-2022,11-6-2022,14-7-2022,17-8-2022,16-9-2022,19-10-2022,19-11-2022,21-12-2022,23-1-2023,23-2-2022,24-3-2023,24-4-2023,24-5-2023,27-6-2023,26-7-2023,26-8-2023,30-9-2023,27-10-2023,30-11-2023\n",
      "\n",
      "29-1-2021,31-12-2021,31-1-2022,7-3-2022,8-4-2022,5-5-2022,9-6-2022,3-9-2022,7-11-2022,9-12-2022,14-2-2023,24-4-2023,11-7-2023\n",
      "\n",
      "26-5-2018,2-6-2018,2-7-2018,31-7-2018,31-8-2018,28-9-2018,29-10-2018,26-11-2018,24-12-2018,23-1-2019,25-2-2019,23-3-2019,26-4-2019,6-6-2019,21-8-2019,18-11-2019,4-1-2020,28-1-2020,23-2-2021,20-3-2021,13-4-2021,10-9-2021,23-10-2021,25-11-2021,2012-20-12-2021,8-2-2022,11-3-2022,13-4-2022,5-5-2022,4-6-2022,8-7-2022,-8-8-2022,10-9-2022,11-10-2022,12-11-2022,10-1-2023,10-4-2023,21-6-2023,26-8-2023,23-11-2023\n",
      "\n",
      "5-5-2022,27-6-2022,18-11-2022,14-3-2023,26-4-2023\n",
      "\n",
      "20-5-2020,23-6-2020,29-7-2020,9-9-2020,10-10-2020,12-11-2020,301-11-2020,12-1-2021,17-2-2021,26-3-2021,19-4-2021,1-6-2021,29-6-2021,27-7-2021,16-8-2021,4-10-2021,1-112021,3-1-2022,15-2-2022,18-3-2022,18-4-2022,19-5-2022,27-6-2022,12-9-2022,22-10-2022,31-1-2023,4-4-2023,30-6-2023\n",
      "\n",
      "5-5-2022,2-6-2022,30-12-2022,5-1-2023,12-6-2023,20-6-2023,\n",
      "\n",
      "8-9-2021,12-11-2021,5-5-2022,9-8-2022,7-10-2022,13-12-2022,24-3-2023,26-6-2023,12-10-2023\n",
      "\n",
      "28-11-2020,11-11-2021,16-11-2021,3-1-2022,12-7-2022,3-3-2023,16-3-2023,6-4-2023\n",
      "\n",
      "3.1.2022,31.1.2022,11.3.2022,26.4.2022,13.6.2022,25.7.2022,5.9.2022,28.10.2022,24.1.2023\n",
      "\n",
      "28.12.20,8.1.21,20.2.21,20.3.21,20.4.21,2.9.21,1.11.21,3.1.22,2.3.22,2.5.22,31.5.22,28.6.22,28.7.22,26.8.22,22.9.22,21.10.22,21.12.22,23.1.23,18.2.23,24.3.23,21.4.23,23.5.23,22.6.23,22.7.23,21.8.23,22.9.23,21.10.23,21.11.23,21.12.23,19.1.24\n",
      "\n",
      "04.01.21,13-03-21,11-09-21,25-10-21,03-01-22,21-04-22,23-06-22,22-08-22,24-10-22,09-12-22,16-01-23,31-03-23,17-05-23,03-07-23,21-08-23,13-10-23,28-11-23\n",
      "\n",
      "30-12-2020,30-1-2021,2-3-2021,2-4-2021,3-5-2021,3-6-2021,3-7-2021,3-8-2021,3-9-2021,3-11-2021,3-1-2022,1-4-2022,11-6-2022,6-12-2022,9-2-2023,29-5-2023,19-9-2023,16-1-2024\n",
      "\n",
      "26-10-20,201-11-20,21-12-20,07-01-21,22-1-21,29-1-21,08-02-21,11-02-21,22-02-21,24-09-21,03-01-22,10-01-22,22-07-22,25-09-23\n",
      "\n",
      "17.12.2021,3.1.2022\n",
      "\n",
      "3.1.2022,5.3.2022\n",
      "\n",
      "21-8-2020,20-10-2020,201-11-2020,19-12-2020,25-1-2021,23-2-2021,23-3-2021,20-4-2021,20-5-2021,19-6-2021,23-7-2021,24-8-2021,5-10-2021,23-11-2021,23-12-2021,24-1-2022,24-2-2022,10-5-2022,7-7-2022,8-8-2022,7-9-2022,11-10-2022,22-11-2022,3-1-2023,6-2-2023,22-3-2023,1-5-2023,30-5-2023,5-7-2023,7-8-2023,12-9-2023,30-5-20235-7-2023,27-10-2023,27-11-2023\n",
      "\n",
      "25.06.21,26.06.21,20.7.21,24.09.21,14.10.21,6.11.21,6.12.21,3.1.22,4.3.22,2.5.22,6.6.22,1.7.22,25.7.22,10.9.22,10.10.22,8.11.22,2.12.22,5.1.23,21.2.23,30.3.23,3.5.23,1.6.23,7.7.23,2.8.23,4.9.23,9.10.23,6.11.23,11.12.23,10.1.24\n",
      "\n",
      "nan\n",
      "\n",
      "25.3.2021,11.6.2021,3.8.2021,20.9.2021,3.1.2022,3.3.2022,10.3.2022,11.12.2023\n",
      "\n",
      "28-10-2021,3-1-2022,18-5-2022,20-6-2022,25-8-2022\n",
      "\n",
      "3-1-2022,17-1-2022,21-1-2022\n",
      "\n",
      "26-10-20,20-11-20,21-12-20,07-01-21,22-1-21,29-1-21,08-02-21,11-02-21,22-02-21,24-09-21,03-01-22,10-01-22,22-07-22,25-09-23\n",
      "\n",
      "8-8-17,5-9-17,5-10-17,30-10-17,29-11-17,28-12-17,1-2-18,13-2-18,19-3-18,17-4-18,15-5-18,9-6-18,10-7-18,06-8-18,5-9-18,28-9-18,29-10-18,30-11-18,27-12-18,2-2-19,5-4-19,3-5-19,27-5-19,18-6-19,15-7-19,17-8-19,07-9-19,3-10-19,6-11-19,6-12-19,4-1-2020,4-2-20,7-3-20,3-7-20,28-8-20,27-11-20,5-2-21,9-4-21,3-8-21,22-10-21,3-1-22,6-5-22,30-7-22,21-10-22,27-1-23,18-4-23,25-10-23,2-2-24\n",
      "\n",
      "17-5-2021,18-6-2021,13-9-2021,28-9-2021,11-10-2021,5-11-2021,3-1-2022,1-2-2022,28-2-2022,29-4-2022,30-5-2022,1-7-2022,1-8-2022,30-8-2022,30-9-2022,1-11-2022,2-12-2022,3-1-2023,6-2-2023,21-3-2023,2-5-2023,11-8-2023,22-9-2023,1-11-2023,9-1-2024\n",
      "\n",
      "21-8-2020,20-10-2020,20-11-2020,19-12-2020,25-1-2021,23-2-2021,23-3-2021,20-4-2021,20-5-2021,19-6-2021,23-7-2021,24-8-2021,5-10-2021,23-11-2021,23-12-2021,24-1-2022,24-2-2022,10-5-2022,7-7-2022,8-8-2022,7-9-2022,11-10-2022,22-11-2022,3-1-2023,6-2-2023,22-3-2023,1-5-2023,30-5-2023,5-7-2023,7-8-2023,12-9-2023,30-5-20235-7-2023,27-10-2023,27-11-2023\n",
      "\n",
      "3-1-2022,25-5-2022\n",
      "\n",
      "2012-2021,3-1-2022,22-6-2022,31-8-2022,21-3-2023,21-4-2023,22-5-2023,22-6-2023,20-7-2023,28-1-2023,21-9-2023,21-11-202316-1-2024\n",
      "\n",
      "1-11-2021,1-12-2021,3-1-2022,31-1-2022,8-3-2022,9-4-2022,8-8-2022,10-9-2022,7-10-2022,8-11-2022,10-12-2022,11-1-2023,8-2-2023,9-3-2023,8-4-2023,13-5-2023,3-6-2023,18-7-2023,22-8-2023\n",
      "\n",
      "13-07-2021,13-08-2021,14-09-2021,19-10-2021,22-10-2021,26-10-2021,03-01-2022,15-02-2022,17-02-2022,25-03-2022,31-03-2022,30-05-2022,22-07-2022,23-07-2022,25-07-2022,26-07-2022,17-10-2022,26-12-2022,10-02-2023,15-05-2023,27-06-2023\n",
      "\n",
      "3-1-2022,3-2-2022,3-3-2022,13-4-2022,15-9-2023,6-11-2023\n",
      "\n",
      "nan\n",
      "\n",
      "19-7-2021,21-9-2021,3-1-2022,16-7-2022,11-8-2022,7-09-2022,8-10-2022,6-12-2022,7-1-2023,13-4-2023.11-5-2023,11-7-2023,10-8-2023-14-12-2023,11-1-2024,9-2-2024\n",
      "\n",
      "19.1.2022,16.2.2022,6.5.2022,23.6.2022,26.7.2022,15.9.2022,14.11.2022,31.12.2022,2.2.2023,4.3.2023,3.5.2023,29.5.2023\n",
      "\n",
      "16.11.2021,3.1.2022\n",
      "\n",
      "nan\n",
      "\n",
      "9-6-2018,13-7-2018,11-8-2018,11-9-2018,4-10-2018,5-11-2018,6-12-2018,10-6-2019,10-7-2019,7-8-2019,21-8-2019,1-10-2019,26-10-2019,4-12-2019,6-1-2020,1-2-2020,13-3-2020,12-6-2020,4-8-2020,7-9-2020,4-11-2020,25-12-2020,11-2-2021,17-3-2021,22-4-2021,17-8-2021,21-9-2021,25-10-2021,3-1-2022,17-3-2022,14-4-2022,12-5-2022,27-7-2022,5-9-2022,1-10-2022,27-1-2023,24-2-2023,25-3-2023,17-4-2023,15-7-2023,26-10-2023\n",
      "\n",
      "nan\n",
      "\n",
      "30-9-14,07-11-14,2-12-14,6-1-15,5-2-15,7-3-15,7-4-15,9-5-15,8-6-15,8-7-15,6-8-15,4-9-15,5-10-15,2-11-15,17-12-15,16-1-16,13-2-16,14-3-16,14-4-6,12-5-16,11-6-16,12-7-16,11-8-16,10-9-16,27-9-16,24-10-16,24-11-16,22-12-16,21-1-17,21-2-17,23-3-17,22-4-17,22-5-17,24-6-17,27-7-17,26-8-17,25-9-17,25-10-17,23-11-17,23-12-17,23-1-18,20-2-18,26-3-18,24-4-18,24-5-18,6-6-18,5-7-18,4-8-18,18-9-18,16-10-18,15-11-18,17-12-18,15-1-19,16-2-19,18-3-19,16-4-19,16-5-19,15-6-19,16-7-19,14-8-19,12-9-19,14-10-19,12-11-19,16-12-19,15-1-20,15-2-20,16-3-20,24-4-20,18-6-20,21-7-20,28-8-20,28-9-20,201-11-20,21-12-20,4-9-21,11-10-21,1-11-21,3-12-21,10-1-22,11-2-22,11-3-22,15-4-22,15-5-22,18-6-22,20-7-22,26-8-22,13-10-22\n",
      "\n",
      "16-10-2019,15-11-2019,15-12-2019,13-1-2020,11-2-2020,13-3-2020,15-5-1010,17-4-2020,15-6-2020,13-8-2020,22-9-2020,27-11-2020,4-1-2021,28-1-2021,24-2-2021,24-3-2021,30-4-2021,29-5-2021,19-6-2021,2-8-2021,2-9-2021,4-10-2021,3-11-2021,6-12-2021,3-1-2022,2-2-2022,5-3-2022,4-4-2022,7-5-2022,4-6-2022,9-7-2022,16-8-2022,14-9-2022,16-10-2022,25-11-2022,30-12-2022,28-1-2023,11-3-2023,18-4-2023,23-5-2023,21-6-2023,21-7-2023,29-8-2023,28-9-2023,27-10-2023,28-11-2023,29-12-2023\n",
      "\n",
      "3-11-2022,3-1-2023,2-3-2023,25-4-2023\n",
      "\n",
      "26-7-2022,26-8-2022,27-9-2022,18-4-2023,4-5-2023\n",
      "\n",
      "1-7-2022,1-8-2022,26-8-2022,1-10-2022,1-11-2022,9-1-2023,14-2-2023\n",
      "\n",
      "26-8-2022,24-9-2022,1-11-2022\n",
      "\n",
      "22-12-21,24-1-22,25-02-22,26-03-22,25-05-22,25-06-22,27-07-22,26-08-22\n",
      "\n",
      "27-7-15,30-9-15,5-11-15,10-12-15,12-1-16,11-2-16,18-5-16,11-11-16,21-12-16,25-1-17,27-2-17,3-4-17,9-5-17,21-6-17,3-8-17,18-9-17,29-11-17,3-1-18,9-2-18,27-3-18,26-4-18,8-6-18,24-7-18,12-9-18,24-10-18,10-12-18,25-1-19,26-3-19,6-6-19,26-7-19,3-9-19,24-10-19,18-11-19,30-12-19,4-2-20,5-2-20,6-5-20,2-6-20,25-8-20,29-10-20,19-12-20,21-1-21,23-3-21,30-6-21,19-10-21,28-12-21,31-3-22,5-7-22,26-8-22,26-9-22,3-11-22,1-12-22,2-1-23,7-2-23,16-3-23,25-4-23,5-6-23,31-7-23,10-10-23,2-12-23,27-1-24\n",
      "\n",
      "9-10-15,12-11-15,11-1-15,9-1-16,6-2-16,7-3-16,9-4-16,30-4-16,14-5-16,22-6-16,26-7-16,20-8-16,6-10-16,7-11-16,9-12-16,23-1-17,20-2-17,30-3-17,28-4-17,10-6-17,4-7-17,1-8-17,30-8-17,4-10-17,27-11-17,26-12-17,1-2-18,7-3-18,11-4-18,22-5-18,25-6-18,9-8-18,13-9-18,13-10-18,8-11-18,19-12-18,17-1-19,15-2-19,16-2-19,20-4-19,22-5-19,26-6-19,29-7-19,27-8-19,5-10-19,5-11-19,17-12-19,14-1-20,19-2-20,20-3-20,8-5-20,5-6-20,26-9-20,20-10-20,24-11-20,24-12-20,1-2-21,8-3-21,16-4-21,23-6-21,20-7-21,25-8-21,18-9-21,26-10-21,25-11-21,21-12-21,20-1-22,15-2-22,15-3-22,22-4-22,23-5-22,19-7-22,26-8-22,28-9-22,6-12-22,24-1-23,16-3-23,24-4-23,7-6-23,27-7-23,11-9-23,31-10-23,8-1-24\n",
      "\n",
      "26-02-21,06-04-21,01-10-21,26-08-22,14-10-22\n",
      "\n",
      "30-9-14,07-11-14,2-12-14,6-1-15,5-2-15,7-3-15,7-4-15,9-5-15,8-6-15,8-7-15,6-8-15,4-9-15,5-10-15,2-11-15,17-12-15,16-1-16,13-2-16,14-3-16,14-4-6,12-5-16,11-6-16,12-7-16,11-8-16,10-9-16,27-9-16,24-10-16,24-11-16,22-12-16,21-1-17,21-2-17,23-3-17,22-4-17,22-5-17,24-6-17,27-7-17,26-8-17,25-9-17,25-10-17,23-11-17,23-12-17,23-1-18,20-2-18,26-3-18,24-4-18,24-5-18,6-6-18,5-7-18,4-8-18,18-9-18,16-10-18,15-11-18,17-12-18,15-1-19,16-2-19,18-3-19,16-4-19,16-5-19,15-6-19,16-7-19,14-8-19,12-9-19,14-10-19,12-11-19,16-12-19,15-1-20,15-2-20,16-3-20,24-4-20,18-6-20,21-7-20,28-8-20,28-9-20,20-11-20,21-12-20,4-9-21,11-10-21,1-11-21,3-12-21,10-1-22,11-2-22,11-3-22,15-4-22,15-5-22,18-6-22,20-7-22,26-8-22,13-10-22\n",
      "\n",
      "16-5-20,16-6-20,9-1-21,26-8-22,12-6-23,24-7-23,23-8-23\n",
      "\n",
      "31-05-22,28-06-22,26-08-22,30-09-22,04-11-22,09-12-22\n",
      "\n",
      "30-06-22,04-07-22,29-07-22,05-08-22,19-08-22,26-08-22,11-10-22,13-10-22,11-11-22,07-02-23,24-03-23,23-06-23,14-07-23,28-07-23,15-09-23\n",
      "\n",
      "26-8-2022,24-9-2022,26-10-2022,18-11-2022,21-7-2023,18-8-2023\n",
      "\n",
      "7-6-2019,21-6-2019,22-7-2019,22-8-2019,11-11-2019,9-12-2019,6-1-2020,3-2-2020-27-6-2020,5-3-2021,12-3-2021,20-4-2021,11-5-2021,9-8-2021,22-10-2021,14-2-2022,6-5-2022,26-8-2022,31-10-2022,23-1-2023,7-4-2023,30-6-2023,29-9-2023,1-12-2023,5-2-2024\n",
      "\n",
      "7-8-2022,17-8-2022,26-8-2022,21-9-2022,11-11-2022,18-11-2022,25-11-2022,2-12-2022,9-12-2022,10-1-2023,13-1-2023,19-1-2023,31-1-2023,7-2-2023,24-2-2023,1-4-2023,28-4-2023,30-5-2023,4-7-2023,29-7-2023,31-8-2023,28-9-2023,30-10-2023,25-11-2023,21-12-2023,29-1-2024\n",
      "\n",
      "28-03-22,13-07-22,26-08-22,11-10-22,15-05-23,31-07-23,07-09-23,03-10-23,01-11-23,04-12-23\n",
      "\n",
      "08-06-22,26-08-22,19-12-22,23-01-23,02-11-23\n",
      "\n",
      "28-08-2021,15-07-2022,17-08-2022\n",
      "\n",
      "29-06-2020,21-08-2020,30-08-2020,31-10-2020,03-12-2020,04-01-2021,19-01-2021,02-02-2021,10-03-2021,12-04-2021,28-08-2021,22-10-2021,24-11-2021,07-02-2022,17-02-2022,25-02-2022,07-03-2022,04-04-2022,21-06-2022,24-08-2022,24-09-2022,16-11-2022\n",
      "\n",
      "16-05-2019,14-08-2019,03-02-2020,06-02-2020,19-06-2020,17-07-2020,21-08-2020,19-11-2020,19-12-2020,18-02-2021,27-02-2021,28-08-2021,29-10-2021,28-12-2021,21-03-2022,25-05-2022,02-07-2022,13-08-2022,13-09-2022,12-10-2022,12-11-2022,13-12-2022,12-01-2023,08-02-2023,05-08-2023\n",
      "\n",
      "16-5-2018,15-6-2018,16-7-2018,16-8-2018,15-09-2018,15-11-2018,5-3-2019,3-4-2019,2-5-2019,27-5-2019,27-6-2019,27-7-2019,27-8-2019,31-8-2019,13-9-2019,26-10-2019,301-11-2019,27-12-2019,27-1-2020,29-2-2020,22-4-2020,16-12-2020,3-5-2022,19-5-2022,17-6-2022,16-7-2022,9-8-2022,3-9-2022,3-10-2022,2-11-2022,6-12-2022,4-1-2023,9-2-2023,9-3-2023,3-4-2023,24-4-2023,5-6-2023,4-7-2023,7-8-2023,6-9-2023,5-10-2023,4-11-2023,4-12-2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in df2['frequency of follow up at lgb (to write down follow-up dates)']:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "06ced5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>District</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>No of relapses/exacerbations</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Final</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>frequency of follow up at lgb (to write down follow-up dates)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "      <th>total_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>22-06-2020,30-09-2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>6.6</td>\n",
       "      <td>480</td>\n",
       "      <td>3495</td>\n",
       "      <td>10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>110.0</td>\n",
       "      <td>morigaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>330</td>\n",
       "      <td>Poor</td>\n",
       "      <td>3.8</td>\n",
       "      <td>113</td>\n",
       "      <td>576</td>\n",
       "      <td>08-06-22,26-08-22,19-12-22,23-01-23,02-11-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>326.0</td>\n",
       "      <td>Dhubri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180</td>\n",
       "      <td>Poor</td>\n",
       "      <td>4.3</td>\n",
       "      <td>170</td>\n",
       "      <td>384</td>\n",
       "      <td>28-08-2021,15-07-2022,17-08-2022</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-5-2018,15-6-2018,16-7-2018,16-8-2018,15-09-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "1                             8.0                   10.0    female     Islam   \n",
       "2                            17.0                   18.0    female     Islam   \n",
       "3                             7.0                   17.0      male     Islam   \n",
       "4                            10.0                   10.0      male  Hinduism   \n",
       "5                             8.0                   15.0    female     Islam   \n",
       "..                            ...                    ...       ...       ...   \n",
       "164                          16.0                   17.0      male     Islam   \n",
       "186                          15.0                   15.0      male     Islam   \n",
       "187                          15.0                   17.0      male     Islam   \n",
       "191                           5.0                    8.0      male  Hinduism   \n",
       "75                            NaN                    NaN       NaN       NaN   \n",
       "\n",
       "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "1                                                  NaN                                         \n",
       "2                                              Primary                                         \n",
       "3                                                  NaN                                         \n",
       "4                                              primary                                         \n",
       "5                                  no formal education                                         \n",
       "..                                                 ...                                         \n",
       "164                                            primary                                         \n",
       "186                                        high school                                         \n",
       "187                                        high school                                         \n",
       "191                                            primary                                         \n",
       "75                                                 NaN                                         \n",
       "\n",
       "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "1                      NaN       Rural                           62.0   \n",
       "2                  Primary       Rural                           55.0   \n",
       "3                      NaN       Rural                          102.0   \n",
       "4                  Primary       Rural                           29.0   \n",
       "5      no formal education       Rural                          102.0   \n",
       "..                     ...         ...                            ...   \n",
       "164                primary       Rural                          110.0   \n",
       "186            high school       Rural                          326.0   \n",
       "187            high school       Rural                           37.0   \n",
       "191                primary       Rural                           63.0   \n",
       "75                     NaN         NaN                            NaN   \n",
       "\n",
       "     District  State  ... No of relapses/exacerbations  \\\n",
       "1    Udalguri  Assam  ...                          6.0   \n",
       "2      Nagaon  Assam  ...                          0.0   \n",
       "3      Nagaon  Assam  ...                          6.0   \n",
       "4    Sonitpur  Assam  ...                          1.0   \n",
       "5      Nagaon  Assam  ...                         33.0   \n",
       "..        ...    ...  ...                          ...   \n",
       "164  morigaon  Assam  ...                          2.0   \n",
       "186    Dhubri  Assam  ...                          1.0   \n",
       "187    Nagaon  Assam  ...                          0.0   \n",
       "191    Nagaon  Assam  ...                          0.0   \n",
       "75        NaN    NaN  ...                          NaN   \n",
       "\n",
       "     Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "1                                                   22                             \n",
       "2                                                   30                             \n",
       "3                                                   58                             \n",
       "4                                                   20                             \n",
       "5                                                   65                             \n",
       "..                                                 ...                             \n",
       "164                                                330                             \n",
       "186                                                180                             \n",
       "187                                                120                             \n",
       "191                                                  0                             \n",
       "75                                                 NaN                             \n",
       "\n",
       "            Final  \\\n",
       "1    Satisfactory   \n",
       "2            Poor   \n",
       "3            Good   \n",
       "4            Good   \n",
       "5    Satisfactory   \n",
       "..            ...   \n",
       "164          Poor   \n",
       "186          Poor   \n",
       "187  Satisfactory   \n",
       "191  Satisfactory   \n",
       "75            NaN   \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "5                                                  6.6                                    \n",
       "..                                                 ...                                    \n",
       "164                                                3.8                                    \n",
       "186                                                4.3                                    \n",
       "187                                               1.21                                    \n",
       "191                                               2.15                                    \n",
       "75                                                 NaN                                    \n",
       "\n",
       "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "1                                                  395                                  \n",
       "2                                                  240                                  \n",
       "3                                                  NaN                                  \n",
       "4                                                   90                                  \n",
       "5                                                  480                                  \n",
       "..                                                 ...                                  \n",
       "164                                                113                                  \n",
       "186                                                170                                  \n",
       "187                                                390                                  \n",
       "191                                               1619                                  \n",
       "75                                                 NaN                                  \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "5                                                 3495                                                   \n",
       "..                                                 ...                                                   \n",
       "164                                                576                                                   \n",
       "186                                                384                                                   \n",
       "187                                                875                                                   \n",
       "191                                               1619                                                   \n",
       "75                                                 NaN                                                   \n",
       "\n",
       "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
       "1    24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...              \n",
       "2    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
       "3    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
       "4                                22-06-2020,30-09-2020              \n",
       "5    10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...              \n",
       "..                                                 ...              \n",
       "164       08-06-22,26-08-22,19-12-22,23-01-23,02-11-23              \n",
       "186                   28-08-2021,15-07-2022,17-08-2022              \n",
       "187  29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...              \n",
       "191  16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...              \n",
       "75   16-5-2018,15-6-2018,16-7-2018,16-8-2018,15-09-...              \n",
       "\n",
       "    total number of follow up at LGBRIMH Number of In patient cares  \\\n",
       "1                                   12.0                        0.0   \n",
       "2                                    4.0                        0.0   \n",
       "3                                   69.0                        0.0   \n",
       "4                                    2.0                        1.0   \n",
       "5                                   71.0                        0.0   \n",
       "..                                   ...                        ...   \n",
       "164                                  5.0                        0.0   \n",
       "186                                  3.0                        0.0   \n",
       "187                                 24.0                        0.0   \n",
       "191                                 25.0                        0.0   \n",
       "75                                   NaN                        NaN   \n",
       "\n",
       "    total_frequency  \n",
       "1              12.0  \n",
       "2               4.0  \n",
       "3              67.0  \n",
       "4               2.0  \n",
       "5              70.0  \n",
       "..              ...  \n",
       "164             5.0  \n",
       "186             3.0  \n",
       "187            22.0  \n",
       "191            25.0  \n",
       "75              NaN  \n",
       "\n",
       "[149 rows x 265 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "12245901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['total_days1'] = day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fd22d298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>District</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Final</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>frequency of follow up at lgb (to write down follow-up dates)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "      <th>total_frequency</th>\n",
       "      <th>total_days1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>22-06-2020,30-09-2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>6.6</td>\n",
       "      <td>480</td>\n",
       "      <td>3495</td>\n",
       "      <td>10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>110.0</td>\n",
       "      <td>morigaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>330</td>\n",
       "      <td>Poor</td>\n",
       "      <td>3.8</td>\n",
       "      <td>113</td>\n",
       "      <td>576</td>\n",
       "      <td>08-06-22,26-08-22,19-12-22,23-01-23,02-11-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>326.0</td>\n",
       "      <td>Dhubri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>Poor</td>\n",
       "      <td>4.3</td>\n",
       "      <td>170</td>\n",
       "      <td>384</td>\n",
       "      <td>28-08-2021,15-07-2022,17-08-2022</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-5-2018,15-6-2018,16-7-2018,16-8-2018,15-09-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "1                             8.0                   10.0    female     Islam   \n",
       "2                            17.0                   18.0    female     Islam   \n",
       "3                             7.0                   17.0      male     Islam   \n",
       "4                            10.0                   10.0      male  Hinduism   \n",
       "5                             8.0                   15.0    female     Islam   \n",
       "..                            ...                    ...       ...       ...   \n",
       "164                          16.0                   17.0      male     Islam   \n",
       "186                          15.0                   15.0      male     Islam   \n",
       "187                          15.0                   17.0      male     Islam   \n",
       "191                           5.0                    8.0      male  Hinduism   \n",
       "75                            NaN                    NaN       NaN       NaN   \n",
       "\n",
       "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "1                                                  NaN                                         \n",
       "2                                              Primary                                         \n",
       "3                                                  NaN                                         \n",
       "4                                              primary                                         \n",
       "5                                  no formal education                                         \n",
       "..                                                 ...                                         \n",
       "164                                            primary                                         \n",
       "186                                        high school                                         \n",
       "187                                        high school                                         \n",
       "191                                            primary                                         \n",
       "75                                                 NaN                                         \n",
       "\n",
       "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "1                      NaN       Rural                           62.0   \n",
       "2                  Primary       Rural                           55.0   \n",
       "3                      NaN       Rural                          102.0   \n",
       "4                  Primary       Rural                           29.0   \n",
       "5      no formal education       Rural                          102.0   \n",
       "..                     ...         ...                            ...   \n",
       "164                primary       Rural                          110.0   \n",
       "186            high school       Rural                          326.0   \n",
       "187            high school       Rural                           37.0   \n",
       "191                primary       Rural                           63.0   \n",
       "75                     NaN         NaN                            NaN   \n",
       "\n",
       "     District  State  ...  \\\n",
       "1    Udalguri  Assam  ...   \n",
       "2      Nagaon  Assam  ...   \n",
       "3      Nagaon  Assam  ...   \n",
       "4    Sonitpur  Assam  ...   \n",
       "5      Nagaon  Assam  ...   \n",
       "..        ...    ...  ...   \n",
       "164  morigaon  Assam  ...   \n",
       "186    Dhubri  Assam  ...   \n",
       "187    Nagaon  Assam  ...   \n",
       "191    Nagaon  Assam  ...   \n",
       "75        NaN    NaN  ...   \n",
       "\n",
       "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "1                                                   22                            \n",
       "2                                                   30                            \n",
       "3                                                   58                            \n",
       "4                                                   20                            \n",
       "5                                                   65                            \n",
       "..                                                 ...                            \n",
       "164                                                330                            \n",
       "186                                                180                            \n",
       "187                                                120                            \n",
       "191                                                  0                            \n",
       "75                                                 NaN                            \n",
       "\n",
       "            Final  \\\n",
       "1    Satisfactory   \n",
       "2            Poor   \n",
       "3            Good   \n",
       "4            Good   \n",
       "5    Satisfactory   \n",
       "..            ...   \n",
       "164          Poor   \n",
       "186          Poor   \n",
       "187  Satisfactory   \n",
       "191  Satisfactory   \n",
       "75            NaN   \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "5                                                  6.6                                    \n",
       "..                                                 ...                                    \n",
       "164                                                3.8                                    \n",
       "186                                                4.3                                    \n",
       "187                                               1.21                                    \n",
       "191                                               2.15                                    \n",
       "75                                                 NaN                                    \n",
       "\n",
       "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "1                                                  395                                  \n",
       "2                                                  240                                  \n",
       "3                                                  NaN                                  \n",
       "4                                                   90                                  \n",
       "5                                                  480                                  \n",
       "..                                                 ...                                  \n",
       "164                                                113                                  \n",
       "186                                                170                                  \n",
       "187                                                390                                  \n",
       "191                                               1619                                  \n",
       "75                                                 NaN                                  \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "5                                                 3495                                                   \n",
       "..                                                 ...                                                   \n",
       "164                                                576                                                   \n",
       "186                                                384                                                   \n",
       "187                                                875                                                   \n",
       "191                                               1619                                                   \n",
       "75                                                 NaN                                                   \n",
       "\n",
       "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
       "1    24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...              \n",
       "2    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
       "3    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
       "4                                22-06-2020,30-09-2020              \n",
       "5    10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...              \n",
       "..                                                 ...              \n",
       "164       08-06-22,26-08-22,19-12-22,23-01-23,02-11-23              \n",
       "186                   28-08-2021,15-07-2022,17-08-2022              \n",
       "187  29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...              \n",
       "191  16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...              \n",
       "75   16-5-2018,15-6-2018,16-7-2018,16-8-2018,15-09-...              \n",
       "\n",
       "    total number of follow up at LGBRIMH Number of In patient cares  \\\n",
       "1                                   12.0                        0.0   \n",
       "2                                    4.0                        0.0   \n",
       "3                                   69.0                        0.0   \n",
       "4                                    2.0                        1.0   \n",
       "5                                   71.0                        0.0   \n",
       "..                                   ...                        ...   \n",
       "164                                  5.0                        0.0   \n",
       "186                                  3.0                        0.0   \n",
       "187                                 24.0                        0.0   \n",
       "191                                 25.0                        0.0   \n",
       "75                                   NaN                        NaN   \n",
       "\n",
       "    total_frequency total_days1  \n",
       "1              12.0         577  \n",
       "2               4.0        3547  \n",
       "3              67.0        3547  \n",
       "4               2.0         100  \n",
       "5              70.0        3804  \n",
       "..              ...         ...  \n",
       "164             5.0         512  \n",
       "186             3.0         354  \n",
       "187            22.0         870  \n",
       "191            25.0        1542  \n",
       "75              NaN        2028  \n",
       "\n",
       "[149 rows x 266 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "afea5bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel('df2_original.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0b05f71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)                                                                                                        16.0\n",
      "Age at last follow up                                                                                                               17.0\n",
      "Sex (m/f)                                                                                                                           male\n",
      "Religion                                                                                                                           Islam\n",
      "Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)                                         primary\n",
      "                                                                                                                ...                     \n",
      "frequency of follow up at lgb (to write down follow-up dates)                               08-06-22,26-08-22,19-12-22,23-01-23,02-11-23\n",
      "total number of follow up at LGBRIMH                                                                                                 5.0\n",
      "Number of In patient cares                                                                                                           0.0\n",
      "total_frequency                                                                                                                      5.0\n",
      "total_days1                                                                                                                          512\n",
      "Name: 164, Length: 266, dtype: object\n"
     ]
    }
   ],
   "source": [
    "row_at_150 = df2.loc[164]\n",
    "print(row_at_150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b5a3d2e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['total_days'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [153], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming df2 is your DataFrame\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# df2 = ...\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Drop the 'total_days' column\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_days\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# If you want to modify the DataFrame in-place, you can use the 'inplace' parameter\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# df2.drop('total_days', axis=1, inplace=True)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5388\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5240\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5249\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5251\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5386\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5390\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5394\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5395\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5396\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6975\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6975\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6976\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['total_days'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df2 = df2.drop('total_days', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cdf859dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 149 entries, 1 to 75\n",
      "Columns: 266 entries, Age at presentation (in yrs) to total_days1\n",
      "dtypes: float64(8), int64(1), object(257)\n",
      "memory usage: 314.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d11168ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age at presentation (in yrs)', 'Age at last follow up', 'Sex (m/f)',\n",
      "       'Religion',\n",
      "       'Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)',\n",
      "       'Max education attained', 'Rural/Urban',\n",
      "       'Distance from LGBRIMH (in KM)', 'District', 'State',\n",
      "       ...\n",
      "       'Off-medications duration (to add all such durations over follow-up in days)',\n",
      "       'Final',\n",
      "       'mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)',\n",
      "       'maximum period of compliance at lgb (in days) (longest streak of good compliance)',\n",
      "       'total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)',\n",
      "       'frequency of follow up at lgb (to write down follow-up dates)',\n",
      "       'total number of follow up at LGBRIMH', 'Number of In patient cares',\n",
      "       'total_frequency', 'total_days1'],\n",
      "      dtype='object', length=266)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "column_names = df2.columns\n",
    "print(column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e657bd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)\n",
      "Age at last follow up\n",
      "Sex (m/f)\n",
      "Religion\n",
      "Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)\n",
      "Max education attained\n",
      "Rural/Urban\n",
      "Distance from LGBRIMH (in KM)\n",
      "District\n",
      "State\n",
      "Socioeconomic status\n",
      "Age at onset(in years)\n",
      "Chief complaint 1\n",
      "Chief complaint 2\n",
      "Chief complaint 3\n",
      "Time period between onset to first consultation at LGBRIMH (DUI) (in days)\n",
      "Type of Family (Nuclear/Joint/single parent/orphan/ foster family\n",
      "Family environment\n",
      "Details of family abnormality (describe)\n",
      "Family h/o stillbirth/abortion\n",
      "Family history(general medical)\n",
      "Family history (psychiatric/neurological)\n",
      "Faith healer visited before consultation or not(yes/no)\n",
      "Antenatal risk factor\n",
      "Place of delivery (Home/hospital)\n",
      "Birth weight(in kg)\n",
      "Neonatal complication\n",
      "Postnatal complication\n",
      "Developmental history\n",
      "Age of school entry(in years)\n",
      "Type of school\n",
      "School adjustment\n",
      "Academic performance\n",
      "School dropout present (yes/no)\n",
      "Detail of past psychiatric history 1\n",
      "Past treatment 1\n",
      "Past treatment medication 1\n",
      "Starting dose past medication 1\n",
      "Age of starting of past medication 1(in years)\n",
      "Past maintenance dose1 (in mg)\n",
      "Side effects of past medication 1\n",
      "Age of occurance past side effects 1(in years)\n",
      "Duration of past side effect 1(in months)\n",
      "Response to past medication 1\n",
      "Detail of past history 2\n",
      "Past treatment 2\n",
      "Past treatment medication 2\n",
      "Starting dose past medication 2\n",
      "Age of starting of past medication 2(in years)\n",
      "Past maintenance dose2\n",
      "Side effects of past medication 2\n",
      "Age of occurance past side effects 2(in years)\n",
      "Duration of past side effect 2(in months)\n",
      "Response to past medication 2\n",
      "Detail of past history 3\n",
      "Past treatment  3\n",
      "Past treatment medication 3\n",
      "Starting dose past medication 3 \n",
      "Age of starting past medication 3 (in years)\n",
      "Past maintenance dose 3\n",
      "Side effects past medication 3\n",
      "Age of occurance of past side effects 3 (in years)\n",
      "Duration of past side effects 3 (in months)\n",
      "Response to past medication 3\n",
      "Change in doctor\n",
      "Past/Current medical conditions\n",
      "Age of onset of medical conditions (in years)\n",
      "Details of medical conditions\n",
      "Treatments for medical conditions\n",
      "Severity of medical conditions\n",
      "weight (in Kg)\n",
      "weight z score\n",
      "height (in cm)\n",
      "height z score\n",
      "head circumference (in cm)\n",
      "head circumference z score\n",
      "systemic examination(abnormal/normal)\n",
      "systemic examination details (main finding only)\n",
      "Mental status examination/Behavioral Observation details (abnormal/normal)\n",
      "Mental status examination/Behavioral observation details (main finding only in description)\n",
      "Screening diagnosis \n",
      "detailed workup diagnosis\n",
      "Follow up diagnosis changed or not (yes/no)\n",
      "If yes, changed once or multiple times (once/multiple)\n",
      "If yes, after how many days from first presentation diagnosis changed (in days)\n",
      "If yes, diagnosis changed to what\n",
      "Axis 1_1\n",
      "Axis 1_2\n",
      "Axis 1_3\n",
      "Axis 1_4\n",
      "Axis 2\n",
      "Axis 3\n",
      "Axis 4_1\n",
      "Axis 4_2\n",
      "Axis 4_3\n",
      "Axis 5\n",
      "significant psychosocial stressor\n",
      "name of Medication 1\n",
      "medication 1 starting dose (in mg)\n",
      "Avg dose of medication 1 (Mode value of medication) (in mg)\n",
      "Maximum dose of medication 1 (in mg)\n",
      "Total duration of medication 1 (in days) \n",
      "Continued medication 1/stopped/changed\n",
      "Response to medication 1 (Good/partial/no)\n",
      "Side effect of medication 1\n",
      "onset of side effect post starting med 1 ( in days)\n",
      "total duration of side effect of medication 1 (in days)\n",
      "Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) \n",
      "name of Medication 2\n",
      "Medication 2 starting dose (in mg)\n",
      "Avg dose of medication 2 (in mg)\n",
      "Maximum dose of medication 2 (in mg)\n",
      "Total duration of medication 2(in days) \n",
      "Continued medication 2/stopped/changed\n",
      "Response to medication 2 (Good/partial/no)\n",
      "Side effect of medication 2\n",
      "onset of side effect post starting med 2 ( in days)\n",
      "total duration of side effect of medication 2 (in days)\n",
      "Medication possession ratios 2(MPRs) in lgb;x-syrup\n",
      "name of Medication 3\n",
      "Medication 3 starting dose (in mg)\n",
      "Avg dose of medication 3 (in mg)\n",
      "Maximum dose of medication 3 (in mg)\n",
      "Total duration of medication 3 (in days\n",
      "continued medication 3/stopped/changed\n",
      "Response to medication 3 (Good/partial/no)\n",
      "Side effect of medication 3\n",
      "onset of side effect post starting med 3 ( in days)\n",
      "total duration of side effect of medication 3 (in days)\n",
      "Medication possession ratios 3(MPRs) in lgb;x-syrup\n",
      "name of Medication 4\n",
      "Medication 4 starting dose (in mg)\n",
      "Avg dose of medication 4 (in mg)\n",
      "Maximum dose of medication 4 (in mg)\n",
      "Total duration of medication 4 (in days)\n",
      "continued medication 4/stopped/changed\n",
      "Response to medication 4(Good/partial/no)\n",
      "Side effect of medication 4\n",
      "onset of side effect post starting med 4 ( in days)\n",
      "total duration of side effect of medication 4 (in days)\n",
      "Medication possession ratios 4(MPRs) in lgb;x-syrup\n",
      "name of Medication 5\n",
      "Medication 5 starting dose (in mg)\n",
      "Avg dose of medication 5 (in mg)\n",
      "Maximum dose of medication 5(in mg)\n",
      "Total duration of medication 5 (in days)\n",
      "continued medication 5/stopped/changed\n",
      "Response to medication 5(Good/partial/no)\n",
      "Side effect of medication 5\n",
      "onset of side effect post starting med 5 ( in days)\n",
      "total duration of side effect of medication 5 (in days)\n",
      "Medication possession ratios 5(MPRs) in lgb;x-syrup\n",
      "name of Medication 6\n",
      "Medication 6 starting dose\n",
      "Avg dose of medication 6\n",
      "Maximum dose of medication 6\n",
      "Total duration of medication 6\n",
      "continued medication 6/stopped/changed\n",
      "Response to medication 6(Good/partial/no)\n",
      "Side effect of medication 6\n",
      "onset of side effect post starting med 6 ( in days)\n",
      "total duration of side effect of medication 6 (in days)\n",
      "Medication possession ratios 6(MPRs) in lgb;x-syrup\n",
      "name of Medication 7\n",
      "Medication 7 starting dose\n",
      "Avg dose of medication 7\n",
      "Maximum dose of medication 7\n",
      "Total duration of medication 7\n",
      "continued medication 7/stopped/changed\n",
      "Response to medication 7(Good/partial/no)\n",
      "Side effect of medication 7\n",
      "onset of side effect post starting med 7 ( in days)\n",
      "total duration of side effect of medication 7 (in days)\n",
      "Medication possession ratios 7(MPRs) in lgb;x-syrup\n",
      "name of Medication 8\n",
      "Medication 8 starting dose\n",
      "Avg dose of medication 8\n",
      "Maximum dose of medication 8\n",
      "Total duration of medication 8\n",
      "Continued medication 8/stopped/changed\n",
      "Response to medication 8(Good/partial/no)\n",
      "Side effect of medication 8\n",
      "onset of side effect post starting med 8 ( in days)\n",
      "total duration of side effect of medication 8 (in days)\n",
      "Medication possession ratios 8(MPRs) in lgb;x-syrup\n",
      "name of Medication 9\n",
      "Medication 9 starting dose\n",
      "Avg dose of medication 9\n",
      "Maximum dose of medication 9\n",
      "Total duration of medication 9\n",
      "continued medication 9/stopped/changed\n",
      "Response to medication 9(Good/partial/no)\n",
      "Side effect of medication 9\n",
      "onset of side effect post starting med 9 ( in days)\n",
      "total duration of side effect of medication 9 (in days)\n",
      "Medication possession ratios 9(MPRs) in lgb;x-syrup\n",
      "name of Medication 10\n",
      "Medication 10 starting dose\n",
      "Avg dose of medication 10\n",
      "Maximum dose of medication 10\n",
      "Total duration of medication 10\n",
      "continued medication 10/stopped/changed\n",
      "Response to medication 10(Good/partial/no)\n",
      "Side effect of medication 10\n",
      "onset of side effect post starting med 10 ( in days)\n",
      "total duration of side effect of medication 10 (in days)\n",
      "Medication possession ratios 10(MPRs) in lgb;x-syrup\n",
      "name of Medication 11\n",
      "Medication 11 starting dose\n",
      "Avg dose of medication 11\n",
      "Maximum dose of medication 11\n",
      "Total duration of medication 11\n",
      "continued medication 11/stopped/changed\n",
      "Response to medication 11(Good/partial/no)\n",
      "Side effect of medication 11\n",
      "onset of side effect post starting med 11 ( in days)\n",
      "total duration of side effect of medication 11 (in days)\n",
      "Medication possession ratios 11(MPRs) in lgb;x-syrup\n",
      "name of Medication 12\n",
      "Medication 12 starting dose\n",
      "Avg dose of medication 12\n",
      "Maximum dose of medication 12\n",
      "Total duration of medication 12\n",
      "continued medication 12/stopped/changed\n",
      "Response to medication 12(Good/partial/no)\n",
      "Side effect of medication 12\n",
      "onset of side effect post starting med 12 ( in days)\n",
      "total duration of side effect of medication 12 (in days)\n",
      "Medication possession ratios 12(MPRs) in lgb;x-syrup\n",
      "name of Medication 13\n",
      "Medication 13 starting dose\n",
      "Avg dose of medication 13\n",
      "Maximum dose of medication 13\n",
      "Total duration of medication 13\n",
      "continued medication 13/stopped/changed\n",
      "Response to medication 13(Good/partial/no)\n",
      "Side effect of medication 13\n",
      "onset of side effect post starting med 13 ( in days)\n",
      "total duration of side effect of medication 13 (in days)\n",
      "Medication possession ratios 13(MPRs) in lgb;x-syrup\n",
      "name of Medication 14\n",
      "Medication 14 starting dose\n",
      "Avg dose of medication 14\n",
      "Maximum dose of medication 14\n",
      "Total duration of medication 14\n",
      "continued medication 14/stopped/changed\n",
      "Response to medication 14(Good/partial/no)\n",
      "Side effect of medication 14\n",
      "onset of side effect post starting med 14 ( in days)\n",
      "total duration of side effect of medication 14 (in days)\n",
      "Medication possession ratios 14(MPRs) in lgb;x-syrup\n",
      "cost of medication\n",
      "Other treatments(rehabilitative intervention/IT/CBT/ipt/FT/PMT/BEHAVIOURAL INTERVENTIONS FOR DEVELOPMENTAL DISORDERS, Combination therapy)\n",
      "Maximum duration of symptom free period (in days)\n",
      "Max Duration of resolution of symptoms before recurrence/relapse (in days)\n",
      "No of relapses/exacerbations\n",
      "Off-medications duration (to add all such durations over follow-up in days)\n",
      "Final\n",
      "mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)\n",
      "maximum period of compliance at lgb (in days) (longest streak of good compliance)\n",
      "total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)\n",
      "frequency of follow up at lgb (to write down follow-up dates)\n",
      "total number of follow up at LGBRIMH\n",
      "Number of In patient cares\n",
      "total_frequency\n",
      "total_days1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "column_names = df2.columns.tolist()\n",
    "for name in column_names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6bc7dccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>District</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Final</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>frequency of follow up at lgb (to write down follow-up dates)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "      <th>total_frequency</th>\n",
       "      <th>total_days1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>22-06-2020,30-09-2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>6.6</td>\n",
       "      <td>480</td>\n",
       "      <td>3495</td>\n",
       "      <td>10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>110.0</td>\n",
       "      <td>morigaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>330</td>\n",
       "      <td>Poor</td>\n",
       "      <td>3.8</td>\n",
       "      <td>113</td>\n",
       "      <td>576</td>\n",
       "      <td>08-06-22,26-08-22,19-12-22,23-01-23,02-11-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>326.0</td>\n",
       "      <td>Dhubri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>Poor</td>\n",
       "      <td>4.3</td>\n",
       "      <td>170</td>\n",
       "      <td>384</td>\n",
       "      <td>28-08-2021,15-07-2022,17-08-2022</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-5-2018,15-6-2018,16-7-2018,16-8-2018,15-09-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "1                             8.0                   10.0    female     Islam   \n",
       "2                            17.0                   18.0    female     Islam   \n",
       "3                             7.0                   17.0      male     Islam   \n",
       "4                            10.0                   10.0      male  Hinduism   \n",
       "5                             8.0                   15.0    female     Islam   \n",
       "..                            ...                    ...       ...       ...   \n",
       "164                          16.0                   17.0      male     Islam   \n",
       "186                          15.0                   15.0      male     Islam   \n",
       "187                          15.0                   17.0      male     Islam   \n",
       "191                           5.0                    8.0      male  Hinduism   \n",
       "75                            NaN                    NaN       NaN       NaN   \n",
       "\n",
       "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "1                                                  NaN                                         \n",
       "2                                              Primary                                         \n",
       "3                                                  NaN                                         \n",
       "4                                              primary                                         \n",
       "5                                  no formal education                                         \n",
       "..                                                 ...                                         \n",
       "164                                            primary                                         \n",
       "186                                        high school                                         \n",
       "187                                        high school                                         \n",
       "191                                            primary                                         \n",
       "75                                                 NaN                                         \n",
       "\n",
       "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "1                      NaN       Rural                           62.0   \n",
       "2                  Primary       Rural                           55.0   \n",
       "3                      NaN       Rural                          102.0   \n",
       "4                  Primary       Rural                           29.0   \n",
       "5      no formal education       Rural                          102.0   \n",
       "..                     ...         ...                            ...   \n",
       "164                primary       Rural                          110.0   \n",
       "186            high school       Rural                          326.0   \n",
       "187            high school       Rural                           37.0   \n",
       "191                primary       Rural                           63.0   \n",
       "75                     NaN         NaN                            NaN   \n",
       "\n",
       "     District  State  ...  \\\n",
       "1    Udalguri  Assam  ...   \n",
       "2      Nagaon  Assam  ...   \n",
       "3      Nagaon  Assam  ...   \n",
       "4    Sonitpur  Assam  ...   \n",
       "5      Nagaon  Assam  ...   \n",
       "..        ...    ...  ...   \n",
       "164  morigaon  Assam  ...   \n",
       "186    Dhubri  Assam  ...   \n",
       "187    Nagaon  Assam  ...   \n",
       "191    Nagaon  Assam  ...   \n",
       "75        NaN    NaN  ...   \n",
       "\n",
       "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "1                                                   22                            \n",
       "2                                                   30                            \n",
       "3                                                   58                            \n",
       "4                                                   20                            \n",
       "5                                                   65                            \n",
       "..                                                 ...                            \n",
       "164                                                330                            \n",
       "186                                                180                            \n",
       "187                                                120                            \n",
       "191                                                  0                            \n",
       "75                                                 NaN                            \n",
       "\n",
       "            Final  \\\n",
       "1    Satisfactory   \n",
       "2            Poor   \n",
       "3            Good   \n",
       "4            Good   \n",
       "5    Satisfactory   \n",
       "..            ...   \n",
       "164          Poor   \n",
       "186          Poor   \n",
       "187  Satisfactory   \n",
       "191  Satisfactory   \n",
       "75            NaN   \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "5                                                  6.6                                    \n",
       "..                                                 ...                                    \n",
       "164                                                3.8                                    \n",
       "186                                                4.3                                    \n",
       "187                                               1.21                                    \n",
       "191                                               2.15                                    \n",
       "75                                                 NaN                                    \n",
       "\n",
       "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "1                                                  395                                  \n",
       "2                                                  240                                  \n",
       "3                                                  NaN                                  \n",
       "4                                                   90                                  \n",
       "5                                                  480                                  \n",
       "..                                                 ...                                  \n",
       "164                                                113                                  \n",
       "186                                                170                                  \n",
       "187                                                390                                  \n",
       "191                                               1619                                  \n",
       "75                                                 NaN                                  \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "5                                                 3495                                                   \n",
       "..                                                 ...                                                   \n",
       "164                                                576                                                   \n",
       "186                                                384                                                   \n",
       "187                                                875                                                   \n",
       "191                                               1619                                                   \n",
       "75                                                 NaN                                                   \n",
       "\n",
       "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
       "1    24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...              \n",
       "2    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
       "3    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
       "4                                22-06-2020,30-09-2020              \n",
       "5    10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...              \n",
       "..                                                 ...              \n",
       "164       08-06-22,26-08-22,19-12-22,23-01-23,02-11-23              \n",
       "186                   28-08-2021,15-07-2022,17-08-2022              \n",
       "187  29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...              \n",
       "191  16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...              \n",
       "75   16-5-2018,15-6-2018,16-7-2018,16-8-2018,15-09-...              \n",
       "\n",
       "    total number of follow up at LGBRIMH Number of In patient cares  \\\n",
       "1                                   12.0                        0.0   \n",
       "2                                    4.0                        0.0   \n",
       "3                                   69.0                        0.0   \n",
       "4                                    2.0                        1.0   \n",
       "5                                   71.0                        0.0   \n",
       "..                                   ...                        ...   \n",
       "164                                  5.0                        0.0   \n",
       "186                                  3.0                        0.0   \n",
       "187                                 24.0                        0.0   \n",
       "191                                 25.0                        0.0   \n",
       "75                                   NaN                        NaN   \n",
       "\n",
       "    total_frequency total_days1  \n",
       "1              12.0         577  \n",
       "2               4.0        3547  \n",
       "3              67.0        3547  \n",
       "4               2.0         100  \n",
       "5              70.0        3804  \n",
       "..              ...         ...  \n",
       "164             5.0         512  \n",
       "186             3.0         354  \n",
       "187            22.0         870  \n",
       "191            25.0        1542  \n",
       "75              NaN        2028  \n",
       "\n",
       "[149 rows x 266 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a7201377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = df2.drop(df2.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8fffef12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>District</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Final</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>frequency of follow up at lgb (to write down follow-up dates)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "      <th>total_frequency</th>\n",
       "      <th>total_days1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>22-06-2020,30-09-2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>6.6</td>\n",
       "      <td>480</td>\n",
       "      <td>3495</td>\n",
       "      <td>10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>Rural</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>2.1</td>\n",
       "      <td>648</td>\n",
       "      <td>648</td>\n",
       "      <td>28-03-22,13-07-22,26-08-22,11-10-22,15-05-23,3...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>110.0</td>\n",
       "      <td>morigaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>330</td>\n",
       "      <td>Poor</td>\n",
       "      <td>3.8</td>\n",
       "      <td>113</td>\n",
       "      <td>576</td>\n",
       "      <td>08-06-22,26-08-22,19-12-22,23-01-23,02-11-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>326.0</td>\n",
       "      <td>Dhubri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>Poor</td>\n",
       "      <td>4.3</td>\n",
       "      <td>170</td>\n",
       "      <td>384</td>\n",
       "      <td>28-08-2021,15-07-2022,17-08-2022</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "1                             8.0                   10.0    female     Islam   \n",
       "2                            17.0                   18.0    female     Islam   \n",
       "3                             7.0                   17.0      male     Islam   \n",
       "4                            10.0                   10.0      male  Hinduism   \n",
       "5                             8.0                   15.0    female     Islam   \n",
       "..                            ...                    ...       ...       ...   \n",
       "163                           7.0                    9.0      male  Hinduism   \n",
       "164                          16.0                   17.0      male     Islam   \n",
       "186                          15.0                   15.0      male     Islam   \n",
       "187                          15.0                   17.0      male     Islam   \n",
       "191                           5.0                    8.0      male  Hinduism   \n",
       "\n",
       "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "1                                                  NaN                                         \n",
       "2                                              Primary                                         \n",
       "3                                                  NaN                                         \n",
       "4                                              primary                                         \n",
       "5                                  no formal education                                         \n",
       "..                                                 ...                                         \n",
       "163                                no formal education                                         \n",
       "164                                            primary                                         \n",
       "186                                        high school                                         \n",
       "187                                        high school                                         \n",
       "191                                            primary                                         \n",
       "\n",
       "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "1                      NaN       Rural                           62.0   \n",
       "2                  Primary       Rural                           55.0   \n",
       "3                      NaN       Rural                          102.0   \n",
       "4                  Primary       Rural                           29.0   \n",
       "5      no formal education       Rural                          102.0   \n",
       "..                     ...         ...                            ...   \n",
       "163    no formal education       Rural                           57.0   \n",
       "164                primary       Rural                          110.0   \n",
       "186            high school       Rural                          326.0   \n",
       "187            high school       Rural                           37.0   \n",
       "191                primary       Rural                           63.0   \n",
       "\n",
       "     District  State  ...  \\\n",
       "1    Udalguri  Assam  ...   \n",
       "2      Nagaon  Assam  ...   \n",
       "3      Nagaon  Assam  ...   \n",
       "4    Sonitpur  Assam  ...   \n",
       "5      Nagaon  Assam  ...   \n",
       "..        ...    ...  ...   \n",
       "163  Sonitpur  Assam  ...   \n",
       "164  morigaon  Assam  ...   \n",
       "186    Dhubri  Assam  ...   \n",
       "187    Nagaon  Assam  ...   \n",
       "191    Nagaon  Assam  ...   \n",
       "\n",
       "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "1                                                   22                            \n",
       "2                                                   30                            \n",
       "3                                                   58                            \n",
       "4                                                   20                            \n",
       "5                                                   65                            \n",
       "..                                                 ...                            \n",
       "163                                                  0                            \n",
       "164                                                330                            \n",
       "186                                                180                            \n",
       "187                                                120                            \n",
       "191                                                  0                            \n",
       "\n",
       "            Final  \\\n",
       "1    Satisfactory   \n",
       "2            Poor   \n",
       "3            Good   \n",
       "4            Good   \n",
       "5    Satisfactory   \n",
       "..            ...   \n",
       "163          Good   \n",
       "164          Poor   \n",
       "186          Poor   \n",
       "187  Satisfactory   \n",
       "191  Satisfactory   \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "5                                                  6.6                                    \n",
       "..                                                 ...                                    \n",
       "163                                                2.1                                    \n",
       "164                                                3.8                                    \n",
       "186                                                4.3                                    \n",
       "187                                               1.21                                    \n",
       "191                                               2.15                                    \n",
       "\n",
       "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "1                                                  395                                  \n",
       "2                                                  240                                  \n",
       "3                                                  NaN                                  \n",
       "4                                                   90                                  \n",
       "5                                                  480                                  \n",
       "..                                                 ...                                  \n",
       "163                                                648                                  \n",
       "164                                                113                                  \n",
       "186                                                170                                  \n",
       "187                                                390                                  \n",
       "191                                               1619                                  \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "5                                                 3495                                                   \n",
       "..                                                 ...                                                   \n",
       "163                                                648                                                   \n",
       "164                                                576                                                   \n",
       "186                                                384                                                   \n",
       "187                                                875                                                   \n",
       "191                                               1619                                                   \n",
       "\n",
       "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
       "1    24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...              \n",
       "2    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
       "3    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
       "4                                22-06-2020,30-09-2020              \n",
       "5    10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...              \n",
       "..                                                 ...              \n",
       "163  28-03-22,13-07-22,26-08-22,11-10-22,15-05-23,3...              \n",
       "164       08-06-22,26-08-22,19-12-22,23-01-23,02-11-23              \n",
       "186                   28-08-2021,15-07-2022,17-08-2022              \n",
       "187  29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...              \n",
       "191  16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...              \n",
       "\n",
       "    total number of follow up at LGBRIMH Number of In patient cares  \\\n",
       "1                                   12.0                        0.0   \n",
       "2                                    4.0                        0.0   \n",
       "3                                   69.0                        0.0   \n",
       "4                                    2.0                        1.0   \n",
       "5                                   71.0                        0.0   \n",
       "..                                   ...                        ...   \n",
       "163                                 10.0                        0.0   \n",
       "164                                  5.0                        0.0   \n",
       "186                                  3.0                        0.0   \n",
       "187                                 24.0                        0.0   \n",
       "191                                 25.0                        0.0   \n",
       "\n",
       "    total_frequency total_days1  \n",
       "1              12.0         577  \n",
       "2               4.0        3547  \n",
       "3              67.0        3547  \n",
       "4               2.0         100  \n",
       "5              70.0        3804  \n",
       "..              ...         ...  \n",
       "163            10.0         616  \n",
       "164             5.0         512  \n",
       "186             3.0         354  \n",
       "187            22.0         870  \n",
       "191            25.0        1542  \n",
       "\n",
       "[148 rows x 266 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c125f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel('df2_original.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4eabe180",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1658201535.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [161], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    17.6.2019,23.7.2019,27.8.2019,24.9.2019,26.10.2019,25.11.2019,26.12.2019,27.1.2020,13.3.2020,23.4.2020,19.5.2020,19.6.2020,22.7.2020,25.7.2020,14.10.2020,17.12.2020,18.1.2021,16.2.2021,19.3.2021,20.4.2021,20.5.2021,1.11.2021,24.11.2021,28.1.2022,8.4.2022,5.5.2022,10.6.2022,13.7.2022,5.9.2022,7.10.2022,10.11.2022,14.12.2022,13.1.2023,13.2.2023,13.3.2023,21.4.2023,23.5.2023,27.6.2023,1.8.2023,31.8.2023,10.10.2023,17.11.2023\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "17.6.2019,23.7.2019,27.8.2019,24.9.2019,26.10.2019,25.11.2019,26.12.2019,27.1.2020,13.3.2020,23.4.2020,19.5.2020,19.6.2020,22.7.2020,25.7.2020,14.10.2020,17.12.2020,18.1.2021,16.2.2021,19.3.2021,20.4.2021,20.5.2021,1.11.2021,24.11.2021,28.1.2022,8.4.2022,5.5.2022,10.6.2022,13.7.2022,5.9.2022,7.10.2022,10.11.2022,14.12.2022,13.1.2023,13.2.2023,13.3.2023,21.4.2023,23.5.2023,27.6.2023,1.8.2023,31.8.2023,10.10.2023,17.11.2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "65bba3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2013,\n",
       " -2015,\n",
       " -2016,\n",
       " -2008,\n",
       " -2011,\n",
       " -2010,\n",
       " -2010,\n",
       " -2007,\n",
       " -2011,\n",
       " -2015,\n",
       " -2007,\n",
       " -2004,\n",
       " -2018,\n",
       " -1994,\n",
       " -1999,\n",
       " -2000,\n",
       " -1995,\n",
       " -1997,\n",
       " -2008,\n",
       " -2027,\n",
       " -2028,\n",
       " -2027,\n",
       " -2029,\n",
       " -2027,\n",
       " -2020,\n",
       " -2022,\n",
       " -2020,\n",
       " -2022,\n",
       " -2020,\n",
       " -2024,\n",
       " -2020,\n",
       " -2014,\n",
       " -2017,\n",
       " -2016,\n",
       " -2008,\n",
       " -2004,\n",
       " -1996,\n",
       " -2015,\n",
       " -2009,\n",
       " -2005,\n",
       " -2008,\n",
       " -2009,\n",
       " -2002,\n",
       " -2004,\n",
       " -2006,\n",
       " -2006,\n",
       " -2006)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16-10-2019,15-11-2019,15-12-2019,13-1-2020,11-2-2020,13-3-2020,15-5-2020,17-4-2020,15-6-2020,13-8-2020,22-9-2020,27-11-2020,4-1-2021,28-1-2021,24-2-2021,24-3-2021,30-4-2021,29-5-2021,19-6-2021,2-8-2021,2-9-2021,4-10-2021,3-11-2021,6-12-2021,3-1-2022,2-2-2022,5-3-2022,4-4-2022,7-5-2022,4-6-2022,9-7-2022,16-8-2022,14-9-2022,16-10-2022,25-11-2022,30-12-2022,28-1-2023,11-3-2023,18-4-2023,23-5-2023,21-6-2023,21-7-2023,29-8-2023,28-9-2023,27-10-2023,28-11-2023,29-12-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0305434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days between 29-12-2023 and 16-10-2019: 1535 days\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def calculate_days_difference(date1_str, date2_str, date_format=\"%d-%m-%Y\"):\n",
    "    date1 = datetime.strptime(date1_str, date_format)\n",
    "    date2 = datetime.strptime(date2_str, date_format)\n",
    "    days_difference = abs((date2 - date1).days)\n",
    "\n",
    "    return days_difference\n",
    "\n",
    "date2_str = \"16-10-2019\"\n",
    "date1_str = \"29-12-2023\"\n",
    "result = calculate_days_difference(date1_str, date2_str)\n",
    "\n",
    "print(f\"Number of days between {date1_str} and {date2_str}: {result} days\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dd071b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days between 17-11-2023 and 17-6-2019: 1614 days\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def calculate_days_difference(date1_str, date2_str, date_format=\"%d-%m-%Y\"):\n",
    "    date1 = datetime.strptime(date1_str, date_format)\n",
    "    date2 = datetime.strptime(date2_str, date_format)\n",
    "    days_difference = abs((date2 - date1).days)\n",
    "\n",
    "    return days_difference\n",
    "\n",
    "date2_str = \"17-6-2019\"\n",
    "date1_str = \"17-11-2023\"\n",
    "result = calculate_days_difference(date1_str, date2_str)\n",
    "\n",
    "print(f\"Number of days between {date1_str} and {date2_str}: {result} days\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e3a5410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)                                                                                                              8.0\n",
      "Age at last follow up                                                                                                                    15.0\n",
      "Sex (m/f)                                                                                                                              female\n",
      "Religion                                                                                                                             Hinduism\n",
      "Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)                                  no formal education\n",
      "                                                                                                                  ...                        \n",
      "frequency of follow up at lgb (to write down follow-up dates)                               17.6.2109,23.7.2019,27.8.2019,24.9.2019,26.10....\n",
      "total number of follow up at LGBRIMH                                                                                                     42.0\n",
      "Number of In patient cares                                                                                                                0.0\n",
      "total_frequency                                                                                                                          42.0\n",
      "total_days1                                                                                                                             34414\n",
      "Name: 93, Length: 266, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "row_93 = df2.loc[93]\n",
    "print(row_93)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1303794f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34414\n"
     ]
    }
   ],
   "source": [
    "print(row_93['total_days1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fa87a6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0    female     Islam   \n",
      "2                            17.0                   18.0    female     Islam   \n",
      "3                             7.0                   17.0      male     Islam   \n",
      "4                            10.0                   10.0      male  Hinduism   \n",
      "5                             8.0                   15.0    female     Islam   \n",
      "..                            ...                    ...       ...       ...   \n",
      "163                           7.0                    9.0      male  Hinduism   \n",
      "164                          16.0                   17.0      male     Islam   \n",
      "186                          15.0                   15.0      male     Islam   \n",
      "187                          15.0                   17.0      male     Islam   \n",
      "191                           5.0                    8.0      male  Hinduism   \n",
      "\n",
      "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
      "1                                                  NaN                                         \n",
      "2                                              Primary                                         \n",
      "3                                                  NaN                                         \n",
      "4                                              primary                                         \n",
      "5                                  no formal education                                         \n",
      "..                                                 ...                                         \n",
      "163                                no formal education                                         \n",
      "164                                            primary                                         \n",
      "186                                        high school                                         \n",
      "187                                        high school                                         \n",
      "191                                            primary                                         \n",
      "\n",
      "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                      NaN       Rural                           62.0   \n",
      "2                  Primary       Rural                           55.0   \n",
      "3                      NaN       Rural                          102.0   \n",
      "4                  Primary       Rural                           29.0   \n",
      "5      no formal education       Rural                          102.0   \n",
      "..                     ...         ...                            ...   \n",
      "163    no formal education       Rural                           57.0   \n",
      "164                primary       Rural                          110.0   \n",
      "186            high school       Rural                          326.0   \n",
      "187            high school       Rural                           37.0   \n",
      "191                primary       Rural                           63.0   \n",
      "\n",
      "     District  State  ...  \\\n",
      "1    Udalguri  Assam  ...   \n",
      "2      Nagaon  Assam  ...   \n",
      "3      Nagaon  Assam  ...   \n",
      "4    Sonitpur  Assam  ...   \n",
      "5      Nagaon  Assam  ...   \n",
      "..        ...    ...  ...   \n",
      "163  Sonitpur  Assam  ...   \n",
      "164  morigaon  Assam  ...   \n",
      "186    Dhubri  Assam  ...   \n",
      "187    Nagaon  Assam  ...   \n",
      "191    Nagaon  Assam  ...   \n",
      "\n",
      "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
      "1                                                   22                            \n",
      "2                                                   30                            \n",
      "3                                                   58                            \n",
      "4                                                   20                            \n",
      "5                                                   65                            \n",
      "..                                                 ...                            \n",
      "163                                                  0                            \n",
      "164                                                330                            \n",
      "186                                                180                            \n",
      "187                                                120                            \n",
      "191                                                  0                            \n",
      "\n",
      "            Final  \\\n",
      "1    Satisfactory   \n",
      "2            Poor   \n",
      "3            Good   \n",
      "4            Good   \n",
      "5    Satisfactory   \n",
      "..            ...   \n",
      "163          Good   \n",
      "164          Poor   \n",
      "186          Poor   \n",
      "187  Satisfactory   \n",
      "191  Satisfactory   \n",
      "\n",
      "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
      "1                                                 1.66                                    \n",
      "2                                                 1.78                                    \n",
      "3                                                  NaN                                    \n",
      "4                                                    1                                    \n",
      "5                                                  6.6                                    \n",
      "..                                                 ...                                    \n",
      "163                                                2.1                                    \n",
      "164                                                3.8                                    \n",
      "186                                                4.3                                    \n",
      "187                                               1.21                                    \n",
      "191                                               2.15                                    \n",
      "\n",
      "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
      "1                                                  395                                  \n",
      "2                                                  240                                  \n",
      "3                                                  NaN                                  \n",
      "4                                                   90                                  \n",
      "5                                                  480                                  \n",
      "..                                                 ...                                  \n",
      "163                                                648                                  \n",
      "164                                                113                                  \n",
      "186                                                170                                  \n",
      "187                                                390                                  \n",
      "191                                               1619                                  \n",
      "\n",
      "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
      "1                                                  626                                                   \n",
      "2                                                  330                                                   \n",
      "3                                                 1320                                                   \n",
      "4                                                   90                                                   \n",
      "5                                                 3495                                                   \n",
      "..                                                 ...                                                   \n",
      "163                                                648                                                   \n",
      "164                                                576                                                   \n",
      "186                                                384                                                   \n",
      "187                                                875                                                   \n",
      "191                                               1619                                                   \n",
      "\n",
      "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
      "1    24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...              \n",
      "2    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
      "3    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
      "4                                22-06-2020,30-09-2020              \n",
      "5    10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...              \n",
      "..                                                 ...              \n",
      "163  28-03-22,13-07-22,26-08-22,11-10-22,15-05-23,3...              \n",
      "164       08-06-22,26-08-22,19-12-22,23-01-23,02-11-23              \n",
      "186                   28-08-2021,15-07-2022,17-08-2022              \n",
      "187  29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...              \n",
      "191  16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...              \n",
      "\n",
      "    total number of follow up at LGBRIMH Number of In patient cares  \\\n",
      "1                                   12.0                        0.0   \n",
      "2                                    4.0                        0.0   \n",
      "3                                   69.0                        0.0   \n",
      "4                                    2.0                        1.0   \n",
      "5                                   71.0                        0.0   \n",
      "..                                   ...                        ...   \n",
      "163                                 10.0                        0.0   \n",
      "164                                  5.0                        0.0   \n",
      "186                                  3.0                        0.0   \n",
      "187                                 24.0                        0.0   \n",
      "191                                 25.0                        0.0   \n",
      "\n",
      "    total_frequency total_days1  \n",
      "1              12.0         577  \n",
      "2               4.0        3547  \n",
      "3              67.0        3547  \n",
      "4               2.0         100  \n",
      "5              70.0        3804  \n",
      "..              ...         ...  \n",
      "163            10.0         616  \n",
      "164             5.0         512  \n",
      "186             3.0         354  \n",
      "187            22.0         870  \n",
      "191            25.0        1542  \n",
      "\n",
      "[148 rows x 266 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df2 is your DataFrame\n",
    "# df2 = ...\n",
    "\n",
    "# Replace the value in the \"total_days1\" column for the row at index 93 with 1614\n",
    "df2.at[93, 'total_days1'] = 1614\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "05d467e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)                                                                                                              8.0\n",
      "Age at last follow up                                                                                                                    15.0\n",
      "Sex (m/f)                                                                                                                              female\n",
      "Religion                                                                                                                             Hinduism\n",
      "Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)                                  no formal education\n",
      "                                                                                                                  ...                        \n",
      "frequency of follow up at lgb (to write down follow-up dates)                               17.6.2109,23.7.2019,27.8.2019,24.9.2019,26.10....\n",
      "total number of follow up at LGBRIMH                                                                                                     42.0\n",
      "Number of In patient cares                                                                                                                0.0\n",
      "total_frequency                                                                                                                          42.0\n",
      "total_days1                                                                                                                              1614\n",
      "Name: 93, Length: 266, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "row_93 = df2.loc[93]\n",
    "print(row_93)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9e5c110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)                                                                                                             10.0\n",
      "Age at last follow up                                                                                                                    14.0\n",
      "Sex (m/f)                                                                                                                              female\n",
      "Religion                                                                                                                             Hinduism\n",
      "Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)                                              primary\n",
      "                                                                                                                  ...                        \n",
      "frequency of follow up at lgb (to write down follow-up dates)                               16-10-2019,15-11-2019,15-12-2019,13-1-2020,11-...\n",
      "total number of follow up at LGBRIMH                                                                                                     48.0\n",
      "Number of In patient cares                                                                                                                0.0\n",
      "total_frequency                                                                                                                          47.0\n",
      "total_days1                                                                                                                            739201\n",
      "Name: 137, Length: 266, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "row_93 = df2.loc[137]\n",
    "print(row_93)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a313656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0    female     Islam   \n",
      "2                            17.0                   18.0    female     Islam   \n",
      "3                             7.0                   17.0      male     Islam   \n",
      "4                            10.0                   10.0      male  Hinduism   \n",
      "5                             8.0                   15.0    female     Islam   \n",
      "..                            ...                    ...       ...       ...   \n",
      "163                           7.0                    9.0      male  Hinduism   \n",
      "164                          16.0                   17.0      male     Islam   \n",
      "186                          15.0                   15.0      male     Islam   \n",
      "187                          15.0                   17.0      male     Islam   \n",
      "191                           5.0                    8.0      male  Hinduism   \n",
      "\n",
      "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
      "1                                                  NaN                                         \n",
      "2                                              Primary                                         \n",
      "3                                                  NaN                                         \n",
      "4                                              primary                                         \n",
      "5                                  no formal education                                         \n",
      "..                                                 ...                                         \n",
      "163                                no formal education                                         \n",
      "164                                            primary                                         \n",
      "186                                        high school                                         \n",
      "187                                        high school                                         \n",
      "191                                            primary                                         \n",
      "\n",
      "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                      NaN       Rural                           62.0   \n",
      "2                  Primary       Rural                           55.0   \n",
      "3                      NaN       Rural                          102.0   \n",
      "4                  Primary       Rural                           29.0   \n",
      "5      no formal education       Rural                          102.0   \n",
      "..                     ...         ...                            ...   \n",
      "163    no formal education       Rural                           57.0   \n",
      "164                primary       Rural                          110.0   \n",
      "186            high school       Rural                          326.0   \n",
      "187            high school       Rural                           37.0   \n",
      "191                primary       Rural                           63.0   \n",
      "\n",
      "     District  State  ...  \\\n",
      "1    Udalguri  Assam  ...   \n",
      "2      Nagaon  Assam  ...   \n",
      "3      Nagaon  Assam  ...   \n",
      "4    Sonitpur  Assam  ...   \n",
      "5      Nagaon  Assam  ...   \n",
      "..        ...    ...  ...   \n",
      "163  Sonitpur  Assam  ...   \n",
      "164  morigaon  Assam  ...   \n",
      "186    Dhubri  Assam  ...   \n",
      "187    Nagaon  Assam  ...   \n",
      "191    Nagaon  Assam  ...   \n",
      "\n",
      "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
      "1                                                   22                            \n",
      "2                                                   30                            \n",
      "3                                                   58                            \n",
      "4                                                   20                            \n",
      "5                                                   65                            \n",
      "..                                                 ...                            \n",
      "163                                                  0                            \n",
      "164                                                330                            \n",
      "186                                                180                            \n",
      "187                                                120                            \n",
      "191                                                  0                            \n",
      "\n",
      "            Final  \\\n",
      "1    Satisfactory   \n",
      "2            Poor   \n",
      "3            Good   \n",
      "4            Good   \n",
      "5    Satisfactory   \n",
      "..            ...   \n",
      "163          Good   \n",
      "164          Poor   \n",
      "186          Poor   \n",
      "187  Satisfactory   \n",
      "191  Satisfactory   \n",
      "\n",
      "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
      "1                                                 1.66                                    \n",
      "2                                                 1.78                                    \n",
      "3                                                  NaN                                    \n",
      "4                                                    1                                    \n",
      "5                                                  6.6                                    \n",
      "..                                                 ...                                    \n",
      "163                                                2.1                                    \n",
      "164                                                3.8                                    \n",
      "186                                                4.3                                    \n",
      "187                                               1.21                                    \n",
      "191                                               2.15                                    \n",
      "\n",
      "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
      "1                                                  395                                  \n",
      "2                                                  240                                  \n",
      "3                                                  NaN                                  \n",
      "4                                                   90                                  \n",
      "5                                                  480                                  \n",
      "..                                                 ...                                  \n",
      "163                                                648                                  \n",
      "164                                                113                                  \n",
      "186                                                170                                  \n",
      "187                                                390                                  \n",
      "191                                               1619                                  \n",
      "\n",
      "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
      "1                                                  626                                                   \n",
      "2                                                  330                                                   \n",
      "3                                                 1320                                                   \n",
      "4                                                   90                                                   \n",
      "5                                                 3495                                                   \n",
      "..                                                 ...                                                   \n",
      "163                                                648                                                   \n",
      "164                                                576                                                   \n",
      "186                                                384                                                   \n",
      "187                                                875                                                   \n",
      "191                                               1619                                                   \n",
      "\n",
      "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
      "1    24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...              \n",
      "2    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
      "3    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
      "4                                22-06-2020,30-09-2020              \n",
      "5    10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...              \n",
      "..                                                 ...              \n",
      "163  28-03-22,13-07-22,26-08-22,11-10-22,15-05-23,3...              \n",
      "164       08-06-22,26-08-22,19-12-22,23-01-23,02-11-23              \n",
      "186                   28-08-2021,15-07-2022,17-08-2022              \n",
      "187  29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...              \n",
      "191  16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...              \n",
      "\n",
      "    total number of follow up at LGBRIMH Number of In patient cares  \\\n",
      "1                                   12.0                        0.0   \n",
      "2                                    4.0                        0.0   \n",
      "3                                   69.0                        0.0   \n",
      "4                                    2.0                        1.0   \n",
      "5                                   71.0                        0.0   \n",
      "..                                   ...                        ...   \n",
      "163                                 10.0                        0.0   \n",
      "164                                  5.0                        0.0   \n",
      "186                                  3.0                        0.0   \n",
      "187                                 24.0                        0.0   \n",
      "191                                 25.0                        0.0   \n",
      "\n",
      "    total_frequency total_days1  \n",
      "1              12.0         577  \n",
      "2               4.0        3547  \n",
      "3              67.0        3547  \n",
      "4               2.0         100  \n",
      "5              70.0        3804  \n",
      "..              ...         ...  \n",
      "163            10.0         616  \n",
      "164             5.0         512  \n",
      "186             3.0         354  \n",
      "187            22.0         870  \n",
      "191            25.0        1542  \n",
      "\n",
      "[148 rows x 266 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df2.at[137, 'total_days1'] = 1535\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f7fd528d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)                                                                                                             10.0\n",
      "Age at last follow up                                                                                                                    14.0\n",
      "Sex (m/f)                                                                                                                              female\n",
      "Religion                                                                                                                             Hinduism\n",
      "Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)                                              primary\n",
      "                                                                                                                  ...                        \n",
      "frequency of follow up at lgb (to write down follow-up dates)                               16-10-2019,15-11-2019,15-12-2019,13-1-2020,11-...\n",
      "total number of follow up at LGBRIMH                                                                                                     48.0\n",
      "Number of In patient cares                                                                                                                0.0\n",
      "total_frequency                                                                                                                          47.0\n",
      "total_days1                                                                                                                              1535\n",
      "Name: 137, Length: 266, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "row_93 = df2.loc[137]\n",
    "print(row_93)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "663f1043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>District</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Final</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>frequency of follow up at lgb (to write down follow-up dates)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "      <th>total_frequency</th>\n",
       "      <th>total_days1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>22-06-2020,30-09-2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>6.6</td>\n",
       "      <td>480</td>\n",
       "      <td>3495</td>\n",
       "      <td>10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>Rural</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>2.1</td>\n",
       "      <td>648</td>\n",
       "      <td>648</td>\n",
       "      <td>28-03-22,13-07-22,26-08-22,11-10-22,15-05-23,3...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>110.0</td>\n",
       "      <td>morigaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>330</td>\n",
       "      <td>Poor</td>\n",
       "      <td>3.8</td>\n",
       "      <td>113</td>\n",
       "      <td>576</td>\n",
       "      <td>08-06-22,26-08-22,19-12-22,23-01-23,02-11-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>326.0</td>\n",
       "      <td>Dhubri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>Poor</td>\n",
       "      <td>4.3</td>\n",
       "      <td>170</td>\n",
       "      <td>384</td>\n",
       "      <td>28-08-2021,15-07-2022,17-08-2022</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "1                             8.0                   10.0    female     Islam   \n",
       "2                            17.0                   18.0    female     Islam   \n",
       "3                             7.0                   17.0      male     Islam   \n",
       "4                            10.0                   10.0      male  Hinduism   \n",
       "5                             8.0                   15.0    female     Islam   \n",
       "..                            ...                    ...       ...       ...   \n",
       "163                           7.0                    9.0      male  Hinduism   \n",
       "164                          16.0                   17.0      male     Islam   \n",
       "186                          15.0                   15.0      male     Islam   \n",
       "187                          15.0                   17.0      male     Islam   \n",
       "191                           5.0                    8.0      male  Hinduism   \n",
       "\n",
       "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "1                                                  NaN                                         \n",
       "2                                              Primary                                         \n",
       "3                                                  NaN                                         \n",
       "4                                              primary                                         \n",
       "5                                  no formal education                                         \n",
       "..                                                 ...                                         \n",
       "163                                no formal education                                         \n",
       "164                                            primary                                         \n",
       "186                                        high school                                         \n",
       "187                                        high school                                         \n",
       "191                                            primary                                         \n",
       "\n",
       "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "1                      NaN       Rural                           62.0   \n",
       "2                  Primary       Rural                           55.0   \n",
       "3                      NaN       Rural                          102.0   \n",
       "4                  Primary       Rural                           29.0   \n",
       "5      no formal education       Rural                          102.0   \n",
       "..                     ...         ...                            ...   \n",
       "163    no formal education       Rural                           57.0   \n",
       "164                primary       Rural                          110.0   \n",
       "186            high school       Rural                          326.0   \n",
       "187            high school       Rural                           37.0   \n",
       "191                primary       Rural                           63.0   \n",
       "\n",
       "     District  State  ...  \\\n",
       "1    Udalguri  Assam  ...   \n",
       "2      Nagaon  Assam  ...   \n",
       "3      Nagaon  Assam  ...   \n",
       "4    Sonitpur  Assam  ...   \n",
       "5      Nagaon  Assam  ...   \n",
       "..        ...    ...  ...   \n",
       "163  Sonitpur  Assam  ...   \n",
       "164  morigaon  Assam  ...   \n",
       "186    Dhubri  Assam  ...   \n",
       "187    Nagaon  Assam  ...   \n",
       "191    Nagaon  Assam  ...   \n",
       "\n",
       "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "1                                                   22                            \n",
       "2                                                   30                            \n",
       "3                                                   58                            \n",
       "4                                                   20                            \n",
       "5                                                   65                            \n",
       "..                                                 ...                            \n",
       "163                                                  0                            \n",
       "164                                                330                            \n",
       "186                                                180                            \n",
       "187                                                120                            \n",
       "191                                                  0                            \n",
       "\n",
       "            Final  \\\n",
       "1    Satisfactory   \n",
       "2            Poor   \n",
       "3            Good   \n",
       "4            Good   \n",
       "5    Satisfactory   \n",
       "..            ...   \n",
       "163          Good   \n",
       "164          Poor   \n",
       "186          Poor   \n",
       "187  Satisfactory   \n",
       "191  Satisfactory   \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "5                                                  6.6                                    \n",
       "..                                                 ...                                    \n",
       "163                                                2.1                                    \n",
       "164                                                3.8                                    \n",
       "186                                                4.3                                    \n",
       "187                                               1.21                                    \n",
       "191                                               2.15                                    \n",
       "\n",
       "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "1                                                  395                                  \n",
       "2                                                  240                                  \n",
       "3                                                  NaN                                  \n",
       "4                                                   90                                  \n",
       "5                                                  480                                  \n",
       "..                                                 ...                                  \n",
       "163                                                648                                  \n",
       "164                                                113                                  \n",
       "186                                                170                                  \n",
       "187                                                390                                  \n",
       "191                                               1619                                  \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "5                                                 3495                                                   \n",
       "..                                                 ...                                                   \n",
       "163                                                648                                                   \n",
       "164                                                576                                                   \n",
       "186                                                384                                                   \n",
       "187                                                875                                                   \n",
       "191                                               1619                                                   \n",
       "\n",
       "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
       "1    24-06-2019,29-07-2019,09-09-2019,21-10-2019,17...              \n",
       "2    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
       "3    31-03-2014,29-04-2014,29-05-2014,04-07-2014,25...              \n",
       "4                                22-06-2020,30-09-2020              \n",
       "5    10-06-15,22-06-15,15-07-15,29-07-15,26-05-15,2...              \n",
       "..                                                 ...              \n",
       "163  28-03-22,13-07-22,26-08-22,11-10-22,15-05-23,3...              \n",
       "164       08-06-22,26-08-22,19-12-22,23-01-23,02-11-23              \n",
       "186                   28-08-2021,15-07-2022,17-08-2022              \n",
       "187  29-06-2020,21-08-2020,30-08-2020,31-10-2020,03...              \n",
       "191  16-05-2019,14-08-2019,03-02-2020,06-02-2020,19...              \n",
       "\n",
       "    total number of follow up at LGBRIMH Number of In patient cares  \\\n",
       "1                                   12.0                        0.0   \n",
       "2                                    4.0                        0.0   \n",
       "3                                   69.0                        0.0   \n",
       "4                                    2.0                        1.0   \n",
       "5                                   71.0                        0.0   \n",
       "..                                   ...                        ...   \n",
       "163                                 10.0                        0.0   \n",
       "164                                  5.0                        0.0   \n",
       "186                                  3.0                        0.0   \n",
       "187                                 24.0                        0.0   \n",
       "191                                 25.0                        0.0   \n",
       "\n",
       "    total_frequency total_days1  \n",
       "1              12.0         577  \n",
       "2               4.0        3547  \n",
       "3              67.0        3547  \n",
       "4               2.0         100  \n",
       "5              70.0        3804  \n",
       "..              ...         ...  \n",
       "163            10.0         616  \n",
       "164             5.0         512  \n",
       "186             3.0         354  \n",
       "187            22.0         870  \n",
       "191            25.0        1542  \n",
       "\n",
       "[148 rows x 266 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ce0804c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = df2.drop('frequency of follow up at lgb (to write down follow-up dates)', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4ef2293b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0    female     Islam   \n",
      "2                            17.0                   18.0    female     Islam   \n",
      "3                             7.0                   17.0      male     Islam   \n",
      "4                            10.0                   10.0      male  Hinduism   \n",
      "5                             8.0                   15.0    female     Islam   \n",
      "..                            ...                    ...       ...       ...   \n",
      "163                           7.0                    9.0      male  Hinduism   \n",
      "164                          16.0                   17.0      male     Islam   \n",
      "186                          15.0                   15.0      male     Islam   \n",
      "187                          15.0                   17.0      male     Islam   \n",
      "191                           5.0                    8.0      male  Hinduism   \n",
      "\n",
      "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
      "1                                                  NaN                                         \n",
      "2                                              Primary                                         \n",
      "3                                                  NaN                                         \n",
      "4                                              primary                                         \n",
      "5                                  no formal education                                         \n",
      "..                                                 ...                                         \n",
      "163                                no formal education                                         \n",
      "164                                            primary                                         \n",
      "186                                        high school                                         \n",
      "187                                        high school                                         \n",
      "191                                            primary                                         \n",
      "\n",
      "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                      NaN       Rural                           62.0   \n",
      "2                  Primary       Rural                           55.0   \n",
      "3                      NaN       Rural                          102.0   \n",
      "4                  Primary       Rural                           29.0   \n",
      "5      no formal education       Rural                          102.0   \n",
      "..                     ...         ...                            ...   \n",
      "163    no formal education       Rural                           57.0   \n",
      "164                primary       Rural                          110.0   \n",
      "186            high school       Rural                          326.0   \n",
      "187            high school       Rural                           37.0   \n",
      "191                primary       Rural                           63.0   \n",
      "\n",
      "     District  State  ...  \\\n",
      "1    Udalguri  Assam  ...   \n",
      "2      Nagaon  Assam  ...   \n",
      "3      Nagaon  Assam  ...   \n",
      "4    Sonitpur  Assam  ...   \n",
      "5      Nagaon  Assam  ...   \n",
      "..        ...    ...  ...   \n",
      "163  Sonitpur  Assam  ...   \n",
      "164  morigaon  Assam  ...   \n",
      "186    Dhubri  Assam  ...   \n",
      "187    Nagaon  Assam  ...   \n",
      "191    Nagaon  Assam  ...   \n",
      "\n",
      "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
      "1                                                   22                            \n",
      "2                                                   30                            \n",
      "3                                                   58                            \n",
      "4                                                   20                            \n",
      "5                                                   65                            \n",
      "..                                                 ...                            \n",
      "163                                                  0                            \n",
      "164                                                330                            \n",
      "186                                                180                            \n",
      "187                                                120                            \n",
      "191                                                  0                            \n",
      "\n",
      "            Final  \\\n",
      "1    Satisfactory   \n",
      "2            Poor   \n",
      "3            Good   \n",
      "4            Good   \n",
      "5    Satisfactory   \n",
      "..            ...   \n",
      "163          Good   \n",
      "164          Poor   \n",
      "186          Poor   \n",
      "187  Satisfactory   \n",
      "191  Satisfactory   \n",
      "\n",
      "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
      "1                                                 1.66                                    \n",
      "2                                                 1.78                                    \n",
      "3                                                  NaN                                    \n",
      "4                                                    1                                    \n",
      "5                                                  6.6                                    \n",
      "..                                                 ...                                    \n",
      "163                                                2.1                                    \n",
      "164                                                3.8                                    \n",
      "186                                                4.3                                    \n",
      "187                                               1.21                                    \n",
      "191                                               2.15                                    \n",
      "\n",
      "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
      "1                                                  395                                  \n",
      "2                                                  240                                  \n",
      "3                                                  NaN                                  \n",
      "4                                                   90                                  \n",
      "5                                                  480                                  \n",
      "..                                                 ...                                  \n",
      "163                                                648                                  \n",
      "164                                                113                                  \n",
      "186                                                170                                  \n",
      "187                                                390                                  \n",
      "191                                               1619                                  \n",
      "\n",
      "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
      "1                                                  626                                                   \n",
      "2                                                  330                                                   \n",
      "3                                                 1320                                                   \n",
      "4                                                   90                                                   \n",
      "5                                                 3495                                                   \n",
      "..                                                 ...                                                   \n",
      "163                                                648                                                   \n",
      "164                                                576                                                   \n",
      "186                                                384                                                   \n",
      "187                                                875                                                   \n",
      "191                                               1619                                                   \n",
      "\n",
      "    total number of follow up at LGBRIMH Number of In patient cares  \\\n",
      "1                                   12.0                        0.0   \n",
      "2                                    4.0                        0.0   \n",
      "3                                   69.0                        0.0   \n",
      "4                                    2.0                        1.0   \n",
      "5                                   71.0                        0.0   \n",
      "..                                   ...                        ...   \n",
      "163                                 10.0                        0.0   \n",
      "164                                  5.0                        0.0   \n",
      "186                                  3.0                        0.0   \n",
      "187                                 24.0                        0.0   \n",
      "191                                 25.0                        0.0   \n",
      "\n",
      "    total_frequency total_days1   days/freq  \n",
      "1              12.0         577   48.083333  \n",
      "2               4.0        3547  886.750000  \n",
      "3              67.0        3547   52.940299  \n",
      "4               2.0         100   50.000000  \n",
      "5              70.0        3804   54.342857  \n",
      "..              ...         ...         ...  \n",
      "163            10.0         616   61.600000  \n",
      "164             5.0         512  102.400000  \n",
      "186             3.0         354  118.000000  \n",
      "187            22.0         870   39.545455  \n",
      "191            25.0        1542   61.680000  \n",
      "\n",
      "[148 rows x 266 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df2['days/freq'] = df2['total_days1'] / df2['total_frequency']\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "74b85faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>District</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Final</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "      <th>total_frequency</th>\n",
       "      <th>total_days1</th>\n",
       "      <th>days/freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Udalguri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>577</td>\n",
       "      <td>48.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3547</td>\n",
       "      <td>886.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3547</td>\n",
       "      <td>52.940299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Islam</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>Rural</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>6.6</td>\n",
       "      <td>480</td>\n",
       "      <td>3495</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3804</td>\n",
       "      <td>54.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>no formal education</td>\n",
       "      <td>Rural</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Sonitpur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>2.1</td>\n",
       "      <td>648</td>\n",
       "      <td>648</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>616</td>\n",
       "      <td>61.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>110.0</td>\n",
       "      <td>morigaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>330</td>\n",
       "      <td>Poor</td>\n",
       "      <td>3.8</td>\n",
       "      <td>113</td>\n",
       "      <td>576</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512</td>\n",
       "      <td>102.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>326.0</td>\n",
       "      <td>Dhubri</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>Poor</td>\n",
       "      <td>4.3</td>\n",
       "      <td>170</td>\n",
       "      <td>384</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>354</td>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Islam</td>\n",
       "      <td>high school</td>\n",
       "      <td>high school</td>\n",
       "      <td>Rural</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>870</td>\n",
       "      <td>39.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Hinduism</td>\n",
       "      <td>primary</td>\n",
       "      <td>primary</td>\n",
       "      <td>Rural</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nagaon</td>\n",
       "      <td>Assam</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1542</td>\n",
       "      <td>61.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up Sex (m/f)  Religion  \\\n",
       "1                             8.0                   10.0    female     Islam   \n",
       "2                            17.0                   18.0    female     Islam   \n",
       "3                             7.0                   17.0      male     Islam   \n",
       "4                            10.0                   10.0      male  Hinduism   \n",
       "5                             8.0                   15.0    female     Islam   \n",
       "..                            ...                    ...       ...       ...   \n",
       "163                           7.0                    9.0      male  Hinduism   \n",
       "164                          16.0                   17.0      male     Islam   \n",
       "186                          15.0                   15.0      male     Islam   \n",
       "187                          15.0                   17.0      male     Islam   \n",
       "191                           5.0                    8.0      male  Hinduism   \n",
       "\n",
       "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
       "1                                                  NaN                                         \n",
       "2                                              Primary                                         \n",
       "3                                                  NaN                                         \n",
       "4                                              primary                                         \n",
       "5                                  no formal education                                         \n",
       "..                                                 ...                                         \n",
       "163                                no formal education                                         \n",
       "164                                            primary                                         \n",
       "186                                        high school                                         \n",
       "187                                        high school                                         \n",
       "191                                            primary                                         \n",
       "\n",
       "    Max education attained Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "1                      NaN       Rural                           62.0   \n",
       "2                  Primary       Rural                           55.0   \n",
       "3                      NaN       Rural                          102.0   \n",
       "4                  Primary       Rural                           29.0   \n",
       "5      no formal education       Rural                          102.0   \n",
       "..                     ...         ...                            ...   \n",
       "163    no formal education       Rural                           57.0   \n",
       "164                primary       Rural                          110.0   \n",
       "186            high school       Rural                          326.0   \n",
       "187            high school       Rural                           37.0   \n",
       "191                primary       Rural                           63.0   \n",
       "\n",
       "     District  State  ...  \\\n",
       "1    Udalguri  Assam  ...   \n",
       "2      Nagaon  Assam  ...   \n",
       "3      Nagaon  Assam  ...   \n",
       "4    Sonitpur  Assam  ...   \n",
       "5      Nagaon  Assam  ...   \n",
       "..        ...    ...  ...   \n",
       "163  Sonitpur  Assam  ...   \n",
       "164  morigaon  Assam  ...   \n",
       "186    Dhubri  Assam  ...   \n",
       "187    Nagaon  Assam  ...   \n",
       "191    Nagaon  Assam  ...   \n",
       "\n",
       "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "1                                                   22                            \n",
       "2                                                   30                            \n",
       "3                                                   58                            \n",
       "4                                                   20                            \n",
       "5                                                   65                            \n",
       "..                                                 ...                            \n",
       "163                                                  0                            \n",
       "164                                                330                            \n",
       "186                                                180                            \n",
       "187                                                120                            \n",
       "191                                                  0                            \n",
       "\n",
       "            Final  \\\n",
       "1    Satisfactory   \n",
       "2            Poor   \n",
       "3            Good   \n",
       "4            Good   \n",
       "5    Satisfactory   \n",
       "..            ...   \n",
       "163          Good   \n",
       "164          Poor   \n",
       "186          Poor   \n",
       "187  Satisfactory   \n",
       "191  Satisfactory   \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "5                                                  6.6                                    \n",
       "..                                                 ...                                    \n",
       "163                                                2.1                                    \n",
       "164                                                3.8                                    \n",
       "186                                                4.3                                    \n",
       "187                                               1.21                                    \n",
       "191                                               2.15                                    \n",
       "\n",
       "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "1                                                  395                                  \n",
       "2                                                  240                                  \n",
       "3                                                  NaN                                  \n",
       "4                                                   90                                  \n",
       "5                                                  480                                  \n",
       "..                                                 ...                                  \n",
       "163                                                648                                  \n",
       "164                                                113                                  \n",
       "186                                                170                                  \n",
       "187                                                390                                  \n",
       "191                                               1619                                  \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "5                                                 3495                                                   \n",
       "..                                                 ...                                                   \n",
       "163                                                648                                                   \n",
       "164                                                576                                                   \n",
       "186                                                384                                                   \n",
       "187                                                875                                                   \n",
       "191                                               1619                                                   \n",
       "\n",
       "    total number of follow up at LGBRIMH Number of In patient cares  \\\n",
       "1                                   12.0                        0.0   \n",
       "2                                    4.0                        0.0   \n",
       "3                                   69.0                        0.0   \n",
       "4                                    2.0                        1.0   \n",
       "5                                   71.0                        0.0   \n",
       "..                                   ...                        ...   \n",
       "163                                 10.0                        0.0   \n",
       "164                                  5.0                        0.0   \n",
       "186                                  3.0                        0.0   \n",
       "187                                 24.0                        0.0   \n",
       "191                                 25.0                        0.0   \n",
       "\n",
       "    total_frequency total_days1   days/freq  \n",
       "1              12.0         577   48.083333  \n",
       "2               4.0        3547  886.750000  \n",
       "3              67.0        3547   52.940299  \n",
       "4               2.0         100   50.000000  \n",
       "5              70.0        3804   54.342857  \n",
       "..              ...         ...         ...  \n",
       "163            10.0         616   61.600000  \n",
       "164             5.0         512  102.400000  \n",
       "186             3.0         354  118.000000  \n",
       "187            22.0         870   39.545455  \n",
       "191            25.0        1542   61.680000  \n",
       "\n",
       "[148 rows x 266 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c419457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = df2.drop(['State', 'District'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "531d33f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age at presentation (in yrs)', 'Age at last follow up', 'Sex (m/f)',\n",
      "       'Religion',\n",
      "       'Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)',\n",
      "       'Max education attained', 'Rural/Urban',\n",
      "       'Distance from LGBRIMH (in KM)', 'Socioeconomic status',\n",
      "       'Age at onset(in years)',\n",
      "       ...\n",
      "       'Off-medications duration (to add all such durations over follow-up in days)',\n",
      "       'Final',\n",
      "       'mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)',\n",
      "       'maximum period of compliance at lgb (in days) (longest streak of good compliance)',\n",
      "       'total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)',\n",
      "       'total number of follow up at LGBRIMH', 'Number of In patient cares',\n",
      "       'total_frequency', 'total_days1', 'days/freq'],\n",
      "      dtype='object', length=264)\n"
     ]
    }
   ],
   "source": [
    "column_names = df2.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e8b4275b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)\n",
      "Age at last follow up\n",
      "Sex (m/f)\n",
      "Religion\n",
      "Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)\n",
      "Max education attained\n",
      "Rural/Urban\n",
      "Distance from LGBRIMH (in KM)\n",
      "Socioeconomic status\n",
      "Age at onset(in years)\n",
      "Chief complaint 1\n",
      "Chief complaint 2\n",
      "Chief complaint 3\n",
      "Time period between onset to first consultation at LGBRIMH (DUI) (in days)\n",
      "Type of Family (Nuclear/Joint/single parent/orphan/ foster family\n",
      "Family environment\n",
      "Details of family abnormality (describe)\n",
      "Family h/o stillbirth/abortion\n",
      "Family history(general medical)\n",
      "Family history (psychiatric/neurological)\n",
      "Faith healer visited before consultation or not(yes/no)\n",
      "Antenatal risk factor\n",
      "Place of delivery (Home/hospital)\n",
      "Birth weight(in kg)\n",
      "Neonatal complication\n",
      "Postnatal complication\n",
      "Developmental history\n",
      "Age of school entry(in years)\n",
      "Type of school\n",
      "School adjustment\n",
      "Academic performance\n",
      "School dropout present (yes/no)\n",
      "Detail of past psychiatric history 1\n",
      "Past treatment 1\n",
      "Past treatment medication 1\n",
      "Starting dose past medication 1\n",
      "Age of starting of past medication 1(in years)\n",
      "Past maintenance dose1 (in mg)\n",
      "Side effects of past medication 1\n",
      "Age of occurance past side effects 1(in years)\n",
      "Duration of past side effect 1(in months)\n",
      "Response to past medication 1\n",
      "Detail of past history 2\n",
      "Past treatment 2\n",
      "Past treatment medication 2\n",
      "Starting dose past medication 2\n",
      "Age of starting of past medication 2(in years)\n",
      "Past maintenance dose2\n",
      "Side effects of past medication 2\n",
      "Age of occurance past side effects 2(in years)\n",
      "Duration of past side effect 2(in months)\n",
      "Response to past medication 2\n",
      "Detail of past history 3\n",
      "Past treatment  3\n",
      "Past treatment medication 3\n",
      "Starting dose past medication 3 \n",
      "Age of starting past medication 3 (in years)\n",
      "Past maintenance dose 3\n",
      "Side effects past medication 3\n",
      "Age of occurance of past side effects 3 (in years)\n",
      "Duration of past side effects 3 (in months)\n",
      "Response to past medication 3\n",
      "Change in doctor\n",
      "Past/Current medical conditions\n",
      "Age of onset of medical conditions (in years)\n",
      "Details of medical conditions\n",
      "Treatments for medical conditions\n",
      "Severity of medical conditions\n",
      "weight (in Kg)\n",
      "weight z score\n",
      "height (in cm)\n",
      "height z score\n",
      "head circumference (in cm)\n",
      "head circumference z score\n",
      "systemic examination(abnormal/normal)\n",
      "systemic examination details (main finding only)\n",
      "Mental status examination/Behavioral Observation details (abnormal/normal)\n",
      "Mental status examination/Behavioral observation details (main finding only in description)\n",
      "Screening diagnosis \n",
      "detailed workup diagnosis\n",
      "Follow up diagnosis changed or not (yes/no)\n",
      "If yes, changed once or multiple times (once/multiple)\n",
      "If yes, after how many days from first presentation diagnosis changed (in days)\n",
      "If yes, diagnosis changed to what\n",
      "Axis 1_1\n",
      "Axis 1_2\n",
      "Axis 1_3\n",
      "Axis 1_4\n",
      "Axis 2\n",
      "Axis 3\n",
      "Axis 4_1\n",
      "Axis 4_2\n",
      "Axis 4_3\n",
      "Axis 5\n",
      "significant psychosocial stressor\n",
      "name of Medication 1\n",
      "medication 1 starting dose (in mg)\n",
      "Avg dose of medication 1 (Mode value of medication) (in mg)\n",
      "Maximum dose of medication 1 (in mg)\n",
      "Total duration of medication 1 (in days) \n",
      "Continued medication 1/stopped/changed\n",
      "Response to medication 1 (Good/partial/no)\n",
      "Side effect of medication 1\n",
      "onset of side effect post starting med 1 ( in days)\n",
      "total duration of side effect of medication 1 (in days)\n",
      "Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) \n",
      "name of Medication 2\n",
      "Medication 2 starting dose (in mg)\n",
      "Avg dose of medication 2 (in mg)\n",
      "Maximum dose of medication 2 (in mg)\n",
      "Total duration of medication 2(in days) \n",
      "Continued medication 2/stopped/changed\n",
      "Response to medication 2 (Good/partial/no)\n",
      "Side effect of medication 2\n",
      "onset of side effect post starting med 2 ( in days)\n",
      "total duration of side effect of medication 2 (in days)\n",
      "Medication possession ratios 2(MPRs) in lgb;x-syrup\n",
      "name of Medication 3\n",
      "Medication 3 starting dose (in mg)\n",
      "Avg dose of medication 3 (in mg)\n",
      "Maximum dose of medication 3 (in mg)\n",
      "Total duration of medication 3 (in days\n",
      "continued medication 3/stopped/changed\n",
      "Response to medication 3 (Good/partial/no)\n",
      "Side effect of medication 3\n",
      "onset of side effect post starting med 3 ( in days)\n",
      "total duration of side effect of medication 3 (in days)\n",
      "Medication possession ratios 3(MPRs) in lgb;x-syrup\n",
      "name of Medication 4\n",
      "Medication 4 starting dose (in mg)\n",
      "Avg dose of medication 4 (in mg)\n",
      "Maximum dose of medication 4 (in mg)\n",
      "Total duration of medication 4 (in days)\n",
      "continued medication 4/stopped/changed\n",
      "Response to medication 4(Good/partial/no)\n",
      "Side effect of medication 4\n",
      "onset of side effect post starting med 4 ( in days)\n",
      "total duration of side effect of medication 4 (in days)\n",
      "Medication possession ratios 4(MPRs) in lgb;x-syrup\n",
      "name of Medication 5\n",
      "Medication 5 starting dose (in mg)\n",
      "Avg dose of medication 5 (in mg)\n",
      "Maximum dose of medication 5(in mg)\n",
      "Total duration of medication 5 (in days)\n",
      "continued medication 5/stopped/changed\n",
      "Response to medication 5(Good/partial/no)\n",
      "Side effect of medication 5\n",
      "onset of side effect post starting med 5 ( in days)\n",
      "total duration of side effect of medication 5 (in days)\n",
      "Medication possession ratios 5(MPRs) in lgb;x-syrup\n",
      "name of Medication 6\n",
      "Medication 6 starting dose\n",
      "Avg dose of medication 6\n",
      "Maximum dose of medication 6\n",
      "Total duration of medication 6\n",
      "continued medication 6/stopped/changed\n",
      "Response to medication 6(Good/partial/no)\n",
      "Side effect of medication 6\n",
      "onset of side effect post starting med 6 ( in days)\n",
      "total duration of side effect of medication 6 (in days)\n",
      "Medication possession ratios 6(MPRs) in lgb;x-syrup\n",
      "name of Medication 7\n",
      "Medication 7 starting dose\n",
      "Avg dose of medication 7\n",
      "Maximum dose of medication 7\n",
      "Total duration of medication 7\n",
      "continued medication 7/stopped/changed\n",
      "Response to medication 7(Good/partial/no)\n",
      "Side effect of medication 7\n",
      "onset of side effect post starting med 7 ( in days)\n",
      "total duration of side effect of medication 7 (in days)\n",
      "Medication possession ratios 7(MPRs) in lgb;x-syrup\n",
      "name of Medication 8\n",
      "Medication 8 starting dose\n",
      "Avg dose of medication 8\n",
      "Maximum dose of medication 8\n",
      "Total duration of medication 8\n",
      "Continued medication 8/stopped/changed\n",
      "Response to medication 8(Good/partial/no)\n",
      "Side effect of medication 8\n",
      "onset of side effect post starting med 8 ( in days)\n",
      "total duration of side effect of medication 8 (in days)\n",
      "Medication possession ratios 8(MPRs) in lgb;x-syrup\n",
      "name of Medication 9\n",
      "Medication 9 starting dose\n",
      "Avg dose of medication 9\n",
      "Maximum dose of medication 9\n",
      "Total duration of medication 9\n",
      "continued medication 9/stopped/changed\n",
      "Response to medication 9(Good/partial/no)\n",
      "Side effect of medication 9\n",
      "onset of side effect post starting med 9 ( in days)\n",
      "total duration of side effect of medication 9 (in days)\n",
      "Medication possession ratios 9(MPRs) in lgb;x-syrup\n",
      "name of Medication 10\n",
      "Medication 10 starting dose\n",
      "Avg dose of medication 10\n",
      "Maximum dose of medication 10\n",
      "Total duration of medication 10\n",
      "continued medication 10/stopped/changed\n",
      "Response to medication 10(Good/partial/no)\n",
      "Side effect of medication 10\n",
      "onset of side effect post starting med 10 ( in days)\n",
      "total duration of side effect of medication 10 (in days)\n",
      "Medication possession ratios 10(MPRs) in lgb;x-syrup\n",
      "name of Medication 11\n",
      "Medication 11 starting dose\n",
      "Avg dose of medication 11\n",
      "Maximum dose of medication 11\n",
      "Total duration of medication 11\n",
      "continued medication 11/stopped/changed\n",
      "Response to medication 11(Good/partial/no)\n",
      "Side effect of medication 11\n",
      "onset of side effect post starting med 11 ( in days)\n",
      "total duration of side effect of medication 11 (in days)\n",
      "Medication possession ratios 11(MPRs) in lgb;x-syrup\n",
      "name of Medication 12\n",
      "Medication 12 starting dose\n",
      "Avg dose of medication 12\n",
      "Maximum dose of medication 12\n",
      "Total duration of medication 12\n",
      "continued medication 12/stopped/changed\n",
      "Response to medication 12(Good/partial/no)\n",
      "Side effect of medication 12\n",
      "onset of side effect post starting med 12 ( in days)\n",
      "total duration of side effect of medication 12 (in days)\n",
      "Medication possession ratios 12(MPRs) in lgb;x-syrup\n",
      "name of Medication 13\n",
      "Medication 13 starting dose\n",
      "Avg dose of medication 13\n",
      "Maximum dose of medication 13\n",
      "Total duration of medication 13\n",
      "continued medication 13/stopped/changed\n",
      "Response to medication 13(Good/partial/no)\n",
      "Side effect of medication 13\n",
      "onset of side effect post starting med 13 ( in days)\n",
      "total duration of side effect of medication 13 (in days)\n",
      "Medication possession ratios 13(MPRs) in lgb;x-syrup\n",
      "name of Medication 14\n",
      "Medication 14 starting dose\n",
      "Avg dose of medication 14\n",
      "Maximum dose of medication 14\n",
      "Total duration of medication 14\n",
      "continued medication 14/stopped/changed\n",
      "Response to medication 14(Good/partial/no)\n",
      "Side effect of medication 14\n",
      "onset of side effect post starting med 14 ( in days)\n",
      "total duration of side effect of medication 14 (in days)\n",
      "Medication possession ratios 14(MPRs) in lgb;x-syrup\n",
      "cost of medication\n",
      "Other treatments(rehabilitative intervention/IT/CBT/ipt/FT/PMT/BEHAVIOURAL INTERVENTIONS FOR DEVELOPMENTAL DISORDERS, Combination therapy)\n",
      "Maximum duration of symptom free period (in days)\n",
      "Max Duration of resolution of symptoms before recurrence/relapse (in days)\n",
      "No of relapses/exacerbations\n",
      "Off-medications duration (to add all such durations over follow-up in days)\n",
      "Final\n",
      "mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)\n",
      "maximum period of compliance at lgb (in days) (longest streak of good compliance)\n",
      "total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)\n",
      "total number of follow up at LGBRIMH\n",
      "Number of In patient cares\n",
      "total_frequency\n",
      "total_days1\n",
      "days/freq\n"
     ]
    }
   ],
   "source": [
    "column_names = df2.columns.tolist()\n",
    "for name in column_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "297ac54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      female\n",
       "2      female\n",
       "3        male\n",
       "4        male\n",
       "5      female\n",
       "        ...  \n",
       "163      male\n",
       "164      male\n",
       "186      male\n",
       "187      male\n",
       "191      male\n",
       "Name: Sex (m/f), Length: 148, dtype: object"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Sex (m/f)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a524c35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Sex (m/f)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6c4f0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_values = df2['Sex (m/f)'].unique()\n",
    "mapping_details = {value: idx / (len(unique_values) - 1) for idx, value in enumerate(unique_values)}\n",
    "\n",
    "df2['Sex (m/f)'] =  df2['Sex (m/f)'].map(mapping_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cd429437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'female': 0.0, 'male': 1.0}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8e5d5b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Islam', 'Hinduism', 'hinduism', 'Christianity'], dtype=object)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Religion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2717e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_values = df2['Religion'].unique()\n",
    "mapping_details = {value: idx / (len(unique_values) - 1) for idx, value in enumerate(unique_values)}\n",
    "\n",
    "df2['Religion'] =  df2['Religion'].map(mapping_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a418821c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Islam': 0.0,\n",
       " 'Hinduism': 0.3333333333333333,\n",
       " 'hinduism': 0.6666666666666666,\n",
       " 'Christianity': 1.0}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6520e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_values = df2['Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)'].unique()\n",
    "mapping_details = {value: idx / (len(unique_values) - 1) for idx, value in enumerate(unique_values)}\n",
    "\n",
    "df2['Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)'] =  df2['Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)'].map(mapping_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d850af5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Primary', 'primary', 'no formal education', 'high school',\n",
       "       'Pre primary/play school', 'others', 'higher secondary',\n",
       "       'play school/preprimary'], dtype=object)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f5427f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "education_mapping = {\n",
    "    'Primary': 0.25,\n",
    "    'primary': 0.25,\n",
    "    'no formal education': 0.75,\n",
    "    'high school': 0.5,\n",
    "    'Pre primary/play school': 0,\n",
    "    'others': 1,\n",
    "    'higher secondary': 0.5,\n",
    "    'play school/preprimary': 0,\n",
    "    # Add more mappings as needed\n",
    "    # For NaN values, you can decide to keep them as-is or map them to a default value\n",
    "    np.nan: 1\n",
    "}\n",
    "\n",
    "# Map values in the DataFrame\n",
    "df2['Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)'] = df2['Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)'].map(education_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c1c954ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)\n",
      "Age at last follow up\n",
      "Sex (m/f)\n",
      "Religion\n",
      "Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)\n",
      "Max education attained\n",
      "Rural/Urban\n",
      "Distance from LGBRIMH (in KM)\n",
      "Socioeconomic status\n",
      "Age at onset(in years)\n",
      "Chief complaint 1\n",
      "Chief complaint 2\n",
      "Chief complaint 3\n",
      "Time period between onset to first consultation at LGBRIMH (DUI) (in days)\n",
      "Type of Family (Nuclear/Joint/single parent/orphan/ foster family\n",
      "Family environment\n",
      "Details of family abnormality (describe)\n",
      "Family h/o stillbirth/abortion\n",
      "Family history(general medical)\n",
      "Family history (psychiatric/neurological)\n",
      "Faith healer visited before consultation or not(yes/no)\n",
      "Antenatal risk factor\n",
      "Place of delivery (Home/hospital)\n",
      "Birth weight(in kg)\n",
      "Neonatal complication\n",
      "Postnatal complication\n",
      "Developmental history\n",
      "Age of school entry(in years)\n",
      "Type of school\n",
      "School adjustment\n",
      "Academic performance\n",
      "School dropout present (yes/no)\n",
      "Detail of past psychiatric history 1\n",
      "Past treatment 1\n",
      "Past treatment medication 1\n",
      "Starting dose past medication 1\n",
      "Age of starting of past medication 1(in years)\n",
      "Past maintenance dose1 (in mg)\n",
      "Side effects of past medication 1\n",
      "Age of occurance past side effects 1(in years)\n",
      "Duration of past side effect 1(in months)\n",
      "Response to past medication 1\n",
      "Detail of past history 2\n",
      "Past treatment 2\n",
      "Past treatment medication 2\n",
      "Starting dose past medication 2\n",
      "Age of starting of past medication 2(in years)\n",
      "Past maintenance dose2\n",
      "Side effects of past medication 2\n",
      "Age of occurance past side effects 2(in years)\n",
      "Duration of past side effect 2(in months)\n",
      "Response to past medication 2\n",
      "Detail of past history 3\n",
      "Past treatment  3\n",
      "Past treatment medication 3\n",
      "Starting dose past medication 3 \n",
      "Age of starting past medication 3 (in years)\n",
      "Past maintenance dose 3\n",
      "Side effects past medication 3\n",
      "Age of occurance of past side effects 3 (in years)\n",
      "Duration of past side effects 3 (in months)\n",
      "Response to past medication 3\n",
      "Change in doctor\n",
      "Past/Current medical conditions\n",
      "Age of onset of medical conditions (in years)\n",
      "Details of medical conditions\n",
      "Treatments for medical conditions\n",
      "Severity of medical conditions\n",
      "weight (in Kg)\n",
      "weight z score\n",
      "height (in cm)\n",
      "height z score\n",
      "head circumference (in cm)\n",
      "head circumference z score\n",
      "systemic examination(abnormal/normal)\n",
      "systemic examination details (main finding only)\n",
      "Mental status examination/Behavioral Observation details (abnormal/normal)\n",
      "Mental status examination/Behavioral observation details (main finding only in description)\n",
      "Screening diagnosis \n",
      "detailed workup diagnosis\n",
      "Follow up diagnosis changed or not (yes/no)\n",
      "If yes, changed once or multiple times (once/multiple)\n",
      "If yes, after how many days from first presentation diagnosis changed (in days)\n",
      "If yes, diagnosis changed to what\n",
      "Axis 1_1\n",
      "Axis 1_2\n",
      "Axis 1_3\n",
      "Axis 1_4\n",
      "Axis 2\n",
      "Axis 3\n",
      "Axis 4_1\n",
      "Axis 4_2\n",
      "Axis 4_3\n",
      "Axis 5\n",
      "significant psychosocial stressor\n",
      "name of Medication 1\n",
      "medication 1 starting dose (in mg)\n",
      "Avg dose of medication 1 (Mode value of medication) (in mg)\n",
      "Maximum dose of medication 1 (in mg)\n",
      "Total duration of medication 1 (in days) \n",
      "Continued medication 1/stopped/changed\n",
      "Response to medication 1 (Good/partial/no)\n",
      "Side effect of medication 1\n",
      "onset of side effect post starting med 1 ( in days)\n",
      "total duration of side effect of medication 1 (in days)\n",
      "Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) \n",
      "name of Medication 2\n",
      "Medication 2 starting dose (in mg)\n",
      "Avg dose of medication 2 (in mg)\n",
      "Maximum dose of medication 2 (in mg)\n",
      "Total duration of medication 2(in days) \n",
      "Continued medication 2/stopped/changed\n",
      "Response to medication 2 (Good/partial/no)\n",
      "Side effect of medication 2\n",
      "onset of side effect post starting med 2 ( in days)\n",
      "total duration of side effect of medication 2 (in days)\n",
      "Medication possession ratios 2(MPRs) in lgb;x-syrup\n",
      "name of Medication 3\n",
      "Medication 3 starting dose (in mg)\n",
      "Avg dose of medication 3 (in mg)\n",
      "Maximum dose of medication 3 (in mg)\n",
      "Total duration of medication 3 (in days\n",
      "continued medication 3/stopped/changed\n",
      "Response to medication 3 (Good/partial/no)\n",
      "Side effect of medication 3\n",
      "onset of side effect post starting med 3 ( in days)\n",
      "total duration of side effect of medication 3 (in days)\n",
      "Medication possession ratios 3(MPRs) in lgb;x-syrup\n",
      "name of Medication 4\n",
      "Medication 4 starting dose (in mg)\n",
      "Avg dose of medication 4 (in mg)\n",
      "Maximum dose of medication 4 (in mg)\n",
      "Total duration of medication 4 (in days)\n",
      "continued medication 4/stopped/changed\n",
      "Response to medication 4(Good/partial/no)\n",
      "Side effect of medication 4\n",
      "onset of side effect post starting med 4 ( in days)\n",
      "total duration of side effect of medication 4 (in days)\n",
      "Medication possession ratios 4(MPRs) in lgb;x-syrup\n",
      "name of Medication 5\n",
      "Medication 5 starting dose (in mg)\n",
      "Avg dose of medication 5 (in mg)\n",
      "Maximum dose of medication 5(in mg)\n",
      "Total duration of medication 5 (in days)\n",
      "continued medication 5/stopped/changed\n",
      "Response to medication 5(Good/partial/no)\n",
      "Side effect of medication 5\n",
      "onset of side effect post starting med 5 ( in days)\n",
      "total duration of side effect of medication 5 (in days)\n",
      "Medication possession ratios 5(MPRs) in lgb;x-syrup\n",
      "name of Medication 6\n",
      "Medication 6 starting dose\n",
      "Avg dose of medication 6\n",
      "Maximum dose of medication 6\n",
      "Total duration of medication 6\n",
      "continued medication 6/stopped/changed\n",
      "Response to medication 6(Good/partial/no)\n",
      "Side effect of medication 6\n",
      "onset of side effect post starting med 6 ( in days)\n",
      "total duration of side effect of medication 6 (in days)\n",
      "Medication possession ratios 6(MPRs) in lgb;x-syrup\n",
      "name of Medication 7\n",
      "Medication 7 starting dose\n",
      "Avg dose of medication 7\n",
      "Maximum dose of medication 7\n",
      "Total duration of medication 7\n",
      "continued medication 7/stopped/changed\n",
      "Response to medication 7(Good/partial/no)\n",
      "Side effect of medication 7\n",
      "onset of side effect post starting med 7 ( in days)\n",
      "total duration of side effect of medication 7 (in days)\n",
      "Medication possession ratios 7(MPRs) in lgb;x-syrup\n",
      "name of Medication 8\n",
      "Medication 8 starting dose\n",
      "Avg dose of medication 8\n",
      "Maximum dose of medication 8\n",
      "Total duration of medication 8\n",
      "Continued medication 8/stopped/changed\n",
      "Response to medication 8(Good/partial/no)\n",
      "Side effect of medication 8\n",
      "onset of side effect post starting med 8 ( in days)\n",
      "total duration of side effect of medication 8 (in days)\n",
      "Medication possession ratios 8(MPRs) in lgb;x-syrup\n",
      "name of Medication 9\n",
      "Medication 9 starting dose\n",
      "Avg dose of medication 9\n",
      "Maximum dose of medication 9\n",
      "Total duration of medication 9\n",
      "continued medication 9/stopped/changed\n",
      "Response to medication 9(Good/partial/no)\n",
      "Side effect of medication 9\n",
      "onset of side effect post starting med 9 ( in days)\n",
      "total duration of side effect of medication 9 (in days)\n",
      "Medication possession ratios 9(MPRs) in lgb;x-syrup\n",
      "name of Medication 10\n",
      "Medication 10 starting dose\n",
      "Avg dose of medication 10\n",
      "Maximum dose of medication 10\n",
      "Total duration of medication 10\n",
      "continued medication 10/stopped/changed\n",
      "Response to medication 10(Good/partial/no)\n",
      "Side effect of medication 10\n",
      "onset of side effect post starting med 10 ( in days)\n",
      "total duration of side effect of medication 10 (in days)\n",
      "Medication possession ratios 10(MPRs) in lgb;x-syrup\n",
      "name of Medication 11\n",
      "Medication 11 starting dose\n",
      "Avg dose of medication 11\n",
      "Maximum dose of medication 11\n",
      "Total duration of medication 11\n",
      "continued medication 11/stopped/changed\n",
      "Response to medication 11(Good/partial/no)\n",
      "Side effect of medication 11\n",
      "onset of side effect post starting med 11 ( in days)\n",
      "total duration of side effect of medication 11 (in days)\n",
      "Medication possession ratios 11(MPRs) in lgb;x-syrup\n",
      "name of Medication 12\n",
      "Medication 12 starting dose\n",
      "Avg dose of medication 12\n",
      "Maximum dose of medication 12\n",
      "Total duration of medication 12\n",
      "continued medication 12/stopped/changed\n",
      "Response to medication 12(Good/partial/no)\n",
      "Side effect of medication 12\n",
      "onset of side effect post starting med 12 ( in days)\n",
      "total duration of side effect of medication 12 (in days)\n",
      "Medication possession ratios 12(MPRs) in lgb;x-syrup\n",
      "name of Medication 13\n",
      "Medication 13 starting dose\n",
      "Avg dose of medication 13\n",
      "Maximum dose of medication 13\n",
      "Total duration of medication 13\n",
      "continued medication 13/stopped/changed\n",
      "Response to medication 13(Good/partial/no)\n",
      "Side effect of medication 13\n",
      "onset of side effect post starting med 13 ( in days)\n",
      "total duration of side effect of medication 13 (in days)\n",
      "Medication possession ratios 13(MPRs) in lgb;x-syrup\n",
      "name of Medication 14\n",
      "Medication 14 starting dose\n",
      "Avg dose of medication 14\n",
      "Maximum dose of medication 14\n",
      "Total duration of medication 14\n",
      "continued medication 14/stopped/changed\n",
      "Response to medication 14(Good/partial/no)\n",
      "Side effect of medication 14\n",
      "onset of side effect post starting med 14 ( in days)\n",
      "total duration of side effect of medication 14 (in days)\n",
      "Medication possession ratios 14(MPRs) in lgb;x-syrup\n",
      "cost of medication\n",
      "Other treatments(rehabilitative intervention/IT/CBT/ipt/FT/PMT/BEHAVIOURAL INTERVENTIONS FOR DEVELOPMENTAL DISORDERS, Combination therapy)\n",
      "Maximum duration of symptom free period (in days)\n",
      "Max Duration of resolution of symptoms before recurrence/relapse (in days)\n",
      "No of relapses/exacerbations\n",
      "Off-medications duration (to add all such durations over follow-up in days)\n",
      "Final\n",
      "mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)\n",
      "maximum period of compliance at lgb (in days) (longest streak of good compliance)\n",
      "total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)\n",
      "total number of follow up at LGBRIMH\n",
      "Number of In patient cares\n",
      "total_frequency\n",
      "total_days1\n",
      "days/freq\n"
     ]
    }
   ],
   "source": [
    "column_names = df2.columns.tolist()\n",
    "for name in column_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4379a44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Primary', 'no formal education', 'nil', 'high school',\n",
       "       'others', 'primary', 'higher secondary', 'Pre primary/playschool',\n",
       "       'graduation'], dtype=object)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Max education attained'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2c1dedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "education_mapping = {\n",
    "    'Primary': 0.4,\n",
    "    'primary': 0.4,\n",
    "    'no formal education': 0,\n",
    "    'nil': 0,  # Assuming 'nil' means unknown or not specified\n",
    "    'high school': 0.6,\n",
    "    'others': 1,\n",
    "    'higher secondary': 0.6,\n",
    "    'Pre primary/playschool': 0.2,\n",
    "    'graduation': 0.8,  # Assuming 'graduation' refers to higher education beyond high school\n",
    "    np.nan: 0\n",
    "}\n",
    "\n",
    "df2['Max education attained'] = df2['Max education attained'].map(education_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c0f418ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the column name is 'Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)'\n",
    "# and the DataFrame is df2\n",
    "\n",
    "df2.drop('Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "56f9d9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rural', 'Urban', nan, 'urban', 'rural'], dtype=object)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Rural/Urban'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "61bf6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "location_mapping = {\n",
    "    'Rural': 0.5,\n",
    "    'rural': 0.5,\n",
    "    'Urban': 1,\n",
    "    'urban': 1,\n",
    "    np.nan: 9\n",
    "}\n",
    "\n",
    "# Map values in the DataFrame\n",
    "df2['Rural/Urban'] = df2['Rural/Urban'].map(location_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "972127d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>Socioeconomic status</th>\n",
       "      <th>Age at onset(in years)</th>\n",
       "      <th>Chief complaint 1</th>\n",
       "      <th>...</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Final</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>Number of In patient cares</th>\n",
       "      <th>total_frequency</th>\n",
       "      <th>total_days1</th>\n",
       "      <th>days/freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>episodes of unresponsiveness</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.66</td>\n",
       "      <td>395</td>\n",
       "      <td>626</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>577</td>\n",
       "      <td>48.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Episodes of abnormal jerky movement of body</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>Poor</td>\n",
       "      <td>1.78</td>\n",
       "      <td>240</td>\n",
       "      <td>330</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3547</td>\n",
       "      <td>886.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>episode of abnormal jerky movement with LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3547</td>\n",
       "      <td>52.940299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>LSES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inattention</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>LSES</td>\n",
       "      <td>5.5</td>\n",
       "      <td>epileptic fits</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>6.6</td>\n",
       "      <td>480</td>\n",
       "      <td>3495</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3804</td>\n",
       "      <td>54.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>delayed developmental milestones</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "      <td>2.1</td>\n",
       "      <td>648</td>\n",
       "      <td>648</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>616</td>\n",
       "      <td>61.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>LSES</td>\n",
       "      <td>16.0</td>\n",
       "      <td>suspiciousness towards parents and neighbours</td>\n",
       "      <td>...</td>\n",
       "      <td>330</td>\n",
       "      <td>Poor</td>\n",
       "      <td>3.8</td>\n",
       "      <td>113</td>\n",
       "      <td>576</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512</td>\n",
       "      <td>102.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>326.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Irrelevent Talking</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>Poor</td>\n",
       "      <td>4.3</td>\n",
       "      <td>170</td>\n",
       "      <td>384</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>354</td>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>No Memory of events, Cant recognize people</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>1.21</td>\n",
       "      <td>390</td>\n",
       "      <td>875</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>870</td>\n",
       "      <td>39.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>unable to speak</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1619</td>\n",
       "      <td>1619</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1542</td>\n",
       "      <td>61.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
       "1                             8.0                   10.0        0.0  0.000000   \n",
       "2                            17.0                   18.0        0.0  0.000000   \n",
       "3                             7.0                   17.0        1.0  0.000000   \n",
       "4                            10.0                   10.0        1.0  0.333333   \n",
       "5                             8.0                   15.0        0.0  0.000000   \n",
       "..                            ...                    ...        ...       ...   \n",
       "163                           7.0                    9.0        1.0  0.333333   \n",
       "164                          16.0                   17.0        1.0  0.000000   \n",
       "186                          15.0                   15.0        1.0  0.000000   \n",
       "187                          15.0                   17.0        1.0  0.000000   \n",
       "191                           5.0                    8.0        1.0  0.333333   \n",
       "\n",
       "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "1                       0.0          0.5                           62.0   \n",
       "2                       0.4          0.5                           55.0   \n",
       "3                       0.0          0.5                          102.0   \n",
       "4                       0.4          0.5                           29.0   \n",
       "5                       0.0          0.5                          102.0   \n",
       "..                      ...          ...                            ...   \n",
       "163                     0.0          0.5                           57.0   \n",
       "164                     0.4          0.5                          110.0   \n",
       "186                     0.6          0.5                          326.0   \n",
       "187                     0.6          0.5                           37.0   \n",
       "191                     0.4          0.5                           63.0   \n",
       "\n",
       "    Socioeconomic status  Age at onset(in years)  \\\n",
       "1                    NaN                     8.0   \n",
       "2                    NaN                    17.0   \n",
       "3                    NaN                     5.5   \n",
       "4                   LSES                     0.0   \n",
       "5                   LSES                     5.5   \n",
       "..                   ...                     ...   \n",
       "163                  NaN                     0.0   \n",
       "164                 LSES                    16.0   \n",
       "186                  NaN                    15.0   \n",
       "187                  NaN                    15.0   \n",
       "191                  NaN                     4.0   \n",
       "\n",
       "                                 Chief complaint 1  ...  \\\n",
       "1                    episodes of unresponsiveness   ...   \n",
       "2      Episodes of abnormal jerky movement of body  ...   \n",
       "3      episode of abnormal jerky movement with LOC  ...   \n",
       "4                                      inattention  ...   \n",
       "5                                   epileptic fits  ...   \n",
       "..                                             ...  ...   \n",
       "163               delayed developmental milestones  ...   \n",
       "164  suspiciousness towards parents and neighbours  ...   \n",
       "186                             Irrelevent Talking  ...   \n",
       "187    No Memory of events, Cant recognize people   ...   \n",
       "191                               unable to speak   ...   \n",
       "\n",
       "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "1                                                   22                            \n",
       "2                                                   30                            \n",
       "3                                                   58                            \n",
       "4                                                   20                            \n",
       "5                                                   65                            \n",
       "..                                                 ...                            \n",
       "163                                                  0                            \n",
       "164                                                330                            \n",
       "186                                                180                            \n",
       "187                                                120                            \n",
       "191                                                  0                            \n",
       "\n",
       "            Final  \\\n",
       "1    Satisfactory   \n",
       "2            Poor   \n",
       "3            Good   \n",
       "4            Good   \n",
       "5    Satisfactory   \n",
       "..            ...   \n",
       "163          Good   \n",
       "164          Poor   \n",
       "186          Poor   \n",
       "187  Satisfactory   \n",
       "191  Satisfactory   \n",
       "\n",
       "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "1                                                 1.66                                    \n",
       "2                                                 1.78                                    \n",
       "3                                                  NaN                                    \n",
       "4                                                    1                                    \n",
       "5                                                  6.6                                    \n",
       "..                                                 ...                                    \n",
       "163                                                2.1                                    \n",
       "164                                                3.8                                    \n",
       "186                                                4.3                                    \n",
       "187                                               1.21                                    \n",
       "191                                               2.15                                    \n",
       "\n",
       "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "1                                                  395                                  \n",
       "2                                                  240                                  \n",
       "3                                                  NaN                                  \n",
       "4                                                   90                                  \n",
       "5                                                  480                                  \n",
       "..                                                 ...                                  \n",
       "163                                                648                                  \n",
       "164                                                113                                  \n",
       "186                                                170                                  \n",
       "187                                                390                                  \n",
       "191                                               1619                                  \n",
       "\n",
       "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "1                                                  626                                                   \n",
       "2                                                  330                                                   \n",
       "3                                                 1320                                                   \n",
       "4                                                   90                                                   \n",
       "5                                                 3495                                                   \n",
       "..                                                 ...                                                   \n",
       "163                                                648                                                   \n",
       "164                                                576                                                   \n",
       "186                                                384                                                   \n",
       "187                                                875                                                   \n",
       "191                                               1619                                                   \n",
       "\n",
       "    total number of follow up at LGBRIMH Number of In patient cares  \\\n",
       "1                                   12.0                        0.0   \n",
       "2                                    4.0                        0.0   \n",
       "3                                   69.0                        0.0   \n",
       "4                                    2.0                        1.0   \n",
       "5                                   71.0                        0.0   \n",
       "..                                   ...                        ...   \n",
       "163                                 10.0                        0.0   \n",
       "164                                  5.0                        0.0   \n",
       "186                                  3.0                        0.0   \n",
       "187                                 24.0                        0.0   \n",
       "191                                 25.0                        0.0   \n",
       "\n",
       "    total_frequency total_days1   days/freq  \n",
       "1              12.0         577   48.083333  \n",
       "2               4.0        3547  886.750000  \n",
       "3              67.0        3547   52.940299  \n",
       "4               2.0         100   50.000000  \n",
       "5              70.0        3804   54.342857  \n",
       "..              ...         ...         ...  \n",
       "163            10.0         616   61.600000  \n",
       "164             5.0         512  102.400000  \n",
       "186             3.0         354  118.000000  \n",
       "187            22.0         870   39.545455  \n",
       "191            25.0        1542   61.680000  \n",
       "\n",
       "[148 rows x 263 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "290cabf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'LSES', 'HSES', 'MSES'], dtype=object)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Socioeconomic status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3b406dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ses_mapping = {\n",
    "    'LSES': 0.33,\n",
    "    'HSES': 1,\n",
    "    'MSES': 0.66,\n",
    "    np.nan: 0\n",
    "}\n",
    "df2['Socioeconomic status'] = df2['Socioeconomic status'].map(ses_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1e08e774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)\n",
      "Age at last follow up\n",
      "Sex (m/f)\n",
      "Religion\n",
      "Max education attained\n",
      "Rural/Urban\n",
      "Distance from LGBRIMH (in KM)\n",
      "Socioeconomic status\n",
      "Age at onset(in years)\n",
      "Chief complaint 1\n",
      "Chief complaint 2\n",
      "Chief complaint 3\n",
      "Time period between onset to first consultation at LGBRIMH (DUI) (in days)\n",
      "Type of Family (Nuclear/Joint/single parent/orphan/ foster family\n",
      "Family environment\n",
      "Details of family abnormality (describe)\n",
      "Family h/o stillbirth/abortion\n",
      "Family history(general medical)\n",
      "Family history (psychiatric/neurological)\n",
      "Faith healer visited before consultation or not(yes/no)\n",
      "Antenatal risk factor\n",
      "Place of delivery (Home/hospital)\n",
      "Birth weight(in kg)\n",
      "Neonatal complication\n",
      "Postnatal complication\n",
      "Developmental history\n",
      "Age of school entry(in years)\n",
      "Type of school\n",
      "School adjustment\n",
      "Academic performance\n",
      "School dropout present (yes/no)\n",
      "Detail of past psychiatric history 1\n",
      "Past treatment 1\n",
      "Past treatment medication 1\n",
      "Starting dose past medication 1\n",
      "Age of starting of past medication 1(in years)\n",
      "Past maintenance dose1 (in mg)\n",
      "Side effects of past medication 1\n",
      "Age of occurance past side effects 1(in years)\n",
      "Duration of past side effect 1(in months)\n",
      "Response to past medication 1\n",
      "Detail of past history 2\n",
      "Past treatment 2\n",
      "Past treatment medication 2\n",
      "Starting dose past medication 2\n",
      "Age of starting of past medication 2(in years)\n",
      "Past maintenance dose2\n",
      "Side effects of past medication 2\n",
      "Age of occurance past side effects 2(in years)\n",
      "Duration of past side effect 2(in months)\n",
      "Response to past medication 2\n",
      "Detail of past history 3\n",
      "Past treatment  3\n",
      "Past treatment medication 3\n",
      "Starting dose past medication 3 \n",
      "Age of starting past medication 3 (in years)\n",
      "Past maintenance dose 3\n",
      "Side effects past medication 3\n",
      "Age of occurance of past side effects 3 (in years)\n",
      "Duration of past side effects 3 (in months)\n",
      "Response to past medication 3\n",
      "Change in doctor\n",
      "Past/Current medical conditions\n",
      "Age of onset of medical conditions (in years)\n",
      "Details of medical conditions\n",
      "Treatments for medical conditions\n",
      "Severity of medical conditions\n",
      "weight (in Kg)\n",
      "weight z score\n",
      "height (in cm)\n",
      "height z score\n",
      "head circumference (in cm)\n",
      "head circumference z score\n",
      "systemic examination(abnormal/normal)\n",
      "systemic examination details (main finding only)\n",
      "Mental status examination/Behavioral Observation details (abnormal/normal)\n",
      "Mental status examination/Behavioral observation details (main finding only in description)\n",
      "Screening diagnosis \n",
      "detailed workup diagnosis\n",
      "Follow up diagnosis changed or not (yes/no)\n",
      "If yes, changed once or multiple times (once/multiple)\n",
      "If yes, after how many days from first presentation diagnosis changed (in days)\n",
      "If yes, diagnosis changed to what\n",
      "Axis 1_1\n",
      "Axis 1_2\n",
      "Axis 1_3\n",
      "Axis 1_4\n",
      "Axis 2\n",
      "Axis 3\n",
      "Axis 4_1\n",
      "Axis 4_2\n",
      "Axis 4_3\n",
      "Axis 5\n",
      "significant psychosocial stressor\n",
      "name of Medication 1\n",
      "medication 1 starting dose (in mg)\n",
      "Avg dose of medication 1 (Mode value of medication) (in mg)\n",
      "Maximum dose of medication 1 (in mg)\n",
      "Total duration of medication 1 (in days) \n",
      "Continued medication 1/stopped/changed\n",
      "Response to medication 1 (Good/partial/no)\n",
      "Side effect of medication 1\n",
      "onset of side effect post starting med 1 ( in days)\n",
      "total duration of side effect of medication 1 (in days)\n",
      "Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) \n",
      "name of Medication 2\n",
      "Medication 2 starting dose (in mg)\n",
      "Avg dose of medication 2 (in mg)\n",
      "Maximum dose of medication 2 (in mg)\n",
      "Total duration of medication 2(in days) \n",
      "Continued medication 2/stopped/changed\n",
      "Response to medication 2 (Good/partial/no)\n",
      "Side effect of medication 2\n",
      "onset of side effect post starting med 2 ( in days)\n",
      "total duration of side effect of medication 2 (in days)\n",
      "Medication possession ratios 2(MPRs) in lgb;x-syrup\n",
      "name of Medication 3\n",
      "Medication 3 starting dose (in mg)\n",
      "Avg dose of medication 3 (in mg)\n",
      "Maximum dose of medication 3 (in mg)\n",
      "Total duration of medication 3 (in days\n",
      "continued medication 3/stopped/changed\n",
      "Response to medication 3 (Good/partial/no)\n",
      "Side effect of medication 3\n",
      "onset of side effect post starting med 3 ( in days)\n",
      "total duration of side effect of medication 3 (in days)\n",
      "Medication possession ratios 3(MPRs) in lgb;x-syrup\n",
      "name of Medication 4\n",
      "Medication 4 starting dose (in mg)\n",
      "Avg dose of medication 4 (in mg)\n",
      "Maximum dose of medication 4 (in mg)\n",
      "Total duration of medication 4 (in days)\n",
      "continued medication 4/stopped/changed\n",
      "Response to medication 4(Good/partial/no)\n",
      "Side effect of medication 4\n",
      "onset of side effect post starting med 4 ( in days)\n",
      "total duration of side effect of medication 4 (in days)\n",
      "Medication possession ratios 4(MPRs) in lgb;x-syrup\n",
      "name of Medication 5\n",
      "Medication 5 starting dose (in mg)\n",
      "Avg dose of medication 5 (in mg)\n",
      "Maximum dose of medication 5(in mg)\n",
      "Total duration of medication 5 (in days)\n",
      "continued medication 5/stopped/changed\n",
      "Response to medication 5(Good/partial/no)\n",
      "Side effect of medication 5\n",
      "onset of side effect post starting med 5 ( in days)\n",
      "total duration of side effect of medication 5 (in days)\n",
      "Medication possession ratios 5(MPRs) in lgb;x-syrup\n",
      "name of Medication 6\n",
      "Medication 6 starting dose\n",
      "Avg dose of medication 6\n",
      "Maximum dose of medication 6\n",
      "Total duration of medication 6\n",
      "continued medication 6/stopped/changed\n",
      "Response to medication 6(Good/partial/no)\n",
      "Side effect of medication 6\n",
      "onset of side effect post starting med 6 ( in days)\n",
      "total duration of side effect of medication 6 (in days)\n",
      "Medication possession ratios 6(MPRs) in lgb;x-syrup\n",
      "name of Medication 7\n",
      "Medication 7 starting dose\n",
      "Avg dose of medication 7\n",
      "Maximum dose of medication 7\n",
      "Total duration of medication 7\n",
      "continued medication 7/stopped/changed\n",
      "Response to medication 7(Good/partial/no)\n",
      "Side effect of medication 7\n",
      "onset of side effect post starting med 7 ( in days)\n",
      "total duration of side effect of medication 7 (in days)\n",
      "Medication possession ratios 7(MPRs) in lgb;x-syrup\n",
      "name of Medication 8\n",
      "Medication 8 starting dose\n",
      "Avg dose of medication 8\n",
      "Maximum dose of medication 8\n",
      "Total duration of medication 8\n",
      "Continued medication 8/stopped/changed\n",
      "Response to medication 8(Good/partial/no)\n",
      "Side effect of medication 8\n",
      "onset of side effect post starting med 8 ( in days)\n",
      "total duration of side effect of medication 8 (in days)\n",
      "Medication possession ratios 8(MPRs) in lgb;x-syrup\n",
      "name of Medication 9\n",
      "Medication 9 starting dose\n",
      "Avg dose of medication 9\n",
      "Maximum dose of medication 9\n",
      "Total duration of medication 9\n",
      "continued medication 9/stopped/changed\n",
      "Response to medication 9(Good/partial/no)\n",
      "Side effect of medication 9\n",
      "onset of side effect post starting med 9 ( in days)\n",
      "total duration of side effect of medication 9 (in days)\n",
      "Medication possession ratios 9(MPRs) in lgb;x-syrup\n",
      "name of Medication 10\n",
      "Medication 10 starting dose\n",
      "Avg dose of medication 10\n",
      "Maximum dose of medication 10\n",
      "Total duration of medication 10\n",
      "continued medication 10/stopped/changed\n",
      "Response to medication 10(Good/partial/no)\n",
      "Side effect of medication 10\n",
      "onset of side effect post starting med 10 ( in days)\n",
      "total duration of side effect of medication 10 (in days)\n",
      "Medication possession ratios 10(MPRs) in lgb;x-syrup\n",
      "name of Medication 11\n",
      "Medication 11 starting dose\n",
      "Avg dose of medication 11\n",
      "Maximum dose of medication 11\n",
      "Total duration of medication 11\n",
      "continued medication 11/stopped/changed\n",
      "Response to medication 11(Good/partial/no)\n",
      "Side effect of medication 11\n",
      "onset of side effect post starting med 11 ( in days)\n",
      "total duration of side effect of medication 11 (in days)\n",
      "Medication possession ratios 11(MPRs) in lgb;x-syrup\n",
      "name of Medication 12\n",
      "Medication 12 starting dose\n",
      "Avg dose of medication 12\n",
      "Maximum dose of medication 12\n",
      "Total duration of medication 12\n",
      "continued medication 12/stopped/changed\n",
      "Response to medication 12(Good/partial/no)\n",
      "Side effect of medication 12\n",
      "onset of side effect post starting med 12 ( in days)\n",
      "total duration of side effect of medication 12 (in days)\n",
      "Medication possession ratios 12(MPRs) in lgb;x-syrup\n",
      "name of Medication 13\n",
      "Medication 13 starting dose\n",
      "Avg dose of medication 13\n",
      "Maximum dose of medication 13\n",
      "Total duration of medication 13\n",
      "continued medication 13/stopped/changed\n",
      "Response to medication 13(Good/partial/no)\n",
      "Side effect of medication 13\n",
      "onset of side effect post starting med 13 ( in days)\n",
      "total duration of side effect of medication 13 (in days)\n",
      "Medication possession ratios 13(MPRs) in lgb;x-syrup\n",
      "name of Medication 14\n",
      "Medication 14 starting dose\n",
      "Avg dose of medication 14\n",
      "Maximum dose of medication 14\n",
      "Total duration of medication 14\n",
      "continued medication 14/stopped/changed\n",
      "Response to medication 14(Good/partial/no)\n",
      "Side effect of medication 14\n",
      "onset of side effect post starting med 14 ( in days)\n",
      "total duration of side effect of medication 14 (in days)\n",
      "Medication possession ratios 14(MPRs) in lgb;x-syrup\n",
      "cost of medication\n",
      "Other treatments(rehabilitative intervention/IT/CBT/ipt/FT/PMT/BEHAVIOURAL INTERVENTIONS FOR DEVELOPMENTAL DISORDERS, Combination therapy)\n",
      "Maximum duration of symptom free period (in days)\n",
      "Max Duration of resolution of symptoms before recurrence/relapse (in days)\n",
      "No of relapses/exacerbations\n",
      "Off-medications duration (to add all such durations over follow-up in days)\n",
      "Final\n",
      "mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)\n",
      "maximum period of compliance at lgb (in days) (longest streak of good compliance)\n",
      "total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)\n",
      "total number of follow up at LGBRIMH\n",
      "Number of In patient cares\n",
      "total_frequency\n",
      "total_days1\n",
      "days/freq\n"
     ]
    }
   ],
   "source": [
    "column_names = df2.columns.tolist()\n",
    "for name in column_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1b2d6aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['episodes of unresponsiveness ',\n",
       "       'Episodes of abnormal jerky movement of body',\n",
       "       'episode of abnormal jerky movement with LOC', 'inattention',\n",
       "       'epileptic fits', 'abnormal jerky movements with fall',\n",
       "       'abnormal movement of body with deviation of face to opposite side',\n",
       "       'Delayed speech', 'Abnormal jerky movements',\n",
       "       'Episodes of loss of consciousness', 'persistent low mood',\n",
       "       'anger outburst', 'episodes of loss of consciousness',\n",
       "       'jerks of hands and legs', 'overactivity',\n",
       "       'jerky movement of limbs', 'episodes of LOC',\n",
       "       'generalised weakness', 'involuntary movements of hands and feet',\n",
       "       'irritability', 'aggressiveness',\n",
       "       'decreased interest in studies and poor academic performance',\n",
       "       'Excessive talking with tall talks', 'decrease talk',\n",
       "       'school refusal', 'delayed developmental milestones',\n",
       "       'Episodes ofinvoluntary jerky movements of the body',\n",
       "       'Poor self care activity and forgetful after learning',\n",
       "       'Self crying',\n",
       "       'abnormal jerky movements with loss of conciousness',\n",
       "       'sudden jerky movemnts of body', 'abnormal jerky movements',\n",
       "       'does not obey commands, verbally abusive', 'irrelevant talk',\n",
       "       'intake of cannabis once', 'tall claim', 'Tightening of body',\n",
       "       'fearfulness', 'low social interaction', 'Unable to care for self',\n",
       "       'unconscious with abnormal body movement', 'withdrawan to self',\n",
       "       'Reduce social interaction', 'Dizziness',\n",
       "       'Delay in developmental milestones', 'feeling of unreality',\n",
       "       'headache', 'decreased interest in studies', 'low intelligence',\n",
       "       'tonic clonic movement of the body',\n",
       "       'Involuntary jerky movement of whole body', 'Silly talking',\n",
       "       'increased anger outbursts',\n",
       "       'abnormal jerky movements of right upper and lower limbs',\n",
       "       'demand money', 'delayed speech',\n",
       "       'Not able to speak since childhood', 'jerky movement ',\n",
       "       'Decreased sleep and appetite', 'complain from school',\n",
       "       'Not able to speak', 'decreased self care',\n",
       "       'abnormal movements of all 4 limbs', 'Decrease sleep',\n",
       "       'headache, dizziness',\n",
       "       'sudden jerky movemnts of body with loss of consciousness',\n",
       "       'generalized fits',\n",
       "       'Poor understanding, Restlessness and inattention',\n",
       "       'Does not respond to queries', 'Excessive use of mobile',\n",
       "       'Does not respond to query', 'altered consciousness',\n",
       "       'Fearfulness', 'jerky movements with loss of awareness',\n",
       "       'excessiv ecrying ', 'disturbed sleep', 'fearfullness',\n",
       "       'decreased social interaction', 'Poor undersanding',\n",
       "       'difficulty in reading and writing', 'overtalkativeness',\n",
       "       'delay developmental milestone',\n",
       "       'does not speak more than one word',\n",
       "       'sudden loss of consciousness', 'not speaking adequet for age ',\n",
       "       'blank stare after getting up suddenly from sleep',\n",
       "       'smiling and muttering to self',\n",
       "       'episodes of abnormal body movements',\n",
       "       'abnormal jerky movement of body with tightening of right side of body',\n",
       "       'abnormal jerky movement of body with loss of consciousness',\n",
       "       'hoarding of inner garments',\n",
       "       'rigidity of all four limbs while sleeping', 'irrelevant talking',\n",
       "       'wandresome behaviour', 'Self muttering and self laughing',\n",
       "       'unable to speak properly', 'poor academic performance ',\n",
       "       'clenching of fist',\n",
       "       'delayed language development and required assistance in daily activities',\n",
       "       'involuntary jerky movements of both upper and lower limbs',\n",
       "       'decreased academic perforamnce',\n",
       "       'involuntary jerky movements of head and legs',\n",
       "       'hyperactivity and restlessness', 'Self absorbed behavior',\n",
       "       'Making unusual sounds and abnormal movements of limbs and eyes',\n",
       "       'sudden jerky movement of body',\n",
       "       'hearing of voices not heard by other',\n",
       "       'involuntary jerky movements of hands and legs',\n",
       "       'jerky movements of bilateral upper and lower limbs',\n",
       "       'repeated complain from school',\n",
       "       'abnormal jerky movements of body',\n",
       "       \"doesn't go to school regularly\",\n",
       "       'Episodesof generalized abnormal jerky movement ',\n",
       "       'loss of consciousness ', 'poor comprehension',\n",
       "       'reduced level of intellectual functioning',\n",
       "       'tightening of hands and leg',\n",
       "       'jerky movements of body with frothing, tongue bite',\n",
       "       'Episodes of jerky movements of body with loss of consciousness',\n",
       "       'Poor comprehension', 'pervasive low mood, irritability',\n",
       "       'Fearfullness', 'poor social interaction', 'low mood',\n",
       "       'suspiciousness towards parents and neighbours',\n",
       "       'Irrelevent Talking',\n",
       "       'No Memory of events, Cant recognize people ', 'unable to speak '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Chief complaint 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5d446d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...         Final  \\\n",
      "1                    episodes of unresponsiveness   ...  Satisfactory   \n",
      "2      Episodes of abnormal jerky movement of body  ...          Poor   \n",
      "3      episode of abnormal jerky movement with LOC  ...          Good   \n",
      "4                                      inattention  ...          Good   \n",
      "5                                   epileptic fits  ...  Satisfactory   \n",
      "..                                             ...  ...           ...   \n",
      "163               delayed developmental milestones  ...          Good   \n",
      "164  suspiciousness towards parents and neighbours  ...          Poor   \n",
      "186                             Irrelevent Talking  ...          Poor   \n",
      "187    No Memory of events, Cant recognize people   ...  Satisfactory   \n",
      "191                               unable to speak   ...  Satisfactory   \n",
      "\n",
      "    mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
      "1                                                 1.66                                    \n",
      "2                                                 1.78                                    \n",
      "3                                                  NaN                                    \n",
      "4                                                    1                                    \n",
      "5                                                  6.6                                    \n",
      "..                                                 ...                                    \n",
      "163                                                2.1                                    \n",
      "164                                                3.8                                    \n",
      "186                                                4.3                                    \n",
      "187                                               1.21                                    \n",
      "191                                               2.15                                    \n",
      "\n",
      "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
      "1                                                  395                                  \n",
      "2                                                  240                                  \n",
      "3                                                  NaN                                  \n",
      "4                                                   90                                  \n",
      "5                                                  480                                  \n",
      "..                                                 ...                                  \n",
      "163                                                648                                  \n",
      "164                                                113                                  \n",
      "186                                                170                                  \n",
      "187                                                390                                  \n",
      "191                                               1619                                  \n",
      "\n",
      "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
      "1                                                  626                                                   \n",
      "2                                                  330                                                   \n",
      "3                                                 1320                                                   \n",
      "4                                                   90                                                   \n",
      "5                                                 3495                                                   \n",
      "..                                                 ...                                                   \n",
      "163                                                648                                                   \n",
      "164                                                576                                                   \n",
      "186                                                384                                                   \n",
      "187                                                875                                                   \n",
      "191                                               1619                                                   \n",
      "\n",
      "    total number of follow up at LGBRIMH Number of In patient cares  \\\n",
      "1                                   12.0                        0.0   \n",
      "2                                    4.0                        0.0   \n",
      "3                                   69.0                        0.0   \n",
      "4                                    2.0                        1.0   \n",
      "5                                   71.0                        0.0   \n",
      "..                                   ...                        ...   \n",
      "163                                 10.0                        0.0   \n",
      "164                                  5.0                        0.0   \n",
      "186                                  3.0                        0.0   \n",
      "187                                 24.0                        0.0   \n",
      "191                                 25.0                        0.0   \n",
      "\n",
      "    total_frequency total_days1   days/freq    cc1  \n",
      "1              12.0         577   48.083333  Other  \n",
      "2               4.0        3547  886.750000  Other  \n",
      "3              67.0        3547   52.940299  Other  \n",
      "4               2.0         100   50.000000  Other  \n",
      "5              70.0        3804   54.342857  Other  \n",
      "..              ...         ...         ...    ...  \n",
      "163            10.0         616   61.600000  Other  \n",
      "164             5.0         512  102.400000  Other  \n",
      "186             3.0         354  118.000000  Other  \n",
      "187            22.0         870   39.545455  Other  \n",
      "191            25.0        1542   61.680000  Other  \n",
      "\n",
      "[148 rows x 264 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "df2['cc1'] = ''\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for index, row in df2.iterrows():\n",
    "    text = str(row['Chief complaint 1'])\n",
    "    tokens = [word.lower() for word in word_tokenize(text) if word.isalpha() and word.lower() not in stop_words]\n",
    "    keywords = [word for word, count in Counter(tokens).items() if count > 1]  # Adjust frequency threshold as needed\n",
    "    df2.at[index, 'cc1'] = ', '.join(keywords)\n",
    "df2['cc1'] = df2['cc1'].replace('', 'Other')\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f3a78ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2.drop('cc1', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ca978a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Chief complaint 1 keywords\n",
      "1                    episodes of unresponsiveness        []\n",
      "2      Episodes of abnormal jerky movement of body       []\n",
      "3      episode of abnormal jerky movement with LOC       []\n",
      "4                                      inattention       []\n",
      "5                                   epileptic fits       []\n",
      "..                                             ...      ...\n",
      "163               delayed developmental milestones       []\n",
      "164  suspiciousness towards parents and neighbours       []\n",
      "186                             Irrelevent Talking       []\n",
      "187    No Memory of events, Cant recognize people        []\n",
      "191                               unable to speak        []\n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def extract_keywords(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(text) if word.isalpha() and word.lower() not in stop_words]\n",
    "    keywords = [word for word, count in Counter(tokens).items() if count > 1]  \n",
    "    return keywords\n",
    "\n",
    "df2['keywords'] = df2['Chief complaint 1'].apply(extract_keywords)\n",
    "print(df2[['Chief complaint 1', 'keywords']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3aecdfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nil', 44), ('self', 37), ('jerky', 35), ('body', 28), ('movements', 25), ('behaviour', 23), ('abnormal', 22), ('poor', 22), ('decreased', 22), ('anger', 19)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "df2['combined_complaints'] = df2['Chief complaint 1'].fillna('') + ' ' + df2['Chief complaint 2'].fillna('') + ' ' + df2['Chief complaint 3'].fillna('')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def extract_keywords(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(text) if word.isalpha() and word.lower() not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "df2['combined_keywords'] = df2['combined_complaints'].apply(extract_keywords)\n",
    "\n",
    "all_tokens = [token for sublist in df2['combined_keywords'].tolist() for token in sublist]\n",
    "\n",
    "word_counts = Counter(all_tokens)\n",
    "\n",
    "print(word_counts.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "31706955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodes: 11\n",
      "unresponsiveness: 1\n",
      "nil: 44\n",
      "abnormal: 22\n",
      "jerky: 35\n",
      "movement: 17\n",
      "body: 28\n",
      "poor: 22\n",
      "scholastic: 2\n",
      "performance: 7\n",
      "episode: 2\n",
      "loc: 2\n",
      "left: 1\n",
      "sided: 3\n",
      "weakness: 6\n",
      "inattention: 3\n",
      "hyperactivity: 3\n",
      "mscholastic: 1\n",
      "epileptic: 1\n",
      "fits: 2\n",
      "movements: 25\n",
      "fall: 2\n",
      "removes: 1\n",
      "clothes: 1\n",
      "deviation: 2\n",
      "face: 1\n",
      "opposite: 1\n",
      "side: 2\n",
      "urinary: 2\n",
      "stream: 1\n",
      "difficulty: 4\n",
      "urination: 2\n",
      "delayed: 8\n",
      "speech: 4\n",
      "self: 37\n",
      "care: 6\n",
      "identify: 1\n",
      "colours: 1\n",
      "anger: 19\n",
      "outbursts: 5\n",
      "speak: 6\n",
      "words: 1\n",
      "toilet: 1\n",
      "training: 1\n",
      "attained: 1\n",
      "loss: 17\n",
      "consciousness: 14\n",
      "persistent: 1\n",
      "low: 8\n",
      "mood: 4\n",
      "decreased: 22\n",
      "interest: 7\n",
      "pleasureable: 1\n",
      "activities: 4\n",
      "food: 2\n",
      "intake: 3\n",
      "outburst: 4\n",
      "restlesness: 1\n",
      "unconsciousness: 3\n",
      "jerks: 1\n",
      "hands: 6\n",
      "legs: 6\n",
      "irrelevant: 14\n",
      "talk: 15\n",
      "reduced: 7\n",
      "sleep: 17\n",
      "abusive: 4\n",
      "overtalkativeness: 2\n",
      "physical: 1\n",
      "abuse: 2\n",
      "verbal: 1\n",
      "overactivity: 1\n",
      "response: 1\n",
      "vocal: 1\n",
      "stimuli: 1\n",
      "less: 1\n",
      "engaged: 1\n",
      "one: 6\n",
      "interaction: 7\n",
      "limbs: 12\n",
      "whole: 7\n",
      "frothing: 6\n",
      "generalised: 1\n",
      "restlessness: 15\n",
      "involuntary: 9\n",
      "feet: 1\n",
      "irritability: 14\n",
      "sit: 1\n",
      "place: 3\n",
      "fights: 2\n",
      "peers: 2\n",
      "aggressiveness: 1\n",
      "suspiciousness: 5\n",
      "concentration: 2\n",
      "studies: 6\n",
      "academic: 5\n",
      "withdrawn: 2\n",
      "behaviour: 23\n",
      "esteem: 1\n",
      "excessive: 2\n",
      "talking: 7\n",
      "tall: 2\n",
      "talks: 2\n",
      "disturbances: 1\n",
      "increased: 13\n",
      "decrease: 3\n",
      "irrelevent: 2\n",
      "school: 7\n",
      "refusal: 3\n",
      "wandersome: 6\n",
      "developmental: 6\n",
      "milestones: 6\n",
      "harm: 2\n",
      "ofinvoluntary: 1\n",
      "activity: 4\n",
      "forgetful: 1\n",
      "learning: 2\n",
      "verbally: 4\n",
      "physically: 2\n",
      "mild: 1\n",
      "provocation: 3\n",
      "play: 2\n",
      "crying: 2\n",
      "smilling: 6\n",
      "conciousness: 1\n",
      "sudden: 5\n",
      "movemnts: 2\n",
      "injurious: 1\n",
      "obey: 1\n",
      "commands: 1\n",
      "roaming: 1\n",
      "aimlesless: 1\n",
      "trivial: 2\n",
      "issues: 4\n",
      "cannabis: 2\n",
      "fearfullness: 7\n",
      "taking: 1\n",
      "misidentifying: 1\n",
      "family: 5\n",
      "members: 1\n",
      "claim: 1\n",
      "talkativeness: 3\n",
      "tightening: 4\n",
      "doesnot: 2\n",
      "respond: 4\n",
      "called: 2\n",
      "eye: 1\n",
      "contact: 1\n",
      "fearfulness: 5\n",
      "inetlligence: 1\n",
      "social: 8\n",
      "muttering: 7\n",
      "unable: 4\n",
      "blaming: 1\n",
      "molesting: 1\n",
      "unconscious: 1\n",
      "understanding: 4\n",
      "withdrawan: 1\n",
      "reading: 2\n",
      "writing: 3\n",
      "laughing: 4\n",
      "reduce: 1\n",
      "hearing: 3\n",
      "voice: 1\n",
      "heard: 3\n",
      "dizziness: 3\n",
      "senselesseness: 1\n",
      "delay: 3\n",
      "feeling: 1\n",
      "unreality: 1\n",
      "headache: 3\n",
      "attention: 1\n",
      "somatic: 1\n",
      "complain: 3\n",
      "forgetting: 1\n",
      "studied: 1\n",
      "material: 1\n",
      "continuous: 1\n",
      "small: 1\n",
      "quantity: 1\n",
      "intelligence: 1\n",
      "tonic: 1\n",
      "clonic: 1\n",
      "irritable: 1\n",
      "issue: 1\n",
      "right: 4\n",
      "neck: 1\n",
      "uprolling: 1\n",
      "eyes: 3\n",
      "silly: 2\n",
      "withdrawal: 2\n",
      "disobediency: 1\n",
      "demanding: 5\n",
      "stubborn: 1\n",
      "upper: 3\n",
      "lower: 4\n",
      "demand: 1\n",
      "money: 1\n",
      "listen: 1\n",
      "member: 2\n",
      "go: 3\n",
      "known: 1\n",
      "person: 1\n",
      "able: 2\n",
      "since: 1\n",
      "childhood: 1\n",
      "mouth: 5\n",
      "appetite: 3\n",
      "aggressive: 3\n",
      "listening: 2\n",
      "parent: 2\n",
      "seating: 2\n",
      "seeing: 1\n",
      "things: 1\n",
      "seen: 1\n",
      "distractible: 1\n",
      "hyperactive: 2\n",
      "letters: 1\n",
      "repeatedly: 1\n",
      "destructive: 3\n",
      "behavior: 10\n",
      "generalized: 3\n",
      "harming: 4\n",
      "spitting: 1\n",
      "flashbacks: 1\n",
      "drowning: 1\n",
      "voices: 2\n",
      "others: 1\n",
      "queries: 1\n",
      "use: 1\n",
      "mobile: 1\n",
      "query: 1\n",
      "repeatitive: 1\n",
      "uttering: 1\n",
      "work: 1\n",
      "pharase: 1\n",
      "altered: 1\n",
      "withdrwan: 1\n",
      "disorganised: 1\n",
      "awareness: 2\n",
      "excessiv: 1\n",
      "ecrying: 1\n",
      "motor: 1\n",
      "milestone: 2\n",
      "disturbed: 1\n",
      "wandering: 3\n",
      "rolling: 1\n",
      "foul: 1\n",
      "smelling: 1\n",
      "coming: 1\n",
      "undersanding: 1\n",
      "abussive: 1\n",
      "towards: 4\n",
      "mother: 1\n",
      "following: 1\n",
      "direction: 1\n",
      "momentary: 1\n",
      "stop: 1\n",
      "became: 1\n",
      "film: 1\n",
      "actor: 1\n",
      "toward: 1\n",
      "dependent: 1\n",
      "memebers: 1\n",
      "feeding: 1\n",
      "word: 1\n",
      "interact: 1\n",
      "otrhers: 1\n",
      "post: 1\n",
      "ictal: 1\n",
      "confusion: 1\n",
      "speaking: 1\n",
      "adequet: 1\n",
      "age: 1\n",
      "group: 1\n",
      "blank: 1\n",
      "stare: 1\n",
      "getting: 1\n",
      "suddenly: 1\n",
      "palpitations: 1\n",
      "shortness: 1\n",
      "breath: 1\n",
      "smiling: 1\n",
      "need: 1\n",
      "assistance: 2\n",
      "help: 1\n",
      "hoarding: 1\n",
      "inner: 1\n",
      "garments: 1\n",
      "intellectual: 2\n",
      "ability: 1\n",
      "rigidity: 2\n",
      "four: 1\n",
      "sleeping: 2\n",
      "wandresome: 1\n",
      "misidentification: 1\n",
      "productivity: 1\n",
      "properly: 1\n",
      "irritabilty: 1\n",
      "clenching: 2\n",
      "fist: 1\n",
      "apprehension: 2\n",
      "language: 2\n",
      "development: 1\n",
      "required: 1\n",
      "daily: 2\n",
      "repeated: 2\n",
      "asking: 1\n",
      "questions: 1\n",
      "problems: 1\n",
      "phsycal: 1\n",
      "aggression: 1\n",
      "skin: 1\n",
      "picking: 1\n",
      "perforamnce: 1\n",
      "withouth: 1\n",
      "consumption: 1\n",
      "alcohol: 1\n",
      "tobacco: 1\n",
      "product: 1\n",
      "teeth: 1\n",
      "head: 1\n",
      "followed: 1\n",
      "needs: 1\n",
      "assistant: 1\n",
      "absorbed: 1\n",
      "singing: 1\n",
      "inappropriate: 1\n",
      "gesture: 1\n",
      "making: 1\n",
      "unusual: 1\n",
      "sounds: 1\n",
      "disinterst: 1\n",
      "pain: 1\n",
      "fearfullenss: 1\n",
      "villager: 1\n",
      "bilateral: 1\n",
      "teacher: 1\n",
      "passage: 1\n",
      "urine: 1\n",
      "regularly: 1\n",
      "parents: 2\n",
      "episodesof: 1\n",
      "bowel: 1\n",
      "incontinence: 1\n",
      "staring: 1\n",
      "looking: 1\n",
      "comprehension: 3\n",
      "banging: 1\n",
      "door: 1\n",
      "wall: 1\n",
      "level: 3\n",
      "functioning: 1\n",
      "leg: 1\n",
      "tongue: 1\n",
      "bite: 1\n",
      "easy: 1\n",
      "regression: 1\n",
      "disruptive: 1\n",
      "crossing: 1\n",
      "angry: 1\n",
      "overtalkativenesss: 2\n",
      "grooming: 1\n",
      "pervasive: 1\n",
      "reaction: 1\n",
      "people: 2\n",
      "frequent: 1\n",
      "regarding: 1\n",
      "exam: 1\n",
      "neighbours: 1\n",
      "memory: 1\n",
      "events: 1\n",
      "cant: 1\n",
      "recognize: 1\n",
      "study: 1\n",
      "decreassed: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df2['combined_complaints'] = df2['Chief complaint 1'].fillna('') + ' ' + df2['Chief complaint 2'].fillna('') + ' ' + df2['Chief complaint 3'].fillna('')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def extract_keywords(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(text) if word.isalpha() and word.lower() not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "df2['combined_keywords'] = df2['combined_complaints'].apply(extract_keywords)\n",
    "\n",
    "\n",
    "all_tokens = [token for sublist in df2['combined_keywords'].tolist() for token in sublist]\n",
    "\n",
    "word_counts = Counter(all_tokens)\n",
    "\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(f'{word}: {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fd796fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nil: 44\n",
      "self: 37\n",
      "jerky: 35\n",
      "body: 28\n",
      "movements: 25\n",
      "behaviour: 23\n",
      "abnormal: 22\n",
      "poor: 22\n",
      "decreased: 22\n",
      "anger: 19\n",
      "movement: 17\n",
      "loss: 17\n",
      "sleep: 17\n",
      "talk: 15\n",
      "restlessness: 15\n",
      "consciousness: 14\n",
      "irrelevant: 14\n",
      "irritability: 14\n",
      "increased: 13\n",
      "limbs: 12\n",
      "episodes: 11\n",
      "behavior: 10\n",
      "involuntary: 9\n",
      "delayed: 8\n",
      "low: 8\n",
      "social: 8\n",
      "performance: 7\n",
      "interest: 7\n",
      "reduced: 7\n",
      "interaction: 7\n",
      "whole: 7\n",
      "talking: 7\n",
      "school: 7\n",
      "fearfullness: 7\n",
      "muttering: 7\n",
      "weakness: 6\n",
      "care: 6\n",
      "speak: 6\n",
      "hands: 6\n",
      "legs: 6\n",
      "one: 6\n",
      "frothing: 6\n",
      "studies: 6\n",
      "wandersome: 6\n",
      "developmental: 6\n",
      "milestones: 6\n",
      "smilling: 6\n",
      "outbursts: 5\n",
      "suspiciousness: 5\n",
      "academic: 5\n",
      "sudden: 5\n",
      "family: 5\n",
      "fearfulness: 5\n",
      "demanding: 5\n",
      "mouth: 5\n",
      "difficulty: 4\n",
      "speech: 4\n",
      "mood: 4\n",
      "activities: 4\n",
      "outburst: 4\n",
      "abusive: 4\n",
      "activity: 4\n",
      "verbally: 4\n",
      "issues: 4\n",
      "tightening: 4\n",
      "respond: 4\n",
      "unable: 4\n",
      "understanding: 4\n",
      "laughing: 4\n",
      "right: 4\n",
      "lower: 4\n",
      "harming: 4\n",
      "towards: 4\n",
      "sided: 3\n",
      "inattention: 3\n",
      "hyperactivity: 3\n",
      "intake: 3\n",
      "unconsciousness: 3\n",
      "place: 3\n",
      "decrease: 3\n",
      "refusal: 3\n",
      "provocation: 3\n",
      "talkativeness: 3\n",
      "writing: 3\n",
      "hearing: 3\n",
      "heard: 3\n",
      "dizziness: 3\n",
      "delay: 3\n",
      "headache: 3\n",
      "complain: 3\n",
      "eyes: 3\n",
      "upper: 3\n",
      "go: 3\n",
      "appetite: 3\n",
      "aggressive: 3\n",
      "destructive: 3\n",
      "generalized: 3\n",
      "wandering: 3\n",
      "comprehension: 3\n",
      "level: 3\n",
      "scholastic: 2\n",
      "episode: 2\n",
      "loc: 2\n",
      "fits: 2\n",
      "fall: 2\n",
      "deviation: 2\n",
      "side: 2\n",
      "urinary: 2\n",
      "urination: 2\n",
      "food: 2\n",
      "overtalkativeness: 2\n",
      "abuse: 2\n",
      "fights: 2\n",
      "peers: 2\n",
      "concentration: 2\n",
      "withdrawn: 2\n",
      "excessive: 2\n",
      "tall: 2\n",
      "talks: 2\n",
      "irrelevent: 2\n",
      "harm: 2\n",
      "learning: 2\n",
      "physically: 2\n",
      "play: 2\n",
      "crying: 2\n",
      "movemnts: 2\n",
      "trivial: 2\n",
      "cannabis: 2\n",
      "doesnot: 2\n",
      "called: 2\n",
      "reading: 2\n",
      "silly: 2\n",
      "withdrawal: 2\n",
      "member: 2\n",
      "able: 2\n",
      "listening: 2\n",
      "parent: 2\n",
      "seating: 2\n",
      "hyperactive: 2\n",
      "voices: 2\n",
      "awareness: 2\n",
      "milestone: 2\n",
      "assistance: 2\n",
      "intellectual: 2\n",
      "rigidity: 2\n",
      "sleeping: 2\n",
      "clenching: 2\n",
      "apprehension: 2\n",
      "language: 2\n",
      "daily: 2\n",
      "repeated: 2\n",
      "parents: 2\n",
      "overtalkativenesss: 2\n",
      "people: 2\n",
      "unresponsiveness: 1\n",
      "left: 1\n",
      "mscholastic: 1\n",
      "epileptic: 1\n",
      "removes: 1\n",
      "clothes: 1\n",
      "face: 1\n",
      "opposite: 1\n",
      "stream: 1\n",
      "identify: 1\n",
      "colours: 1\n",
      "words: 1\n",
      "toilet: 1\n",
      "training: 1\n",
      "attained: 1\n",
      "persistent: 1\n",
      "pleasureable: 1\n",
      "restlesness: 1\n",
      "jerks: 1\n",
      "physical: 1\n",
      "verbal: 1\n",
      "overactivity: 1\n",
      "response: 1\n",
      "vocal: 1\n",
      "stimuli: 1\n",
      "less: 1\n",
      "engaged: 1\n",
      "generalised: 1\n",
      "feet: 1\n",
      "sit: 1\n",
      "aggressiveness: 1\n",
      "esteem: 1\n",
      "disturbances: 1\n",
      "ofinvoluntary: 1\n",
      "forgetful: 1\n",
      "mild: 1\n",
      "conciousness: 1\n",
      "injurious: 1\n",
      "obey: 1\n",
      "commands: 1\n",
      "roaming: 1\n",
      "aimlesless: 1\n",
      "taking: 1\n",
      "misidentifying: 1\n",
      "members: 1\n",
      "claim: 1\n",
      "eye: 1\n",
      "contact: 1\n",
      "inetlligence: 1\n",
      "blaming: 1\n",
      "molesting: 1\n",
      "unconscious: 1\n",
      "withdrawan: 1\n",
      "reduce: 1\n",
      "voice: 1\n",
      "senselesseness: 1\n",
      "feeling: 1\n",
      "unreality: 1\n",
      "attention: 1\n",
      "somatic: 1\n",
      "forgetting: 1\n",
      "studied: 1\n",
      "material: 1\n",
      "continuous: 1\n",
      "small: 1\n",
      "quantity: 1\n",
      "intelligence: 1\n",
      "tonic: 1\n",
      "clonic: 1\n",
      "irritable: 1\n",
      "issue: 1\n",
      "neck: 1\n",
      "uprolling: 1\n",
      "disobediency: 1\n",
      "stubborn: 1\n",
      "demand: 1\n",
      "money: 1\n",
      "listen: 1\n",
      "known: 1\n",
      "person: 1\n",
      "since: 1\n",
      "childhood: 1\n",
      "seeing: 1\n",
      "things: 1\n",
      "seen: 1\n",
      "distractible: 1\n",
      "letters: 1\n",
      "repeatedly: 1\n",
      "spitting: 1\n",
      "flashbacks: 1\n",
      "drowning: 1\n",
      "others: 1\n",
      "queries: 1\n",
      "use: 1\n",
      "mobile: 1\n",
      "query: 1\n",
      "repeatitive: 1\n",
      "uttering: 1\n",
      "work: 1\n",
      "pharase: 1\n",
      "altered: 1\n",
      "withdrwan: 1\n",
      "disorganised: 1\n",
      "excessiv: 1\n",
      "ecrying: 1\n",
      "motor: 1\n",
      "disturbed: 1\n",
      "rolling: 1\n",
      "foul: 1\n",
      "smelling: 1\n",
      "coming: 1\n",
      "undersanding: 1\n",
      "abussive: 1\n",
      "mother: 1\n",
      "following: 1\n",
      "direction: 1\n",
      "momentary: 1\n",
      "stop: 1\n",
      "became: 1\n",
      "film: 1\n",
      "actor: 1\n",
      "toward: 1\n",
      "dependent: 1\n",
      "memebers: 1\n",
      "feeding: 1\n",
      "word: 1\n",
      "interact: 1\n",
      "otrhers: 1\n",
      "post: 1\n",
      "ictal: 1\n",
      "confusion: 1\n",
      "speaking: 1\n",
      "adequet: 1\n",
      "age: 1\n",
      "group: 1\n",
      "blank: 1\n",
      "stare: 1\n",
      "getting: 1\n",
      "suddenly: 1\n",
      "palpitations: 1\n",
      "shortness: 1\n",
      "breath: 1\n",
      "smiling: 1\n",
      "need: 1\n",
      "help: 1\n",
      "hoarding: 1\n",
      "inner: 1\n",
      "garments: 1\n",
      "ability: 1\n",
      "four: 1\n",
      "wandresome: 1\n",
      "misidentification: 1\n",
      "productivity: 1\n",
      "properly: 1\n",
      "irritabilty: 1\n",
      "fist: 1\n",
      "development: 1\n",
      "required: 1\n",
      "asking: 1\n",
      "questions: 1\n",
      "problems: 1\n",
      "phsycal: 1\n",
      "aggression: 1\n",
      "skin: 1\n",
      "picking: 1\n",
      "perforamnce: 1\n",
      "withouth: 1\n",
      "consumption: 1\n",
      "alcohol: 1\n",
      "tobacco: 1\n",
      "product: 1\n",
      "teeth: 1\n",
      "head: 1\n",
      "followed: 1\n",
      "needs: 1\n",
      "assistant: 1\n",
      "absorbed: 1\n",
      "singing: 1\n",
      "inappropriate: 1\n",
      "gesture: 1\n",
      "making: 1\n",
      "unusual: 1\n",
      "sounds: 1\n",
      "disinterst: 1\n",
      "pain: 1\n",
      "fearfullenss: 1\n",
      "villager: 1\n",
      "bilateral: 1\n",
      "teacher: 1\n",
      "passage: 1\n",
      "urine: 1\n",
      "regularly: 1\n",
      "episodesof: 1\n",
      "bowel: 1\n",
      "incontinence: 1\n",
      "staring: 1\n",
      "looking: 1\n",
      "banging: 1\n",
      "door: 1\n",
      "wall: 1\n",
      "functioning: 1\n",
      "leg: 1\n",
      "tongue: 1\n",
      "bite: 1\n",
      "easy: 1\n",
      "regression: 1\n",
      "disruptive: 1\n",
      "crossing: 1\n",
      "angry: 1\n",
      "grooming: 1\n",
      "pervasive: 1\n",
      "reaction: 1\n",
      "frequent: 1\n",
      "regarding: 1\n",
      "exam: 1\n",
      "neighbours: 1\n",
      "memory: 1\n",
      "events: 1\n",
      "cant: 1\n",
      "recognize: 1\n",
      "study: 1\n",
      "decreassed: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "df2['combined_complaints'] = df2['Chief complaint 1'].fillna('') + ' ' + df2['Chief complaint 2'].fillna('') + ' ' + df2['Chief complaint 3'].fillna('')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def extract_keywords(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(text) if word.isalpha() and word.lower() not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "df2['combined_keywords'] = df2['combined_complaints'].apply(extract_keywords)\n",
    "\n",
    "all_tokens = [token for sublist in df2['combined_keywords'].tolist() for token in sublist]\n",
    "\n",
    "word_counts = Counter(all_tokens)\n",
    "sorted_word_counts = dict(sorted(word_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "for word, count in sorted_word_counts.items():\n",
    "    print(f'{word}: {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "92353024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...   days/freq keywords  \\\n",
      "1                    episodes of unresponsiveness   ...   48.083333       []   \n",
      "2      Episodes of abnormal jerky movement of body  ...  886.750000       []   \n",
      "3      episode of abnormal jerky movement with LOC  ...   52.940299       []   \n",
      "4                                      inattention  ...   50.000000       []   \n",
      "5                                   epileptic fits  ...   54.342857       []   \n",
      "..                                             ...  ...         ...      ...   \n",
      "163               delayed developmental milestones  ...   61.600000       []   \n",
      "164  suspiciousness towards parents and neighbours  ...  102.400000       []   \n",
      "186                             Irrelevent Talking  ...  118.000000       []   \n",
      "187    No Memory of events, Cant recognize people   ...   39.545455       []   \n",
      "191                               unable to speak   ...   61.680000       []   \n",
      "\n",
      "                                     combined_keywords irritable angry  \\\n",
      "1               [episodes, unresponsiveness, nil, nil]         0     0   \n",
      "2    [episodes, abnormal, jerky, movement, body, po...         0     0   \n",
      "3    [episode, abnormal, jerky, movement, loc, left...         0     0   \n",
      "4    [inattention, hyperactivity, poor, mscholastic...         0     0   \n",
      "5                          [epileptic, fits, nil, nil]         0     0   \n",
      "..                                                 ...       ...   ...   \n",
      "163  [delayed, developmental, milestones, poor, com...         0     0   \n",
      "164  [suspiciousness, towards, parents, neighbours,...         0     1   \n",
      "186  [irrelevent, talking, increased, activity, lev...         0     0   \n",
      "187  [memory, events, cant, recognize, people, stud...         0     0   \n",
      "191  [unable, speak, self, harming, abnormal, jerky...         0     0   \n",
      "\n",
      "    abnormal restlessness jerky low outbursts  \n",
      "1          0            0     0   0         0  \n",
      "2          1            0     1   0         0  \n",
      "3          1            0     1   0         0  \n",
      "4          0            0     0   0         0  \n",
      "5          0            0     0   0         0  \n",
      "..       ...          ...   ...  ..       ...  \n",
      "163        0            0     1   0         0  \n",
      "164        0            0     0   0         0  \n",
      "186        0            0     0   0         0  \n",
      "187        0            0     0   0         0  \n",
      "191        1            0     1   0         0  \n",
      "\n",
      "[148 rows x 272 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "df2['combined_complaints'] = df2['Chief complaint 1'].fillna('') + ' ' + df2['Chief complaint 2'].fillna('') + ' ' + df2['Chief complaint 3'].fillna('')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def count_occurrences(text, word):\n",
    "    tokens = [word.lower() for word in word_tokenize(text) if word.isalpha() and word.lower() not in stop_words]\n",
    "    return tokens.count(word.lower())\n",
    "\n",
    "df2['irritable'] = df2['combined_complaints'].apply(lambda x: count_occurrences(x, 'irritable') + count_occurrences(x, 'irritability')  + count_occurrences(x, 'irritabilty') )\n",
    "df2['angry'] = df2['combined_complaints'].apply(lambda x: count_occurrences(x, 'angry')+ count_occurrences(x, 'anger'))\n",
    "df2['abnormal'] = df2['combined_complaints'].apply(lambda x: count_occurrences(x, 'abnormal'))\n",
    "df2['restlessness'] = df2['combined_complaints'].apply(lambda x: count_occurrences(x, 'restlessness') +  count_occurrences(x, 'restlesness'))\n",
    "df2['jerky'] = df2['combined_complaints'].apply(lambda x: count_occurrences(x, 'jerky'))\n",
    "df2['low'] = df2['combined_complaints'].apply(lambda x: count_occurrences(x, 'low'))\n",
    "df2['outbursts'] = df2['combined_complaints'].apply(lambda x: count_occurrences(x, 'outburst') + count_occurrences(x, 'outbursts'))\n",
    "\n",
    "df2.drop('combined_complaints', axis=1, inplace=True)\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "627be3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value in the 'irritable' column for index 191 is: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "integer_index_to_find = 191\n",
    "irritable_value = df2.loc[integer_index_to_find, 'irritable']\n",
    "print(f\"The value in the 'irritable' column for index {integer_index_to_find} is: {irritable_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "700a3ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df2 (Method 1): 148\n",
      "Number of rows in df2 (Method 2): 148\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_rows_method1 = len(df2)\n",
    "print(f\"Number of rows in df2 (Method 1): {num_rows_method1}\")\n",
    "\n",
    "num_rows_method2 = df2.shape[0]\n",
    "print(f\"Number of rows in df2 (Method 2): {num_rows_method2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "93405811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value in the 'irritable' column for index 1 is: 0\n",
      "The value in the 'irritable' column for index 2 is: 0\n",
      "The value in the 'irritable' column for index 3 is: 0\n",
      "The value in the 'irritable' column for index 4 is: 0\n",
      "The value in the 'irritable' column for index 5 is: 0\n",
      "The value in the 'irritable' column for index 6 is: 0\n",
      "The value in the 'irritable' column for index 7 is: 0\n",
      "The value in the 'irritable' column for index 8 is: 0\n",
      "The value in the 'irritable' column for index 9 is: 0\n",
      "The value in the 'irritable' column for index 10 is: 0\n",
      "The value in the 'irritable' column for index 11 is: 0\n",
      "The value in the 'irritable' column for index 12 is: 0\n",
      "The value in the 'irritable' column for index 13 is: 0\n",
      "The value in the 'irritable' column for index 14 is: 0\n",
      "The value in the 'irritable' column for index 15 is: 0\n",
      "The value in the 'irritable' column for index 16 is: 0\n",
      "The value in the 'irritable' column for index 17 is: 0\n",
      "The value in the 'irritable' column for index 18 is: 0\n",
      "The value in the 'irritable' column for index 19 is: 0\n",
      "The value in the 'irritable' column for index 20 is: 0\n",
      "The value in the 'irritable' column for index 21 is: 0\n",
      "The value in the 'irritable' column for index 22 is: 0\n",
      "The value in the 'irritable' column for index 23 is: 1\n",
      "The value in the 'irritable' column for index 24 is: 0\n",
      "The value in the 'irritable' column for index 25 is: 1\n",
      "The value in the 'irritable' column for index 26 is: 0\n",
      "The value in the 'irritable' column for index 27 is: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "28",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 28",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [223], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Find the corresponding value in the 'irritable' column for the specified integer index\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m148\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     irritable_value \u001b[38;5;241m=\u001b[39m \u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mirritable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe value in the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mirritable\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column for index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mirritable_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1066\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1064\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m-> 1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3921\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   3915\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m   3917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m   3918\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[0;32m   3919\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[0;32m   3920\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[1;32m-> 3921\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3922\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[0;32m   3924\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[0;32m   3925\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 28"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1,148):\n",
    "    irritable_value = df2.loc[i, 'irritable']\n",
    "    print(f\"The value in the 'irritable' column for index {i} is: {irritable_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1cd24e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "      ..\n",
       "163    0\n",
       "164    0\n",
       "186    0\n",
       "187    0\n",
       "191    0\n",
       "Name: irritable, Length: 148, dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['irritable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e506a881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value in the 'irritable' column for index 1 is: 0\n",
      "The value in the 'irritable' column for index 2 is: 0\n",
      "The value in the 'irritable' column for index 3 is: 0\n",
      "The value in the 'irritable' column for index 4 is: 0\n",
      "The value in the 'irritable' column for index 5 is: 0\n",
      "The value in the 'irritable' column for index 6 is: 0\n",
      "The value in the 'irritable' column for index 7 is: 0\n",
      "The value in the 'irritable' column for index 8 is: 0\n",
      "The value in the 'irritable' column for index 9 is: 0\n",
      "The value in the 'irritable' column for index 10 is: 0\n",
      "The value in the 'irritable' column for index 11 is: 0\n",
      "The value in the 'irritable' column for index 12 is: 0\n",
      "The value in the 'irritable' column for index 13 is: 0\n",
      "The value in the 'irritable' column for index 14 is: 0\n",
      "The value in the 'irritable' column for index 15 is: 0\n",
      "The value in the 'irritable' column for index 16 is: 0\n",
      "The value in the 'irritable' column for index 17 is: 0\n",
      "The value in the 'irritable' column for index 18 is: 0\n",
      "The value in the 'irritable' column for index 19 is: 0\n",
      "The value in the 'irritable' column for index 20 is: 0\n",
      "The value in the 'irritable' column for index 21 is: 0\n",
      "The value in the 'irritable' column for index 22 is: 0\n",
      "The value in the 'irritable' column for index 23 is: 1\n",
      "The value in the 'irritable' column for index 24 is: 0\n",
      "The value in the 'irritable' column for index 25 is: 1\n",
      "The value in the 'irritable' column for index 26 is: 0\n",
      "The value in the 'irritable' column for index 27 is: 0\n",
      "Index 28 does not exist, skipping the row.\n",
      "Index 29 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 30 is: 0\n",
      "The value in the 'irritable' column for index 31 is: 0\n",
      "The value in the 'irritable' column for index 32 is: 0\n",
      "The value in the 'irritable' column for index 33 is: 0\n",
      "The value in the 'irritable' column for index 34 is: 0\n",
      "The value in the 'irritable' column for index 35 is: 0\n",
      "The value in the 'irritable' column for index 36 is: 0\n",
      "The value in the 'irritable' column for index 37 is: 0\n",
      "The value in the 'irritable' column for index 38 is: 0\n",
      "The value in the 'irritable' column for index 39 is: 0\n",
      "The value in the 'irritable' column for index 40 is: 1\n",
      "The value in the 'irritable' column for index 41 is: 1\n",
      "The value in the 'irritable' column for index 42 is: 0\n",
      "Index 43 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 44 is: 0\n",
      "The value in the 'irritable' column for index 45 is: 1\n",
      "The value in the 'irritable' column for index 46 is: 0\n",
      "The value in the 'irritable' column for index 47 is: 0\n",
      "The value in the 'irritable' column for index 48 is: 0\n",
      "The value in the 'irritable' column for index 49 is: 0\n",
      "The value in the 'irritable' column for index 50 is: 0\n",
      "The value in the 'irritable' column for index 51 is: 0\n",
      "The value in the 'irritable' column for index 52 is: 0\n",
      "The value in the 'irritable' column for index 53 is: 0\n",
      "The value in the 'irritable' column for index 54 is: 0\n",
      "The value in the 'irritable' column for index 55 is: 0\n",
      "The value in the 'irritable' column for index 56 is: 0\n",
      "The value in the 'irritable' column for index 57 is: 0\n",
      "The value in the 'irritable' column for index 58 is: 0\n",
      "The value in the 'irritable' column for index 59 is: 1\n",
      "The value in the 'irritable' column for index 60 is: 0\n",
      "The value in the 'irritable' column for index 61 is: 1\n",
      "The value in the 'irritable' column for index 62 is: 0\n",
      "The value in the 'irritable' column for index 63 is: 1\n",
      "The value in the 'irritable' column for index 64 is: 0\n",
      "Index 65 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 66 is: 0\n",
      "The value in the 'irritable' column for index 67 is: 0\n",
      "The value in the 'irritable' column for index 68 is: 0\n",
      "The value in the 'irritable' column for index 69 is: 0\n",
      "The value in the 'irritable' column for index 70 is: 0\n",
      "The value in the 'irritable' column for index 71 is: 0\n",
      "The value in the 'irritable' column for index 72 is: 0\n",
      "Index 73 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 74 is: 0\n",
      "Index 75 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 76 is: 0\n",
      "The value in the 'irritable' column for index 77 is: 0\n",
      "The value in the 'irritable' column for index 78 is: 0\n",
      "The value in the 'irritable' column for index 79 is: 0\n",
      "The value in the 'irritable' column for index 80 is: 0\n",
      "The value in the 'irritable' column for index 81 is: 0\n",
      "The value in the 'irritable' column for index 82 is: 0\n",
      "The value in the 'irritable' column for index 83 is: 0\n",
      "The value in the 'irritable' column for index 84 is: 0\n",
      "The value in the 'irritable' column for index 85 is: 0\n",
      "Index 86 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 87 is: 0\n",
      "The value in the 'irritable' column for index 88 is: 0\n",
      "The value in the 'irritable' column for index 89 is: 0\n",
      "The value in the 'irritable' column for index 90 is: 0\n",
      "The value in the 'irritable' column for index 91 is: 0\n",
      "The value in the 'irritable' column for index 92 is: 0\n",
      "The value in the 'irritable' column for index 93 is: 0\n",
      "The value in the 'irritable' column for index 94 is: 1\n",
      "The value in the 'irritable' column for index 95 is: 0\n",
      "The value in the 'irritable' column for index 96 is: 0\n",
      "The value in the 'irritable' column for index 97 is: 0\n",
      "The value in the 'irritable' column for index 98 is: 0\n",
      "The value in the 'irritable' column for index 99 is: 0\n",
      "The value in the 'irritable' column for index 100 is: 0\n",
      "The value in the 'irritable' column for index 101 is: 0\n",
      "The value in the 'irritable' column for index 102 is: 0\n",
      "The value in the 'irritable' column for index 103 is: 0\n",
      "Index 104 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 105 is: 0\n",
      "The value in the 'irritable' column for index 106 is: 0\n",
      "The value in the 'irritable' column for index 107 is: 0\n",
      "The value in the 'irritable' column for index 108 is: 0\n",
      "The value in the 'irritable' column for index 109 is: 1\n",
      "The value in the 'irritable' column for index 110 is: 0\n",
      "The value in the 'irritable' column for index 111 is: 0\n",
      "The value in the 'irritable' column for index 112 is: 0\n",
      "The value in the 'irritable' column for index 113 is: 0\n",
      "The value in the 'irritable' column for index 114 is: 0\n",
      "The value in the 'irritable' column for index 115 is: 0\n",
      "The value in the 'irritable' column for index 116 is: 1\n",
      "The value in the 'irritable' column for index 117 is: 0\n",
      "The value in the 'irritable' column for index 118 is: 0\n",
      "The value in the 'irritable' column for index 119 is: 0\n",
      "The value in the 'irritable' column for index 120 is: 0\n",
      "The value in the 'irritable' column for index 121 is: 0\n",
      "The value in the 'irritable' column for index 122 is: 0\n",
      "The value in the 'irritable' column for index 123 is: 0\n",
      "The value in the 'irritable' column for index 124 is: 0\n",
      "The value in the 'irritable' column for index 125 is: 0\n",
      "The value in the 'irritable' column for index 126 is: 1\n",
      "The value in the 'irritable' column for index 127 is: 0\n",
      "The value in the 'irritable' column for index 128 is: 0\n",
      "Index 129 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 130 is: 0\n",
      "The value in the 'irritable' column for index 131 is: 0\n",
      "The value in the 'irritable' column for index 132 is: 0\n",
      "The value in the 'irritable' column for index 133 is: 0\n",
      "The value in the 'irritable' column for index 134 is: 0\n",
      "The value in the 'irritable' column for index 135 is: 1\n",
      "The value in the 'irritable' column for index 136 is: 0\n",
      "The value in the 'irritable' column for index 137 is: 0\n",
      "The value in the 'irritable' column for index 138 is: 0\n",
      "Index 139 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 140 is: 0\n",
      "The value in the 'irritable' column for index 141 is: 0\n",
      "The value in the 'irritable' column for index 142 is: 0\n",
      "The value in the 'irritable' column for index 143 is: 0\n",
      "The value in the 'irritable' column for index 144 is: 1\n",
      "The value in the 'irritable' column for index 145 is: 0\n",
      "Index 146 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 147 is: 0\n",
      "Index 148 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 149 is: 0\n",
      "The value in the 'irritable' column for index 150 is: 1\n",
      "The value in the 'irritable' column for index 151 is: 0\n",
      "The value in the 'irritable' column for index 152 is: 1\n",
      "Index 153 does not exist, skipping the row.\n",
      "Index 154 does not exist, skipping the row.\n",
      "Index 155 does not exist, skipping the row.\n",
      "Index 156 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 157 is: 0\n",
      "Index 158 does not exist, skipping the row.\n",
      "Index 159 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 160 is: 0\n",
      "Index 161 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 162 is: 0\n",
      "The value in the 'irritable' column for index 163 is: 0\n",
      "The value in the 'irritable' column for index 164 is: 0\n",
      "Index 165 does not exist, skipping the row.\n",
      "Index 166 does not exist, skipping the row.\n",
      "Index 167 does not exist, skipping the row.\n",
      "Index 168 does not exist, skipping the row.\n",
      "Index 169 does not exist, skipping the row.\n",
      "Index 170 does not exist, skipping the row.\n",
      "Index 171 does not exist, skipping the row.\n",
      "Index 172 does not exist, skipping the row.\n",
      "Index 173 does not exist, skipping the row.\n",
      "Index 174 does not exist, skipping the row.\n",
      "Index 175 does not exist, skipping the row.\n",
      "Index 176 does not exist, skipping the row.\n",
      "Index 177 does not exist, skipping the row.\n",
      "Index 178 does not exist, skipping the row.\n",
      "Index 179 does not exist, skipping the row.\n",
      "Index 180 does not exist, skipping the row.\n",
      "Index 181 does not exist, skipping the row.\n",
      "Index 182 does not exist, skipping the row.\n",
      "Index 183 does not exist, skipping the row.\n",
      "Index 184 does not exist, skipping the row.\n",
      "Index 185 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 186 is: 0\n",
      "The value in the 'irritable' column for index 187 is: 0\n",
      "Index 188 does not exist, skipping the row.\n",
      "Index 189 does not exist, skipping the row.\n",
      "Index 190 does not exist, skipping the row.\n",
      "The value in the 'irritable' column for index 191 is: 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 192):\n",
    "    try:\n",
    "        irritable_value = df2.loc[i, 'irritable']\n",
    "        print(f\"The value in the 'irritable' column for index {i} is: {irritable_value}\")\n",
    "    except KeyError:\n",
    "        print(f\"Index {i} does not exist, skipping the row.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ebcda834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...   days/freq keywords  \\\n",
      "1                    episodes of unresponsiveness   ...   48.083333       []   \n",
      "2      Episodes of abnormal jerky movement of body  ...  886.750000       []   \n",
      "3      episode of abnormal jerky movement with LOC  ...   52.940299       []   \n",
      "4                                      inattention  ...   50.000000       []   \n",
      "5                                   epileptic fits  ...   54.342857       []   \n",
      "..                                             ...  ...         ...      ...   \n",
      "163               delayed developmental milestones  ...   61.600000       []   \n",
      "164  suspiciousness towards parents and neighbours  ...  102.400000       []   \n",
      "186                             Irrelevent Talking  ...  118.000000       []   \n",
      "187    No Memory of events, Cant recognize people   ...   39.545455       []   \n",
      "191                               unable to speak   ...   61.680000       []   \n",
      "\n",
      "                                     combined_keywords irritable angry  \\\n",
      "1               [episodes, unresponsiveness, nil, nil]         0     0   \n",
      "2    [episodes, abnormal, jerky, movement, body, po...         0     0   \n",
      "3    [episode, abnormal, jerky, movement, loc, left...         0     0   \n",
      "4    [inattention, hyperactivity, poor, mscholastic...         0     0   \n",
      "5                          [epileptic, fits, nil, nil]         0     0   \n",
      "..                                                 ...       ...   ...   \n",
      "163  [delayed, developmental, milestones, poor, com...         0     0   \n",
      "164  [suspiciousness, towards, parents, neighbours,...         0     1   \n",
      "186  [irrelevent, talking, increased, activity, lev...         0     0   \n",
      "187  [memory, events, cant, recognize, people, stud...         0     0   \n",
      "191  [unable, speak, self, harming, abnormal, jerky...         0     0   \n",
      "\n",
      "    abnormal restlessness jerky low outbursts  \n",
      "1          0            0     0   0         0  \n",
      "2          1            0     1   0         0  \n",
      "3          1            0     1   0         0  \n",
      "4          0            0     0   0         0  \n",
      "5          0            0     0   0         0  \n",
      "..       ...          ...   ...  ..       ...  \n",
      "163        0            0     1   0         0  \n",
      "164        0            0     0   0         0  \n",
      "186        0            0     0   0         0  \n",
      "187        0            0     0   0         0  \n",
      "191        1            0     1   0         0  \n",
      "\n",
      "[148 rows x 272 columns]\n"
     ]
    }
   ],
   "source": [
    "df2.rename(columns={'Compliant to medications (yes/no) (if off medications period is less than 7 days then it is considered as compliant': 'Final'}, inplace=True)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "bc941508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of 'irritable' values for 'Good': 6\n",
      "Sum of 'irritable' values for 'Satisfactory': 5\n",
      "Sum of 'irritable' values for 'Poor': 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_counts = df2['Final'].value_counts()\n",
    "\n",
    "good_sum = 0\n",
    "satisfactory_sum = 0\n",
    "poor_sum = 0\n",
    "\n",
    "for category, count in final_counts.items():\n",
    "    if category == 'Good':\n",
    "        good_sum = df2.loc[df2['Final'] == category, 'irritable'].sum()\n",
    "    elif category == 'Satisfactory':\n",
    "        satisfactory_sum = df2.loc[df2['Final'] == category, 'irritable'].sum()\n",
    "    elif category == 'Poor':\n",
    "        poor_sum = df2.loc[df2['Final'] == category, 'irritable'].sum()\n",
    "\n",
    "print(f\"Sum of 'irritable' values for 'Good': {good_sum}\")\n",
    "print(f\"Sum of 'irritable' values for 'Satisfactory': {satisfactory_sum}\")\n",
    "print(f\"Sum of 'irritable' values for 'Poor': {poor_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "82d39973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of 'angry' values for 'Good': 7\n",
      "Sum of 'angry' values for 'Satisfactory': 7\n",
      "Sum of 'angry' values for 'Poor': 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_counts = df2['Final'].value_counts()\n",
    "\n",
    "good_sum = 0\n",
    "satisfactory_sum = 0\n",
    "poor_sum = 0\n",
    "\n",
    "for category, count in final_counts.items():\n",
    "    if category == 'Good':\n",
    "        good_sum = df2.loc[df2['Final'] == category, 'angry'].sum()\n",
    "    elif category == 'Satisfactory':\n",
    "        satisfactory_sum = df2.loc[df2['Final'] == category, 'angry'].sum()\n",
    "    elif category == 'Poor':\n",
    "        poor_sum = df2.loc[df2['Final'] == category, 'angry'].sum()\n",
    "\n",
    "print(f\"Sum of 'angry' values for 'Good': {good_sum}\")\n",
    "print(f\"Sum of 'angry' values for 'Satisfactory': {satisfactory_sum}\")\n",
    "print(f\"Sum of 'angry' values for 'Poor': {poor_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9097f78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of'abnormal' values for 'Good': 10\n",
      "Sum of 'abnormal' values for 'Satisfactory': 5\n",
      "Sum of 'abnormal' values for 'Poor': 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_counts = df2['Final'].value_counts()\n",
    "\n",
    "good_sum = 0\n",
    "satisfactory_sum = 0\n",
    "poor_sum = 0\n",
    "\n",
    "for category, count in final_counts.items():\n",
    "    if category == 'Good':\n",
    "        good_sum = df2.loc[df2['Final'] == category, 'abnormal'].sum()\n",
    "    elif category == 'Satisfactory':\n",
    "        satisfactory_sum = df2.loc[df2['Final'] == category, 'abnormal'].sum()\n",
    "    elif category == 'Poor':\n",
    "        poor_sum = df2.loc[df2['Final'] == category, 'abnormal'].sum()\n",
    "\n",
    "print(f\"Sum of'abnormal' values for 'Good': {good_sum}\")\n",
    "print(f\"Sum of 'abnormal' values for 'Satisfactory': {satisfactory_sum}\")\n",
    "print(f\"Sum of 'abnormal' values for 'Poor': {poor_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ed7c1ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of 'restlessness' values for 'Good': 7\n",
      "Sum of 'restlessness' values for 'Satisfactory': 5\n",
      "Sum of 'restlessness' values for 'Poor': 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_counts = df2['Final'].value_counts()\n",
    "\n",
    "\n",
    "good_sum = 0\n",
    "satisfactory_sum = 0\n",
    "poor_sum = 0\n",
    "\n",
    "for category, count in final_counts.items():\n",
    "    if category == 'Good':\n",
    "        good_sum = df2.loc[df2['Final'] == category, 'restlessness'].sum()\n",
    "    elif category == 'Satisfactory':\n",
    "        satisfactory_sum = df2.loc[df2['Final'] == category, 'restlessness'].sum()\n",
    "    elif category == 'Poor':\n",
    "        poor_sum = df2.loc[df2['Final'] == category, 'restlessness'].sum()\n",
    "\n",
    "print(f\"Sum of 'restlessness' values for 'Good': {good_sum}\")\n",
    "print(f\"Sum of 'restlessness' values for 'Satisfactory': {satisfactory_sum}\")\n",
    "print(f\"Sum of 'restlessness' values for 'Poor': {poor_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b8904587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of 'jerky' values for 'Good': 17\n",
      "Sum of 'jerky' values for 'Satisfactory': 5\n",
      "Sum of 'jerky' values for 'Poor': 13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_counts = df2['Final'].value_counts()\n",
    "\n",
    "good_sum = 0\n",
    "satisfactory_sum = 0\n",
    "poor_sum = 0\n",
    "\n",
    "for category, count in final_counts.items():\n",
    "    if category == 'Good':\n",
    "        good_sum = df2.loc[df2['Final'] == category, 'jerky'].sum()\n",
    "    elif category == 'Satisfactory':\n",
    "        satisfactory_sum = df2.loc[df2['Final'] == category, 'jerky'].sum()\n",
    "    elif category == 'Poor':\n",
    "        poor_sum = df2.loc[df2['Final'] == category, 'jerky'].sum()\n",
    "\n",
    "print(f\"Sum of 'jerky' values for 'Good': {good_sum}\")\n",
    "print(f\"Sum of 'jerky' values for 'Satisfactory': {satisfactory_sum}\")\n",
    "print(f\"Sum of 'jerky' values for 'Poor': {poor_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8d72f3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of 'low' values for 'Good': 4\n",
      "Sum of 'low' values for 'Satisfactory': 3\n",
      "Sum of 'low' values for 'Poor': 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_counts = df2['Final'].value_counts()\n",
    "\n",
    "good_sum = 0\n",
    "satisfactory_sum = 0\n",
    "poor_sum = 0\n",
    "\n",
    "for category, count in final_counts.items():\n",
    "    if category == 'Good':\n",
    "        good_sum = df2.loc[df2['Final'] == category, 'low'].sum()\n",
    "    elif category == 'Satisfactory':\n",
    "        satisfactory_sum = df2.loc[df2['Final'] == category, 'low'].sum()\n",
    "    elif category == 'Poor':\n",
    "        poor_sum = df2.loc[df2['Final'] == category, 'low'].sum()\n",
    "\n",
    "print(f\"Sum of 'low' values for 'Good': {good_sum}\")\n",
    "print(f\"Sum of 'low' values for 'Satisfactory': {satisfactory_sum}\")\n",
    "print(f\"Sum of 'low' values for 'Poor': {poor_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b589331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of 'outbursts' values for 'Good': 1\n",
      "Sum of 'outbursts' values for 'Satisfactory': 4\n",
      "Sum of 'outbursts' values for 'Poor': 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_counts = df2['Final'].value_counts()\n",
    "\n",
    "good_sum = 0\n",
    "satisfactory_sum = 0\n",
    "poor_sum = 0\n",
    "\n",
    "for category, count in final_counts.items():\n",
    "    if category == 'Good':\n",
    "        good_sum = df2.loc[df2['Final'] == category, 'outbursts'].sum()\n",
    "    elif category == 'Satisfactory':\n",
    "        satisfactory_sum = df2.loc[df2['Final'] == category, 'outbursts'].sum()\n",
    "    elif category == 'Poor':\n",
    "        poor_sum = df2.loc[df2['Final'] == category, 'outbursts'].sum()\n",
    "\n",
    "print(f\"Sum of 'outbursts' values for 'Good': {good_sum}\")\n",
    "print(f\"Sum of 'outbursts' values for 'Satisfactory': {satisfactory_sum}\")\n",
    "print(f\"Sum of 'outbursts' values for 'Poor': {poor_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a3688b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)\n",
      "Age at last follow up\n",
      "Sex (m/f)\n",
      "Religion\n",
      "Max education attained\n",
      "Rural/Urban\n",
      "Distance from LGBRIMH (in KM)\n",
      "Socioeconomic status\n",
      "Age at onset(in years)\n",
      "Chief complaint 1\n",
      "Chief complaint 2\n",
      "Chief complaint 3\n",
      "Time period between onset to first consultation at LGBRIMH (DUI) (in days)\n",
      "Type of Family (Nuclear/Joint/single parent/orphan/ foster family\n",
      "Family environment\n",
      "Details of family abnormality (describe)\n",
      "Family h/o stillbirth/abortion\n",
      "Family history(general medical)\n",
      "Family history (psychiatric/neurological)\n",
      "Faith healer visited before consultation or not(yes/no)\n",
      "Antenatal risk factor\n",
      "Place of delivery (Home/hospital)\n",
      "Birth weight(in kg)\n",
      "Neonatal complication\n",
      "Postnatal complication\n",
      "Developmental history\n",
      "Age of school entry(in years)\n",
      "Type of school\n",
      "School adjustment\n",
      "Academic performance\n",
      "School dropout present (yes/no)\n",
      "Detail of past psychiatric history 1\n",
      "Past treatment 1\n",
      "Past treatment medication 1\n",
      "Starting dose past medication 1\n",
      "Age of starting of past medication 1(in years)\n",
      "Past maintenance dose1 (in mg)\n",
      "Side effects of past medication 1\n",
      "Age of occurance past side effects 1(in years)\n",
      "Duration of past side effect 1(in months)\n",
      "Response to past medication 1\n",
      "Detail of past history 2\n",
      "Past treatment 2\n",
      "Past treatment medication 2\n",
      "Starting dose past medication 2\n",
      "Age of starting of past medication 2(in years)\n",
      "Past maintenance dose2\n",
      "Side effects of past medication 2\n",
      "Age of occurance past side effects 2(in years)\n",
      "Duration of past side effect 2(in months)\n",
      "Response to past medication 2\n",
      "Detail of past history 3\n",
      "Past treatment  3\n",
      "Past treatment medication 3\n",
      "Starting dose past medication 3 \n",
      "Age of starting past medication 3 (in years)\n",
      "Past maintenance dose 3\n",
      "Side effects past medication 3\n",
      "Age of occurance of past side effects 3 (in years)\n",
      "Duration of past side effects 3 (in months)\n",
      "Response to past medication 3\n",
      "Change in doctor\n",
      "Past/Current medical conditions\n",
      "Age of onset of medical conditions (in years)\n",
      "Details of medical conditions\n",
      "Treatments for medical conditions\n",
      "Severity of medical conditions\n",
      "weight (in Kg)\n",
      "weight z score\n",
      "height (in cm)\n",
      "height z score\n",
      "head circumference (in cm)\n",
      "head circumference z score\n",
      "systemic examination(abnormal/normal)\n",
      "systemic examination details (main finding only)\n",
      "Mental status examination/Behavioral Observation details (abnormal/normal)\n",
      "Mental status examination/Behavioral observation details (main finding only in description)\n",
      "Screening diagnosis \n",
      "detailed workup diagnosis\n",
      "Follow up diagnosis changed or not (yes/no)\n",
      "If yes, changed once or multiple times (once/multiple)\n",
      "If yes, after how many days from first presentation diagnosis changed (in days)\n",
      "If yes, diagnosis changed to what\n",
      "Axis 1_1\n",
      "Axis 1_2\n",
      "Axis 1_3\n",
      "Axis 1_4\n",
      "Axis 2\n",
      "Axis 3\n",
      "Axis 4_1\n",
      "Axis 4_2\n",
      "Axis 4_3\n",
      "Axis 5\n",
      "significant psychosocial stressor\n",
      "name of Medication 1\n",
      "medication 1 starting dose (in mg)\n",
      "Avg dose of medication 1 (Mode value of medication) (in mg)\n",
      "Maximum dose of medication 1 (in mg)\n",
      "Total duration of medication 1 (in days) \n",
      "Continued medication 1/stopped/changed\n",
      "Response to medication 1 (Good/partial/no)\n",
      "Side effect of medication 1\n",
      "onset of side effect post starting med 1 ( in days)\n",
      "total duration of side effect of medication 1 (in days)\n",
      "Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) \n",
      "name of Medication 2\n",
      "Medication 2 starting dose (in mg)\n",
      "Avg dose of medication 2 (in mg)\n",
      "Maximum dose of medication 2 (in mg)\n",
      "Total duration of medication 2(in days) \n",
      "Continued medication 2/stopped/changed\n",
      "Response to medication 2 (Good/partial/no)\n",
      "Side effect of medication 2\n",
      "onset of side effect post starting med 2 ( in days)\n",
      "total duration of side effect of medication 2 (in days)\n",
      "Medication possession ratios 2(MPRs) in lgb;x-syrup\n",
      "name of Medication 3\n",
      "Medication 3 starting dose (in mg)\n",
      "Avg dose of medication 3 (in mg)\n",
      "Maximum dose of medication 3 (in mg)\n",
      "Total duration of medication 3 (in days\n",
      "continued medication 3/stopped/changed\n",
      "Response to medication 3 (Good/partial/no)\n",
      "Side effect of medication 3\n",
      "onset of side effect post starting med 3 ( in days)\n",
      "total duration of side effect of medication 3 (in days)\n",
      "Medication possession ratios 3(MPRs) in lgb;x-syrup\n",
      "name of Medication 4\n",
      "Medication 4 starting dose (in mg)\n",
      "Avg dose of medication 4 (in mg)\n",
      "Maximum dose of medication 4 (in mg)\n",
      "Total duration of medication 4 (in days)\n",
      "continued medication 4/stopped/changed\n",
      "Response to medication 4(Good/partial/no)\n",
      "Side effect of medication 4\n",
      "onset of side effect post starting med 4 ( in days)\n",
      "total duration of side effect of medication 4 (in days)\n",
      "Medication possession ratios 4(MPRs) in lgb;x-syrup\n",
      "name of Medication 5\n",
      "Medication 5 starting dose (in mg)\n",
      "Avg dose of medication 5 (in mg)\n",
      "Maximum dose of medication 5(in mg)\n",
      "Total duration of medication 5 (in days)\n",
      "continued medication 5/stopped/changed\n",
      "Response to medication 5(Good/partial/no)\n",
      "Side effect of medication 5\n",
      "onset of side effect post starting med 5 ( in days)\n",
      "total duration of side effect of medication 5 (in days)\n",
      "Medication possession ratios 5(MPRs) in lgb;x-syrup\n",
      "name of Medication 6\n",
      "Medication 6 starting dose\n",
      "Avg dose of medication 6\n",
      "Maximum dose of medication 6\n",
      "Total duration of medication 6\n",
      "continued medication 6/stopped/changed\n",
      "Response to medication 6(Good/partial/no)\n",
      "Side effect of medication 6\n",
      "onset of side effect post starting med 6 ( in days)\n",
      "total duration of side effect of medication 6 (in days)\n",
      "Medication possession ratios 6(MPRs) in lgb;x-syrup\n",
      "name of Medication 7\n",
      "Medication 7 starting dose\n",
      "Avg dose of medication 7\n",
      "Maximum dose of medication 7\n",
      "Total duration of medication 7\n",
      "continued medication 7/stopped/changed\n",
      "Response to medication 7(Good/partial/no)\n",
      "Side effect of medication 7\n",
      "onset of side effect post starting med 7 ( in days)\n",
      "total duration of side effect of medication 7 (in days)\n",
      "Medication possession ratios 7(MPRs) in lgb;x-syrup\n",
      "name of Medication 8\n",
      "Medication 8 starting dose\n",
      "Avg dose of medication 8\n",
      "Maximum dose of medication 8\n",
      "Total duration of medication 8\n",
      "Continued medication 8/stopped/changed\n",
      "Response to medication 8(Good/partial/no)\n",
      "Side effect of medication 8\n",
      "onset of side effect post starting med 8 ( in days)\n",
      "total duration of side effect of medication 8 (in days)\n",
      "Medication possession ratios 8(MPRs) in lgb;x-syrup\n",
      "name of Medication 9\n",
      "Medication 9 starting dose\n",
      "Avg dose of medication 9\n",
      "Maximum dose of medication 9\n",
      "Total duration of medication 9\n",
      "continued medication 9/stopped/changed\n",
      "Response to medication 9(Good/partial/no)\n",
      "Side effect of medication 9\n",
      "onset of side effect post starting med 9 ( in days)\n",
      "total duration of side effect of medication 9 (in days)\n",
      "Medication possession ratios 9(MPRs) in lgb;x-syrup\n",
      "name of Medication 10\n",
      "Medication 10 starting dose\n",
      "Avg dose of medication 10\n",
      "Maximum dose of medication 10\n",
      "Total duration of medication 10\n",
      "continued medication 10/stopped/changed\n",
      "Response to medication 10(Good/partial/no)\n",
      "Side effect of medication 10\n",
      "onset of side effect post starting med 10 ( in days)\n",
      "total duration of side effect of medication 10 (in days)\n",
      "Medication possession ratios 10(MPRs) in lgb;x-syrup\n",
      "name of Medication 11\n",
      "Medication 11 starting dose\n",
      "Avg dose of medication 11\n",
      "Maximum dose of medication 11\n",
      "Total duration of medication 11\n",
      "continued medication 11/stopped/changed\n",
      "Response to medication 11(Good/partial/no)\n",
      "Side effect of medication 11\n",
      "onset of side effect post starting med 11 ( in days)\n",
      "total duration of side effect of medication 11 (in days)\n",
      "Medication possession ratios 11(MPRs) in lgb;x-syrup\n",
      "name of Medication 12\n",
      "Medication 12 starting dose\n",
      "Avg dose of medication 12\n",
      "Maximum dose of medication 12\n",
      "Total duration of medication 12\n",
      "continued medication 12/stopped/changed\n",
      "Response to medication 12(Good/partial/no)\n",
      "Side effect of medication 12\n",
      "onset of side effect post starting med 12 ( in days)\n",
      "total duration of side effect of medication 12 (in days)\n",
      "Medication possession ratios 12(MPRs) in lgb;x-syrup\n",
      "name of Medication 13\n",
      "Medication 13 starting dose\n",
      "Avg dose of medication 13\n",
      "Maximum dose of medication 13\n",
      "Total duration of medication 13\n",
      "continued medication 13/stopped/changed\n",
      "Response to medication 13(Good/partial/no)\n",
      "Side effect of medication 13\n",
      "onset of side effect post starting med 13 ( in days)\n",
      "total duration of side effect of medication 13 (in days)\n",
      "Medication possession ratios 13(MPRs) in lgb;x-syrup\n",
      "name of Medication 14\n",
      "Medication 14 starting dose\n",
      "Avg dose of medication 14\n",
      "Maximum dose of medication 14\n",
      "Total duration of medication 14\n",
      "continued medication 14/stopped/changed\n",
      "Response to medication 14(Good/partial/no)\n",
      "Side effect of medication 14\n",
      "onset of side effect post starting med 14 ( in days)\n",
      "total duration of side effect of medication 14 (in days)\n",
      "Medication possession ratios 14(MPRs) in lgb;x-syrup\n",
      "cost of medication\n",
      "Other treatments(rehabilitative intervention/IT/CBT/ipt/FT/PMT/BEHAVIOURAL INTERVENTIONS FOR DEVELOPMENTAL DISORDERS, Combination therapy)\n",
      "Maximum duration of symptom free period (in days)\n",
      "Max Duration of resolution of symptoms before recurrence/relapse (in days)\n",
      "No of relapses/exacerbations\n",
      "Off-medications duration (to add all such durations over follow-up in days)\n",
      "Final\n",
      "mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)\n",
      "maximum period of compliance at lgb (in days) (longest streak of good compliance)\n",
      "total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)\n",
      "total number of follow up at LGBRIMH\n",
      "Number of In patient cares\n",
      "total_frequency\n",
      "total_days1\n",
      "days/freq\n",
      "keywords\n",
      "combined_keywords\n",
      "irritable\n",
      "angry\n",
      "abnormal\n",
      "restlessness\n",
      "jerky\n",
      "low\n",
      "outbursts\n"
     ]
    }
   ],
   "source": [
    "column_names = df2.columns.tolist()\n",
    "for name in column_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a965626f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Joint', 'joint', 'Nuclear', 'Single parent', 'Foster family'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Type of Family (Nuclear/Joint/single parent/orphan/ foster family'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f902f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ses_mapping = {\n",
    "    'Joint': 0.25,\n",
    "    'joint': 0.25,\n",
    "    'Nuclear': 0.5,\n",
    "    'Single parent': 0.75,\n",
    "    'Foster family': 1,\n",
    "    np.nan:0,  # Include NaN mapping\n",
    "}\n",
    "df2['Type of Family (Nuclear/Joint/single parent/orphan/ foster family'] = df2['Type of Family (Nuclear/Joint/single parent/orphan/ foster family'].map(ses_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f7149f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Atypical', 'Typical'], dtype=object)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Family environment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "cf215021",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ses_mapping = {\n",
    "    'Atypical': 1,\n",
    "    'Typical': 0.5,\n",
    "    np.nan:0,  \n",
    "}\n",
    "\n",
    "df2['Family environment'] = df2['Family environment'].map(ses_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f8d1f678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'frequent critical comments in family', 'Nil',\n",
       "       'understimulation', 'na', 'child stays with grandfather',\n",
       "       'strained relationship between mother and in-laws',\n",
       "       'permissive parenting, IPR issues between siblings',\n",
       "       'Rigid and harsh parenting, parental hostility and physical abuse, high parental expectations and poor maternal attachment',\n",
       "       'permissive parenting',\n",
       "       'frequent beating by parents, caregiver burden, teasing by others',\n",
       "       'Alcohol abuse in father with phyical and verbal abuse to mother',\n",
       "       'Suicide by father, mother eloped with another man',\n",
       "       'Alcohol abuse in mother with uninvoled parents in the growth of adolescent',\n",
       "       'suicide attempt in elder sister, father has mood disorder, outsides influence in family matters',\n",
       "       'Broken family, maternal lack', 'No',\n",
       "       'Broken family, divorced parents, negligent paternal figure, domestic violence',\n",
       "       'Early history of parental conflict due to gambling issues in father,Separated parents,Enmeshed family boundaries',\n",
       "       'inconsistency parenting', 'Normal',\n",
       "       'father physically abusive toward mother',\n",
       "       'history of multiple deaths within a month in the  family due to unknown reasons',\n",
       "       'Adolescent is abusive towards younger brother'], dtype=object)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Details of family abnormality (describe)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "15b29003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...   days/freq keywords  \\\n",
      "1                    episodes of unresponsiveness   ...   48.083333       []   \n",
      "2      Episodes of abnormal jerky movement of body  ...  886.750000       []   \n",
      "3      episode of abnormal jerky movement with LOC  ...   52.940299       []   \n",
      "4                                      inattention  ...   50.000000       []   \n",
      "5                                   epileptic fits  ...   54.342857       []   \n",
      "..                                             ...  ...         ...      ...   \n",
      "163               delayed developmental milestones  ...   61.600000       []   \n",
      "164  suspiciousness towards parents and neighbours  ...  102.400000       []   \n",
      "186                             Irrelevent Talking  ...  118.000000       []   \n",
      "187    No Memory of events, Cant recognize people   ...   39.545455       []   \n",
      "191                               unable to speak   ...   61.680000       []   \n",
      "\n",
      "                                     combined_keywords  irritable  angry  \\\n",
      "1               [episodes, unresponsiveness, nil, nil]          0      0   \n",
      "2    [episodes, abnormal, jerky, movement, body, po...          0      0   \n",
      "3    [episode, abnormal, jerky, movement, loc, left...          0      0   \n",
      "4    [inattention, hyperactivity, poor, mscholastic...          0      0   \n",
      "5                          [epileptic, fits, nil, nil]          0      0   \n",
      "..                                                 ...        ...    ...   \n",
      "163  [delayed, developmental, milestones, poor, com...          0      0   \n",
      "164  [suspiciousness, towards, parents, neighbours,...          0      1   \n",
      "186  [irrelevent, talking, increased, activity, lev...          0      0   \n",
      "187  [memory, events, cant, recognize, people, stud...          0      0   \n",
      "191  [unable, speak, self, harming, abnormal, jerky...          0      0   \n",
      "\n",
      "    abnormal restlessness jerky low outbursts  \n",
      "1          0            0     0   0         0  \n",
      "2          1            0     1   0         0  \n",
      "3          1            0     1   0         0  \n",
      "4          0            0     0   0         0  \n",
      "5          0            0     0   0         0  \n",
      "..       ...          ...   ...  ..       ...  \n",
      "163        0            0     1   0         0  \n",
      "164        0            0     0   0         0  \n",
      "186        0            0     0   0         0  \n",
      "187        0            0     0   0         0  \n",
      "191        1            0     1   0         0  \n",
      "\n",
      "[148 rows x 271 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2.drop('Details of family abnormality (describe)', axis=1, inplace=True)\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "acaee710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...   days/freq keywords  \\\n",
      "1                    episodes of unresponsiveness   ...   48.083333       []   \n",
      "2      Episodes of abnormal jerky movement of body  ...  886.750000       []   \n",
      "3      episode of abnormal jerky movement with LOC  ...   52.940299       []   \n",
      "4                                      inattention  ...   50.000000       []   \n",
      "5                                   epileptic fits  ...   54.342857       []   \n",
      "..                                             ...  ...         ...      ...   \n",
      "163               delayed developmental milestones  ...   61.600000       []   \n",
      "164  suspiciousness towards parents and neighbours  ...  102.400000       []   \n",
      "186                             Irrelevent Talking  ...  118.000000       []   \n",
      "187    No Memory of events, Cant recognize people   ...   39.545455       []   \n",
      "191                               unable to speak   ...   61.680000       []   \n",
      "\n",
      "                                     combined_keywords  irritable  angry  \\\n",
      "1               [episodes, unresponsiveness, nil, nil]          0      0   \n",
      "2    [episodes, abnormal, jerky, movement, body, po...          0      0   \n",
      "3    [episode, abnormal, jerky, movement, loc, left...          0      0   \n",
      "4    [inattention, hyperactivity, poor, mscholastic...          0      0   \n",
      "5                          [epileptic, fits, nil, nil]          0      0   \n",
      "..                                                 ...        ...    ...   \n",
      "163  [delayed, developmental, milestones, poor, com...          0      0   \n",
      "164  [suspiciousness, towards, parents, neighbours,...          0      1   \n",
      "186  [irrelevent, talking, increased, activity, lev...          0      0   \n",
      "187  [memory, events, cant, recognize, people, stud...          0      0   \n",
      "191  [unable, speak, self, harming, abnormal, jerky...          0      0   \n",
      "\n",
      "    abnormal restlessness jerky low outbursts  \n",
      "1          0            0     0   0         0  \n",
      "2          1            0     1   0         0  \n",
      "3          1            0     1   0         0  \n",
      "4          0            0     0   0         0  \n",
      "5          0            0     0   0         0  \n",
      "..       ...          ...   ...  ..       ...  \n",
      "163        0            0     1   0         0  \n",
      "164        0            0     0   0         0  \n",
      "186        0            0     0   0         0  \n",
      "187        0            0     0   0         0  \n",
      "191        1            0     1   0         0  \n",
      "\n",
      "[148 rows x 270 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2.drop('Family h/o stillbirth/abortion', axis=1, inplace=True)\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "34c26ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...   days/freq keywords  \\\n",
      "1                    episodes of unresponsiveness   ...   48.083333       []   \n",
      "2      Episodes of abnormal jerky movement of body  ...  886.750000       []   \n",
      "3      episode of abnormal jerky movement with LOC  ...   52.940299       []   \n",
      "4                                      inattention  ...   50.000000       []   \n",
      "5                                   epileptic fits  ...   54.342857       []   \n",
      "..                                             ...  ...         ...      ...   \n",
      "163               delayed developmental milestones  ...   61.600000       []   \n",
      "164  suspiciousness towards parents and neighbours  ...  102.400000       []   \n",
      "186                             Irrelevent Talking  ...  118.000000       []   \n",
      "187    No Memory of events, Cant recognize people   ...   39.545455       []   \n",
      "191                               unable to speak   ...   61.680000       []   \n",
      "\n",
      "                                     combined_keywords  irritable  angry  \\\n",
      "1               [episodes, unresponsiveness, nil, nil]          0      0   \n",
      "2    [episodes, abnormal, jerky, movement, body, po...          0      0   \n",
      "3    [episode, abnormal, jerky, movement, loc, left...          0      0   \n",
      "4    [inattention, hyperactivity, poor, mscholastic...          0      0   \n",
      "5                          [epileptic, fits, nil, nil]          0      0   \n",
      "..                                                 ...        ...    ...   \n",
      "163  [delayed, developmental, milestones, poor, com...          0      0   \n",
      "164  [suspiciousness, towards, parents, neighbours,...          0      1   \n",
      "186  [irrelevent, talking, increased, activity, lev...          0      0   \n",
      "187  [memory, events, cant, recognize, people, stud...          0      0   \n",
      "191  [unable, speak, self, harming, abnormal, jerky...          0      0   \n",
      "\n",
      "    abnormal restlessness jerky low outbursts  \n",
      "1          0            0     0   0         0  \n",
      "2          1            0     1   0         0  \n",
      "3          1            0     1   0         0  \n",
      "4          0            0     0   0         0  \n",
      "5          0            0     0   0         0  \n",
      "..       ...          ...   ...  ..       ...  \n",
      "163        0            0     1   0         0  \n",
      "164        0            0     0   0         0  \n",
      "186        0            0     0   0         0  \n",
      "187        0            0     0   0         0  \n",
      "191        1            0     1   0         0  \n",
      "\n",
      "[148 rows x 269 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2.drop('Family history(general medical)', axis=1, inplace=True)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "09e81566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...   days/freq keywords  \\\n",
      "1                    episodes of unresponsiveness   ...   48.083333       []   \n",
      "2      Episodes of abnormal jerky movement of body  ...  886.750000       []   \n",
      "3      episode of abnormal jerky movement with LOC  ...   52.940299       []   \n",
      "4                                      inattention  ...   50.000000       []   \n",
      "5                                   epileptic fits  ...   54.342857       []   \n",
      "..                                             ...  ...         ...      ...   \n",
      "163               delayed developmental milestones  ...   61.600000       []   \n",
      "164  suspiciousness towards parents and neighbours  ...  102.400000       []   \n",
      "186                             Irrelevent Talking  ...  118.000000       []   \n",
      "187    No Memory of events, Cant recognize people   ...   39.545455       []   \n",
      "191                               unable to speak   ...   61.680000       []   \n",
      "\n",
      "                                     combined_keywords  irritable  angry  \\\n",
      "1               [episodes, unresponsiveness, nil, nil]          0      0   \n",
      "2    [episodes, abnormal, jerky, movement, body, po...          0      0   \n",
      "3    [episode, abnormal, jerky, movement, loc, left...          0      0   \n",
      "4    [inattention, hyperactivity, poor, mscholastic...          0      0   \n",
      "5                          [epileptic, fits, nil, nil]          0      0   \n",
      "..                                                 ...        ...    ...   \n",
      "163  [delayed, developmental, milestones, poor, com...          0      0   \n",
      "164  [suspiciousness, towards, parents, neighbours,...          0      1   \n",
      "186  [irrelevent, talking, increased, activity, lev...          0      0   \n",
      "187  [memory, events, cant, recognize, people, stud...          0      0   \n",
      "191  [unable, speak, self, harming, abnormal, jerky...          0      0   \n",
      "\n",
      "    abnormal restlessness jerky low outbursts  \n",
      "1          0            0     0   0         0  \n",
      "2          1            0     1   0         0  \n",
      "3          1            0     1   0         0  \n",
      "4          0            0     0   0         0  \n",
      "5          0            0     0   0         0  \n",
      "..       ...          ...   ...  ..       ...  \n",
      "163        0            0     1   0         0  \n",
      "164        0            0     0   0         0  \n",
      "186        0            0     0   0         0  \n",
      "187        0            0     0   0         0  \n",
      "191        1            0     1   0         0  \n",
      "\n",
      "[148 rows x 268 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2.drop('Family history (psychiatric/neurological)', axis=1, inplace=True)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6a1c7ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...   days/freq keywords  \\\n",
      "1                    episodes of unresponsiveness   ...   48.083333       []   \n",
      "2      Episodes of abnormal jerky movement of body  ...  886.750000       []   \n",
      "3      episode of abnormal jerky movement with LOC  ...   52.940299       []   \n",
      "4                                      inattention  ...   50.000000       []   \n",
      "5                                   epileptic fits  ...   54.342857       []   \n",
      "..                                             ...  ...         ...      ...   \n",
      "163               delayed developmental milestones  ...   61.600000       []   \n",
      "164  suspiciousness towards parents and neighbours  ...  102.400000       []   \n",
      "186                             Irrelevent Talking  ...  118.000000       []   \n",
      "187    No Memory of events, Cant recognize people   ...   39.545455       []   \n",
      "191                               unable to speak   ...   61.680000       []   \n",
      "\n",
      "                                     combined_keywords  irritable  angry  \\\n",
      "1               [episodes, unresponsiveness, nil, nil]          0      0   \n",
      "2    [episodes, abnormal, jerky, movement, body, po...          0      0   \n",
      "3    [episode, abnormal, jerky, movement, loc, left...          0      0   \n",
      "4    [inattention, hyperactivity, poor, mscholastic...          0      0   \n",
      "5                          [epileptic, fits, nil, nil]          0      0   \n",
      "..                                                 ...        ...    ...   \n",
      "163  [delayed, developmental, milestones, poor, com...          0      0   \n",
      "164  [suspiciousness, towards, parents, neighbours,...          0      1   \n",
      "186  [irrelevent, talking, increased, activity, lev...          0      0   \n",
      "187  [memory, events, cant, recognize, people, stud...          0      0   \n",
      "191  [unable, speak, self, harming, abnormal, jerky...          0      0   \n",
      "\n",
      "    abnormal restlessness jerky low outbursts  \n",
      "1          0            0     0   0         0  \n",
      "2          1            0     1   0         0  \n",
      "3          1            0     1   0         0  \n",
      "4          0            0     0   0         0  \n",
      "5          0            0     0   0         0  \n",
      "..       ...          ...   ...  ..       ...  \n",
      "163        0            0     1   0         0  \n",
      "164        0            0     0   0         0  \n",
      "186        0            0     0   0         0  \n",
      "187        0            0     0   0         0  \n",
      "191        1            0     1   0         0  \n",
      "\n",
      "[148 rows x 263 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop = [\n",
    "    'Faith healer visited before consultation or not(yes/no)',\n",
    "    'Antenatal risk factor',\n",
    "    'Place of delivery (Home/hospital)',\n",
    "    'Neonatal complication',\n",
    "    'Birth weight(in kg)'\n",
    "]\n",
    "\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "0d15b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...   days/freq keywords  \\\n",
      "1                    episodes of unresponsiveness   ...   48.083333       []   \n",
      "2      Episodes of abnormal jerky movement of body  ...  886.750000       []   \n",
      "3      episode of abnormal jerky movement with LOC  ...   52.940299       []   \n",
      "4                                      inattention  ...   50.000000       []   \n",
      "5                                   epileptic fits  ...   54.342857       []   \n",
      "..                                             ...  ...         ...      ...   \n",
      "163               delayed developmental milestones  ...   61.600000       []   \n",
      "164  suspiciousness towards parents and neighbours  ...  102.400000       []   \n",
      "186                             Irrelevent Talking  ...  118.000000       []   \n",
      "187    No Memory of events, Cant recognize people   ...   39.545455       []   \n",
      "191                               unable to speak   ...   61.680000       []   \n",
      "\n",
      "                                     combined_keywords  irritable  angry  \\\n",
      "1               [episodes, unresponsiveness, nil, nil]          0      0   \n",
      "2    [episodes, abnormal, jerky, movement, body, po...          0      0   \n",
      "3    [episode, abnormal, jerky, movement, loc, left...          0      0   \n",
      "4    [inattention, hyperactivity, poor, mscholastic...          0      0   \n",
      "5                          [epileptic, fits, nil, nil]          0      0   \n",
      "..                                                 ...        ...    ...   \n",
      "163  [delayed, developmental, milestones, poor, com...          0      0   \n",
      "164  [suspiciousness, towards, parents, neighbours,...          0      1   \n",
      "186  [irrelevent, talking, increased, activity, lev...          0      0   \n",
      "187  [memory, events, cant, recognize, people, stud...          0      0   \n",
      "191  [unable, speak, self, harming, abnormal, jerky...          0      0   \n",
      "\n",
      "    abnormal restlessness jerky low outbursts  \n",
      "1          0            0     0   0         0  \n",
      "2          1            0     1   0         0  \n",
      "3          1            0     1   0         0  \n",
      "4          0            0     0   0         0  \n",
      "5          0            0     0   0         0  \n",
      "..       ...          ...   ...  ..       ...  \n",
      "163        0            0     1   0         0  \n",
      "164        0            0     0   0         0  \n",
      "186        0            0     0   0         0  \n",
      "187        0            0     0   0         0  \n",
      "191        1            0     1   0         0  \n",
      "\n",
      "[148 rows x 262 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop = [\n",
    "    'Postnatal complication',\n",
    "]\n",
    "\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "fe4617a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)\n",
      "Age at last follow up\n",
      "Sex (m/f)\n",
      "Religion\n",
      "Max education attained\n",
      "Rural/Urban\n",
      "Distance from LGBRIMH (in KM)\n",
      "Socioeconomic status\n",
      "Age at onset(in years)\n",
      "Chief complaint 1\n",
      "Chief complaint 2\n",
      "Chief complaint 3\n",
      "Time period between onset to first consultation at LGBRIMH (DUI) (in days)\n",
      "Type of Family (Nuclear/Joint/single parent/orphan/ foster family\n",
      "Family environment\n",
      "Developmental history\n",
      "Age of school entry(in years)\n",
      "Type of school\n",
      "School adjustment\n",
      "Academic performance\n",
      "School dropout present (yes/no)\n",
      "Detail of past psychiatric history 1\n",
      "Past treatment 1\n",
      "Past treatment medication 1\n",
      "Starting dose past medication 1\n",
      "Age of starting of past medication 1(in years)\n",
      "Past maintenance dose1 (in mg)\n",
      "Side effects of past medication 1\n",
      "Age of occurance past side effects 1(in years)\n",
      "Duration of past side effect 1(in months)\n",
      "Response to past medication 1\n",
      "Detail of past history 2\n",
      "Past treatment 2\n",
      "Past treatment medication 2\n",
      "Starting dose past medication 2\n",
      "Age of starting of past medication 2(in years)\n",
      "Past maintenance dose2\n",
      "Side effects of past medication 2\n",
      "Age of occurance past side effects 2(in years)\n",
      "Duration of past side effect 2(in months)\n",
      "Response to past medication 2\n",
      "Detail of past history 3\n",
      "Past treatment  3\n",
      "Past treatment medication 3\n",
      "Starting dose past medication 3 \n",
      "Age of starting past medication 3 (in years)\n",
      "Past maintenance dose 3\n",
      "Side effects past medication 3\n",
      "Age of occurance of past side effects 3 (in years)\n",
      "Duration of past side effects 3 (in months)\n",
      "Response to past medication 3\n",
      "Change in doctor\n",
      "Past/Current medical conditions\n",
      "Age of onset of medical conditions (in years)\n",
      "Details of medical conditions\n",
      "Treatments for medical conditions\n",
      "Severity of medical conditions\n",
      "weight (in Kg)\n",
      "weight z score\n",
      "height (in cm)\n",
      "height z score\n",
      "head circumference (in cm)\n",
      "head circumference z score\n",
      "systemic examination(abnormal/normal)\n",
      "systemic examination details (main finding only)\n",
      "Mental status examination/Behavioral Observation details (abnormal/normal)\n",
      "Mental status examination/Behavioral observation details (main finding only in description)\n",
      "Screening diagnosis \n",
      "detailed workup diagnosis\n",
      "Follow up diagnosis changed or not (yes/no)\n",
      "If yes, changed once or multiple times (once/multiple)\n",
      "If yes, after how many days from first presentation diagnosis changed (in days)\n",
      "If yes, diagnosis changed to what\n",
      "Axis 1_1\n",
      "Axis 1_2\n",
      "Axis 1_3\n",
      "Axis 1_4\n",
      "Axis 2\n",
      "Axis 3\n",
      "Axis 4_1\n",
      "Axis 4_2\n",
      "Axis 4_3\n",
      "Axis 5\n",
      "significant psychosocial stressor\n",
      "name of Medication 1\n",
      "medication 1 starting dose (in mg)\n",
      "Avg dose of medication 1 (Mode value of medication) (in mg)\n",
      "Maximum dose of medication 1 (in mg)\n",
      "Total duration of medication 1 (in days) \n",
      "Continued medication 1/stopped/changed\n",
      "Response to medication 1 (Good/partial/no)\n",
      "Side effect of medication 1\n",
      "onset of side effect post starting med 1 ( in days)\n",
      "total duration of side effect of medication 1 (in days)\n",
      "Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) \n",
      "name of Medication 2\n",
      "Medication 2 starting dose (in mg)\n",
      "Avg dose of medication 2 (in mg)\n",
      "Maximum dose of medication 2 (in mg)\n",
      "Total duration of medication 2(in days) \n",
      "Continued medication 2/stopped/changed\n",
      "Response to medication 2 (Good/partial/no)\n",
      "Side effect of medication 2\n",
      "onset of side effect post starting med 2 ( in days)\n",
      "total duration of side effect of medication 2 (in days)\n",
      "Medication possession ratios 2(MPRs) in lgb;x-syrup\n",
      "name of Medication 3\n",
      "Medication 3 starting dose (in mg)\n",
      "Avg dose of medication 3 (in mg)\n",
      "Maximum dose of medication 3 (in mg)\n",
      "Total duration of medication 3 (in days\n",
      "continued medication 3/stopped/changed\n",
      "Response to medication 3 (Good/partial/no)\n",
      "Side effect of medication 3\n",
      "onset of side effect post starting med 3 ( in days)\n",
      "total duration of side effect of medication 3 (in days)\n",
      "Medication possession ratios 3(MPRs) in lgb;x-syrup\n",
      "name of Medication 4\n",
      "Medication 4 starting dose (in mg)\n",
      "Avg dose of medication 4 (in mg)\n",
      "Maximum dose of medication 4 (in mg)\n",
      "Total duration of medication 4 (in days)\n",
      "continued medication 4/stopped/changed\n",
      "Response to medication 4(Good/partial/no)\n",
      "Side effect of medication 4\n",
      "onset of side effect post starting med 4 ( in days)\n",
      "total duration of side effect of medication 4 (in days)\n",
      "Medication possession ratios 4(MPRs) in lgb;x-syrup\n",
      "name of Medication 5\n",
      "Medication 5 starting dose (in mg)\n",
      "Avg dose of medication 5 (in mg)\n",
      "Maximum dose of medication 5(in mg)\n",
      "Total duration of medication 5 (in days)\n",
      "continued medication 5/stopped/changed\n",
      "Response to medication 5(Good/partial/no)\n",
      "Side effect of medication 5\n",
      "onset of side effect post starting med 5 ( in days)\n",
      "total duration of side effect of medication 5 (in days)\n",
      "Medication possession ratios 5(MPRs) in lgb;x-syrup\n",
      "name of Medication 6\n",
      "Medication 6 starting dose\n",
      "Avg dose of medication 6\n",
      "Maximum dose of medication 6\n",
      "Total duration of medication 6\n",
      "continued medication 6/stopped/changed\n",
      "Response to medication 6(Good/partial/no)\n",
      "Side effect of medication 6\n",
      "onset of side effect post starting med 6 ( in days)\n",
      "total duration of side effect of medication 6 (in days)\n",
      "Medication possession ratios 6(MPRs) in lgb;x-syrup\n",
      "name of Medication 7\n",
      "Medication 7 starting dose\n",
      "Avg dose of medication 7\n",
      "Maximum dose of medication 7\n",
      "Total duration of medication 7\n",
      "continued medication 7/stopped/changed\n",
      "Response to medication 7(Good/partial/no)\n",
      "Side effect of medication 7\n",
      "onset of side effect post starting med 7 ( in days)\n",
      "total duration of side effect of medication 7 (in days)\n",
      "Medication possession ratios 7(MPRs) in lgb;x-syrup\n",
      "name of Medication 8\n",
      "Medication 8 starting dose\n",
      "Avg dose of medication 8\n",
      "Maximum dose of medication 8\n",
      "Total duration of medication 8\n",
      "Continued medication 8/stopped/changed\n",
      "Response to medication 8(Good/partial/no)\n",
      "Side effect of medication 8\n",
      "onset of side effect post starting med 8 ( in days)\n",
      "total duration of side effect of medication 8 (in days)\n",
      "Medication possession ratios 8(MPRs) in lgb;x-syrup\n",
      "name of Medication 9\n",
      "Medication 9 starting dose\n",
      "Avg dose of medication 9\n",
      "Maximum dose of medication 9\n",
      "Total duration of medication 9\n",
      "continued medication 9/stopped/changed\n",
      "Response to medication 9(Good/partial/no)\n",
      "Side effect of medication 9\n",
      "onset of side effect post starting med 9 ( in days)\n",
      "total duration of side effect of medication 9 (in days)\n",
      "Medication possession ratios 9(MPRs) in lgb;x-syrup\n",
      "name of Medication 10\n",
      "Medication 10 starting dose\n",
      "Avg dose of medication 10\n",
      "Maximum dose of medication 10\n",
      "Total duration of medication 10\n",
      "continued medication 10/stopped/changed\n",
      "Response to medication 10(Good/partial/no)\n",
      "Side effect of medication 10\n",
      "onset of side effect post starting med 10 ( in days)\n",
      "total duration of side effect of medication 10 (in days)\n",
      "Medication possession ratios 10(MPRs) in lgb;x-syrup\n",
      "name of Medication 11\n",
      "Medication 11 starting dose\n",
      "Avg dose of medication 11\n",
      "Maximum dose of medication 11\n",
      "Total duration of medication 11\n",
      "continued medication 11/stopped/changed\n",
      "Response to medication 11(Good/partial/no)\n",
      "Side effect of medication 11\n",
      "onset of side effect post starting med 11 ( in days)\n",
      "total duration of side effect of medication 11 (in days)\n",
      "Medication possession ratios 11(MPRs) in lgb;x-syrup\n",
      "name of Medication 12\n",
      "Medication 12 starting dose\n",
      "Avg dose of medication 12\n",
      "Maximum dose of medication 12\n",
      "Total duration of medication 12\n",
      "continued medication 12/stopped/changed\n",
      "Response to medication 12(Good/partial/no)\n",
      "Side effect of medication 12\n",
      "onset of side effect post starting med 12 ( in days)\n",
      "total duration of side effect of medication 12 (in days)\n",
      "Medication possession ratios 12(MPRs) in lgb;x-syrup\n",
      "name of Medication 13\n",
      "Medication 13 starting dose\n",
      "Avg dose of medication 13\n",
      "Maximum dose of medication 13\n",
      "Total duration of medication 13\n",
      "continued medication 13/stopped/changed\n",
      "Response to medication 13(Good/partial/no)\n",
      "Side effect of medication 13\n",
      "onset of side effect post starting med 13 ( in days)\n",
      "total duration of side effect of medication 13 (in days)\n",
      "Medication possession ratios 13(MPRs) in lgb;x-syrup\n",
      "name of Medication 14\n",
      "Medication 14 starting dose\n",
      "Avg dose of medication 14\n",
      "Maximum dose of medication 14\n",
      "Total duration of medication 14\n",
      "continued medication 14/stopped/changed\n",
      "Response to medication 14(Good/partial/no)\n",
      "Side effect of medication 14\n",
      "onset of side effect post starting med 14 ( in days)\n",
      "total duration of side effect of medication 14 (in days)\n",
      "Medication possession ratios 14(MPRs) in lgb;x-syrup\n",
      "cost of medication\n",
      "Other treatments(rehabilitative intervention/IT/CBT/ipt/FT/PMT/BEHAVIOURAL INTERVENTIONS FOR DEVELOPMENTAL DISORDERS, Combination therapy)\n",
      "Maximum duration of symptom free period (in days)\n",
      "Max Duration of resolution of symptoms before recurrence/relapse (in days)\n",
      "No of relapses/exacerbations\n",
      "Off-medications duration (to add all such durations over follow-up in days)\n",
      "Final\n",
      "mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)\n",
      "maximum period of compliance at lgb (in days) (longest streak of good compliance)\n",
      "total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)\n",
      "total number of follow up at LGBRIMH\n",
      "Number of In patient cares\n",
      "total_frequency\n",
      "total_days1\n",
      "days/freq\n",
      "keywords\n",
      "combined_keywords\n",
      "irritable\n",
      "angry\n",
      "abnormal\n",
      "restlessness\n",
      "jerky\n",
      "low\n",
      "outbursts\n"
     ]
    }
   ],
   "source": [
    "column_names = df2.columns.tolist()\n",
    "for name in column_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "639a5b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...   days/freq keywords  \\\n",
      "1                    episodes of unresponsiveness   ...   48.083333       []   \n",
      "2      Episodes of abnormal jerky movement of body  ...  886.750000       []   \n",
      "3      episode of abnormal jerky movement with LOC  ...   52.940299       []   \n",
      "4                                      inattention  ...   50.000000       []   \n",
      "5                                   epileptic fits  ...   54.342857       []   \n",
      "..                                             ...  ...         ...      ...   \n",
      "163               delayed developmental milestones  ...   61.600000       []   \n",
      "164  suspiciousness towards parents and neighbours  ...  102.400000       []   \n",
      "186                             Irrelevent Talking  ...  118.000000       []   \n",
      "187    No Memory of events, Cant recognize people   ...   39.545455       []   \n",
      "191                               unable to speak   ...   61.680000       []   \n",
      "\n",
      "                                     combined_keywords  irritable  angry  \\\n",
      "1               [episodes, unresponsiveness, nil, nil]          0      0   \n",
      "2    [episodes, abnormal, jerky, movement, body, po...          0      0   \n",
      "3    [episode, abnormal, jerky, movement, loc, left...          0      0   \n",
      "4    [inattention, hyperactivity, poor, mscholastic...          0      0   \n",
      "5                          [epileptic, fits, nil, nil]          0      0   \n",
      "..                                                 ...        ...    ...   \n",
      "163  [delayed, developmental, milestones, poor, com...          0      0   \n",
      "164  [suspiciousness, towards, parents, neighbours,...          0      1   \n",
      "186  [irrelevent, talking, increased, activity, lev...          0      0   \n",
      "187  [memory, events, cant, recognize, people, stud...          0      0   \n",
      "191  [unable, speak, self, harming, abnormal, jerky...          0      0   \n",
      "\n",
      "    abnormal restlessness jerky low outbursts  \n",
      "1          0            0     0   0         0  \n",
      "2          1            0     1   0         0  \n",
      "3          1            0     1   0         0  \n",
      "4          0            0     0   0         0  \n",
      "5          0            0     0   0         0  \n",
      "..       ...          ...   ...  ..       ...  \n",
      "163        0            0     1   0         0  \n",
      "164        0            0     0   0         0  \n",
      "186        0            0     0   0         0  \n",
      "187        0            0     0   0         0  \n",
      "191        1            0     1   0         0  \n",
      "\n",
      "[148 rows x 240 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop = [\n",
    "    'Developmental history',\n",
    "    'Age of school entry(in years)',\n",
    "    'School dropout present (yes/no)',\n",
    "    'Detail of past psychiatric history 1',\n",
    "    'Past treatment 1',\n",
    "    'Past treatment medication 1',\n",
    "    'Starting dose past medication 1',\n",
    "    'Age of starting of past medication 1(in years)',\n",
    "    'Past maintenance dose1 (in mg)',\n",
    "    'Side effects of past medication 1',\n",
    "    'Age of occurance past side effects 1(in years)',\n",
    "    'Duration of past side effect 1(in months)',\n",
    "    'Response to past medication 1',\n",
    "    'Detail of past history 2',\n",
    "    'Past treatment 2',\n",
    "    'Past treatment medication 2',\n",
    "    'Starting dose past medication 2',\n",
    "    'Age of starting of past medication 2(in years)',\n",
    "    'Past maintenance dose2',\n",
    "    'Side effects of past medication 2',\n",
    "    'Age of occurance past side effects 2(in years)',\n",
    "    'Duration of past side effect 2(in months)',\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "009423df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data1.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "excel_file_path = 'df2_data1.xlsx'\n",
    "\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ae0500e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...   days/freq keywords  \\\n",
      "1                    episodes of unresponsiveness   ...   48.083333       []   \n",
      "2      Episodes of abnormal jerky movement of body  ...  886.750000       []   \n",
      "3      episode of abnormal jerky movement with LOC  ...   52.940299       []   \n",
      "4                                      inattention  ...   50.000000       []   \n",
      "5                                   epileptic fits  ...   54.342857       []   \n",
      "..                                             ...  ...         ...      ...   \n",
      "163               delayed developmental milestones  ...   61.600000       []   \n",
      "164  suspiciousness towards parents and neighbours  ...  102.400000       []   \n",
      "186                             Irrelevent Talking  ...  118.000000       []   \n",
      "187    No Memory of events, Cant recognize people   ...   39.545455       []   \n",
      "191                               unable to speak   ...   61.680000       []   \n",
      "\n",
      "                                     combined_keywords  irritable  angry  \\\n",
      "1               [episodes, unresponsiveness, nil, nil]          0      0   \n",
      "2    [episodes, abnormal, jerky, movement, body, po...          0      0   \n",
      "3    [episode, abnormal, jerky, movement, loc, left...          0      0   \n",
      "4    [inattention, hyperactivity, poor, mscholastic...          0      0   \n",
      "5                          [epileptic, fits, nil, nil]          0      0   \n",
      "..                                                 ...        ...    ...   \n",
      "163  [delayed, developmental, milestones, poor, com...          0      0   \n",
      "164  [suspiciousness, towards, parents, neighbours,...          0      1   \n",
      "186  [irrelevent, talking, increased, activity, lev...          0      0   \n",
      "187  [memory, events, cant, recognize, people, stud...          0      0   \n",
      "191  [unable, speak, self, harming, abnormal, jerky...          0      0   \n",
      "\n",
      "    abnormal restlessness jerky low outbursts  \n",
      "1          0            0     0   0         0  \n",
      "2          1            0     1   0         0  \n",
      "3          1            0     1   0         0  \n",
      "4          0            0     0   0         0  \n",
      "5          0            0     0   0         0  \n",
      "..       ...          ...   ...  ..       ...  \n",
      "163        0            0     1   0         0  \n",
      "164        0            0     0   0         0  \n",
      "186        0            0     0   0         0  \n",
      "187        0            0     0   0         0  \n",
      "191        1            0     1   0         0  \n",
      "\n",
      "[148 rows x 232 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop = [\n",
    "    'Response to past medication 2',\n",
    "    'Detail of past history 3',\n",
    "    'Past treatment  3',\n",
    "    'Past treatment medication 3',\n",
    "    'Starting dose past medication 3 ',\n",
    "    'Age of starting past medication 3 (in years)',\n",
    "    'Past maintenance dose 3',\n",
    "    'Side effects past medication 3',\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ef6a6e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...   days/freq keywords  \\\n",
      "1                    episodes of unresponsiveness   ...   48.083333       []   \n",
      "2      Episodes of abnormal jerky movement of body  ...  886.750000       []   \n",
      "3      episode of abnormal jerky movement with LOC  ...   52.940299       []   \n",
      "4                                      inattention  ...   50.000000       []   \n",
      "5                                   epileptic fits  ...   54.342857       []   \n",
      "..                                             ...  ...         ...      ...   \n",
      "163               delayed developmental milestones  ...   61.600000       []   \n",
      "164  suspiciousness towards parents and neighbours  ...  102.400000       []   \n",
      "186                             Irrelevent Talking  ...  118.000000       []   \n",
      "187    No Memory of events, Cant recognize people   ...   39.545455       []   \n",
      "191                               unable to speak   ...   61.680000       []   \n",
      "\n",
      "                                     combined_keywords  irritable  angry  \\\n",
      "1               [episodes, unresponsiveness, nil, nil]          0      0   \n",
      "2    [episodes, abnormal, jerky, movement, body, po...          0      0   \n",
      "3    [episode, abnormal, jerky, movement, loc, left...          0      0   \n",
      "4    [inattention, hyperactivity, poor, mscholastic...          0      0   \n",
      "5                          [epileptic, fits, nil, nil]          0      0   \n",
      "..                                                 ...        ...    ...   \n",
      "163  [delayed, developmental, milestones, poor, com...          0      0   \n",
      "164  [suspiciousness, towards, parents, neighbours,...          0      1   \n",
      "186  [irrelevent, talking, increased, activity, lev...          0      0   \n",
      "187  [memory, events, cant, recognize, people, stud...          0      0   \n",
      "191  [unable, speak, self, harming, abnormal, jerky...          0      0   \n",
      "\n",
      "    abnormal restlessness jerky low outbursts  \n",
      "1          0            0     0   0         0  \n",
      "2          1            0     1   0         0  \n",
      "3          1            0     1   0         0  \n",
      "4          0            0     0   0         0  \n",
      "5          0            0     0   0         0  \n",
      "..       ...          ...   ...  ..       ...  \n",
      "163        0            0     1   0         0  \n",
      "164        0            0     0   0         0  \n",
      "186        0            0     0   0         0  \n",
      "187        0            0     0   0         0  \n",
      "191        1            0     1   0         0  \n",
      "\n",
      "[148 rows x 220 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop = [\n",
    "    \n",
    "    'Age of occurance of past side effects 3 (in years)',\n",
    "    'Duration of past side effects 3 (in months)',\n",
    "    'Response to past medication 3',\n",
    "    'Age of onset of medical conditions (in years)',\n",
    "    'Details of medical conditions',\n",
    "    'Treatments for medical conditions',\n",
    "    'Severity of medical conditions',\n",
    "    'weight z score',\n",
    "    'height (in cm)',\n",
    "    'height z score',\n",
    "    'head circumference (in cm)',\n",
    "    'head circumference z score'\n",
    "    \n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "7604a4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ...   days/freq keywords  \\\n",
      "1                    episodes of unresponsiveness   ...   48.083333       []   \n",
      "2      Episodes of abnormal jerky movement of body  ...  886.750000       []   \n",
      "3      episode of abnormal jerky movement with LOC  ...   52.940299       []   \n",
      "4                                      inattention  ...   50.000000       []   \n",
      "5                                   epileptic fits  ...   54.342857       []   \n",
      "..                                             ...  ...         ...      ...   \n",
      "163               delayed developmental milestones  ...   61.600000       []   \n",
      "164  suspiciousness towards parents and neighbours  ...  102.400000       []   \n",
      "186                             Irrelevent Talking  ...  118.000000       []   \n",
      "187    No Memory of events, Cant recognize people   ...   39.545455       []   \n",
      "191                               unable to speak   ...   61.680000       []   \n",
      "\n",
      "                                     combined_keywords  irritable  angry  \\\n",
      "1               [episodes, unresponsiveness, nil, nil]          0      0   \n",
      "2    [episodes, abnormal, jerky, movement, body, po...          0      0   \n",
      "3    [episode, abnormal, jerky, movement, loc, left...          0      0   \n",
      "4    [inattention, hyperactivity, poor, mscholastic...          0      0   \n",
      "5                          [epileptic, fits, nil, nil]          0      0   \n",
      "..                                                 ...        ...    ...   \n",
      "163  [delayed, developmental, milestones, poor, com...          0      0   \n",
      "164  [suspiciousness, towards, parents, neighbours,...          0      1   \n",
      "186  [irrelevent, talking, increased, activity, lev...          0      0   \n",
      "187  [memory, events, cant, recognize, people, stud...          0      0   \n",
      "191  [unable, speak, self, harming, abnormal, jerky...          0      0   \n",
      "\n",
      "    abnormal restlessness jerky low outbursts  \n",
      "1          0            0     0   0         0  \n",
      "2          1            0     1   0         0  \n",
      "3          1            0     1   0         0  \n",
      "4          0            0     0   0         0  \n",
      "5          0            0     0   0         0  \n",
      "..       ...          ...   ...  ..       ...  \n",
      "163        0            0     1   0         0  \n",
      "164        0            0     0   0         0  \n",
      "186        0            0     0   0         0  \n",
      "187        0            0     0   0         0  \n",
      "191        1            0     1   0         0  \n",
      "\n",
      "[148 rows x 208 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop = [\n",
    "    \n",
    "    'If yes, changed once or multiple times (once/multiple)',\n",
    "    'If yes, diagnosis changed to what',\n",
    "    'medication 1 starting dose (in mg)',\n",
    "    'Side effect of medication 1',\n",
    "    'onset of side effect post starting med 1 ( in days)',\n",
    "    'total duration of side effect of medication 1 (in days)',\n",
    "    'Medication 2 starting dose (in mg)',\n",
    "    'Avg dose of medication 2 (in mg)',\n",
    "    'Maximum dose of medication 2 (in mg)',\n",
    "    'Side effect of medication 2',\n",
    "    'onset of side effect post starting med 2 ( in days)',\n",
    "    'total duration of side effect of medication 2 (in days)',\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "cd89dae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "7b1aa544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ... total_frequency  \\\n",
      "1                    episodes of unresponsiveness   ...            12.0   \n",
      "2      Episodes of abnormal jerky movement of body  ...             4.0   \n",
      "3      episode of abnormal jerky movement with LOC  ...            67.0   \n",
      "4                                      inattention  ...             2.0   \n",
      "5                                   epileptic fits  ...            70.0   \n",
      "..                                             ...  ...             ...   \n",
      "163               delayed developmental milestones  ...            10.0   \n",
      "164  suspiciousness towards parents and neighbours  ...             5.0   \n",
      "186                             Irrelevent Talking  ...             3.0   \n",
      "187    No Memory of events, Cant recognize people   ...            22.0   \n",
      "191                               unable to speak   ...            25.0   \n",
      "\n",
      "    total_days1   days/freq  irritable  angry abnormal restlessness jerky low  \\\n",
      "1           577   48.083333          0      0        0            0     0   0   \n",
      "2          3547  886.750000          0      0        1            0     1   0   \n",
      "3          3547   52.940299          0      0        1            0     1   0   \n",
      "4           100   50.000000          0      0        0            0     0   0   \n",
      "5          3804   54.342857          0      0        0            0     0   0   \n",
      "..          ...         ...        ...    ...      ...          ...   ...  ..   \n",
      "163         616   61.600000          0      0        0            0     1   0   \n",
      "164         512  102.400000          0      1        0            0     0   0   \n",
      "186         354  118.000000          0      0        0            0     0   0   \n",
      "187         870   39.545455          0      0        0            0     0   0   \n",
      "191        1542   61.680000          0      0        1            0     1   0   \n",
      "\n",
      "    outbursts  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "5           0  \n",
      "..        ...  \n",
      "163         0  \n",
      "164         0  \n",
      "186         0  \n",
      "187         0  \n",
      "191         0  \n",
      "\n",
      "[148 rows x 177 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop = [\n",
    "    \n",
    "    'combined_keywords',\n",
    "    'keywords',\n",
    "    'Other treatments(rehabilitative intervention/IT/CBT/ipt/FT/PMT/BEHAVIOURAL INTERVENTIONS FOR DEVELOPMENTAL DISORDERS, Combination therapy)',\n",
    "    'Medication possession ratios 14(MPRs) in lgb;x-syrup',\n",
    "    'total duration of side effect of medication 14 (in days)',\n",
    "    'onset of side effect post starting med 14 ( in days)',\n",
    "    'Side effect of medication 14',\n",
    "    'Response to medication 14(Good/partial/no)',\n",
    "    'continued medication 14/stopped/changed',\n",
    "    'Total duration of medication 14',\n",
    "    'Maximum dose of medication 14',\n",
    "    'Avg dose of medication 14',\n",
    "    'Medication 14 starting dose',\n",
    "    'name of Medication 14',\n",
    "    'Medication possession ratios 13(MPRs) in lgb;x-syrup',\n",
    "    'total duration of side effect of medication 13 (in days)',\n",
    "    'onset of side effect post starting med 13 ( in days)',\n",
    "    'Side effect of medication 13',\n",
    "    'Response to medication 13(Good/partial/no)',\n",
    "    'continued medication 13/stopped/changed',\n",
    "    'Total duration of medication 13',\n",
    "    'Maximum dose of medication 13',\n",
    "    'Avg dose of medication 13',\n",
    "    'Medication 13 starting dose',\n",
    "    'name of Medication 13',\n",
    "    'Medication possession ratios 12(MPRs) in lgb;x-syrup',\n",
    "    'total duration of side effect of medication 12 (in days)',\n",
    "    'onset of side effect post starting med 12 ( in days)',\n",
    "    'Side effect of medication 12',\n",
    "    'Response to medication 12(Good/partial/no)',\n",
    "    'continued medication 12/stopped/changed'\n",
    "    ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "16114b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ... total_frequency  \\\n",
      "1                    episodes of unresponsiveness   ...            12.0   \n",
      "2      Episodes of abnormal jerky movement of body  ...             4.0   \n",
      "3      episode of abnormal jerky movement with LOC  ...            67.0   \n",
      "4                                      inattention  ...             2.0   \n",
      "5                                   epileptic fits  ...            70.0   \n",
      "..                                             ...  ...             ...   \n",
      "163               delayed developmental milestones  ...            10.0   \n",
      "164  suspiciousness towards parents and neighbours  ...             5.0   \n",
      "186                             Irrelevent Talking  ...             3.0   \n",
      "187    No Memory of events, Cant recognize people   ...            22.0   \n",
      "191                               unable to speak   ...            25.0   \n",
      "\n",
      "    total_days1   days/freq  irritable  angry abnormal restlessness jerky low  \\\n",
      "1           577   48.083333          0      0        0            0     0   0   \n",
      "2          3547  886.750000          0      0        1            0     1   0   \n",
      "3          3547   52.940299          0      0        1            0     1   0   \n",
      "4           100   50.000000          0      0        0            0     0   0   \n",
      "5          3804   54.342857          0      0        0            0     0   0   \n",
      "..          ...         ...        ...    ...      ...          ...   ...  ..   \n",
      "163         616   61.600000          0      0        0            0     1   0   \n",
      "164         512  102.400000          0      1        0            0     0   0   \n",
      "186         354  118.000000          0      0        0            0     0   0   \n",
      "187         870   39.545455          0      0        0            0     0   0   \n",
      "191        1542   61.680000          0      0        1            0     1   0   \n",
      "\n",
      "    outbursts  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "5           0  \n",
      "..        ...  \n",
      "163         0  \n",
      "164         0  \n",
      "186         0  \n",
      "187         0  \n",
      "191         0  \n",
      "\n",
      "[148 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop = [\n",
    "    'Total duration of medication 12',\n",
    "    'Maximum dose of medication 12',\n",
    "    'Avg dose of medication 12',\n",
    "    'Medication 12 starting dose',\n",
    "    'name of Medication 12',\n",
    "    'Medication possession ratios 11(MPRs) in lgb;x-syrup',\n",
    "    'total duration of side effect of medication 11 (in days)',\n",
    "    'onset of side effect post starting med 11 ( in days)',\n",
    "    'Side effect of medication 11',\n",
    "    'Response to medication 11(Good/partial/no)',\n",
    "    'continued medication 11/stopped/changed',\n",
    "    'Total duration of medication 11',\n",
    "    'Maximum dose of medication 11',\n",
    "    'Avg dose of medication 11',\n",
    "    'Medication 11 starting dose',\n",
    "    'name of Medication 11',\n",
    "    'Medication possession ratios 10(MPRs) in lgb;x-syrup',\n",
    "    'total duration of side effect of medication 10 (in days)',\n",
    "    'onset of side effect post starting med 10 ( in days)',\n",
    "    'Side effect of medication 10',\n",
    "    'Response to medication 10(Good/partial/no)',\n",
    "    'continued medication 10/stopped/changed',\n",
    "    'Total duration of medication 10',\n",
    "    'Maximum dose of medication 10',\n",
    "    'Avg dose of medication 10',\n",
    "    'Medication 10 starting dose'\n",
    "    \n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6c8af889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column name at index 57 is: continued medication 3/stopped/changed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index_to_find = 57 \n",
    "\n",
    "column_name = df2.columns[index_to_find]\n",
    "\n",
    "print(f\"The column name at index {index_to_find} is: {column_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "94bd9dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column name at index 52 is: name of Medication 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index_to_find = 52  \n",
    "\n",
    "column_name = df2.columns[index_to_find]\n",
    "\n",
    "print(f\"The column name at index {index_to_find} is: {column_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c14dfea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column name at index 129 is: name of Medication 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index_to_find = 129  \n",
    "column_name = df2.columns[index_to_find]\n",
    "print(f\"The column name at index {index_to_find} is: {column_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "99e0ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "                                 Chief complaint 1  ... total_frequency  \\\n",
      "1                    episodes of unresponsiveness   ...            12.0   \n",
      "2      Episodes of abnormal jerky movement of body  ...             4.0   \n",
      "3      episode of abnormal jerky movement with LOC  ...            67.0   \n",
      "4                                      inattention  ...             2.0   \n",
      "5                                   epileptic fits  ...            70.0   \n",
      "..                                             ...  ...             ...   \n",
      "163               delayed developmental milestones  ...            10.0   \n",
      "164  suspiciousness towards parents and neighbours  ...             5.0   \n",
      "186                             Irrelevent Talking  ...             3.0   \n",
      "187    No Memory of events, Cant recognize people   ...            22.0   \n",
      "191                               unable to speak   ...            25.0   \n",
      "\n",
      "    total_days1   days/freq  irritable  angry abnormal restlessness jerky low  \\\n",
      "1           577   48.083333          0      0        0            0     0   0   \n",
      "2          3547  886.750000          0      0        1            0     1   0   \n",
      "3          3547   52.940299          0      0        1            0     1   0   \n",
      "4           100   50.000000          0      0        0            0     0   0   \n",
      "5          3804   54.342857          0      0        0            0     0   0   \n",
      "..          ...         ...        ...    ...      ...          ...   ...  ..   \n",
      "163         616   61.600000          0      0        0            0     1   0   \n",
      "164         512  102.400000          0      1        0            0     0   0   \n",
      "186         354  118.000000          0      0        0            0     0   0   \n",
      "187         870   39.545455          0      0        0            0     0   0   \n",
      "191        1542   61.680000          0      0        1            0     1   0   \n",
      "\n",
      "    outbursts  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "5           0  \n",
      "..        ...  \n",
      "163         0  \n",
      "164         0  \n",
      "186         0  \n",
      "187         0  \n",
      "191         0  \n",
      "\n",
      "[148 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop_index = [52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129]  # Replace with the actual index positions you want to drop\n",
    "\n",
    "df2.drop(df2.columns[columns_to_drop_index], axis=1, inplace=True)\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "22920d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5223a65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "    Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                  150                           \n",
      "2                                                    3                           \n",
      "3                                                  Nil                           \n",
      "4                                                   10                           \n",
      "5                                                  912                           \n",
      "..                                                 ...                           \n",
      "163                                               2555                           \n",
      "164                                                 20                           \n",
      "186                                                 75                           \n",
      "187                                                180                           \n",
      "191                                                540                           \n",
      "\n",
      "     ...  total_frequency  total_days1   days/freq irritable angry abnormal  \\\n",
      "1    ...             12.0          577   48.083333         0     0        0   \n",
      "2    ...              4.0         3547  886.750000         0     0        1   \n",
      "3    ...             67.0         3547   52.940299         0     0        1   \n",
      "4    ...              2.0          100   50.000000         0     0        0   \n",
      "5    ...             70.0         3804   54.342857         0     0        0   \n",
      "..   ...              ...          ...         ...       ...   ...      ...   \n",
      "163  ...             10.0          616   61.600000         0     0        0   \n",
      "164  ...              5.0          512  102.400000         0     1        0   \n",
      "186  ...              3.0          354  118.000000         0     0        0   \n",
      "187  ...             22.0          870   39.545455         0     0        0   \n",
      "191  ...             25.0         1542   61.680000         0     0        1   \n",
      "\n",
      "    restlessness jerky low outbursts  \n",
      "1              0     0   0         0  \n",
      "2              0     1   0         0  \n",
      "3              0     1   0         0  \n",
      "4              0     0   0         0  \n",
      "5              0     0   0         0  \n",
      "..           ...   ...  ..       ...  \n",
      "163            0     1   0         0  \n",
      "164            0     0   0         0  \n",
      "186            0     0   0         0  \n",
      "187            0     0   0         0  \n",
      "191            0     1   0         0  \n",
      "\n",
      "[148 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop = ['Chief complaint 1', 'Chief complaint 2', 'Chief complaint 3']\n",
    "\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "19c4f59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...  total_frequency  total_days1   days/freq irritable angry abnormal  \\\n",
      "1    ...             12.0          577   48.083333         0     0        0   \n",
      "2    ...              4.0         3547  886.750000         0     0        1   \n",
      "3    ...             67.0         3547   52.940299         0     0        1   \n",
      "4    ...              2.0          100   50.000000         0     0        0   \n",
      "5    ...             70.0         3804   54.342857         0     0        0   \n",
      "..   ...              ...          ...         ...       ...   ...      ...   \n",
      "163  ...             10.0          616   61.600000         0     0        0   \n",
      "164  ...              5.0          512  102.400000         0     1        0   \n",
      "186  ...              3.0          354  118.000000         0     0        0   \n",
      "187  ...             22.0          870   39.545455         0     0        0   \n",
      "191  ...             25.0         1542   61.680000         0     0        1   \n",
      "\n",
      "    restlessness jerky low outbursts  \n",
      "1              0     0   0         0  \n",
      "2              0     1   0         0  \n",
      "3              0     1   0         0  \n",
      "4              0     0   0         0  \n",
      "5              0     0   0         0  \n",
      "..           ...   ...  ..       ...  \n",
      "163            0     1   0         0  \n",
      "164            0     0   0         0  \n",
      "186            0     0   0         0  \n",
      "187            0     0   0         0  \n",
      "191            0     1   0         0  \n",
      "\n",
      "[148 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2['Time period between onset to first consultation at LGBRIMH (DUI) (in days)'].replace('Nil', 0, inplace=True)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "07626e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...  total_frequency  total_days1   days/freq irritable angry abnormal  \\\n",
      "1    ...             12.0          577   48.083333         0     0        0   \n",
      "2    ...              4.0         3547  886.750000         0     0        1   \n",
      "3    ...             67.0         3547   52.940299         0     0        1   \n",
      "4    ...              2.0          100   50.000000         0     0        0   \n",
      "5    ...             70.0         3804   54.342857         0     0        0   \n",
      "..   ...              ...          ...         ...       ...   ...      ...   \n",
      "163  ...             10.0          616   61.600000         0     0        0   \n",
      "164  ...              5.0          512  102.400000         0     1        0   \n",
      "186  ...              3.0          354  118.000000         0     0        0   \n",
      "187  ...             22.0          870   39.545455         0     0        0   \n",
      "191  ...             25.0         1542   61.680000         0     0        1   \n",
      "\n",
      "    restlessness jerky low outbursts  \n",
      "1              0     0   0         0  \n",
      "2              0     1   0         0  \n",
      "3              0     1   0         0  \n",
      "4              0     0   0         0  \n",
      "5              0     0   0         0  \n",
      "..           ...   ...  ..       ...  \n",
      "163            0     1   0         0  \n",
      "164            0     0   0         0  \n",
      "186            0     0   0         0  \n",
      "187            0     0   0         0  \n",
      "191            0     1   0         0  \n",
      "\n",
      "[148 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop = ['Type of school']\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c098f10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'poorly adjusted', 'well adjusted', 'Nil'], dtype=object)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['School adjustment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "f591b872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    School adjustment  Mapped School Adjustment\n",
      "1                 NaN                       0.0\n",
      "2     poorly adjusted                       0.5\n",
      "3                 NaN                       0.0\n",
      "4       well adjusted                       1.0\n",
      "5                 NaN                       0.0\n",
      "..                ...                       ...\n",
      "163               Nil                       0.0\n",
      "164   poorly adjusted                       0.5\n",
      "186     well adjusted                       1.0\n",
      "187               NaN                       0.0\n",
      "191   poorly adjusted                       0.5\n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "school_adjustment_mapping = {\n",
    "    'poorly adjusted': 0.5,\n",
    "    'well adjusted': 1,\n",
    "    'Nil': 0,\n",
    "    np.nan: 0  # Include NaN mapping if needed\n",
    "}\n",
    "\n",
    "df2['Mapped School Adjustment'] = df2['School adjustment'].map(school_adjustment_mapping)\n",
    "print(df2[['School adjustment', 'Mapped School Adjustment']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "b829913c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'poor ', 'poor', 'Nil', 'Good', 'average'], dtype=object)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Academic performance'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "2908bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "school_adjustment_mapping = {\n",
    "    'Nil': 0,\n",
    "    'poor' : 0.33,\n",
    "    'poor ' : 0.33,\n",
    "    'Good' : 1,\n",
    "    'average' : 0.66,\n",
    "    np.nan: 0  # Include NaN mapping if needed\n",
    "}\n",
    "df2['Academic performance'] = df2['Academic performance'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c3c6df37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...  total_frequency  total_days1   days/freq  irritable angry abnormal  \\\n",
      "1    ...             12.0          577   48.083333          0     0        0   \n",
      "2    ...              4.0         3547  886.750000          0     0        1   \n",
      "3    ...             67.0         3547   52.940299          0     0        1   \n",
      "4    ...              2.0          100   50.000000          0     0        0   \n",
      "5    ...             70.0         3804   54.342857          0     0        0   \n",
      "..   ...              ...          ...         ...        ...   ...      ...   \n",
      "163  ...             10.0          616   61.600000          0     0        0   \n",
      "164  ...              5.0          512  102.400000          0     1        0   \n",
      "186  ...              3.0          354  118.000000          0     0        0   \n",
      "187  ...             22.0          870   39.545455          0     0        0   \n",
      "191  ...             25.0         1542   61.680000          0     0        1   \n",
      "\n",
      "    restlessness jerky low outbursts  \n",
      "1              0     0   0         0  \n",
      "2              0     1   0         0  \n",
      "3              0     1   0         0  \n",
      "4              0     0   0         0  \n",
      "5              0     0   0         0  \n",
      "..           ...   ...  ..       ...  \n",
      "163            0     1   0         0  \n",
      "164            0     0   0         0  \n",
      "186            0     0   0         0  \n",
      "187            0     0   0         0  \n",
      "191            0     1   0         0  \n",
      "\n",
      "[148 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_drop = [\n",
    "    'Mapped School Adjustment'  \n",
    "]\n",
    "\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "36120528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes (single)', 'Yes(multiple)', 'Nil', nan], dtype=object)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Change in doctor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "7af4b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "school_adjustment_mapping = {\n",
    "    'No': 0.66,\n",
    "    'Yes (single)' : 1,\n",
    "    'Yes(multiple)' : 1,\n",
    "    'Nil' : 0.33,\n",
    "    np.nan: 0  # Include NaN mapping if needed\n",
    "}\n",
    "df2['Change in doctor'] = df2['Change in doctor'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d4d4c993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'yes', nan, 'Nil'], dtype=object)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Past/Current medical conditions'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "4cccbe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "school_adjustment_mapping = {\n",
    "    'No': 1,\n",
    "    'yes' : 0.5,\n",
    "    'Nil' : 0,\n",
    "    np.nan: 0  # Include NaN mapping if needed\n",
    "}\n",
    "\n",
    "df2['Change in doctor'] = df2['Change in doctor'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "8e00f584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal', 'Abnormal', 'abnormal', nan], dtype=object)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['systemic examination(abnormal/normal)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6ff6d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "school_adjustment_mapping = {\n",
    "    'abnormal': 1,\n",
    "    'Abnormal' : 1,\n",
    "    'Normal' : 0.5,\n",
    "    np.nan: 0  # Include NaN mapping if needed\n",
    "}\n",
    "\n",
    "df2['systemic examination(abnormal/normal)'] = df2['systemic examination(abnormal/normal)'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "e613ff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...  total_frequency  total_days1   days/freq  irritable  angry abnormal  \\\n",
      "1    ...             12.0          577   48.083333          0      0        0   \n",
      "2    ...              4.0         3547  886.750000          0      0        1   \n",
      "3    ...             67.0         3547   52.940299          0      0        1   \n",
      "4    ...              2.0          100   50.000000          0      0        0   \n",
      "5    ...             70.0         3804   54.342857          0      0        0   \n",
      "..   ...              ...          ...         ...        ...    ...      ...   \n",
      "163  ...             10.0          616   61.600000          0      0        0   \n",
      "164  ...              5.0          512  102.400000          0      1        0   \n",
      "186  ...              3.0          354  118.000000          0      0        0   \n",
      "187  ...             22.0          870   39.545455          0      0        0   \n",
      "191  ...             25.0         1542   61.680000          0      0        1   \n",
      "\n",
      "    restlessness  jerky low outbursts  \n",
      "1              0      0   0         0  \n",
      "2              0      1   0         0  \n",
      "3              0      1   0         0  \n",
      "4              0      0   0         0  \n",
      "5              0      0   0         0  \n",
      "..           ...    ...  ..       ...  \n",
      "163            0      1   0         0  \n",
      "164            0      0   0         0  \n",
      "186            0      0   0         0  \n",
      "187            0      0   0         0  \n",
      "191            0      1   0         0  \n",
      "\n",
      "[148 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming the columns to drop are as follows\n",
    "columns_to_drop = [\n",
    "    'systemic examination details (main finding only)'\n",
    "    \n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e0b10ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['normal', 'abnormal', nan], dtype=object)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Mental status examination/Behavioral Observation details (abnormal/normal)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "eff4e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "school_adjustment_mapping = {\n",
    "    'abnormal' : 1,\n",
    "    'normal' : 0.5,\n",
    "    np.nan: 0  # Include NaN mapping if needed\n",
    "}\n",
    "\n",
    "df2['Mental status examination/Behavioral Observation details (abnormal/normal)'] = df2['Mental status examination/Behavioral Observation details (abnormal/normal)'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f0ee8f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['normal',\n",
       "       'look sickly and dysphoric affect, decrease and hesitant speech',\n",
       "       'distractible,hyperactive,inattentive', 'not-cooperative',\n",
       "       'decrease productivity in speech, increase reaction time, poor judgement',\n",
       "       'stereotypies', 'restless', 'restlessness',\n",
       "       'anxious affect, hopelesness, helplesness, worthlesness',\n",
       "       'irrelevant speech', nan,\n",
       "       'attention not sustained, auditory hallucination',\n",
       "       'unkempt, untidy, abussive words, increase pma, increase prosody in speech, decrease reaction time, mood good, affect agitated, unable to elicite thought and perception',\n",
       "       'hyperactive, poor eye to eye contact',\n",
       "       'Inattentive, decrease volume in speech, and increased reaction time, below average intelligence',\n",
       "       'neurotic behaviour', 'pseudohallucination',\n",
       "       'Mood conveyed to be not good, depressed affect, low self esteem,ideas of helplessness and worthlessness in thought,impaired personal judgement',\n",
       "       'Restlessness and overfamiliarity, increased speech productivity,poor judgement',\n",
       "       'Rapport establieshed with difficulty, decrease speech tone, decrease productivity, increase reaction time, blunt affect suspected auditory hallucination',\n",
       "       'Increased psychomotor activity,below average intelligence,poor insight',\n",
       "       'Increased psychomotor activity,uncooperative', 'Normal',\n",
       "       'Irritable affect, Inappropriate smile', 'auditory hallucination ',\n",
       "       'poor eye contact', 'aggressive behavior, irrelevant speech',\n",
       "       'decreased psychomotor activity,perplexed affect',\n",
       "       'no eye contact, delusion that family members have changed, elementray AH',\n",
       "       'increased psychomotor activity, irritable affect, ideas of grandiosity, elimentary auditory hallucination, attention aroused but  not sustained',\n",
       "       'tightening of body and crying continuosly',\n",
       "       'increased psychomotor activity, depressed and restricted affect, delusion of reference and persecution grade 3 insight',\n",
       "       'Incomprehensible sound, started displacing things, does not reciprocate with examiner question, started biting object',\n",
       "       'eye to ey contact not maintain.rapport not established, anxious affect',\n",
       "       'self absorbed, rapport not established , auditory hallucination grade 1 insight',\n",
       "       'not interecting during interview, evasive, poor eye contact, decrease psychomotor  activity',\n",
       "       'sit on chair with support, respond on calling his name, could identify mother',\n",
       "       'poor eye contact, rapport not established, poor intelligence, attention not sustained',\n",
       "       'blunted affect, referential ideas, second and third person auditory hallucination, impaired judgement with grade 1 inside',\n",
       "       'Unable to sit unsupported',\n",
       "       'Preoccupation with illness,worry regarding studies,anxious affect',\n",
       "       'decreased psychomotor activity, decreased productivity in speech, depressed mood',\n",
       "       'hyperactive, not sustaining the given task, difficulty in comprehension',\n",
       "       'increased psychomotor activity, incomprehensible speech',\n",
       "       'hostile,uninterested attitude,irritable affect',\n",
       "       'Increased psychomotor activity, inappropriate affect, delusion of persecution, impaired memory, insight grade1',\n",
       "       'increased psychomotor activity, partial eye contact, rapport not established, irritable affect',\n",
       "       'ormal', 'does not speak',\n",
       "       'hostile, increased psychomotor activity, increased speech output, irritable affect, grade 1 insight',\n",
       "       'restlessness, running around the room',\n",
       "       'keep tapping the table, babbling',\n",
       "       'decreased psychomotor activity, decreased productivity in speech, increased reaction time, uncooperative, recticted affect, insight grade 2',\n",
       "       'irritable , rapport not establieshed, irrelevant speech',\n",
       "       'child cant speak',\n",
       "       'Anxious affect, preoccupation with the drowning incident',\n",
       "       'uncooperative, increased psychomotor activity, irritable affect, irrelvent speech, poor judgment grade 1 insight',\n",
       "       'restless, poor eye contact,stereotypic hand movements',\n",
       "       'unkempt and untidy, poor eye contact,decreased speech productivity,perplexed affect,poor judgement ,grade 1 insight',\n",
       "       'ideas of hopelessness,helplessness,pseudo auditory and visual hallucinations',\n",
       "       'uncooperative, guarded,decreased psychomotor activity',\n",
       "       'irritable, disrobing',\n",
       "       'Uncooperative,poor eye contact,decreased psychomotor activity,inappropriate affect',\n",
       "       'Uncooperative,increased psychomotor activity',\n",
       "       'por eye contact, prosody of speech decreased, increased reaction time, dysphoric affect with restricted range, ideas of helplessnes and hopelessness',\n",
       "       'anxious affect',\n",
       "       'decreased psychomotor activity, shallow affect, poor personal and social judgement',\n",
       "       'anxious affect persecutory ideas, third person auditory hallucination',\n",
       "       'calm, eye contact present, suddenly got aggressive, blunt affect',\n",
       "       'irritable and hostile, abusing his family members, increased psychomotor activity, increased productivity in speech and decreased reaction time, thought preoccupation with going to mumbai',\n",
       "       'silly smilling , poor eye contact, head banging',\n",
       "       'decreased eye contact, decreased speech producitvity',\n",
       "       'frequently looks at ceiling, unsustained eye contact, does not initiate gesture',\n",
       "       'inappropriate affect, 2nd PAH',\n",
       "       'increased psychomotor activity, shallow affect',\n",
       "       'non cooperative, rapport not established, aggressive and restless, non coherent speech',\n",
       "       'irritable affect, irrelevant speech',\n",
       "       'Decreased psychomotor activity,guarded attitute flat affect, mutism',\n",
       "       'increased psychomotor activity,decreased eye contact,plays alone,irritable affect',\n",
       "       'uncooprerative, inappropriate smiling,irritable affect',\n",
       "       'depressed affect,preoccupation of electric shock',\n",
       "       'clinging to mother, irritable affect, poor eye contact',\n",
       "       'depressed affect, idea of hopelessnes,suicidal ideation',\n",
       "       'increased psychomotor activity',\n",
       "       'uncooprerative, restless, repeatedly hitting self,making uncomprehensible sound',\n",
       "       'smilling to self, poor eye contact, low speech productivity, impaired social and personal judgement, insight grade 1',\n",
       "       'Anxious affect, Tics are seen which are exacerbated by anxiety,ideas of helplessness and preoccupation with cleanliness in thought content',\n",
       "       'inappropriate affect, persucutory ideas towards cousin brother, second person auditory hallucinatory',\n",
       "       'touching the things lying on the table, not listening to the interviewer and mother, making noises while sitting',\n",
       "       'poor intelligence', 'irritable affect, impaired judgment',\n",
       "       'anxious affect, thought content rationalization,impaired judgment with grade 1 insight',\n",
       "       'impaired orientation to time, grade 1 insight',\n",
       "       'fidgetting , repeatedly getting up, slurrred speech',\n",
       "       'dysphoric affect', 'poverty of speech', 'irritable, restless',\n",
       "       'cannot follow instructions, irritable affect',\n",
       "       'anxious, fearful, AH present',\n",
       "       'overgroomed, irritable, inappropriate affect, increased PMA',\n",
       "       'restless, irritable, abusive, disruptive',\n",
       "       'crying spells, depressed affect, guarded',\n",
       "       'absent eye contact, decreased PMA, delusion of persecution, insight grade 2',\n",
       "       'shouting,restless,irritable,not responding to questions',\n",
       "       'depressed affect, increased psychomotor activity, ideas of hopelessness',\n",
       "       'restless, easily distractible, increased PMA, no verbalization',\n",
       "       'Reduced PMA, restricted range of mood',\n",
       "       'Increased PMA, Pressure of Speech, Overfamiliarity',\n",
       "       'Anxious affect, Impaired Judgement, Grade 1 Insight',\n",
       "       'non cooperative, rapport not established'], dtype=object)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Mental status examination/Behavioral observation details (main finding only in description)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "30a02234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mental status examination/Behavioral observation details (main finding only in description)  \\\n",
      "1                                               normal                                            \n",
      "2    look sickly and dysphoric affect, decrease and...                                            \n",
      "3                                               normal                                            \n",
      "4                 distractible,hyperactive,inattentive                                            \n",
      "5                                               normal                                            \n",
      "..                                                 ...                                            \n",
      "163  restless, easily distractible, increased PMA, ...                                            \n",
      "164              Reduced PMA, restricted range of mood                                            \n",
      "186  Increased PMA, Pressure of Speech, Overfamilia...                                            \n",
      "187  Anxious affect, Impaired Judgement, Grade 1 In...                                            \n",
      "191           non cooperative, rapport not established                                            \n",
      "\n",
      "    Keywords  \n",
      "1         []  \n",
      "2         []  \n",
      "3         []  \n",
      "4         []  \n",
      "5         []  \n",
      "..       ...  \n",
      "163       []  \n",
      "164       []  \n",
      "186       []  \n",
      "187       []  \n",
      "191       []  \n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "column_name = 'Mental status examination/Behavioral observation details (main finding only in description)'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def extract_keywords(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.isalpha() and word.lower() not in stop_words]\n",
    "    keywords = [word for word, count in Counter(tokens).items() if count > 1]  # Adjust frequency threshold as needed\n",
    "    return keywords\n",
    "\n",
    "df2['Keywords'] = df2[column_name].apply(extract_keywords)\n",
    "print(df2[[column_name, 'Keywords']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f5cf2729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: affect, Frequency: 45\n",
      "Word: normal, Frequency: 33\n",
      "Word: speech, Frequency: 24\n",
      "Word: increased, Frequency: 24\n",
      "Word: psychomotor, Frequency: 23\n",
      "Word: activity, Frequency: 23\n",
      "Word: eye, Frequency: 20\n",
      "Word: contact, Frequency: 19\n",
      "Word: irritable, Frequency: 19\n",
      "Word: poor, Frequency: 18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "column_name = 'Mental status examination/Behavioral observation details (main finding only in description)'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def extract_keywords(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.isalpha() and word.lower() not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "df2['Keywords'] = df2[column_name].apply(extract_keywords)\n",
    "all_tokens = [token for sublist in df2['Keywords'].tolist() for token in sublist]\n",
    "word_counts = Counter(all_tokens)\n",
    "\n",
    "most_common_words = word_counts.most_common(10)\n",
    "for word, frequency in most_common_words:\n",
    "    print(f\"Word: {word}, Frequency: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "62ff65d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: normal, Frequency: 33\n",
      "Word: look, Frequency: 1\n",
      "Word: sickly, Frequency: 1\n",
      "Word: dysphoric, Frequency: 3\n",
      "Word: affect, Frequency: 45\n",
      "Word: decrease, Frequency: 7\n",
      "Word: hesitant, Frequency: 1\n",
      "Word: speech, Frequency: 24\n",
      "Word: distractible, Frequency: 2\n",
      "Word: hyperactive, Frequency: 3\n",
      "Word: inattentive, Frequency: 2\n",
      "Word: productivity, Frequency: 8\n",
      "Word: increase, Frequency: 4\n",
      "Word: reaction, Frequency: 7\n",
      "Word: time, Frequency: 8\n",
      "Word: poor, Frequency: 18\n",
      "Word: judgement, Frequency: 8\n",
      "Word: stereotypies, Frequency: 1\n",
      "Word: restless, Frequency: 10\n",
      "Word: restlessness, Frequency: 4\n",
      "Word: anxious, Frequency: 10\n",
      "Word: hopelesness, Frequency: 1\n",
      "Word: helplesness, Frequency: 1\n",
      "Word: worthlesness, Frequency: 1\n",
      "Word: irrelevant, Frequency: 4\n",
      "Word: nan, Frequency: 5\n",
      "Word: attention, Frequency: 3\n",
      "Word: sustained, Frequency: 3\n",
      "Word: auditory, Frequency: 9\n",
      "Word: hallucination, Frequency: 7\n",
      "Word: unkempt, Frequency: 2\n",
      "Word: untidy, Frequency: 2\n",
      "Word: abussive, Frequency: 1\n",
      "Word: words, Frequency: 1\n",
      "Word: pma, Frequency: 6\n",
      "Word: prosody, Frequency: 2\n",
      "Word: mood, Frequency: 4\n",
      "Word: good, Frequency: 2\n",
      "Word: agitated, Frequency: 1\n",
      "Word: unable, Frequency: 2\n",
      "Word: elicite, Frequency: 1\n",
      "Word: thought, Frequency: 5\n",
      "Word: perception, Frequency: 1\n",
      "Word: eye, Frequency: 20\n",
      "Word: contact, Frequency: 19\n",
      "Word: volume, Frequency: 1\n",
      "Word: increased, Frequency: 24\n",
      "Word: average, Frequency: 2\n",
      "Word: intelligence, Frequency: 4\n",
      "Word: neurotic, Frequency: 1\n",
      "Word: behaviour, Frequency: 1\n",
      "Word: pseudohallucination, Frequency: 1\n",
      "Word: conveyed, Frequency: 1\n",
      "Word: depressed, Frequency: 7\n",
      "Word: low, Frequency: 2\n",
      "Word: self, Frequency: 4\n",
      "Word: esteem, Frequency: 1\n",
      "Word: ideas, Frequency: 9\n",
      "Word: helplessness, Frequency: 3\n",
      "Word: worthlessness, Frequency: 1\n",
      "Word: impaired, Frequency: 8\n",
      "Word: personal, Frequency: 3\n",
      "Word: overfamiliarity, Frequency: 2\n",
      "Word: rapport, Frequency: 7\n",
      "Word: establieshed, Frequency: 2\n",
      "Word: difficulty, Frequency: 2\n",
      "Word: tone, Frequency: 1\n",
      "Word: blunt, Frequency: 2\n",
      "Word: suspected, Frequency: 1\n",
      "Word: psychomotor, Frequency: 23\n",
      "Word: activity, Frequency: 23\n",
      "Word: insight, Frequency: 13\n",
      "Word: uncooperative, Frequency: 6\n",
      "Word: irritable, Frequency: 19\n",
      "Word: inappropriate, Frequency: 7\n",
      "Word: smile, Frequency: 1\n",
      "Word: aggressive, Frequency: 3\n",
      "Word: behavior, Frequency: 1\n",
      "Word: decreased, Frequency: 16\n",
      "Word: perplexed, Frequency: 2\n",
      "Word: delusion, Frequency: 4\n",
      "Word: family, Frequency: 2\n",
      "Word: members, Frequency: 2\n",
      "Word: changed, Frequency: 1\n",
      "Word: elementray, Frequency: 1\n",
      "Word: ah, Frequency: 2\n",
      "Word: grandiosity, Frequency: 1\n",
      "Word: elimentary, Frequency: 1\n",
      "Word: aroused, Frequency: 1\n",
      "Word: tightening, Frequency: 1\n",
      "Word: body, Frequency: 1\n",
      "Word: crying, Frequency: 2\n",
      "Word: continuosly, Frequency: 1\n",
      "Word: restricted, Frequency: 3\n",
      "Word: reference, Frequency: 1\n",
      "Word: persecution, Frequency: 3\n",
      "Word: grade, Frequency: 12\n",
      "Word: incomprehensible, Frequency: 2\n",
      "Word: sound, Frequency: 2\n",
      "Word: started, Frequency: 2\n",
      "Word: displacing, Frequency: 1\n",
      "Word: things, Frequency: 2\n",
      "Word: reciprocate, Frequency: 1\n",
      "Word: examiner, Frequency: 1\n",
      "Word: question, Frequency: 1\n",
      "Word: biting, Frequency: 1\n",
      "Word: object, Frequency: 1\n",
      "Word: ey, Frequency: 1\n",
      "Word: established, Frequency: 6\n",
      "Word: absorbed, Frequency: 1\n",
      "Word: interecting, Frequency: 1\n",
      "Word: interview, Frequency: 1\n",
      "Word: evasive, Frequency: 1\n",
      "Word: sit, Frequency: 2\n",
      "Word: chair, Frequency: 1\n",
      "Word: support, Frequency: 1\n",
      "Word: respond, Frequency: 1\n",
      "Word: calling, Frequency: 1\n",
      "Word: name, Frequency: 1\n",
      "Word: could, Frequency: 1\n",
      "Word: identify, Frequency: 1\n",
      "Word: mother, Frequency: 3\n",
      "Word: blunted, Frequency: 1\n",
      "Word: referential, Frequency: 1\n",
      "Word: second, Frequency: 2\n",
      "Word: third, Frequency: 2\n",
      "Word: person, Frequency: 3\n",
      "Word: inside, Frequency: 1\n",
      "Word: unsupported, Frequency: 1\n",
      "Word: preoccupation, Frequency: 5\n",
      "Word: illness, Frequency: 1\n",
      "Word: worry, Frequency: 1\n",
      "Word: regarding, Frequency: 1\n",
      "Word: studies, Frequency: 1\n",
      "Word: sustaining, Frequency: 1\n",
      "Word: given, Frequency: 1\n",
      "Word: task, Frequency: 1\n",
      "Word: comprehension, Frequency: 1\n",
      "Word: hostile, Frequency: 3\n",
      "Word: uninterested, Frequency: 1\n",
      "Word: attitude, Frequency: 1\n",
      "Word: memory, Frequency: 1\n",
      "Word: partial, Frequency: 1\n",
      "Word: ormal, Frequency: 1\n",
      "Word: speak, Frequency: 2\n",
      "Word: output, Frequency: 1\n",
      "Word: running, Frequency: 2\n",
      "Word: around, Frequency: 2\n",
      "Word: room, Frequency: 2\n",
      "Word: keep, Frequency: 1\n",
      "Word: tapping, Frequency: 1\n",
      "Word: table, Frequency: 2\n",
      "Word: babbling, Frequency: 1\n",
      "Word: recticted, Frequency: 1\n",
      "Word: child, Frequency: 1\n",
      "Word: cant, Frequency: 1\n",
      "Word: drowning, Frequency: 1\n",
      "Word: incident, Frequency: 1\n",
      "Word: irrelvent, Frequency: 1\n",
      "Word: judgment, Frequency: 3\n",
      "Word: stereotypic, Frequency: 1\n",
      "Word: hand, Frequency: 1\n",
      "Word: movements, Frequency: 1\n",
      "Word: hopelessness, Frequency: 3\n",
      "Word: pseudo, Frequency: 1\n",
      "Word: visual, Frequency: 1\n",
      "Word: hallucinations, Frequency: 1\n",
      "Word: guarded, Frequency: 3\n",
      "Word: disrobing, Frequency: 1\n",
      "Word: por, Frequency: 1\n",
      "Word: range, Frequency: 2\n",
      "Word: helplessnes, Frequency: 1\n",
      "Word: shallow, Frequency: 2\n",
      "Word: social, Frequency: 2\n",
      "Word: persecutory, Frequency: 1\n",
      "Word: calm, Frequency: 1\n",
      "Word: present, Frequency: 2\n",
      "Word: suddenly, Frequency: 1\n",
      "Word: got, Frequency: 1\n",
      "Word: abusing, Frequency: 1\n",
      "Word: going, Frequency: 1\n",
      "Word: mumbai, Frequency: 1\n",
      "Word: silly, Frequency: 1\n",
      "Word: smilling, Frequency: 2\n",
      "Word: head, Frequency: 1\n",
      "Word: banging, Frequency: 1\n",
      "Word: producitvity, Frequency: 1\n",
      "Word: frequently, Frequency: 1\n",
      "Word: looks, Frequency: 1\n",
      "Word: ceiling, Frequency: 1\n",
      "Word: unsustained, Frequency: 1\n",
      "Word: initiate, Frequency: 1\n",
      "Word: gesture, Frequency: 1\n",
      "Word: pah, Frequency: 1\n",
      "Word: non, Frequency: 3\n",
      "Word: cooperative, Frequency: 2\n",
      "Word: coherent, Frequency: 1\n",
      "Word: attitute, Frequency: 1\n",
      "Word: flat, Frequency: 1\n",
      "Word: mutism, Frequency: 1\n",
      "Word: plays, Frequency: 1\n",
      "Word: alone, Frequency: 1\n",
      "Word: uncooprerative, Frequency: 2\n",
      "Word: smiling, Frequency: 1\n",
      "Word: electric, Frequency: 1\n",
      "Word: shock, Frequency: 1\n",
      "Word: clinging, Frequency: 1\n",
      "Word: idea, Frequency: 1\n",
      "Word: hopelessnes, Frequency: 1\n",
      "Word: suicidal, Frequency: 1\n",
      "Word: ideation, Frequency: 1\n",
      "Word: repeatedly, Frequency: 2\n",
      "Word: hitting, Frequency: 1\n",
      "Word: making, Frequency: 2\n",
      "Word: uncomprehensible, Frequency: 1\n",
      "Word: tics, Frequency: 1\n",
      "Word: seen, Frequency: 1\n",
      "Word: exacerbated, Frequency: 1\n",
      "Word: anxiety, Frequency: 1\n",
      "Word: cleanliness, Frequency: 1\n",
      "Word: content, Frequency: 2\n",
      "Word: persucutory, Frequency: 1\n",
      "Word: towards, Frequency: 1\n",
      "Word: cousin, Frequency: 1\n",
      "Word: brother, Frequency: 1\n",
      "Word: hallucinatory, Frequency: 1\n",
      "Word: touching, Frequency: 1\n",
      "Word: lying, Frequency: 1\n",
      "Word: listening, Frequency: 1\n",
      "Word: interviewer, Frequency: 1\n",
      "Word: noises, Frequency: 1\n",
      "Word: sitting, Frequency: 1\n",
      "Word: rationalization, Frequency: 1\n",
      "Word: orientation, Frequency: 1\n",
      "Word: fidgetting, Frequency: 1\n",
      "Word: getting, Frequency: 1\n",
      "Word: slurrred, Frequency: 1\n",
      "Word: poverty, Frequency: 1\n",
      "Word: follow, Frequency: 1\n",
      "Word: instructions, Frequency: 1\n",
      "Word: fearful, Frequency: 1\n",
      "Word: overgroomed, Frequency: 1\n",
      "Word: abusive, Frequency: 1\n",
      "Word: disruptive, Frequency: 1\n",
      "Word: spells, Frequency: 1\n",
      "Word: absent, Frequency: 1\n",
      "Word: shouting, Frequency: 1\n",
      "Word: responding, Frequency: 1\n",
      "Word: questions, Frequency: 1\n",
      "Word: easily, Frequency: 1\n",
      "Word: verbalization, Frequency: 1\n",
      "Word: reduced, Frequency: 1\n",
      "Word: pressure, Frequency: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "column_name = 'Mental status examination/Behavioral observation details (main finding only in description)'\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def extract_keywords(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.isalpha() and word.lower() not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "df2['Keywords'] = df2[column_name].apply(extract_keywords)\n",
    "\n",
    "\n",
    "all_tokens = [token for sublist in df2['Keywords'].tolist() for token in sublist]\n",
    "\n",
    "word_counts = Counter(all_tokens)\n",
    "\n",
    "for word, frequency in word_counts.items():\n",
    "    print(f\"Word: {word}, Frequency: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "a0414fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: affect, Frequency: 45\n",
      "Word: normal, Frequency: 33\n",
      "Word: speech, Frequency: 24\n",
      "Word: increased, Frequency: 24\n",
      "Word: psychomotor, Frequency: 23\n",
      "Word: activity, Frequency: 23\n",
      "Word: eye, Frequency: 20\n",
      "Word: contact, Frequency: 19\n",
      "Word: irritable, Frequency: 19\n",
      "Word: poor, Frequency: 18\n",
      "Word: decreased, Frequency: 16\n",
      "Word: insight, Frequency: 13\n",
      "Word: grade, Frequency: 12\n",
      "Word: restless, Frequency: 10\n",
      "Word: anxious, Frequency: 10\n",
      "Word: auditory, Frequency: 9\n",
      "Word: ideas, Frequency: 9\n",
      "Word: productivity, Frequency: 8\n",
      "Word: time, Frequency: 8\n",
      "Word: judgement, Frequency: 8\n",
      "Word: impaired, Frequency: 8\n",
      "Word: decrease, Frequency: 7\n",
      "Word: reaction, Frequency: 7\n",
      "Word: hallucination, Frequency: 7\n",
      "Word: depressed, Frequency: 7\n",
      "Word: rapport, Frequency: 7\n",
      "Word: inappropriate, Frequency: 7\n",
      "Word: pma, Frequency: 6\n",
      "Word: uncooperative, Frequency: 6\n",
      "Word: established, Frequency: 6\n",
      "Word: nan, Frequency: 5\n",
      "Word: thought, Frequency: 5\n",
      "Word: preoccupation, Frequency: 5\n",
      "Word: increase, Frequency: 4\n",
      "Word: restlessness, Frequency: 4\n",
      "Word: irrelevant, Frequency: 4\n",
      "Word: mood, Frequency: 4\n",
      "Word: intelligence, Frequency: 4\n",
      "Word: self, Frequency: 4\n",
      "Word: delusion, Frequency: 4\n",
      "Word: dysphoric, Frequency: 3\n",
      "Word: hyperactive, Frequency: 3\n",
      "Word: attention, Frequency: 3\n",
      "Word: sustained, Frequency: 3\n",
      "Word: helplessness, Frequency: 3\n",
      "Word: personal, Frequency: 3\n",
      "Word: aggressive, Frequency: 3\n",
      "Word: restricted, Frequency: 3\n",
      "Word: persecution, Frequency: 3\n",
      "Word: mother, Frequency: 3\n",
      "Word: person, Frequency: 3\n",
      "Word: hostile, Frequency: 3\n",
      "Word: judgment, Frequency: 3\n",
      "Word: hopelessness, Frequency: 3\n",
      "Word: guarded, Frequency: 3\n",
      "Word: non, Frequency: 3\n",
      "Word: distractible, Frequency: 2\n",
      "Word: inattentive, Frequency: 2\n",
      "Word: unkempt, Frequency: 2\n",
      "Word: untidy, Frequency: 2\n",
      "Word: prosody, Frequency: 2\n",
      "Word: good, Frequency: 2\n",
      "Word: unable, Frequency: 2\n",
      "Word: average, Frequency: 2\n",
      "Word: low, Frequency: 2\n",
      "Word: overfamiliarity, Frequency: 2\n",
      "Word: establieshed, Frequency: 2\n",
      "Word: difficulty, Frequency: 2\n",
      "Word: blunt, Frequency: 2\n",
      "Word: perplexed, Frequency: 2\n",
      "Word: family, Frequency: 2\n",
      "Word: members, Frequency: 2\n",
      "Word: ah, Frequency: 2\n",
      "Word: crying, Frequency: 2\n",
      "Word: incomprehensible, Frequency: 2\n",
      "Word: sound, Frequency: 2\n",
      "Word: started, Frequency: 2\n",
      "Word: things, Frequency: 2\n",
      "Word: sit, Frequency: 2\n",
      "Word: second, Frequency: 2\n",
      "Word: third, Frequency: 2\n",
      "Word: speak, Frequency: 2\n",
      "Word: running, Frequency: 2\n",
      "Word: around, Frequency: 2\n",
      "Word: room, Frequency: 2\n",
      "Word: table, Frequency: 2\n",
      "Word: range, Frequency: 2\n",
      "Word: shallow, Frequency: 2\n",
      "Word: social, Frequency: 2\n",
      "Word: present, Frequency: 2\n",
      "Word: smilling, Frequency: 2\n",
      "Word: cooperative, Frequency: 2\n",
      "Word: uncooprerative, Frequency: 2\n",
      "Word: repeatedly, Frequency: 2\n",
      "Word: making, Frequency: 2\n",
      "Word: content, Frequency: 2\n",
      "Word: look, Frequency: 1\n",
      "Word: sickly, Frequency: 1\n",
      "Word: hesitant, Frequency: 1\n",
      "Word: stereotypies, Frequency: 1\n",
      "Word: hopelesness, Frequency: 1\n",
      "Word: helplesness, Frequency: 1\n",
      "Word: worthlesness, Frequency: 1\n",
      "Word: abussive, Frequency: 1\n",
      "Word: words, Frequency: 1\n",
      "Word: agitated, Frequency: 1\n",
      "Word: elicite, Frequency: 1\n",
      "Word: perception, Frequency: 1\n",
      "Word: volume, Frequency: 1\n",
      "Word: neurotic, Frequency: 1\n",
      "Word: behaviour, Frequency: 1\n",
      "Word: pseudohallucination, Frequency: 1\n",
      "Word: conveyed, Frequency: 1\n",
      "Word: esteem, Frequency: 1\n",
      "Word: worthlessness, Frequency: 1\n",
      "Word: tone, Frequency: 1\n",
      "Word: suspected, Frequency: 1\n",
      "Word: smile, Frequency: 1\n",
      "Word: behavior, Frequency: 1\n",
      "Word: changed, Frequency: 1\n",
      "Word: elementray, Frequency: 1\n",
      "Word: grandiosity, Frequency: 1\n",
      "Word: elimentary, Frequency: 1\n",
      "Word: aroused, Frequency: 1\n",
      "Word: tightening, Frequency: 1\n",
      "Word: body, Frequency: 1\n",
      "Word: continuosly, Frequency: 1\n",
      "Word: reference, Frequency: 1\n",
      "Word: displacing, Frequency: 1\n",
      "Word: reciprocate, Frequency: 1\n",
      "Word: examiner, Frequency: 1\n",
      "Word: question, Frequency: 1\n",
      "Word: biting, Frequency: 1\n",
      "Word: object, Frequency: 1\n",
      "Word: ey, Frequency: 1\n",
      "Word: absorbed, Frequency: 1\n",
      "Word: interecting, Frequency: 1\n",
      "Word: interview, Frequency: 1\n",
      "Word: evasive, Frequency: 1\n",
      "Word: chair, Frequency: 1\n",
      "Word: support, Frequency: 1\n",
      "Word: respond, Frequency: 1\n",
      "Word: calling, Frequency: 1\n",
      "Word: name, Frequency: 1\n",
      "Word: could, Frequency: 1\n",
      "Word: identify, Frequency: 1\n",
      "Word: blunted, Frequency: 1\n",
      "Word: referential, Frequency: 1\n",
      "Word: inside, Frequency: 1\n",
      "Word: unsupported, Frequency: 1\n",
      "Word: illness, Frequency: 1\n",
      "Word: worry, Frequency: 1\n",
      "Word: regarding, Frequency: 1\n",
      "Word: studies, Frequency: 1\n",
      "Word: sustaining, Frequency: 1\n",
      "Word: given, Frequency: 1\n",
      "Word: task, Frequency: 1\n",
      "Word: comprehension, Frequency: 1\n",
      "Word: uninterested, Frequency: 1\n",
      "Word: attitude, Frequency: 1\n",
      "Word: memory, Frequency: 1\n",
      "Word: partial, Frequency: 1\n",
      "Word: ormal, Frequency: 1\n",
      "Word: output, Frequency: 1\n",
      "Word: keep, Frequency: 1\n",
      "Word: tapping, Frequency: 1\n",
      "Word: babbling, Frequency: 1\n",
      "Word: recticted, Frequency: 1\n",
      "Word: child, Frequency: 1\n",
      "Word: cant, Frequency: 1\n",
      "Word: drowning, Frequency: 1\n",
      "Word: incident, Frequency: 1\n",
      "Word: irrelvent, Frequency: 1\n",
      "Word: stereotypic, Frequency: 1\n",
      "Word: hand, Frequency: 1\n",
      "Word: movements, Frequency: 1\n",
      "Word: pseudo, Frequency: 1\n",
      "Word: visual, Frequency: 1\n",
      "Word: hallucinations, Frequency: 1\n",
      "Word: disrobing, Frequency: 1\n",
      "Word: por, Frequency: 1\n",
      "Word: helplessnes, Frequency: 1\n",
      "Word: persecutory, Frequency: 1\n",
      "Word: calm, Frequency: 1\n",
      "Word: suddenly, Frequency: 1\n",
      "Word: got, Frequency: 1\n",
      "Word: abusing, Frequency: 1\n",
      "Word: going, Frequency: 1\n",
      "Word: mumbai, Frequency: 1\n",
      "Word: silly, Frequency: 1\n",
      "Word: head, Frequency: 1\n",
      "Word: banging, Frequency: 1\n",
      "Word: producitvity, Frequency: 1\n",
      "Word: frequently, Frequency: 1\n",
      "Word: looks, Frequency: 1\n",
      "Word: ceiling, Frequency: 1\n",
      "Word: unsustained, Frequency: 1\n",
      "Word: initiate, Frequency: 1\n",
      "Word: gesture, Frequency: 1\n",
      "Word: pah, Frequency: 1\n",
      "Word: coherent, Frequency: 1\n",
      "Word: attitute, Frequency: 1\n",
      "Word: flat, Frequency: 1\n",
      "Word: mutism, Frequency: 1\n",
      "Word: plays, Frequency: 1\n",
      "Word: alone, Frequency: 1\n",
      "Word: smiling, Frequency: 1\n",
      "Word: electric, Frequency: 1\n",
      "Word: shock, Frequency: 1\n",
      "Word: clinging, Frequency: 1\n",
      "Word: idea, Frequency: 1\n",
      "Word: hopelessnes, Frequency: 1\n",
      "Word: suicidal, Frequency: 1\n",
      "Word: ideation, Frequency: 1\n",
      "Word: hitting, Frequency: 1\n",
      "Word: uncomprehensible, Frequency: 1\n",
      "Word: tics, Frequency: 1\n",
      "Word: seen, Frequency: 1\n",
      "Word: exacerbated, Frequency: 1\n",
      "Word: anxiety, Frequency: 1\n",
      "Word: cleanliness, Frequency: 1\n",
      "Word: persucutory, Frequency: 1\n",
      "Word: towards, Frequency: 1\n",
      "Word: cousin, Frequency: 1\n",
      "Word: brother, Frequency: 1\n",
      "Word: hallucinatory, Frequency: 1\n",
      "Word: touching, Frequency: 1\n",
      "Word: lying, Frequency: 1\n",
      "Word: listening, Frequency: 1\n",
      "Word: interviewer, Frequency: 1\n",
      "Word: noises, Frequency: 1\n",
      "Word: sitting, Frequency: 1\n",
      "Word: rationalization, Frequency: 1\n",
      "Word: orientation, Frequency: 1\n",
      "Word: fidgetting, Frequency: 1\n",
      "Word: getting, Frequency: 1\n",
      "Word: slurrred, Frequency: 1\n",
      "Word: poverty, Frequency: 1\n",
      "Word: follow, Frequency: 1\n",
      "Word: instructions, Frequency: 1\n",
      "Word: fearful, Frequency: 1\n",
      "Word: overgroomed, Frequency: 1\n",
      "Word: abusive, Frequency: 1\n",
      "Word: disruptive, Frequency: 1\n",
      "Word: spells, Frequency: 1\n",
      "Word: absent, Frequency: 1\n",
      "Word: shouting, Frequency: 1\n",
      "Word: responding, Frequency: 1\n",
      "Word: questions, Frequency: 1\n",
      "Word: easily, Frequency: 1\n",
      "Word: verbalization, Frequency: 1\n",
      "Word: reduced, Frequency: 1\n",
      "Word: pressure, Frequency: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "column_name = 'Mental status examination/Behavioral observation details (main finding only in description)'\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def extract_keywords(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.isalpha() and word.lower() not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "df2['Keywords'] = df2[column_name].apply(extract_keywords)\n",
    "\n",
    "all_tokens = [token for sublist in df2['Keywords'].tolist() for token in sublist]\n",
    "\n",
    "word_counts = Counter(all_tokens)\n",
    "\n",
    "sorted_word_counts = dict(sorted(word_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "for word, frequency in sorted_word_counts.items():\n",
    "    print(f\"Word: {word}, Frequency: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "7c0d8660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "ea95ad5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mental status examination/Behavioral observation details (main finding only in description)  \\\n",
      "1                                               normal                                            \n",
      "2    look sickly and dysphoric affect, decrease and...                                            \n",
      "3                                               normal                                            \n",
      "4                 distractible,hyperactive,inattentive                                            \n",
      "5                                               normal                                            \n",
      "..                                                 ...                                            \n",
      "163  restless, easily distractible, increased PMA, ...                                            \n",
      "164              Reduced PMA, restricted range of mood                                            \n",
      "186  Increased PMA, Pressure of Speech, Overfamilia...                                            \n",
      "187  Anxious affect, Impaired Judgement, Grade 1 In...                                            \n",
      "191           non cooperative, rapport not established                                            \n",
      "\n",
      "     eye contact  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "5              0  \n",
      "..           ...  \n",
      "163            0  \n",
      "164            0  \n",
      "186            0  \n",
      "187            0  \n",
      "191            0  \n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "column_name = 'Mental status examination/Behavioral observation details (main finding only in description)'\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def count_eye_contact(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.lower() not in stop_words]\n",
    "    return tokens.count('eye') + tokens.count('contact')\n",
    "\n",
    "df2['eye contact'] = df2[column_name].apply(count_eye_contact)\n",
    "\n",
    "print(df2[['Mental status examination/Behavioral observation details (main finding only in description)', 'eye contact']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "235b5fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in df2['eye contact']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "6c4ea9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mental status examination/Behavioral observation details (main finding only in description)  \\\n",
      "1                                               normal                                            \n",
      "2    look sickly and dysphoric affect, decrease and...                                            \n",
      "3                                               normal                                            \n",
      "4                 distractible,hyperactive,inattentive                                            \n",
      "5                                               normal                                            \n",
      "..                                                 ...                                            \n",
      "163  restless, easily distractible, increased PMA, ...                                            \n",
      "164              Reduced PMA, restricted range of mood                                            \n",
      "186  Increased PMA, Pressure of Speech, Overfamilia...                                            \n",
      "187  Anxious affect, Impaired Judgement, Grade 1 In...                                            \n",
      "191           non cooperative, rapport not established                                            \n",
      "\n",
      "     irritable  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "5            0  \n",
      "..         ...  \n",
      "163          0  \n",
      "164          0  \n",
      "186          0  \n",
      "187          0  \n",
      "191          0  \n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "column_name = 'Mental status examination/Behavioral observation details (main finding only in description)'\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def count_irritable(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.lower() not in stop_words]\n",
    "    return tokens.count('irritable')\n",
    "\n",
    "df2['irritable'] = df2[column_name].apply(count_irritable)\n",
    "\n",
    "print(df2[['Mental status examination/Behavioral observation details (main finding only in description)', 'irritable']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "d71c21c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mental status examination/Behavioral observation details (main finding only in description)  \\\n",
      "1                                               normal                                            \n",
      "2    look sickly and dysphoric affect, decrease and...                                            \n",
      "3                                               normal                                            \n",
      "4                 distractible,hyperactive,inattentive                                            \n",
      "5                                               normal                                            \n",
      "..                                                 ...                                            \n",
      "163  restless, easily distractible, increased PMA, ...                                            \n",
      "164              Reduced PMA, restricted range of mood                                            \n",
      "186  Increased PMA, Pressure of Speech, Overfamilia...                                            \n",
      "187  Anxious affect, Impaired Judgement, Grade 1 In...                                            \n",
      "191           non cooperative, rapport not established                                            \n",
      "\n",
      "     poor  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "5       0  \n",
      "..    ...  \n",
      "163     0  \n",
      "164     0  \n",
      "186     0  \n",
      "187     0  \n",
      "191     0  \n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "column_name = 'Mental status examination/Behavioral observation details (main finding only in description)'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def count_poor(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.lower() not in stop_words]\n",
    "    return tokens.count('poor')\n",
    "\n",
    "df2['poor'] = df2[column_name].apply(count_poor)\n",
    "\n",
    "print(df2[['Mental status examination/Behavioral observation details (main finding only in description)', 'poor']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "de4ad38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mental status examination/Behavioral observation details (main finding only in description)  \\\n",
      "1                                               normal                                            \n",
      "2    look sickly and dysphoric affect, decrease and...                                            \n",
      "3                                               normal                                            \n",
      "4                 distractible,hyperactive,inattentive                                            \n",
      "5                                               normal                                            \n",
      "..                                                 ...                                            \n",
      "163  restless, easily distractible, increased PMA, ...                                            \n",
      "164              Reduced PMA, restricted range of mood                                            \n",
      "186  Increased PMA, Pressure of Speech, Overfamilia...                                            \n",
      "187  Anxious affect, Impaired Judgement, Grade 1 In...                                            \n",
      "191           non cooperative, rapport not established                                            \n",
      "\n",
      "     restless  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "5           0  \n",
      "..        ...  \n",
      "163         1  \n",
      "164         0  \n",
      "186         0  \n",
      "187         0  \n",
      "191         0  \n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "224a39ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mental status examination/Behavioral observation details (main finding only in description)  \\\n",
      "1                                               normal                                            \n",
      "2    look sickly and dysphoric affect, decrease and...                                            \n",
      "3                                               normal                                            \n",
      "4                 distractible,hyperactive,inattentive                                            \n",
      "5                                               normal                                            \n",
      "..                                                 ...                                            \n",
      "163  restless, easily distractible, increased PMA, ...                                            \n",
      "164              Reduced PMA, restricted range of mood                                            \n",
      "186  Increased PMA, Pressure of Speech, Overfamilia...                                            \n",
      "187  Anxious affect, Impaired Judgement, Grade 1 In...                                            \n",
      "191           non cooperative, rapport not established                                            \n",
      "\n",
      "     anxious  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n",
      "5          0  \n",
      "..       ...  \n",
      "163        0  \n",
      "164        0  \n",
      "186        0  \n",
      "187        1  \n",
      "191        0  \n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "column_name = 'Mental status examination/Behavioral observation details (main finding only in description)'\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def count_restless(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.lower() not in stop_words]\n",
    "    return tokens.count('anxious') \n",
    "\n",
    "df2['anxious'] = df2[column_name].apply(count_restless)\n",
    "\n",
    "print(df2[['Mental status examination/Behavioral observation details (main finding only in description)', 'anxious']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "d39f724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mental status examination/Behavioral observation details (main finding only in description)  \\\n",
      "1                                               normal                                            \n",
      "2    look sickly and dysphoric affect, decrease and...                                            \n",
      "3                                               normal                                            \n",
      "4                 distractible,hyperactive,inattentive                                            \n",
      "5                                               normal                                            \n",
      "..                                                 ...                                            \n",
      "163  restless, easily distractible, increased PMA, ...                                            \n",
      "164              Reduced PMA, restricted range of mood                                            \n",
      "186  Increased PMA, Pressure of Speech, Overfamilia...                                            \n",
      "187  Anxious affect, Impaired Judgement, Grade 1 In...                                            \n",
      "191           non cooperative, rapport not established                                            \n",
      "\n",
      "     hallucination  \n",
      "1                0  \n",
      "2                0  \n",
      "3                0  \n",
      "4                0  \n",
      "5                0  \n",
      "..             ...  \n",
      "163              0  \n",
      "164              0  \n",
      "186              0  \n",
      "187              0  \n",
      "191              0  \n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "column_name = 'Mental status examination/Behavioral observation details (main finding only in description)'\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def count_restless(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.lower() not in stop_words]\n",
    "    return tokens.count('hallucination') \n",
    "\n",
    "df2['hallucination'] = df2[column_name].apply(count_restless)\n",
    "\n",
    "print(df2[['Mental status examination/Behavioral observation details (main finding only in description)', 'hallucination']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f03d3edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mental status examination/Behavioral observation details (main finding only in description)  \\\n",
      "1                                               normal                                            \n",
      "2    look sickly and dysphoric affect, decrease and...                                            \n",
      "3                                               normal                                            \n",
      "4                 distractible,hyperactive,inattentive                                            \n",
      "5                                               normal                                            \n",
      "..                                                 ...                                            \n",
      "163  restless, easily distractible, increased PMA, ...                                            \n",
      "164              Reduced PMA, restricted range of mood                                            \n",
      "186  Increased PMA, Pressure of Speech, Overfamilia...                                            \n",
      "187  Anxious affect, Impaired Judgement, Grade 1 In...                                            \n",
      "191           non cooperative, rapport not established                                            \n",
      "\n",
      "     depressed  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "5            0  \n",
      "..         ...  \n",
      "163          0  \n",
      "164          0  \n",
      "186          0  \n",
      "187          0  \n",
      "191          0  \n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Assuming 'Mental status examination/Behavioral observation details (main finding only in description)' is a column in df2\n",
    "column_name = 'Mental status examination/Behavioral observation details (main finding only in description)'\n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define a function to count the frequency of 'restless' and 'restlessness' in each entry\n",
    "def count_restless(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.lower() not in stop_words]\n",
    "    return tokens.count('depressed') \n",
    "\n",
    "# Apply the function to the specified column and store the result in a new column 'restless'\n",
    "df2['depressed'] = df2[column_name].apply(count_restless)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[['Mental status examination/Behavioral observation details (main finding only in description)', 'depressed']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "2ae15f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'poorly adjusted', 'well adjusted', 'Nil'], dtype=object)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['School adjustment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "e92ce88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'well adjusted' : 1,\n",
    "    'poorly adjusted' : 0.5,\n",
    "    'Nil': 0,\n",
    "    np.nan: 0  # Include NaN mapping if needed\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2['School adjustment'] = df2['School adjustment'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "21a7b7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...  jerky  low  outbursts  \\\n",
      "1    ...      0    0          0   \n",
      "2    ...      1    0          0   \n",
      "3    ...      1    0          0   \n",
      "4    ...      0    0          0   \n",
      "5    ...      0    0          0   \n",
      "..   ...    ...  ...        ...   \n",
      "163  ...      1    0          0   \n",
      "164  ...      0    0          0   \n",
      "186  ...      0    0          0   \n",
      "187  ...      0    0          0   \n",
      "191  ...      1    0          0   \n",
      "\n",
      "                                              Keywords  eye contact poor  \\\n",
      "1                                             [normal]            0    0   \n",
      "2    [look, sickly, dysphoric, affect, decrease, he...            0    0   \n",
      "3                                             [normal]            0    0   \n",
      "4             [distractible, hyperactive, inattentive]            0    0   \n",
      "5                                             [normal]            0    0   \n",
      "..                                                 ...          ...  ...   \n",
      "163  [restless, easily, distractible, increased, pm...            0    0   \n",
      "164            [reduced, pma, restricted, range, mood]            0    0   \n",
      "186  [increased, pma, pressure, speech, overfamilia...            0    0   \n",
      "187  [anxious, affect, impaired, judgement, grade, ...            0    0   \n",
      "191           [non, cooperative, rapport, established]            0    0   \n",
      "\n",
      "    restless  anxious  hallucination depressed  \n",
      "1          0        0              0         0  \n",
      "2          0        0              0         0  \n",
      "3          0        0              0         0  \n",
      "4          0        0              0         0  \n",
      "5          0        0              0         0  \n",
      "..       ...      ...            ...       ...  \n",
      "163        1        0              0         0  \n",
      "164        0        0              0         0  \n",
      "186        0        0              0         0  \n",
      "187        0        1              0         0  \n",
      "191        0        0              0         0  \n",
      "\n",
      "[148 rows x 74 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Column_to_drop' is the name of the column you want to drop\n",
    "column_to_drop = 'Mental status examination/Behavioral observation details (main finding only in description)'\n",
    "\n",
    "# Drop the specified column\n",
    "df2.drop(columns=column_to_drop, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "671c8b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df2 is your DataFrame\n",
    "# Specify the file path and name for the Excel file\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Display a message indicating the file has been created\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "17692c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'yes', nan, 'Nil'], dtype=object)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Past/Current medical conditions'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "ce77e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'No' : 0.5,\n",
    "    'yes' : 1,\n",
    "    'Nil': 0.5,\n",
    "    np.nan: 0  # Include NaN mapping if needed\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2['Past/Current medical conditions'] = df2['Past/Current medical conditions'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ff683af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df2 is your DataFrame\n",
    "# Specify the file path and name for the Excel file\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Display a message indicating the file has been created\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "a7d30eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...  jerky  low  outbursts  \\\n",
      "1    ...      0    0          0   \n",
      "2    ...      1    0          0   \n",
      "3    ...      1    0          0   \n",
      "4    ...      0    0          0   \n",
      "5    ...      0    0          0   \n",
      "..   ...    ...  ...        ...   \n",
      "163  ...      1    0          0   \n",
      "164  ...      0    0          0   \n",
      "186  ...      0    0          0   \n",
      "187  ...      0    0          0   \n",
      "191  ...      1    0          0   \n",
      "\n",
      "                                              Keywords  eye contact  poor  \\\n",
      "1                                             [normal]            0     0   \n",
      "2    [look, sickly, dysphoric, affect, decrease, he...            0     0   \n",
      "3                                             [normal]            0     0   \n",
      "4             [distractible, hyperactive, inattentive]            0     0   \n",
      "5                                             [normal]            0     0   \n",
      "..                                                 ...          ...   ...   \n",
      "163  [restless, easily, distractible, increased, pm...            0     0   \n",
      "164            [reduced, pma, restricted, range, mood]            0     0   \n",
      "186  [increased, pma, pressure, speech, overfamilia...            0     0   \n",
      "187  [anxious, affect, impaired, judgement, grade, ...            0     0   \n",
      "191           [non, cooperative, rapport, established]            0     0   \n",
      "\n",
      "    restless  anxious  hallucination depressed  \n",
      "1          0        0              0         0  \n",
      "2          0        0              0         0  \n",
      "3          0        0              0         0  \n",
      "4          0        0              0         0  \n",
      "5          0        0              0         0  \n",
      "..       ...      ...            ...       ...  \n",
      "163        1        0              0         0  \n",
      "164        0        0              0         0  \n",
      "186        0        0              0         0  \n",
      "187        0        1              0         0  \n",
      "191        0        0              0         0  \n",
      "\n",
      "[148 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming the columns to drop are as follows\n",
    "columns_to_drop = [\n",
    "    'detailed workup diagnosis'  \n",
    "]\n",
    "\n",
    "# Drop the specified columns\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "44e157ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'Nil', nan], dtype=object)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Follow up diagnosis changed or not (yes/no)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "281b115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'No' : 0.5,\n",
    "    'Yes' : 1,\n",
    "    'Nil': 0.5,\n",
    "    np.nan: 0  # Include NaN mapping if needed\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2['Follow up diagnosis changed or not (yes/no)'] = df2['Follow up diagnosis changed or not (yes/no)'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "985ecba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'Nil': 0,\n",
    "    np.nan: 0  # Include NaN mapping if needed\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2['If yes, after how many days from first presentation diagnosis changed (in days)'] = df2['If yes, after how many days from first presentation diagnosis changed (in days)'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "0b584506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: Axis 1_1\n",
      "Word: nil, Frequency: 46\n",
      "Word: disorder, Frequency: 32\n",
      "Word: adhd, Frequency: 25\n",
      "Word: psychotic, Frequency: 15\n",
      "Word: depressive, Frequency: 13\n",
      "Word: acute, Frequency: 12\n",
      "Word: transient, Frequency: 12\n",
      "Word: psychosis, Frequency: 12\n",
      "Word: nos, Frequency: 11\n",
      "Word: asd, Frequency: 10\n",
      "Word: mania, Frequency: 6\n",
      "Word: symptoms, Frequency: 4\n",
      "Word: bipolar, Frequency: 3\n",
      "Word: anxiety, Frequency: 3\n",
      "Word: bpad, Frequency: 3\n",
      "Word: atpd, Frequency: 3\n",
      "Word: due, Frequency: 2\n",
      "Word: another, Frequency: 2\n",
      "Word: medical, Frequency: 2\n",
      "Word: condition, Frequency: 2\n",
      "Word: tension, Frequency: 2\n",
      "Word: headache, Frequency: 2\n",
      "Word: ocd, Frequency: 2\n",
      "Word: schizophrenia, Frequency: 2\n",
      "Word: episode, Frequency: 2\n",
      "Word: cd, Frequency: 2\n",
      "Word: risk, Frequency: 1\n",
      "Word: specific, Frequency: 1\n",
      "Word: learning, Frequency: 1\n",
      "Word: moderate, Frequency: 1\n",
      "Word: without, Frequency: 1\n",
      "Word: somatic, Frequency: 1\n",
      "Word: seizure, Frequency: 1\n",
      "Word: dissociative, Frequency: 1\n",
      "Word: cannabis, Frequency: 1\n",
      "Word: induced, Frequency: 1\n",
      "Word: oppositional, Frequency: 1\n",
      "Word: defiant, Frequency: 1\n",
      "Word: behavioral, Frequency: 1\n",
      "Word: abnormalities, Frequency: 1\n",
      "Word: mixed, Frequency: 1\n",
      "Word: pscyhosis, Frequency: 1\n",
      "Word: odd, Frequency: 1\n",
      "Word: paraphilia, Frequency: 1\n",
      "Word: severe, Frequency: 1\n",
      "Word: depression, Frequency: 1\n",
      "Word: symptom, Frequency: 1\n",
      "Word: psycotic, Frequency: 1\n",
      "\n",
      "Column: Axis 1_2\n",
      "Word: nil, Frequency: 104\n",
      "Word: adhd, Frequency: 10\n",
      "Word: disorder, Frequency: 10\n",
      "Word: odd, Frequency: 5\n",
      "Word: ocd, Frequency: 4\n",
      "Word: anxiety, Frequency: 4\n",
      "Word: conduct, Frequency: 3\n",
      "Word: dissociative, Frequency: 3\n",
      "Word: risk, Frequency: 2\n",
      "Word: tics, Frequency: 2\n",
      "Word: dependence, Frequency: 2\n",
      "Word: syndrome, Frequency: 2\n",
      "Word: sld, Frequency: 1\n",
      "Word: vocal, Frequency: 1\n",
      "Word: nicotine, Frequency: 1\n",
      "Word: dissociation, Frequency: 1\n",
      "Word: history, Frequency: 1\n",
      "Word: psychosis, Frequency: 1\n",
      "Word: nos, Frequency: 1\n",
      "Word: secondary, Frequency: 1\n",
      "Word: enuresis, Frequency: 1\n",
      "Word: tic, Frequency: 1\n",
      "Word: exam, Frequency: 1\n",
      "Word: phobia, Frequency: 1\n",
      "Word: ptsd, Frequency: 1\n",
      "Word: depression, Frequency: 1\n",
      "Word: bpad, Frequency: 1\n",
      "Word: social, Frequency: 1\n",
      "Word: nicotinde, Frequency: 1\n",
      "Word: tourette, Frequency: 1\n",
      "Word: cannabis, Frequency: 1\n",
      "Word: use, Frequency: 1\n",
      "\n",
      "Column: Axis 1_3\n",
      "Word: nil, Frequency: 133\n",
      "Word: use, Frequency: 3\n",
      "Word: disorder, Frequency: 3\n",
      "Word: odd, Frequency: 2\n",
      "Word: sld, Frequency: 2\n",
      "Word: nicotine, Frequency: 2\n",
      "Word: transvestism, Frequency: 1\n",
      "Word: fetishism, Frequency: 1\n",
      "Word: polysubstance, Frequency: 1\n",
      "Word: maths, Frequency: 1\n",
      "Word: history, Frequency: 1\n",
      "Word: conduct, Frequency: 1\n",
      "Word: depression, Frequency: 1\n",
      "Word: ni, Frequency: 1\n",
      "Word: cannabis, Frequency: 1\n",
      "Word: abuse, Frequency: 1\n",
      "Word: adhd, Frequency: 1\n",
      "Word: remission, Frequency: 1\n",
      "Word: ocd, Frequency: 1\n",
      "Word: bpad, Frequency: 1\n",
      "\n",
      "Column: Axis 1_4\n",
      "Word: nil, Frequency: 144\n",
      "Word: nicotine, Frequency: 1\n",
      "Word: use, Frequency: 1\n",
      "Word: diorder, Frequency: 1\n",
      "Word: conduct, Frequency: 1\n",
      "Word: features, Frequency: 1\n",
      "Word: separation, Frequency: 1\n",
      "Word: anxiety, Frequency: 1\n",
      "Word: specific, Frequency: 1\n",
      "Word: phobia, Frequency: 1\n",
      "\n",
      "Column: Axis 2\n",
      "Word: nil, Frequency: 143\n",
      "Word: sld, Frequency: 2\n",
      "Word: motor, Frequency: 1\n",
      "Word: coordination, Frequency: 1\n",
      "Word: disorder, Frequency: 1\n",
      "Word: dsl, Frequency: 1\n",
      "Word: delayed, Frequency: 1\n",
      "Word: speech, Frequency: 1\n",
      "Word: language, Frequency: 1\n",
      "\n",
      "Column: Axis 3\n",
      "Word: iq, Frequency: 63\n",
      "Word: average, Frequency: 57\n",
      "Word: mild, Frequency: 23\n",
      "Word: moderate, Frequency: 16\n",
      "Word: nil, Frequency: 13\n",
      "Word: idd, Frequency: 12\n",
      "Word: severe, Frequency: 8\n",
      "Word: borderline, Frequency: 6\n",
      "Word: nan, Frequency: 5\n",
      "Word: gdd, Frequency: 5\n",
      "Word: profound, Frequency: 3\n",
      "\n",
      "Column: Axis 4_1\n",
      "Word: nil, Frequency: 70\n",
      "Word: seizure, Frequency: 57\n",
      "Word: disorder, Frequency: 57\n",
      "Word: subclinical, Frequency: 2\n",
      "Word: secondary, Frequency: 2\n",
      "Word: anaemia, Frequency: 2\n",
      "Word: seizures, Frequency: 2\n",
      "Word: hypothyroidism, Frequency: 1\n",
      "Word: proximal, Frequency: 1\n",
      "Word: myopathy, Frequency: 1\n",
      "Word: evaluation, Frequency: 1\n",
      "Word: microduplication, Frequency: 1\n",
      "Word: chromosome, Frequency: 1\n",
      "Word: eneuresis, Frequency: 1\n",
      "Word: nan, Frequency: 1\n",
      "Word: appendicitis, Frequency: 1\n",
      "Word: squint, Frequency: 1\n",
      "Word: left, Frequency: 1\n",
      "Word: eye, Frequency: 1\n",
      "Word: fragile, Frequency: 1\n",
      "Word: x, Frequency: 1\n",
      "Word: phenotype, Frequency: 1\n",
      "Word: congenital, Frequency: 1\n",
      "Word: heart, Frequency: 1\n",
      "Word: disease, Frequency: 1\n",
      "Word: epilepsy, Frequency: 1\n",
      "Word: malabsorption, Frequency: 1\n",
      "Word: syndrome, Frequency: 1\n",
      "Word: obesity, Frequency: 1\n",
      "Word: tle, Frequency: 1\n",
      "Word: hearing, Frequency: 1\n",
      "Word: impairment, Frequency: 1\n",
      "Word: gait, Frequency: 1\n",
      "Word: abnormality, Frequency: 1\n",
      "Word: inguinal, Frequency: 1\n",
      "Word: hernia, Frequency: 1\n",
      "Word: hypotyroidism, Frequency: 1\n",
      "Word: overweight, Frequency: 1\n",
      "Word: febrile, Frequency: 1\n",
      "Word: fatty, Frequency: 1\n",
      "Word: liver, Frequency: 1\n",
      "Word: complex, Frequency: 1\n",
      "Word: partial, Frequency: 1\n",
      "Word: generalization, Frequency: 1\n",
      "Word: cerebral, Frequency: 1\n",
      "Word: palsy, Frequency: 1\n",
      "\n",
      "Column: Axis 4_2\n",
      "Word: nil, Frequency: 128\n",
      "Word: nan, Frequency: 4\n",
      "Word: hypothyroidism, Frequency: 2\n",
      "Word: diabetes, Frequency: 1\n",
      "Word: melitus, Frequency: 1\n",
      "Word: type, Frequency: 1\n",
      "Word: left, Frequency: 1\n",
      "Word: sided, Frequency: 1\n",
      "Word: hemiparesis, Frequency: 1\n",
      "Word: il, Frequency: 1\n",
      "Word: night, Frequency: 1\n",
      "Word: blindness, Frequency: 1\n",
      "Word: hypospadias, Frequency: 1\n",
      "Word: truncal, Frequency: 1\n",
      "Word: obesity, Frequency: 1\n",
      "Word: seizure, Frequency: 1\n",
      "Word: disorder, Frequency: 1\n",
      "Word: remission, Frequency: 1\n",
      "Word: urinary, Frequency: 1\n",
      "Word: incontinence, Frequency: 1\n",
      "Word: bilateral, Frequency: 1\n",
      "Word: hearing, Frequency: 1\n",
      "Word: loss, Frequency: 1\n",
      "Word: tuberous, Frequency: 1\n",
      "Word: sclerosis, Frequency: 1\n",
      "Word: hypothroidism, Frequency: 1\n",
      "Word: pcos, Frequency: 1\n",
      "Word: otitis, Frequency: 1\n",
      "Word: media, Frequency: 1\n",
      "Word: limb, Frequency: 1\n",
      "Word: length, Frequency: 1\n",
      "Word: descrepancy, Frequency: 1\n",
      "\n",
      "Column: Axis 4_3\n",
      "Word: nil, Frequency: 141\n",
      "Word: nan, Frequency: 2\n",
      "Word: grade, Frequency: 1\n",
      "Word: ii, Frequency: 1\n",
      "Word: fatty, Frequency: 1\n",
      "Word: liver, Frequency: 1\n",
      "Word: cholelithiasis, Frequency: 1\n",
      "Word: anaemia, Frequency: 1\n",
      "Word: nl, Frequency: 1\n",
      "Word: ovarian, Frequency: 1\n",
      "Word: cyst, Frequency: 1\n",
      "Word: pcos, Frequency: 1\n",
      "\n",
      "Column: Axis 5\n",
      "Word: nil, Frequency: 99\n",
      "Word: history, Frequency: 8\n",
      "Word: parenting, Frequency: 7\n",
      "Word: early, Frequency: 7\n",
      "Word: bullying, Frequency: 6\n",
      "Word: parental, Frequency: 6\n",
      "Word: paternal, Frequency: 6\n",
      "Word: permissive, Frequency: 5\n",
      "Word: school, Frequency: 5\n",
      "Word: family, Frequency: 5\n",
      "Word: father, Frequency: 5\n",
      "Word: poor, Frequency: 5\n",
      "Word: death, Frequency: 4\n",
      "Word: loss, Frequency: 4\n",
      "Word: uncle, Frequency: 4\n",
      "Word: psychosis, Frequency: 4\n",
      "Word: kap, Frequency: 4\n",
      "Word: stress, Frequency: 3\n",
      "Word: exam, Frequency: 3\n",
      "Word: parents, Frequency: 3\n",
      "Word: younger, Frequency: 3\n",
      "Word: nan, Frequency: 2\n",
      "Word: academic, Frequency: 2\n",
      "Word: conflict, Frequency: 2\n",
      "Word: abuse, Frequency: 2\n",
      "Word: idd, Frequency: 2\n",
      "Word: psychiatric, Frequency: 2\n",
      "Word: illness, Frequency: 2\n",
      "Word: disorder, Frequency: 2\n",
      "Word: sister, Frequency: 2\n",
      "Word: ads, Frequency: 2\n",
      "Word: mother, Frequency: 2\n",
      "Word: maternal, Frequency: 2\n",
      "Word: separation, Frequency: 2\n",
      "Word: single, Frequency: 2\n",
      "Word: nephew, Frequency: 1\n",
      "Word: month, Frequency: 1\n",
      "Word: back, Frequency: 1\n",
      "Word: understimulation, Frequency: 1\n",
      "Word: lack, Frequency: 1\n",
      "Word: hostility, Frequency: 1\n",
      "Word: towards, Frequency: 1\n",
      "Word: child, Frequency: 1\n",
      "Word: excessive, Frequency: 1\n",
      "Word: mobile, Frequency: 1\n",
      "Word: use, Frequency: 1\n",
      "Word: sleep, Frequency: 1\n",
      "Word: deprivation, Frequency: 1\n",
      "Word: due, Frequency: 1\n",
      "Word: friends, Frequency: 1\n",
      "Word: exposure, Frequency: 1\n",
      "Word: substances, Frequency: 1\n",
      "Word: stressor, Frequency: 1\n",
      "Word: increased, Frequency: 1\n",
      "Word: expectation, Frequency: 1\n",
      "Word: intellectual, Frequency: 1\n",
      "Word: developmental, Frequency: 1\n",
      "Word: inadequate, Frequency: 1\n",
      "Word: socal, Frequency: 1\n",
      "Word: support, Frequency: 1\n",
      "Word: uninvolved, Frequency: 1\n",
      "Word: multiple, Frequency: 1\n",
      "Word: members, Frequency: 1\n",
      "Word: brother, Frequency: 1\n",
      "Word: traumatic, Frequency: 1\n",
      "Word: drowning, Frequency: 1\n",
      "Word: incident, Frequency: 1\n",
      "Word: cousin, Frequency: 1\n",
      "Word: drop, Frequency: 1\n",
      "Word: bpad, Frequency: 1\n",
      "Word: elder, Frequency: 1\n",
      "Word: social, Frequency: 1\n",
      "Word: approach, Frequency: 1\n",
      "Word: alcoholic, Frequency: 1\n",
      "Word: aunt, Frequency: 1\n",
      "Word: electric, Frequency: 1\n",
      "Word: shock, Frequency: 1\n",
      "Word: refusal, Frequency: 1\n",
      "Word: gambling, Frequency: 1\n",
      "Word: burnout, Frequency: 1\n",
      "Word: discord, Frequency: 1\n",
      "Word: marital, Frequency: 1\n",
      "Word: past, Frequency: 1\n",
      "Word: head, Frequency: 1\n",
      "Word: injury, Frequency: 1\n",
      "Word: mr, Frequency: 1\n",
      "Word: authoritarina, Frequency: 1\n",
      "Word: prolonged, Frequency: 1\n",
      "Word: relationship, Frequency: 1\n",
      "Word: issues, Frequency: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming the specified columns are in df2\n",
    "columns_to_check = ['Axis 1_1', 'Axis 1_2', 'Axis 1_3', 'Axis 1_4', 'Axis 2', 'Axis 3', 'Axis 4_1', 'Axis 4_2', 'Axis 4_3', 'Axis 5']\n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define a function to extract keywords from a text\n",
    "def extract_keywords(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.isalpha() and word.lower() not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Iterate through specified columns and find most common words\n",
    "for column in columns_to_check:\n",
    "    # Apply the function to the specified column\n",
    "    df2[column + '_Keywords'] = df2[column].apply(extract_keywords)\n",
    "\n",
    "    # Combine all tokens from the 'Keywords' column\n",
    "    all_tokens = [token for sublist in df2[column + '_Keywords'].tolist() for token in sublist]\n",
    "\n",
    "    # Count the occurrences of each word\n",
    "    word_counts = Counter(all_tokens)\n",
    "\n",
    "    # Sort the word counts in descending order\n",
    "    sorted_word_counts = dict(sorted(word_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    # Display all unique words and their frequencies in descending order for each column\n",
    "    print(f\"\\nColumn: {column}\")\n",
    "    for word, frequency in sorted_word_counts.items():\n",
    "        print(f\"Word: {word}, Frequency: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a496f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: nil, Frequency: 1021\n",
      "Word: disorder, Frequency: 106\n",
      "Word: iq, Frequency: 63\n",
      "Word: seizure, Frequency: 59\n",
      "Word: average, Frequency: 57\n",
      "Word: adhd, Frequency: 36\n",
      "Word: mild, Frequency: 23\n",
      "Word: moderate, Frequency: 17\n",
      "Word: psychosis, Frequency: 17\n",
      "Word: psychotic, Frequency: 15\n",
      "Word: nan, Frequency: 14\n",
      "Word: idd, Frequency: 14\n",
      "Word: depressive, Frequency: 13\n",
      "Word: acute, Frequency: 12\n",
      "Word: transient, Frequency: 12\n",
      "Word: nos, Frequency: 12\n",
      "Word: asd, Frequency: 10\n",
      "Word: history, Frequency: 10\n",
      "Word: severe, Frequency: 9\n",
      "Word: odd, Frequency: 8\n",
      "Word: anxiety, Frequency: 8\n",
      "Word: parenting, Frequency: 7\n",
      "Word: ocd, Frequency: 7\n",
      "Word: early, Frequency: 7\n",
      "Word: bullying, Frequency: 6\n",
      "Word: mania, Frequency: 6\n",
      "Word: parental, Frequency: 6\n",
      "Word: use, Frequency: 6\n",
      "Word: paternal, Frequency: 6\n",
      "Word: bpad, Frequency: 6\n",
      "Word: borderline, Frequency: 6\n",
      "Word: permissive, Frequency: 5\n",
      "Word: sld, Frequency: 5\n",
      "Word: loss, Frequency: 5\n",
      "Word: gdd, Frequency: 5\n",
      "Word: school, Frequency: 5\n",
      "Word: family, Frequency: 5\n",
      "Word: conduct, Frequency: 5\n",
      "Word: father, Frequency: 5\n",
      "Word: poor, Frequency: 5\n",
      "Word: death, Frequency: 4\n",
      "Word: symptoms, Frequency: 4\n",
      "Word: nicotine, Frequency: 4\n",
      "Word: exam, Frequency: 4\n",
      "Word: uncle, Frequency: 4\n",
      "Word: dissociative, Frequency: 4\n",
      "Word: kap, Frequency: 4\n",
      "Word: hypothyroidism, Frequency: 3\n",
      "Word: risk, Frequency: 3\n",
      "Word: due, Frequency: 3\n",
      "Word: stress, Frequency: 3\n",
      "Word: profound, Frequency: 3\n",
      "Word: secondary, Frequency: 3\n",
      "Word: bipolar, Frequency: 3\n",
      "Word: abuse, Frequency: 3\n",
      "Word: cannabis, Frequency: 3\n",
      "Word: parents, Frequency: 3\n",
      "Word: depression, Frequency: 3\n",
      "Word: younger, Frequency: 3\n",
      "Word: anaemia, Frequency: 3\n",
      "Word: separation, Frequency: 3\n",
      "Word: syndrome, Frequency: 3\n",
      "Word: atpd, Frequency: 3\n",
      "Word: left, Frequency: 2\n",
      "Word: subclinical, Frequency: 2\n",
      "Word: fatty, Frequency: 2\n",
      "Word: liver, Frequency: 2\n",
      "Word: another, Frequency: 2\n",
      "Word: medical, Frequency: 2\n",
      "Word: condition, Frequency: 2\n",
      "Word: academic, Frequency: 2\n",
      "Word: tics, Frequency: 2\n",
      "Word: obesity, Frequency: 2\n",
      "Word: dependence, Frequency: 2\n",
      "Word: specific, Frequency: 2\n",
      "Word: remission, Frequency: 2\n",
      "Word: conflict, Frequency: 2\n",
      "Word: hearing, Frequency: 2\n",
      "Word: psychiatric, Frequency: 2\n",
      "Word: illness, Frequency: 2\n",
      "Word: tension, Frequency: 2\n",
      "Word: headache, Frequency: 2\n",
      "Word: sister, Frequency: 2\n",
      "Word: ads, Frequency: 2\n",
      "Word: mother, Frequency: 2\n",
      "Word: phobia, Frequency: 2\n",
      "Word: maternal, Frequency: 2\n",
      "Word: social, Frequency: 2\n",
      "Word: schizophrenia, Frequency: 2\n",
      "Word: episode, Frequency: 2\n",
      "Word: cd, Frequency: 2\n",
      "Word: pcos, Frequency: 2\n",
      "Word: single, Frequency: 2\n",
      "Word: seizures, Frequency: 2\n",
      "Word: diabetes, Frequency: 1\n",
      "Word: melitus, Frequency: 1\n",
      "Word: type, Frequency: 1\n",
      "Word: nephew, Frequency: 1\n",
      "Word: month, Frequency: 1\n",
      "Word: back, Frequency: 1\n",
      "Word: sided, Frequency: 1\n",
      "Word: hemiparesis, Frequency: 1\n",
      "Word: motor, Frequency: 1\n",
      "Word: coordination, Frequency: 1\n",
      "Word: il, Frequency: 1\n",
      "Word: night, Frequency: 1\n",
      "Word: blindness, Frequency: 1\n",
      "Word: grade, Frequency: 1\n",
      "Word: ii, Frequency: 1\n",
      "Word: hypospadias, Frequency: 1\n",
      "Word: vocal, Frequency: 1\n",
      "Word: understimulation, Frequency: 1\n",
      "Word: proximal, Frequency: 1\n",
      "Word: myopathy, Frequency: 1\n",
      "Word: evaluation, Frequency: 1\n",
      "Word: truncal, Frequency: 1\n",
      "Word: microduplication, Frequency: 1\n",
      "Word: chromosome, Frequency: 1\n",
      "Word: learning, Frequency: 1\n",
      "Word: transvestism, Frequency: 1\n",
      "Word: fetishism, Frequency: 1\n",
      "Word: eneuresis, Frequency: 1\n",
      "Word: lack, Frequency: 1\n",
      "Word: polysubstance, Frequency: 1\n",
      "Word: without, Frequency: 1\n",
      "Word: somatic, Frequency: 1\n",
      "Word: hostility, Frequency: 1\n",
      "Word: towards, Frequency: 1\n",
      "Word: child, Frequency: 1\n",
      "Word: excessive, Frequency: 1\n",
      "Word: mobile, Frequency: 1\n",
      "Word: sleep, Frequency: 1\n",
      "Word: deprivation, Frequency: 1\n",
      "Word: dissociation, Frequency: 1\n",
      "Word: maths, Frequency: 1\n",
      "Word: appendicitis, Frequency: 1\n",
      "Word: friends, Frequency: 1\n",
      "Word: urinary, Frequency: 1\n",
      "Word: incontinence, Frequency: 1\n",
      "Word: exposure, Frequency: 1\n",
      "Word: substances, Frequency: 1\n",
      "Word: induced, Frequency: 1\n",
      "Word: squint, Frequency: 1\n",
      "Word: eye, Frequency: 1\n",
      "Word: bilateral, Frequency: 1\n",
      "Word: oppositional, Frequency: 1\n",
      "Word: defiant, Frequency: 1\n",
      "Word: behavioral, Frequency: 1\n",
      "Word: abnormalities, Frequency: 1\n",
      "Word: mixed, Frequency: 1\n",
      "Word: stressor, Frequency: 1\n",
      "Word: enuresis, Frequency: 1\n",
      "Word: fragile, Frequency: 1\n",
      "Word: x, Frequency: 1\n",
      "Word: phenotype, Frequency: 1\n",
      "Word: increased, Frequency: 1\n",
      "Word: expectation, Frequency: 1\n",
      "Word: congenital, Frequency: 1\n",
      "Word: heart, Frequency: 1\n",
      "Word: disease, Frequency: 1\n",
      "Word: cholelithiasis, Frequency: 1\n",
      "Word: tic, Frequency: 1\n",
      "Word: ni, Frequency: 1\n",
      "Word: intellectual, Frequency: 1\n",
      "Word: developmental, Frequency: 1\n",
      "Word: inadequate, Frequency: 1\n",
      "Word: socal, Frequency: 1\n",
      "Word: support, Frequency: 1\n",
      "Word: uninvolved, Frequency: 1\n",
      "Word: multiple, Frequency: 1\n",
      "Word: members, Frequency: 1\n",
      "Word: epilepsy, Frequency: 1\n",
      "Word: tuberous, Frequency: 1\n",
      "Word: sclerosis, Frequency: 1\n",
      "Word: ptsd, Frequency: 1\n",
      "Word: diorder, Frequency: 1\n",
      "Word: brother, Frequency: 1\n",
      "Word: traumatic, Frequency: 1\n",
      "Word: drowning, Frequency: 1\n",
      "Word: incident, Frequency: 1\n",
      "Word: cousin, Frequency: 1\n",
      "Word: drop, Frequency: 1\n",
      "Word: hypothroidism, Frequency: 1\n",
      "Word: elder, Frequency: 1\n",
      "Word: malabsorption, Frequency: 1\n",
      "Word: pscyhosis, Frequency: 1\n",
      "Word: approach, Frequency: 1\n",
      "Word: dsl, Frequency: 1\n",
      "Word: alcoholic, Frequency: 1\n",
      "Word: tle, Frequency: 1\n",
      "Word: paraphilia, Frequency: 1\n",
      "Word: impairment, Frequency: 1\n",
      "Word: gait, Frequency: 1\n",
      "Word: abnormality, Frequency: 1\n",
      "Word: inguinal, Frequency: 1\n",
      "Word: hernia, Frequency: 1\n",
      "Word: nicotinde, Frequency: 1\n",
      "Word: features, Frequency: 1\n",
      "Word: hypotyroidism, Frequency: 1\n",
      "Word: aunt, Frequency: 1\n",
      "Word: electric, Frequency: 1\n",
      "Word: shock, Frequency: 1\n",
      "Word: delayed, Frequency: 1\n",
      "Word: speech, Frequency: 1\n",
      "Word: language, Frequency: 1\n",
      "Word: overweight, Frequency: 1\n",
      "Word: refusal, Frequency: 1\n",
      "Word: nl, Frequency: 1\n",
      "Word: tourette, Frequency: 1\n",
      "Word: febrile, Frequency: 1\n",
      "Word: gambling, Frequency: 1\n",
      "Word: burnout, Frequency: 1\n",
      "Word: discord, Frequency: 1\n",
      "Word: symptom, Frequency: 1\n",
      "Word: marital, Frequency: 1\n",
      "Word: past, Frequency: 1\n",
      "Word: head, Frequency: 1\n",
      "Word: injury, Frequency: 1\n",
      "Word: mr, Frequency: 1\n",
      "Word: complex, Frequency: 1\n",
      "Word: partial, Frequency: 1\n",
      "Word: generalization, Frequency: 1\n",
      "Word: otitis, Frequency: 1\n",
      "Word: media, Frequency: 1\n",
      "Word: cerebral, Frequency: 1\n",
      "Word: palsy, Frequency: 1\n",
      "Word: limb, Frequency: 1\n",
      "Word: length, Frequency: 1\n",
      "Word: descrepancy, Frequency: 1\n",
      "Word: authoritarina, Frequency: 1\n",
      "Word: prolonged, Frequency: 1\n",
      "Word: ovarian, Frequency: 1\n",
      "Word: cyst, Frequency: 1\n",
      "Word: relationship, Frequency: 1\n",
      "Word: issues, Frequency: 1\n",
      "Word: psycotic, Frequency: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming the specified columns are in df2\n",
    "columns_to_check = ['Axis 1_1', 'Axis 1_2', 'Axis 1_3', 'Axis 1_4', 'Axis 2', 'Axis 3', 'Axis 4_1', 'Axis 4_2', 'Axis 4_3', 'Axis 5']\n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Combine text from all specified columns into a single text column\n",
    "df2['Combined_Axis_Text'] = df2[columns_to_check].astype(str).agg(' '.join, axis=1)\n",
    "\n",
    "# Define a function to extract keywords from a text\n",
    "def extract_keywords(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.isalpha() and word.lower() not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Apply the function to the combined text column\n",
    "df2['Combined_Axis_Keywords'] = df2['Combined_Axis_Text'].apply(extract_keywords)\n",
    "\n",
    "# Combine all tokens from the 'Combined_Axis_Keywords' column\n",
    "all_tokens = [token for sublist in df2['Combined_Axis_Keywords'].tolist() for token in sublist]\n",
    "\n",
    "# Count the occurrences of each word\n",
    "word_counts = Counter(all_tokens)\n",
    "\n",
    "# Sort the word counts in descending order\n",
    "sorted_word_counts = dict(sorted(word_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Display all unique words and their frequencies in descending order for all columns combined\n",
    "for word, frequency in sorted_word_counts.items():\n",
    "    print(f\"Word: {word}, Frequency: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "62c3c4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Combined_Axis_Text  seizure\n",
      "1    Nil Nil Nil Nil Nil Nil seizure disorder nan n...        1\n",
      "2    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...        1\n",
      "3    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...        1\n",
      "4    ADHD Nil Nil Nil motor coordination disorder M...        0\n",
      "5    Nil Nil Nil Nil Nil nan seizure disorder Nil N...        1\n",
      "..                                                 ...      ...\n",
      "163  ADHD Nil Nil Nil Nil Severe IDD/GDD seizure di...        1\n",
      "164  Psychosis NOS Nil Nil Nil Nil IDD Nil Nil Nil Nil        0\n",
      "186  BPAD in Mania with psycotic symptoms Nil Nil N...        0\n",
      "187  Depressive Disorder Nil Nil Nil Nil Average IQ...        0\n",
      "191  ADHD Nil Nil Nil Nil Mild IDD/GDD Seizure Diso...        1\n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Assuming the specified columns are in df2\n",
    "columns_to_check = ['Axis 1_1', 'Axis 1_2', 'Axis 1_3', 'Axis 1_4', 'Axis 2', 'Axis 3', 'Axis 4_1', 'Axis 4_2', 'Axis 4_3', 'Axis 5']\n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Combine text from all specified columns into a single text column\n",
    "df2['Combined_Axis_Text'] = df2[columns_to_check].astype(str).agg(' '.join, axis=1)\n",
    "\n",
    "# Define a function to count the frequency of 'seizure' and 'seizures' in each entry\n",
    "def count_seizure(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.lower() not in stop_words]\n",
    "    return tokens.count('seizure') + tokens.count('seizures')\n",
    "\n",
    "# Apply the function to the combined text column and store the result in a new column 'seizure'\n",
    "df2['seizure'] = df2['Combined_Axis_Text'].apply(count_seizure)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[['Combined_Axis_Text', 'seizure']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "a3c18556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Combined_Axis_Text  adhd\n",
      "1    Nil Nil Nil Nil Nil Nil seizure disorder nan n...     0\n",
      "2    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...     0\n",
      "3    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...     0\n",
      "4    ADHD Nil Nil Nil motor coordination disorder M...     1\n",
      "5    Nil Nil Nil Nil Nil nan seizure disorder Nil N...     0\n",
      "..                                                 ...   ...\n",
      "163  ADHD Nil Nil Nil Nil Severe IDD/GDD seizure di...     1\n",
      "164  Psychosis NOS Nil Nil Nil Nil IDD Nil Nil Nil Nil     0\n",
      "186  BPAD in Mania with psycotic symptoms Nil Nil N...     0\n",
      "187  Depressive Disorder Nil Nil Nil Nil Average IQ...     0\n",
      "191  ADHD Nil Nil Nil Nil Mild IDD/GDD Seizure Diso...     1\n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Assuming the specified columns are in df2\n",
    "columns_to_check = ['Axis 1_1', 'Axis 1_2', 'Axis 1_3', 'Axis 1_4', 'Axis 2', 'Axis 3', 'Axis 4_1', 'Axis 4_2', 'Axis 4_3', 'Axis 5']\n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Combine text from all specified columns into a single text column\n",
    "df2['Combined_Axis_Text'] = df2[columns_to_check].astype(str).agg(' '.join, axis=1)\n",
    "\n",
    "# Define a function to count the frequency of 'adhd' in each entry\n",
    "def count_adhd(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.lower() not in stop_words]\n",
    "    return tokens.count('adhd')\n",
    "\n",
    "# Apply the function to the combined text column and store the result in a new column 'adhd'\n",
    "df2['adhd'] = df2['Combined_Axis_Text'].apply(count_adhd)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[['Combined_Axis_Text', 'adhd']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "9ec326ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Combined_Axis_Text  depression1\n",
      "1    Nil Nil Nil Nil Nil Nil seizure disorder nan n...            0\n",
      "2    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...            0\n",
      "3    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...            0\n",
      "4    ADHD Nil Nil Nil motor coordination disorder M...            0\n",
      "5    Nil Nil Nil Nil Nil nan seizure disorder Nil N...            0\n",
      "..                                                 ...          ...\n",
      "163  ADHD Nil Nil Nil Nil Severe IDD/GDD seizure di...            0\n",
      "164  Psychosis NOS Nil Nil Nil Nil IDD Nil Nil Nil Nil            0\n",
      "186  BPAD in Mania with psycotic symptoms Nil Nil N...            0\n",
      "187  Depressive Disorder Nil Nil Nil Nil Average IQ...            1\n",
      "191  ADHD Nil Nil Nil Nil Mild IDD/GDD Seizure Diso...            0\n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Assuming the specified columns are in df2\n",
    "columns_to_check = ['Axis 1_1', 'Axis 1_2', 'Axis 1_3', 'Axis 1_4', 'Axis 2', 'Axis 3', 'Axis 4_1', 'Axis 4_2', 'Axis 4_3', 'Axis 5']\n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Combine text from all specified columns into a single text column\n",
    "df2['Combined_Axis_Text'] = df2[columns_to_check].astype(str).agg(' '.join, axis=1)\n",
    "\n",
    "# Define a function to count the frequency of 'depressive' and 'depression' in each entry\n",
    "def count_depression(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(str(text)) if word.lower() not in stop_words]\n",
    "    return tokens.count('depressive') + tokens.count('depression')\n",
    "\n",
    "# Apply the function to the combined text column and store the result in a new column 'depression1'\n",
    "df2['depression1'] = df2['Combined_Axis_Text'].apply(count_depression)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[['Combined_Axis_Text', 'depression1']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "af7778ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Satisfactory', 'Poor', 'Good'], dtype=object)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Final'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "93a9b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'Poor' : 0,\n",
    "    'Satisfactory' : 0.5,\n",
    "    'Good': 1,\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2['Final'] = df2['Final'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "023c8045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df2 is your DataFrame\n",
    "# Specify the file path and name for the Excel file\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Display a message indicating the file has been created\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "bca5c1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...  Axis 3_Keywords              Axis 4_1_Keywords  \\\n",
      "1    ...            [nil]            [seizure, disorder]   \n",
      "2    ...       [moderate]            [seizure, disorder]   \n",
      "3    ...       [moderate]            [seizure, disorder]   \n",
      "4    ...           [mild]  [subclinical, hypothyroidism]   \n",
      "5    ...            [nan]            [seizure, disorder]   \n",
      "..   ...              ...                            ...   \n",
      "163  ...         [severe]            [seizure, disorder]   \n",
      "164  ...            [idd]                          [nil]   \n",
      "186  ...    [average, iq]                          [nil]   \n",
      "187  ...    [average, iq]                          [nil]   \n",
      "191  ...           [mild]            [seizure, disorder]   \n",
      "\n",
      "              Axis 4_2_Keywords  Axis 4_3_Keywords  \\\n",
      "1                         [nan]              [nan]   \n",
      "2     [diabetes, melitus, type]              [nan]   \n",
      "3    [left, sided, hemiparesis]              [nil]   \n",
      "4                          [il]              [nil]   \n",
      "5                         [nil]              [nil]   \n",
      "..                          ...                ...   \n",
      "163                       [nil]              [nil]   \n",
      "164                       [nil]              [nil]   \n",
      "186                       [nil]              [nil]   \n",
      "187                       [nil]              [nil]   \n",
      "191                       [nan]              [nil]   \n",
      "\n",
      "                  Axis 5_Keywords  \\\n",
      "1                           [nan]   \n",
      "2    [death, nephew, month, back]   \n",
      "3                           [nan]   \n",
      "4         [permissive, parenting]   \n",
      "5                           [nil]   \n",
      "..                            ...   \n",
      "163                         [nil]   \n",
      "164                         [nil]   \n",
      "186                         [nil]   \n",
      "187                         [nil]   \n",
      "191                         [nil]   \n",
      "\n",
      "                                    Combined_Axis_Text  \\\n",
      "1    Nil Nil Nil Nil Nil Nil seizure disorder nan n...   \n",
      "2    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "3    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "4    ADHD Nil Nil Nil motor coordination disorder M...   \n",
      "5    Nil Nil Nil Nil Nil nan seizure disorder Nil N...   \n",
      "..                                                 ...   \n",
      "163  ADHD Nil Nil Nil Nil Severe IDD/GDD seizure di...   \n",
      "164  Psychosis NOS Nil Nil Nil Nil IDD Nil Nil Nil Nil   \n",
      "186  BPAD in Mania with psycotic symptoms Nil Nil N...   \n",
      "187  Depressive Disorder Nil Nil Nil Nil Average IQ...   \n",
      "191  ADHD Nil Nil Nil Nil Mild IDD/GDD Seizure Diso...   \n",
      "\n",
      "                                Combined_Axis_Keywords  seizure  adhd  \\\n",
      "1    [nil, nil, nil, nil, nil, nil, seizure, disord...        1     0   \n",
      "2    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "3    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "4    [adhd, nil, nil, nil, motor, coordination, dis...        0     1   \n",
      "5    [nil, nil, nil, nil, nil, nan, seizure, disord...        1     0   \n",
      "..                                                 ...      ...   ...   \n",
      "163  [adhd, nil, nil, nil, nil, severe, seizure, di...        1     1   \n",
      "164  [psychosis, nos, nil, nil, nil, nil, idd, nil,...        0     0   \n",
      "186  [bpad, mania, psycotic, symptoms, nil, nil, ni...        0     0   \n",
      "187  [depressive, disorder, nil, nil, nil, nil, ave...        0     0   \n",
      "191  [adhd, nil, nil, nil, nil, mild, seizure, diso...        1     1   \n",
      "\n",
      "    depression1  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n",
      "5             0  \n",
      "..          ...  \n",
      "163           0  \n",
      "164           0  \n",
      "186           0  \n",
      "187           1  \n",
      "191           0  \n",
      "\n",
      "[148 rows x 78 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming the specified axis columns are in df2\n",
    "columns_to_drop = ['Axis 1_1', 'Axis 1_2', 'Axis 1_3', 'Axis 1_4', 'Axis 2', 'Axis 3', 'Axis 4_1', 'Axis 4_2', 'Axis 4_3', 'Axis 5']\n",
    "\n",
    "# Drop the specified columns\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "52025f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', nan, 'Nil'], dtype=object)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['significant psychosocial stressor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "4d66893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'No' : 0.5,\n",
    "    'Yes' : 1,\n",
    "    'Nil': 0.5,\n",
    "     np.nan: 0\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2['significant psychosocial stressor'] = df2['significant psychosocial stressor'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "32ac1b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...  Axis 3_Keywords              Axis 4_1_Keywords  \\\n",
      "1    ...            [nil]            [seizure, disorder]   \n",
      "2    ...       [moderate]            [seizure, disorder]   \n",
      "3    ...       [moderate]            [seizure, disorder]   \n",
      "4    ...           [mild]  [subclinical, hypothyroidism]   \n",
      "5    ...            [nan]            [seizure, disorder]   \n",
      "..   ...              ...                            ...   \n",
      "163  ...         [severe]            [seizure, disorder]   \n",
      "164  ...            [idd]                          [nil]   \n",
      "186  ...    [average, iq]                          [nil]   \n",
      "187  ...    [average, iq]                          [nil]   \n",
      "191  ...           [mild]            [seizure, disorder]   \n",
      "\n",
      "              Axis 4_2_Keywords  Axis 4_3_Keywords  \\\n",
      "1                         [nan]              [nan]   \n",
      "2     [diabetes, melitus, type]              [nan]   \n",
      "3    [left, sided, hemiparesis]              [nil]   \n",
      "4                          [il]              [nil]   \n",
      "5                         [nil]              [nil]   \n",
      "..                          ...                ...   \n",
      "163                       [nil]              [nil]   \n",
      "164                       [nil]              [nil]   \n",
      "186                       [nil]              [nil]   \n",
      "187                       [nil]              [nil]   \n",
      "191                       [nan]              [nil]   \n",
      "\n",
      "                  Axis 5_Keywords  \\\n",
      "1                           [nan]   \n",
      "2    [death, nephew, month, back]   \n",
      "3                           [nan]   \n",
      "4         [permissive, parenting]   \n",
      "5                           [nil]   \n",
      "..                            ...   \n",
      "163                         [nil]   \n",
      "164                         [nil]   \n",
      "186                         [nil]   \n",
      "187                         [nil]   \n",
      "191                         [nil]   \n",
      "\n",
      "                                    Combined_Axis_Text  \\\n",
      "1    Nil Nil Nil Nil Nil Nil seizure disorder nan n...   \n",
      "2    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "3    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "4    ADHD Nil Nil Nil motor coordination disorder M...   \n",
      "5    Nil Nil Nil Nil Nil nan seizure disorder Nil N...   \n",
      "..                                                 ...   \n",
      "163  ADHD Nil Nil Nil Nil Severe IDD/GDD seizure di...   \n",
      "164  Psychosis NOS Nil Nil Nil Nil IDD Nil Nil Nil Nil   \n",
      "186  BPAD in Mania with psycotic symptoms Nil Nil N...   \n",
      "187  Depressive Disorder Nil Nil Nil Nil Average IQ...   \n",
      "191  ADHD Nil Nil Nil Nil Mild IDD/GDD Seizure Diso...   \n",
      "\n",
      "                                Combined_Axis_Keywords  seizure  adhd  \\\n",
      "1    [nil, nil, nil, nil, nil, nil, seizure, disord...        1     0   \n",
      "2    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "3    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "4    [adhd, nil, nil, nil, motor, coordination, dis...        0     1   \n",
      "5    [nil, nil, nil, nil, nil, nan, seizure, disord...        1     0   \n",
      "..                                                 ...      ...   ...   \n",
      "163  [adhd, nil, nil, nil, nil, severe, seizure, di...        1     1   \n",
      "164  [psychosis, nos, nil, nil, nil, nil, idd, nil,...        0     0   \n",
      "186  [bpad, mania, psycotic, symptoms, nil, nil, ni...        0     0   \n",
      "187  [depressive, disorder, nil, nil, nil, nil, ave...        0     0   \n",
      "191  [adhd, nil, nil, nil, nil, mild, seizure, diso...        1     1   \n",
      "\n",
      "    depression1  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n",
      "5             0  \n",
      "..          ...  \n",
      "163           0  \n",
      "164           0  \n",
      "186           0  \n",
      "187           1  \n",
      "191           0  \n",
      "\n",
      "[148 rows x 77 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Type of school' is a column in df2\n",
    "columns_to_drop = ['name of Medication 1']\n",
    "\n",
    "# Drop the specified columns\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "c81376f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Continued medication 1/stopped/changed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "929a8d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Continued medication 1/stopped/changed  \\\n",
      "1                                       NaN   \n",
      "2                                       NaN   \n",
      "3                                       NaN   \n",
      "4                                       NaN   \n",
      "5                                       NaN   \n",
      "..                                      ...   \n",
      "163                                     NaN   \n",
      "164                                     NaN   \n",
      "186                                     NaN   \n",
      "187                                     NaN   \n",
      "191                                     NaN   \n",
      "\n",
      "     Continued medication 1/stopped/changed_scaled  \n",
      "1                                              NaN  \n",
      "2                                              NaN  \n",
      "3                                              NaN  \n",
      "4                                              NaN  \n",
      "5                                              NaN  \n",
      "..                                             ...  \n",
      "163                                            NaN  \n",
      "164                                            NaN  \n",
      "186                                            NaN  \n",
      "187                                            NaN  \n",
      "191                                            NaN  \n",
      "\n",
      "[148 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Continued medication 1/stopped/changed' is the column in df2\n",
    "column_name = 'Continued medication 1/stopped/changed'\n",
    "\n",
    "# Convert the column to numeric (handling non-numeric values gracefully)\n",
    "df2[column_name] = pd.to_numeric(df2[column_name], errors='coerce')\n",
    "\n",
    "# Find the minimum and maximum values in the column\n",
    "min_value = df2[column_name].min()\n",
    "max_value = df2[column_name].max()\n",
    "\n",
    "# Create a mapping function to scale values between 0 and 1\n",
    "def map_to_range(value):\n",
    "    return (value - min_value) / (max_value - min_value) if pd.notnull(value) else value\n",
    "\n",
    "# Apply the mapping function to the 'Continued medication 1/stopped/changed' column\n",
    "df2['Continued medication 1/stopped/changed_scaled'] = df2[column_name].apply(map_to_range)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[['Continued medication 1/stopped/changed', 'Continued medication 1/stopped/changed_scaled']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "fdb9ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df2 is your DataFrame\n",
    "# Specify the file path and name for the Excel file\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Display a message indicating the file has been created\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "4e74293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      0.5\n",
      "2      0.5\n",
      "3      0.5\n",
      "4      0.5\n",
      "5      0.5\n",
      "      ... \n",
      "163    0.5\n",
      "164    0.5\n",
      "186    0.5\n",
      "187    0.5\n",
      "191    0.5\n",
      "Name: Rural/Urban, Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Rural/Urban' is the column in df2\n",
    "column_name = 'Rural/Urban'\n",
    "\n",
    "# Replace 9 with 1 in the specified column\n",
    "df2[column_name].replace(9, 0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "eb7b3b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       8.0\n",
      "2      17.0\n",
      "3       5.5\n",
      "4       0.0\n",
      "5       5.5\n",
      "       ... \n",
      "163     0.0\n",
      "164    16.0\n",
      "186    15.0\n",
      "187    15.0\n",
      "191     4.0\n",
      "Name: Age at onset(in years), Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Age at onset(in years)' is the column in df2\n",
    "column_name = 'Age at onset(in years)'\n",
    "\n",
    "# Replace NaN with 0 in the specified column\n",
    "df2[column_name].fillna(0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "627a7914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Cluster_1_date    Date of screening         UHID  \\\n",
      "0             22.06.2020  2019-05-20 00:00:00  20190008847   \n",
      "1             22.06.2020  2019-09-24 00:00:00  20190016882   \n",
      "2             22.06.2020  2014-03-03 00:00:00  20170010718   \n",
      "3             22.06.2020  2020-06-18 00:00:00  20200006501   \n",
      "4             22.06.2020  2014-03-31 00:00:00  20170015662   \n",
      "..                   ...                  ...          ...   \n",
      "143  2022-08-26 00:00:00  2022-02-24 00:00:00  20220002660   \n",
      "144  2022-08-26 00:00:00  2022-05-05 00:00:00  20220006417   \n",
      "145  2021-08-28 00:00:00  2021-07-29 00:00:00  20210007196   \n",
      "146  2021-08-28 00:00:00  2020-06-24 00:00:00  20200006807   \n",
      "147  2021-08-28 00:00:00  2019-02-28 00:00:00  20190003397   \n",
      "\n",
      "                        Name  Age at presentation (in yrs)  \\\n",
      "0                Mampi Shill                           8.0   \n",
      "1             Salema Khatoon                          17.0   \n",
      "2              Jiarur Rahman                           7.0   \n",
      "3              Debashis Nath                          10.0   \n",
      "4             Rahima Khatoon                           8.0   \n",
      "..                       ...                           ...   \n",
      "143          Paragmoni Sarma                           7.0   \n",
      "144           Roshidul Islam                          16.0   \n",
      "145            Rakibul Islam                          15.0   \n",
      "146  Muzzamil Hoque Chordury                          15.0   \n",
      "147             Ronik Barman                           5.0   \n",
      "\n",
      "     Age at last follow up Sex (m/f)  Religion  \\\n",
      "0                     10.0    female     Islam   \n",
      "1                     18.0    female     Islam   \n",
      "2                     17.0      male     Islam   \n",
      "3                     10.0      male  Hinduism   \n",
      "4                     15.0    female     Islam   \n",
      "..                     ...       ...       ...   \n",
      "143                    9.0      male  Hinduism   \n",
      "144                   17.0      male     Islam   \n",
      "145                   15.0      male     Islam   \n",
      "146                   17.0      male     Islam   \n",
      "147                    8.0      male  Hinduism   \n",
      "\n",
      "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
      "0                                                  NaN                                         \n",
      "1                                              Primary                                         \n",
      "2                                                  NaN                                         \n",
      "3                                              primary                                         \n",
      "4                                  no formal education                                         \n",
      "..                                                 ...                                         \n",
      "143                                no formal education                                         \n",
      "144                                            primary                                         \n",
      "145                                        high school                                         \n",
      "146                                        high school                                         \n",
      "147                                            primary                                         \n",
      "\n",
      "    Max education attained  ... No of relapses/exacerbations  \\\n",
      "0                      NaN  ...                          6.0   \n",
      "1                  Primary  ...                          0.0   \n",
      "2                      NaN  ...                          6.0   \n",
      "3                  Primary  ...                          1.0   \n",
      "4      no formal education  ...                         33.0   \n",
      "..                     ...  ...                          ...   \n",
      "143    no formal education  ...                          0.0   \n",
      "144                primary  ...                          2.0   \n",
      "145            high school  ...                          1.0   \n",
      "146            high school  ...                          0.0   \n",
      "147                primary  ...                          0.0   \n",
      "\n",
      "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
      "0                                                 22.0                            \n",
      "1                                                 30.0                            \n",
      "2                                                 58.0                            \n",
      "3                                                 20.0                            \n",
      "4                                                 65.0                            \n",
      "..                                                 ...                            \n",
      "143                                                0.0                            \n",
      "144                                              330.0                            \n",
      "145                                              180.0                            \n",
      "146                                              120.0                            \n",
      "147                                                0.0                            \n",
      "\n",
      "    Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}  \\\n",
      "0                                         Satisfactory                                                                                                                                                                                                                                                                                              \n",
      "1                                                 Poor                                                                                                                                                                                                                                                                                              \n",
      "2                                                 Good                                                                                                                                                                                                                                                                                              \n",
      "3                                                 Good                                                                                                                                                                                                                                                                                              \n",
      "4                                         Satisfactory                                                                                                                                                                                                                                                                                              \n",
      "..                                                 ...                                                                                                                                                                                                                                                                                              \n",
      "143                                               Good                                                                                                                                                                                                                                                                                              \n",
      "144                                               Poor                                                                                                                                                                                                                                                                                              \n",
      "145                                               Poor                                                                                                                                                                                                                                                                                              \n",
      "146                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
      "147                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
      "\n",
      "     mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
      "0                                                 1.66                                     \n",
      "1                                                 1.78                                     \n",
      "2                                                  NaN                                     \n",
      "3                                                    1                                     \n",
      "4                                                  6.6                                     \n",
      "..                                                 ...                                     \n",
      "143                                                2.1                                     \n",
      "144                                                3.8                                     \n",
      "145                                                4.3                                     \n",
      "146                                               1.21                                     \n",
      "147                                               2.15                                     \n",
      "\n",
      "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
      "0                                                395.0                                  \n",
      "1                                                240.0                                  \n",
      "2                                                  NaN                                  \n",
      "3                                                 90.0                                  \n",
      "4                                                480.0                                  \n",
      "..                                                 ...                                  \n",
      "143                                              648.0                                  \n",
      "144                                              113.0                                  \n",
      "145                                              170.0                                  \n",
      "146                                              390.0                                  \n",
      "147                                             1619.0                                  \n",
      "\n",
      "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
      "0                                                626.0                                                   \n",
      "1                                                330.0                                                   \n",
      "2                                               1320.0                                                   \n",
      "3                                                 90.0                                                   \n",
      "4                                               3495.0                                                   \n",
      "..                                                 ...                                                   \n",
      "143                                              648.0                                                   \n",
      "144                                              576.0                                                   \n",
      "145                                              384.0                                                   \n",
      "146                                              875.0                                                   \n",
      "147                                             1619.0                                                   \n",
      "\n",
      "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
      "0    24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...              \n",
      "1       19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020              \n",
      "2    31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...              \n",
      "3                                22-06-2020,30-09-2020              \n",
      "4    29-04-2014, 29-05-2014, 04-07-2014, 25-08-14, ...              \n",
      "..                                                 ...              \n",
      "143  28-03-22, 13-07-22, 26-08-22, 11-10-22, 15-05-...              \n",
      "144   08-06-22, 26-08-22, 19-12-22, 23-01-23, 02-11-23              \n",
      "145                 28-08-2021, 15-07-2022, 17-08-2022              \n",
      "146  29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...              \n",
      "147  16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...              \n",
      "\n",
      "    total number of follow up at LGBRIMH Final (ignore for now)  \\\n",
      "0                                     12                    NaN   \n",
      "1                                      4                    NaN   \n",
      "2                                     69                    NaN   \n",
      "3                                      2                    NaN   \n",
      "4                                     71                    NaN   \n",
      "..                                   ...                    ...   \n",
      "143                                   10                    NaN   \n",
      "144                                    5                    NaN   \n",
      "145                                    3                    NaN   \n",
      "146                                   24                    NaN   \n",
      "147                                   25                    NaN   \n",
      "\n",
      "    Number of In patient cares  \n",
      "0                            0  \n",
      "1                            0  \n",
      "2                            0  \n",
      "3                            1  \n",
      "4                            0  \n",
      "..                         ...  \n",
      "143                          0  \n",
      "144                          0  \n",
      "145                          0  \n",
      "146                          0  \n",
      "147                          0  \n",
      "\n",
      "[148 rows x 274 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df2_loaded = pd.read_excel('df2_n.xlsx')\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(df2_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "12296b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'poorly adjusted', 'well adjusted', 'Nil'], dtype=object)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_loaded['School adjustment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "2c33c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'well adjusted': 1,\n",
    "    'poorly adjusted' : 0.66,\n",
    "    'Nil': 0.33,\n",
    "     np.nan: 0\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2_loaded['School adjustment'] = df2_loaded['School adjustment'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "0a252a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      0.66\n",
      "2      0.00\n",
      "3      1.00\n",
      "4      0.00\n",
      "5      0.00\n",
      "       ... \n",
      "163     NaN\n",
      "164     NaN\n",
      "186     NaN\n",
      "187     NaN\n",
      "191     NaN\n",
      "Name: School adjustment, Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'School adjustment' is the column in both df2 and df2_loaded\n",
    "column_name = 'School adjustment'\n",
    "\n",
    "# Replace values in df2['School adjustment'] with values from df2_loaded['School adjustment']\n",
    "df2[column_name] = df2_loaded[column_name]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "1b59029d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.00\n",
       "1      0.66\n",
       "2      0.00\n",
       "3      1.00\n",
       "4      0.00\n",
       "       ... \n",
       "143    0.33\n",
       "144    0.66\n",
       "145    1.00\n",
       "146    0.00\n",
       "147    0.66\n",
       "Name: School adjustment, Length: 148, dtype: float64"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_loaded['School adjustment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "3919f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['School adjustment'] = df2_loaded['School adjustment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "9bd10e02",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['School adjustment'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [375], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m column_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSchool adjustment\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Drop the specified column\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Display the updated DataFrame\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(df2)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5388\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5240\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5249\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5251\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5386\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5390\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5394\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5395\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5396\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6975\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6975\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6976\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['School adjustment'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Assuming 'School adjustment' is the column in df2 that you want to drop\n",
    "column_name = 'School adjustment'\n",
    "\n",
    "# Drop the specified column\n",
    "df2.drop(columns=[column_name], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "68c62600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      0.66\n",
       "2      0.00\n",
       "3      1.00\n",
       "4      0.00\n",
       "5      0.00\n",
       "       ... \n",
       "163     NaN\n",
       "164     NaN\n",
       "186     NaN\n",
       "187     NaN\n",
       "191     NaN\n",
       "Name: School adjustment, Length: 148, dtype: float64"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['School adjustment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "523d4b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i in df2_loaded['School adjustment'] :\n",
    "    li.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "ca3b4b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.66,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.33,\n",
       " 1.0,\n",
       " 0.33,\n",
       " 0.33,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.33,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.66,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.33,\n",
       " 1.0,\n",
       " 0.33,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.33,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.66,\n",
       " 0.33,\n",
       " 0.0,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.33,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 0.33,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 0.33,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.66,\n",
       " 0.33,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 0.0,\n",
       " 0.66,\n",
       " 0.0,\n",
       " 0.33,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.33,\n",
       " 0.33,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.33,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 0.33,\n",
       " 0.33,\n",
       " 0.33,\n",
       " 0.0,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.33,\n",
       " 0.33,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.33,\n",
       " 0.66,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.66]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "9f867dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      0.00\n",
      "2      0.66\n",
      "3      0.00\n",
      "4      1.00\n",
      "5      0.00\n",
      "       ... \n",
      "163    0.33\n",
      "164    0.66\n",
      "186    1.00\n",
      "187    0.00\n",
      "191    0.66\n",
      "Name: School Adjustment, Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'School Adjustment' is the column in df2 and values_to_insert is your list of values\n",
    "column_name = 'School Adjustment'\n",
    "values_to_insert = li  # Replace with your actual list of values\n",
    "\n",
    "# Check if the length of values_to_insert matches the number of rows in df2\n",
    "if len(values_to_insert) == len(df2):\n",
    "    df2[column_name] = values_to_insert\n",
    "    print(df2[column_name])\n",
    "else:\n",
    "    print(\"Length of values_to_insert does not match the number of rows in df2.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "9c0cef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df2 is your DataFrame\n",
    "# Specify the file path and name for the Excel file\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Display a message indicating the file has been created\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "9056a70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                No\n",
       "1                No\n",
       "2      Yes (single)\n",
       "3                No\n",
       "4                No\n",
       "           ...     \n",
       "143              No\n",
       "144              No\n",
       "145              No\n",
       "146              No\n",
       "147    Yes (single)\n",
       "Name: Change in doctor, Length: 148, dtype: object"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_loaded['Change in doctor'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "c0f9444d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes (single)', 'Yes(multiple)', 'Nil', nan], dtype=object)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_loaded['Change in doctor'] .unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "5f861992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'No': 0.5,\n",
    "    'Yes (single)' : 1,\n",
    "    'Yes(multiple)' : 1,\n",
    "    'Nil': 0.5,\n",
    "     np.nan: 0\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2_loaded['Change in doctor'] = df2_loaded['Change in doctor'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "b31e69f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.5\n",
       "1      0.5\n",
       "2      1.0\n",
       "3      0.5\n",
       "4      0.5\n",
       "      ... \n",
       "143    0.5\n",
       "144    0.5\n",
       "145    0.5\n",
       "146    0.5\n",
       "147    1.0\n",
       "Name: Change in doctor, Length: 148, dtype: float64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_loaded['Change in doctor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "81630f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i in df2_loaded['Change in doctor'] :\n",
    "    li.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "ccbb4f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      0.5\n",
      "2      0.5\n",
      "3      1.0\n",
      "4      0.5\n",
      "5      0.5\n",
      "      ... \n",
      "163    0.5\n",
      "164    0.5\n",
      "186    0.5\n",
      "187    0.5\n",
      "191    1.0\n",
      "Name: Change in doctor, Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'School Adjustment' is the column in df2 and values_to_insert is your list of values\n",
    "column_name = 'Change in doctor'\n",
    "values_to_insert = li  # Replace with your actual list of values\n",
    "\n",
    "# Check if the length of values_to_insert matches the number of rows in df2\n",
    "if len(values_to_insert) == len(df2):\n",
    "    df2[column_name] = values_to_insert\n",
    "    print(df2[column_name])\n",
    "else:\n",
    "    print(\"Length of values_to_insert does not match the number of rows in df2.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "78961013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      20.0\n",
      "2      36.0\n",
      "3      15.0\n",
      "4      35.0\n",
      "5      21.0\n",
      "       ... \n",
      "163    20.0\n",
      "164    30.0\n",
      "186    48.0\n",
      "187    55.0\n",
      "191    15.0\n",
      "Name: weight (in Kg), Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Weight (in Kg)' is the column in df2\n",
    "column_name = 'weight (in Kg)'\n",
    "\n",
    "# Fill NaN values with 0 in the specified column\n",
    "df2[column_name].fillna(0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "7fb0a6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "      ... \n",
      "143      0\n",
      "144    220\n",
      "145      0\n",
      "146    NIL\n",
      "147    266\n",
      "Name: If yes, after how many days from first presentation diagnosis changed (in days), Length: 148, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'If yes, after how many days from first presentation diagnosis changed (in days)' is the column in df2_loaded\n",
    "column_name = 'If yes, after how many days from first presentation diagnosis changed (in days)'\n",
    "\n",
    "# Replace 'nil', 'Nil', and NaN values with 0 in the specified column\n",
    "df2_loaded[column_name].replace(['nil', 'Nil', 'nan'], 0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2_loaded[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "b2e5c820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, nan, 'NIL', 365, 180, 720, 30, 1590, 1050, 1465, 1440, 'No',\n",
       "       409, 72, 163, 787, 280, 1752, 4518, 35, 523, 820, 480, 3453, 707,\n",
       "       5090, 299, 555, 141, 'NIl', 230, 43, 405, 425, 561, 4, 610, 788,\n",
       "       200, 14, 113, 668, 1774, 965, 1345, 2932, 235, 34, 218, 673, 220,\n",
       "       266], dtype=object)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_loaded[column_name].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "8096d3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "      ... \n",
      "143      0\n",
      "144    220\n",
      "145      0\n",
      "146      0\n",
      "147    266\n",
      "Name: If yes, after how many days from first presentation diagnosis changed (in days), Length: 148, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace 'nan', 'NIL', and 'No' with 0 in the specified column\n",
    "df2_loaded[column_name].replace(['nan', 'NIL', 'No'], 0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2_loaded[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "c024c1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, nan, 365, 180, 720, 30, 1590, 1050, 1465, 1440, 409, 72, 163,\n",
       "       787, 280, 1752, 4518, 35, 523, 820, 480, 3453, 707, 5090, 299, 555,\n",
       "       141, 'NIl', 230, 43, 405, 425, 561, 4, 610, 788, 200, 14, 113, 668,\n",
       "       1774, 965, 1345, 2932, 235, 34, 218, 673, 220, 266], dtype=object)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_loaded[column_name].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "bd40c33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "      ... \n",
      "143      0\n",
      "144    220\n",
      "145      0\n",
      "146      0\n",
      "147    266\n",
      "Name: If yes, after how many days from first presentation diagnosis changed (in days), Length: 148, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace 'nan', 'NIL', and 'No' with 0 in the specified column\n",
    "df2_loaded[column_name].replace([np.nan], 0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2_loaded[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "14b2a379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 365, 180, 720, 30, 1590, 1050, 1465, 1440, 409, 72, 163, 787,\n",
       "       280, 1752, 4518, 35, 523, 820, 480, 3453, 707, 5090, 299, 555, 141,\n",
       "       'NIl', 230, 43, 405, 425, 561, 4, 610, 788, 200, 14, 113, 668,\n",
       "       1774, 965, 1345, 2932, 235, 34, 218, 673, 220, 266], dtype=object)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_loaded[column_name].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "8161d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i in df2_loaded[column_name] :\n",
    "    li.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "22eadfcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 365,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 180,\n",
       " 0,\n",
       " 720,\n",
       " 0,\n",
       " 30,\n",
       " 0,\n",
       " 1590,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1050,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1465,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1440,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 409,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 72,\n",
       " 0,\n",
       " 0,\n",
       " 163,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 787,\n",
       " 30,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 280,\n",
       " 0,\n",
       " 0,\n",
       " 1752,\n",
       " 30,\n",
       " 4518,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 35,\n",
       " 0,\n",
       " 0,\n",
       " 523,\n",
       " 820,\n",
       " 365,\n",
       " 480,\n",
       " 3453,\n",
       " 707,\n",
       " 5090,\n",
       " 0,\n",
       " 0,\n",
       " 299,\n",
       " 555,\n",
       " 141,\n",
       " 0,\n",
       " 'NIl',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 230,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 43,\n",
       " 'NIl',\n",
       " 405,\n",
       " 0,\n",
       " 425,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 561,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 610,\n",
       " 788,\n",
       " 200,\n",
       " 0,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 113,\n",
       " 0,\n",
       " 0,\n",
       " 668,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1774,\n",
       " 0,\n",
       " 965,\n",
       " 1345,\n",
       " 0,\n",
       " 0,\n",
       " 30,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2932,\n",
       " 235,\n",
       " 0,\n",
       " 0,\n",
       " 34,\n",
       " 218,\n",
       " 0,\n",
       " 673,\n",
       " 14,\n",
       " 0,\n",
       " 220,\n",
       " 0,\n",
       " 0,\n",
       " 266]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "69f5e593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df2 is your DataFrame\n",
    "# Specify the file path and name for the Excel file\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Display a message indicating the file has been created\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "b661f358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...           Axis 4_2_Keywords  Axis 4_3_Keywords  \\\n",
      "1    ...                       [nan]              [nan]   \n",
      "2    ...   [diabetes, melitus, type]              [nan]   \n",
      "3    ...  [left, sided, hemiparesis]              [nil]   \n",
      "4    ...                        [il]              [nil]   \n",
      "5    ...                       [nil]              [nil]   \n",
      "..   ...                         ...                ...   \n",
      "163  ...                       [nil]              [nil]   \n",
      "164  ...                       [nil]              [nil]   \n",
      "186  ...                       [nil]              [nil]   \n",
      "187  ...                       [nil]              [nil]   \n",
      "191  ...                       [nan]              [nil]   \n",
      "\n",
      "                  Axis 5_Keywords  \\\n",
      "1                           [nan]   \n",
      "2    [death, nephew, month, back]   \n",
      "3                           [nan]   \n",
      "4         [permissive, parenting]   \n",
      "5                           [nil]   \n",
      "..                            ...   \n",
      "163                         [nil]   \n",
      "164                         [nil]   \n",
      "186                         [nil]   \n",
      "187                         [nil]   \n",
      "191                         [nil]   \n",
      "\n",
      "                                    Combined_Axis_Text  \\\n",
      "1    Nil Nil Nil Nil Nil Nil seizure disorder nan n...   \n",
      "2    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "3    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "4    ADHD Nil Nil Nil motor coordination disorder M...   \n",
      "5    Nil Nil Nil Nil Nil nan seizure disorder Nil N...   \n",
      "..                                                 ...   \n",
      "163  ADHD Nil Nil Nil Nil Severe IDD/GDD seizure di...   \n",
      "164  Psychosis NOS Nil Nil Nil Nil IDD Nil Nil Nil Nil   \n",
      "186  BPAD in Mania with psycotic symptoms Nil Nil N...   \n",
      "187  Depressive Disorder Nil Nil Nil Nil Average IQ...   \n",
      "191  ADHD Nil Nil Nil Nil Mild IDD/GDD Seizure Diso...   \n",
      "\n",
      "                                Combined_Axis_Keywords  seizure  adhd  \\\n",
      "1    [nil, nil, nil, nil, nil, nil, seizure, disord...        1     0   \n",
      "2    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "3    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "4    [adhd, nil, nil, nil, motor, coordination, dis...        0     1   \n",
      "5    [nil, nil, nil, nil, nil, nan, seizure, disord...        1     0   \n",
      "..                                                 ...      ...   ...   \n",
      "163  [adhd, nil, nil, nil, nil, severe, seizure, di...        1     1   \n",
      "164  [psychosis, nos, nil, nil, nil, nil, idd, nil,...        0     0   \n",
      "186  [bpad, mania, psycotic, symptoms, nil, nil, ni...        0     0   \n",
      "187  [depressive, disorder, nil, nil, nil, nil, ave...        0     0   \n",
      "191  [adhd, nil, nil, nil, nil, mild, seizure, diso...        1     1   \n",
      "\n",
      "     depression1  Continued medication 1/stopped/changed_scaled  \\\n",
      "1              0                                            NaN   \n",
      "2              0                                            NaN   \n",
      "3              0                                            NaN   \n",
      "4              0                                            NaN   \n",
      "5              0                                            NaN   \n",
      "..           ...                                            ...   \n",
      "163            0                                            NaN   \n",
      "164            0                                            NaN   \n",
      "186            0                                            NaN   \n",
      "187            1                                            NaN   \n",
      "191            0                                            NaN   \n",
      "\n",
      "     School Adjustment  \n",
      "1                 0.00  \n",
      "2                 0.66  \n",
      "3                 0.00  \n",
      "4                 1.00  \n",
      "5                 0.00  \n",
      "..                 ...  \n",
      "163               0.33  \n",
      "164               0.66  \n",
      "186               1.00  \n",
      "187               0.00  \n",
      "191               0.66  \n",
      "\n",
      "[148 rows x 77 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Screening diagnosis' is the column in df1 that you want to drop\n",
    "column_name = 'Screening diagnosis '\n",
    "\n",
    "# Drop the specified column\n",
    "df2.drop(columns=[column_name], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "f87ddc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...           Axis 4_2_Keywords  Axis 4_3_Keywords  \\\n",
      "1    ...                       [nan]              [nan]   \n",
      "2    ...   [diabetes, melitus, type]              [nan]   \n",
      "3    ...  [left, sided, hemiparesis]              [nil]   \n",
      "4    ...                        [il]              [nil]   \n",
      "5    ...                       [nil]              [nil]   \n",
      "..   ...                         ...                ...   \n",
      "163  ...                       [nil]              [nil]   \n",
      "164  ...                       [nil]              [nil]   \n",
      "186  ...                       [nil]              [nil]   \n",
      "187  ...                       [nil]              [nil]   \n",
      "191  ...                       [nan]              [nil]   \n",
      "\n",
      "                  Axis 5_Keywords  \\\n",
      "1                           [nan]   \n",
      "2    [death, nephew, month, back]   \n",
      "3                           [nan]   \n",
      "4         [permissive, parenting]   \n",
      "5                           [nil]   \n",
      "..                            ...   \n",
      "163                         [nil]   \n",
      "164                         [nil]   \n",
      "186                         [nil]   \n",
      "187                         [nil]   \n",
      "191                         [nil]   \n",
      "\n",
      "                                    Combined_Axis_Text  \\\n",
      "1    Nil Nil Nil Nil Nil Nil seizure disorder nan n...   \n",
      "2    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "3    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "4    ADHD Nil Nil Nil motor coordination disorder M...   \n",
      "5    Nil Nil Nil Nil Nil nan seizure disorder Nil N...   \n",
      "..                                                 ...   \n",
      "163  ADHD Nil Nil Nil Nil Severe IDD/GDD seizure di...   \n",
      "164  Psychosis NOS Nil Nil Nil Nil IDD Nil Nil Nil Nil   \n",
      "186  BPAD in Mania with psycotic symptoms Nil Nil N...   \n",
      "187  Depressive Disorder Nil Nil Nil Nil Average IQ...   \n",
      "191  ADHD Nil Nil Nil Nil Mild IDD/GDD Seizure Diso...   \n",
      "\n",
      "                                Combined_Axis_Keywords  seizure  adhd  \\\n",
      "1    [nil, nil, nil, nil, nil, nil, seizure, disord...        1     0   \n",
      "2    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "3    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "4    [adhd, nil, nil, nil, motor, coordination, dis...        0     1   \n",
      "5    [nil, nil, nil, nil, nil, nan, seizure, disord...        1     0   \n",
      "..                                                 ...      ...   ...   \n",
      "163  [adhd, nil, nil, nil, nil, severe, seizure, di...        1     1   \n",
      "164  [psychosis, nos, nil, nil, nil, nil, idd, nil,...        0     0   \n",
      "186  [bpad, mania, psycotic, symptoms, nil, nil, ni...        0     0   \n",
      "187  [depressive, disorder, nil, nil, nil, nil, ave...        0     0   \n",
      "191  [adhd, nil, nil, nil, nil, mild, seizure, diso...        1     1   \n",
      "\n",
      "     depression1  Continued medication 1/stopped/changed_scaled  \\\n",
      "1              0                                            NaN   \n",
      "2              0                                            NaN   \n",
      "3              0                                            NaN   \n",
      "4              0                                            NaN   \n",
      "5              0                                            NaN   \n",
      "..           ...                                            ...   \n",
      "163            0                                            NaN   \n",
      "164            0                                            NaN   \n",
      "186            0                                            NaN   \n",
      "187            1                                            NaN   \n",
      "191            0                                            NaN   \n",
      "\n",
      "     School Adjustment  \n",
      "1                 0.00  \n",
      "2                 0.66  \n",
      "3                 0.00  \n",
      "4                 1.00  \n",
      "5                 0.00  \n",
      "..                 ...  \n",
      "163               0.33  \n",
      "164               0.66  \n",
      "186               1.00  \n",
      "187               0.00  \n",
      "191               0.66  \n",
      "\n",
      "[148 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'If yes, after how many days from first presentation diagnosis changed (in days)' is the column in df2\n",
    "column_name = 'If yes, after how many days from first presentation diagnosis changed (in days)'\n",
    "\n",
    "# Drop the specified column\n",
    "df2.drop(columns=[column_name], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "e8c7bf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 365,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 180,\n",
       " 0,\n",
       " 720,\n",
       " 0,\n",
       " 30,\n",
       " 0,\n",
       " 1590,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1050,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1465,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1440,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 409,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 72,\n",
       " 0,\n",
       " 0,\n",
       " 163,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 787,\n",
       " 30,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 280,\n",
       " 0,\n",
       " 0,\n",
       " 1752,\n",
       " 30,\n",
       " 4518,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 35,\n",
       " 0,\n",
       " 0,\n",
       " 523,\n",
       " 820,\n",
       " 365,\n",
       " 480,\n",
       " 3453,\n",
       " 707,\n",
       " 5090,\n",
       " 0,\n",
       " 0,\n",
       " 299,\n",
       " 555,\n",
       " 141,\n",
       " 0,\n",
       " 'NIl',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 230,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 43,\n",
       " 'NIl',\n",
       " 405,\n",
       " 0,\n",
       " 425,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 561,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 610,\n",
       " 788,\n",
       " 200,\n",
       " 0,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 113,\n",
       " 0,\n",
       " 0,\n",
       " 668,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1774,\n",
       " 0,\n",
       " 965,\n",
       " 1345,\n",
       " 0,\n",
       " 0,\n",
       " 30,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2932,\n",
       " 235,\n",
       " 0,\n",
       " 0,\n",
       " 34,\n",
       " 218,\n",
       " 0,\n",
       " 673,\n",
       " 14,\n",
       " 0,\n",
       " 220,\n",
       " 0,\n",
       " 0,\n",
       " 266]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "8d892b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "5        0\n",
      "      ... \n",
      "163      0\n",
      "164    220\n",
      "186      0\n",
      "187      0\n",
      "191    266\n",
      "Name: If yes, after how many days from first presentation diagnosis changed (in days), Length: 148, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'School Adjustment' is the column in df2 and values_to_insert is your list of values\n",
    "column_name = 'If yes, after how many days from first presentation diagnosis changed (in days)'\n",
    "values_to_insert = li  # Replace with your actual list of values\n",
    "\n",
    "# Check if the length of values_to_insert matches the number of rows in df2\n",
    "if len(values_to_insert) == len(df2):\n",
    "    df2[column_name] = values_to_insert\n",
    "    print(df2[column_name])\n",
    "else:\n",
    "    print(\"Length of values_to_insert does not match the number of rows in df2.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "b2a6fbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df2 is your DataFrame\n",
    "# Specify the file path and name for the Excel file\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Display a message indicating the file has been created\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "f7108fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([300, 400, 1000, 0.05, 1500, 600, 'Nil', 0.25, 500, 10, 5, 250, 15,\n",
       "       800, 4, 450, 20, 375, 0.5, 0.15, 2000, 200, 0.75, 1800, 2.5, 350,\n",
       "       2, 7.5, nan, 25, 6, 30, 50, 1.5, 900, 0.1, 100, 1200, 0.075, 700,\n",
       "       1], dtype=object)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Avg dose of medication 1 (Mode value of medication) (in mg)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "ef541d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       300.00\n",
      "2       400.00\n",
      "3      1000.00\n",
      "4         0.05\n",
      "5      1000.00\n",
      "        ...   \n",
      "163      25.00\n",
      "164       2.00\n",
      "186      15.00\n",
      "187       1.00\n",
      "191     400.00\n",
      "Name: Avg dose of medication 1 (Mode value of medication) (in mg), Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'Avg dose of medication 1 (Mode value of medication) (in mg)' is the column in df2\n",
    "column_name = 'Avg dose of medication 1 (Mode value of medication) (in mg)'\n",
    "\n",
    "# Replace 'Nil' and np.nan with 0 in the specified column\n",
    "df2[column_name].replace(['Nil', np.nan], 0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "c449a5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.00e+02, 4.00e+02, 1.00e+03, 5.00e-02, 1.50e+03, 6.00e+02,\n",
       "       0.00e+00, 2.50e-01, 5.00e+02, 1.00e+01, 5.00e+00, 2.50e+02,\n",
       "       1.50e+01, 8.00e+02, 4.00e+00, 4.50e+02, 2.00e+01, 3.75e+02,\n",
       "       5.00e-01, 1.50e-01, 2.00e+03, 2.00e+02, 7.50e-01, 1.80e+03,\n",
       "       2.50e+00, 3.50e+02, 2.00e+00, 7.50e+00, 2.50e+01, 6.00e+00,\n",
       "       3.00e+01, 5.00e+01, 1.50e+00, 9.00e+02, 1.00e-01, 1.00e+02,\n",
       "       1.20e+03, 7.50e-02, 7.00e+02, 1.00e+00])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Avg dose of medication 1 (Mode value of medication) (in mg)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "927e2096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([500, 1000, 0.075, 1200, 1500, 800, 'Nil', 600, 0.25, 400, 540, 10,\n",
       "       5, 250, 15, 4, 25, 375, 2, 300, 0.15, 6, 7.5, 2000, 1, 20, 200,\n",
       "       0.75, 1800, 700, 2.5, 350, 3, 0.5, 18, nan, 30, 150, 900, 100,\n",
       "       1600, 0.1, 8], dtype=object)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Maximum dose of medication 1 (in mg)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "9bd14152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       500.000\n",
      "2       500.000\n",
      "3      1000.000\n",
      "4         0.075\n",
      "5      1200.000\n",
      "         ...   \n",
      "163      25.000\n",
      "164       2.000\n",
      "186      20.000\n",
      "187       1.000\n",
      "191     400.000\n",
      "Name: Maximum dose of medication 1 (in mg), Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'Avg dose of medication 1 (Mode value of medication) (in mg)' is the column in df2\n",
    "column_name = 'Maximum dose of medication 1 (in mg)'\n",
    "\n",
    "# Replace 'Nil' and np.nan with 0 in the specified column\n",
    "df2[column_name].replace(['Nil', np.nan], 0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "f80ee8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       350.0\n",
      "2       300.0\n",
      "3      3182.0\n",
      "4        90.0\n",
      "5      3495.0\n",
      "        ...  \n",
      "163     648.0\n",
      "164     576.0\n",
      "186     384.0\n",
      "187      63.0\n",
      "191    1619.0\n",
      "Name: Total duration of medication 1 (in days) , Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'Avg dose of medication 1 (Mode value of medication) (in mg)' is the column in df2\n",
    "column_name = 'Total duration of medication 1 (in days) '\n",
    "\n",
    "# Replace 'Nil' and np.nan with 0 in the specified column\n",
    "df2[column_name].replace(['Nil', np.nan], 0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "b534186c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      loss to follow-up\n",
       "1      loss to follow-up\n",
       "2              Continued\n",
       "3      loss to follow-up\n",
       "4              Continued\n",
       "             ...        \n",
       "143            Continued\n",
       "144    loss to follow-up\n",
       "145    loss to follow-up\n",
       "146              Stopped\n",
       "147    loss to follow-up\n",
       "Name: Continued medication 1/stopped/changed, Length: 148, dtype: object"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_loaded['Continued medication 1/stopped/changed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "7653c0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     NaN\n",
       "2     NaN\n",
       "3     NaN\n",
       "4     NaN\n",
       "5     NaN\n",
       "       ..\n",
       "163   NaN\n",
       "164   NaN\n",
       "186   NaN\n",
       "187   NaN\n",
       "191   NaN\n",
       "Name: Continued medication 1/stopped/changed, Length: 148, dtype: float64"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Continued medication 1/stopped/changed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "185e2e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...  Axis 4_3_Keywords               Axis 5_Keywords  \\\n",
      "1    ...              [nan]                         [nan]   \n",
      "2    ...              [nan]  [death, nephew, month, back]   \n",
      "3    ...              [nil]                         [nan]   \n",
      "4    ...              [nil]       [permissive, parenting]   \n",
      "5    ...              [nil]                         [nil]   \n",
      "..   ...                ...                           ...   \n",
      "163  ...              [nil]                         [nil]   \n",
      "164  ...              [nil]                         [nil]   \n",
      "186  ...              [nil]                         [nil]   \n",
      "187  ...              [nil]                         [nil]   \n",
      "191  ...              [nil]                         [nil]   \n",
      "\n",
      "                                    Combined_Axis_Text  \\\n",
      "1    Nil Nil Nil Nil Nil Nil seizure disorder nan n...   \n",
      "2    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "3    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "4    ADHD Nil Nil Nil motor coordination disorder M...   \n",
      "5    Nil Nil Nil Nil Nil nan seizure disorder Nil N...   \n",
      "..                                                 ...   \n",
      "163  ADHD Nil Nil Nil Nil Severe IDD/GDD seizure di...   \n",
      "164  Psychosis NOS Nil Nil Nil Nil IDD Nil Nil Nil Nil   \n",
      "186  BPAD in Mania with psycotic symptoms Nil Nil N...   \n",
      "187  Depressive Disorder Nil Nil Nil Nil Average IQ...   \n",
      "191  ADHD Nil Nil Nil Nil Mild IDD/GDD Seizure Diso...   \n",
      "\n",
      "                                Combined_Axis_Keywords  seizure  adhd  \\\n",
      "1    [nil, nil, nil, nil, nil, nil, seizure, disord...        1     0   \n",
      "2    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "3    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "4    [adhd, nil, nil, nil, motor, coordination, dis...        0     1   \n",
      "5    [nil, nil, nil, nil, nil, nan, seizure, disord...        1     0   \n",
      "..                                                 ...      ...   ...   \n",
      "163  [adhd, nil, nil, nil, nil, severe, seizure, di...        1     1   \n",
      "164  [psychosis, nos, nil, nil, nil, nil, idd, nil,...        0     0   \n",
      "186  [bpad, mania, psycotic, symptoms, nil, nil, ni...        0     0   \n",
      "187  [depressive, disorder, nil, nil, nil, nil, ave...        0     0   \n",
      "191  [adhd, nil, nil, nil, nil, mild, seizure, diso...        1     1   \n",
      "\n",
      "     depression1  Continued medication 1/stopped/changed_scaled  \\\n",
      "1              0                                            NaN   \n",
      "2              0                                            NaN   \n",
      "3              0                                            NaN   \n",
      "4              0                                            NaN   \n",
      "5              0                                            NaN   \n",
      "..           ...                                            ...   \n",
      "163            0                                            NaN   \n",
      "164            0                                            NaN   \n",
      "186            0                                            NaN   \n",
      "187            1                                            NaN   \n",
      "191            0                                            NaN   \n",
      "\n",
      "     School Adjustment  \\\n",
      "1                 0.00   \n",
      "2                 0.66   \n",
      "3                 0.00   \n",
      "4                 1.00   \n",
      "5                 0.00   \n",
      "..                 ...   \n",
      "163               0.33   \n",
      "164               0.66   \n",
      "186               1.00   \n",
      "187               0.00   \n",
      "191               0.66   \n",
      "\n",
      "     If yes, after how many days from first presentation diagnosis changed (in days)  \n",
      "1                                                    0                                \n",
      "2                                                    0                                \n",
      "3                                                    0                                \n",
      "4                                                    0                                \n",
      "5                                                    0                                \n",
      "..                                                 ...                                \n",
      "163                                                  0                                \n",
      "164                                                220                                \n",
      "186                                                  0                                \n",
      "187                                                  0                                \n",
      "191                                                266                                \n",
      "\n",
      "[148 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Continued medication 1/stopped/changed' is the column in df2 that you want to drop\n",
    "column_name = 'Continued medication 1/stopped/changed'\n",
    "\n",
    "# Drop the specified column\n",
    "df2.drop(columns=[column_name], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "dcaa9a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['loss to follow-up', 'Continued', 'Changed d/t poor tolerance',\n",
       "       'Nil', 'Stopped', 'Reduced d/t resolution',\n",
       "       'Changed d/t non response', nan], dtype=object)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_loaded['Continued medication 1/stopped/changed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "8d6e73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'loss to follow-up' : 0.5,\n",
    "    'Continued' : 0.28 , \n",
    "    'Changed d/t poor tolerance' : 0.6,\n",
    "       'Nil' : 0.14, \n",
    "    'Stopped' : 0.8 , \n",
    "    'Reduced d/t resolution' : 0.9,\n",
    "       'Changed d/t non response' : 1, \n",
    "    np.nan : 0\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2_loaded['Continued medication 1/stopped/changed'] = df2_loaded['Continued medication 1/stopped/changed'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "69dba4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i in df2_loaded['Continued medication 1/stopped/changed'] :\n",
    "    li.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "f21b78b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      0.50\n",
      "2      0.50\n",
      "3      0.28\n",
      "4      0.50\n",
      "5      0.28\n",
      "       ... \n",
      "163    0.28\n",
      "164    0.50\n",
      "186    0.50\n",
      "187    0.80\n",
      "191    0.50\n",
      "Name: Continued medication 1/stopped/changed, Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'School Adjustment' is the column in df2 and values_to_insert is your list of values\n",
    "column_name = 'Continued medication 1/stopped/changed'\n",
    "values_to_insert = li  # Replace with your actual list of values\n",
    "\n",
    "# Check if the length of values_to_insert matches the number of rows in df2\n",
    "if len(values_to_insert) == len(df2):\n",
    "    df2[column_name] = values_to_insert\n",
    "    print(df2[column_name])\n",
    "else:\n",
    "    print(\"Length of values_to_insert does not match the number of rows in df2.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "69e3f1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['partial', 'good', 'Nil', nan, 'no', 'Good', 'Partial', 'No'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Response to medication 1 (Good/partial/no)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "c2a10b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'partial' : 0, \n",
    "    'good':0.33,\n",
    "    'Nil':0.66, \n",
    "    np.nan : 1, \n",
    "    'no':0.66, \n",
    "    'Good':0.33, \n",
    "    'Partial' : 0, \n",
    "    'No':0.66\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2['Response to medication 1 (Good/partial/no)'] = df2['Response to medication 1 (Good/partial/no)'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "147e856e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96, 0.9, nan, 0.3, 0.98, 1, 'NIL', 'x', 0.99, 0.97, 0.34, 0.26,\n",
       "       0.24, 0.29, 0.2, 0.61, 0.362, 0.829, 'Nil', 0.94, 0.95, 0.44, 0.16,\n",
       "       0.13, 0.54, 0.92, 0.52, 0.63, 0.69, 0.998, 0.56, 0.89, 0.87, 0.93,\n",
       "       0.42, 'X'], dtype=object)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) '].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "7bea3ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      0.96\n",
      "2      0.90\n",
      "3      0.00\n",
      "4      0.30\n",
      "5      0.98\n",
      "       ... \n",
      "163    1.00\n",
      "164    0.42\n",
      "186    1.00\n",
      "187    1.00\n",
      "191    0.00\n",
      "Name: Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) , Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming the specified column in df2\n",
    "column_name = 'Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) '\n",
    "\n",
    "# Replace 'np.nan', 'Nil', 'NIL', 'x', and 'X' with 0 in the specified column\n",
    "df2[column_name].replace([np.nan, 'Nil', 'NIL', 'x', 'X'], 0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "51060b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96 , 0.9  , 0.   , 0.3  , 0.98 , 1.   , 0.99 , 0.97 , 0.34 ,\n",
       "       0.26 , 0.24 , 0.29 , 0.2  , 0.61 , 0.362, 0.829, 0.94 , 0.95 ,\n",
       "       0.44 , 0.16 , 0.13 , 0.54 , 0.92 , 0.52 , 0.63 , 0.69 , 0.998,\n",
       "       0.56 , 0.89 , 0.87 , 0.93 , 0.42 ])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[column_name].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "18117d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...               Axis 5_Keywords  \\\n",
      "1    ...                         [nan]   \n",
      "2    ...  [death, nephew, month, back]   \n",
      "3    ...                         [nan]   \n",
      "4    ...       [permissive, parenting]   \n",
      "5    ...                         [nil]   \n",
      "..   ...                           ...   \n",
      "163  ...                         [nil]   \n",
      "164  ...                         [nil]   \n",
      "186  ...                         [nil]   \n",
      "187  ...                         [nil]   \n",
      "191  ...                         [nil]   \n",
      "\n",
      "                                    Combined_Axis_Text  \\\n",
      "1    Nil Nil Nil Nil Nil Nil seizure disorder nan n...   \n",
      "2    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "3    Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "4    ADHD Nil Nil Nil motor coordination disorder M...   \n",
      "5    Nil Nil Nil Nil Nil nan seizure disorder Nil N...   \n",
      "..                                                 ...   \n",
      "163  ADHD Nil Nil Nil Nil Severe IDD/GDD seizure di...   \n",
      "164  Psychosis NOS Nil Nil Nil Nil IDD Nil Nil Nil Nil   \n",
      "186  BPAD in Mania with psycotic symptoms Nil Nil N...   \n",
      "187  Depressive Disorder Nil Nil Nil Nil Average IQ...   \n",
      "191  ADHD Nil Nil Nil Nil Mild IDD/GDD Seizure Diso...   \n",
      "\n",
      "                                Combined_Axis_Keywords  seizure  adhd  \\\n",
      "1    [nil, nil, nil, nil, nil, nil, seizure, disord...        1     0   \n",
      "2    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "3    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "4    [adhd, nil, nil, nil, motor, coordination, dis...        0     1   \n",
      "5    [nil, nil, nil, nil, nil, nan, seizure, disord...        1     0   \n",
      "..                                                 ...      ...   ...   \n",
      "163  [adhd, nil, nil, nil, nil, severe, seizure, di...        1     1   \n",
      "164  [psychosis, nos, nil, nil, nil, nil, idd, nil,...        0     0   \n",
      "186  [bpad, mania, psycotic, symptoms, nil, nil, ni...        0     0   \n",
      "187  [depressive, disorder, nil, nil, nil, nil, ave...        0     0   \n",
      "191  [adhd, nil, nil, nil, nil, mild, seizure, diso...        1     1   \n",
      "\n",
      "     depression1  Continued medication 1/stopped/changed_scaled  \\\n",
      "1              0                                            NaN   \n",
      "2              0                                            NaN   \n",
      "3              0                                            NaN   \n",
      "4              0                                            NaN   \n",
      "5              0                                            NaN   \n",
      "..           ...                                            ...   \n",
      "163            0                                            NaN   \n",
      "164            0                                            NaN   \n",
      "186            0                                            NaN   \n",
      "187            1                                            NaN   \n",
      "191            0                                            NaN   \n",
      "\n",
      "     School Adjustment  \\\n",
      "1                 0.00   \n",
      "2                 0.66   \n",
      "3                 0.00   \n",
      "4                 1.00   \n",
      "5                 0.00   \n",
      "..                 ...   \n",
      "163               0.33   \n",
      "164               0.66   \n",
      "186               1.00   \n",
      "187               0.00   \n",
      "191               0.66   \n",
      "\n",
      "     If yes, after how many days from first presentation diagnosis changed (in days)  \\\n",
      "1                                                    0                                 \n",
      "2                                                    0                                 \n",
      "3                                                    0                                 \n",
      "4                                                    0                                 \n",
      "5                                                    0                                 \n",
      "..                                                 ...                                 \n",
      "163                                                  0                                 \n",
      "164                                                220                                 \n",
      "186                                                  0                                 \n",
      "187                                                  0                                 \n",
      "191                                                266                                 \n",
      "\n",
      "     Continued medication 1/stopped/changed  \n",
      "1                                      0.50  \n",
      "2                                      0.50  \n",
      "3                                      0.28  \n",
      "4                                      0.50  \n",
      "5                                      0.28  \n",
      "..                                      ...  \n",
      "163                                    0.28  \n",
      "164                                    0.50  \n",
      "186                                    0.50  \n",
      "187                                    0.80  \n",
      "191                                    0.50  \n",
      "\n",
      "[148 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'name of Medication 2' is the column in df2 that you want to drop\n",
    "column_name = 'name of Medication 2'\n",
    "\n",
    "# Drop the specified column\n",
    "df2.drop(columns=[column_name], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "a8bc4ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([240, 180, 2686, 'Nil', 1819, 1530, 60, 45, 'nil', 1590, 2280, 143,\n",
       "       30, 10, 1906, 1614, 840, 7, 446, 111, 100, 3030, 300, 546, 789, 90,\n",
       "       150, 524, 120, 720, 40, 27, 15, 757, 414, 179, 238, 76, 2349, 22,\n",
       "       451, 2380, 3, 746, 311, 660, 1406, 1067, 109, 1414, 3838, 735,\n",
       "       4598, 1118, 736, 600, 252, 0.13, 122, 774, 110, 301, nan, 89, 33,\n",
       "       389, 1207, 923, 960, 1044, 956, 14, 991, 331, 18, 1064, 151, 1086,\n",
       "       629, 4, 682, 1989, 50, 1565, 54, 296, 258, 123, 941, 846, 49, 2949,\n",
       "       1267, 198, 495, 648, 576, 70, 817, 1619], dtype=object)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Total duration of medication 2(in days) '].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "661663ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       240\n",
      "2       180\n",
      "3      2686\n",
      "4       Nil\n",
      "5      1819\n",
      "       ... \n",
      "163     648\n",
      "164     576\n",
      "186      70\n",
      "187     817\n",
      "191    1619\n",
      "Name: Total duration of medication 2(in days) , Length: 148, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'Total duration of medication 2(in days)' is the column in df2\n",
    "column_name = 'Total duration of medication 2(in days) '\n",
    "\n",
    "# Replace np.nan and 'nil' with 0 in the specified column\n",
    "df2[column_name].replace({np.nan: 0, 'nil': 0}, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "2149797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['loss to follow-up', 'Reduced d/t resolution', 'Continued', 'Nil',\n",
       "       'nil', 'stopped and restarted', 'Stopped',\n",
       "       'Changed d/t non response', 'Change due to financial reason', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Continued medication 2/stopped/changed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "d14fff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'loss to follow-up':0,\n",
    "    'Reduced d/t resolution':1,\n",
    "    'Continued':2, \n",
    "    'Nil':3,\n",
    "    'nil':3,\n",
    "    'stopped and restarted':4,\n",
    "    'Stopped':4,\n",
    "    'Changed d/t non response':5,\n",
    "    'Change due to financial reason':6,\n",
    "    np.nan : 7\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2['Continued medication 2/stopped/changed'] = df2['Continued medication 2/stopped/changed'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "0b31d7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Cluster_1_date    Date of screening         UHID  \\\n",
      "0             22.06.2020  2019-05-20 00:00:00  20190008847   \n",
      "1             22.06.2020  2019-09-24 00:00:00  20190016882   \n",
      "2             22.06.2020  2014-03-03 00:00:00  20170010718   \n",
      "3             22.06.2020  2020-06-18 00:00:00  20200006501   \n",
      "4             22.06.2020  2014-03-31 00:00:00  20170015662   \n",
      "..                   ...                  ...          ...   \n",
      "143  2022-08-26 00:00:00  2022-02-24 00:00:00  20220002660   \n",
      "144  2022-08-26 00:00:00  2022-05-05 00:00:00  20220006417   \n",
      "145  2021-08-28 00:00:00  2021-07-29 00:00:00  20210007196   \n",
      "146  2021-08-28 00:00:00  2020-06-24 00:00:00  20200006807   \n",
      "147  2021-08-28 00:00:00  2019-02-28 00:00:00  20190003397   \n",
      "\n",
      "                        Name  Age at presentation (in yrs)  \\\n",
      "0                Mampi Shill                           8.0   \n",
      "1             Salema Khatoon                          17.0   \n",
      "2              Jiarur Rahman                           7.0   \n",
      "3              Debashis Nath                          10.0   \n",
      "4             Rahima Khatoon                           8.0   \n",
      "..                       ...                           ...   \n",
      "143          Paragmoni Sarma                           7.0   \n",
      "144           Roshidul Islam                          16.0   \n",
      "145            Rakibul Islam                          15.0   \n",
      "146  Muzzamil Hoque Chordury                          15.0   \n",
      "147             Ronik Barman                           5.0   \n",
      "\n",
      "     Age at last follow up Sex (m/f)  Religion  \\\n",
      "0                     10.0    female     Islam   \n",
      "1                     18.0    female     Islam   \n",
      "2                     17.0      male     Islam   \n",
      "3                     10.0      male  Hinduism   \n",
      "4                     15.0    female     Islam   \n",
      "..                     ...       ...       ...   \n",
      "143                    9.0      male  Hinduism   \n",
      "144                   17.0      male     Islam   \n",
      "145                   15.0      male     Islam   \n",
      "146                   17.0      male     Islam   \n",
      "147                    8.0      male  Hinduism   \n",
      "\n",
      "    Education at presentation (Primary 1 to 5, High school 6-10, higher secondary 11 and 12)  \\\n",
      "0                                                  NaN                                         \n",
      "1                                              Primary                                         \n",
      "2                                                  NaN                                         \n",
      "3                                              primary                                         \n",
      "4                                  no formal education                                         \n",
      "..                                                 ...                                         \n",
      "143                                no formal education                                         \n",
      "144                                            primary                                         \n",
      "145                                        high school                                         \n",
      "146                                        high school                                         \n",
      "147                                            primary                                         \n",
      "\n",
      "    Max education attained  ... No of relapses/exacerbations  \\\n",
      "0                      NaN  ...                          6.0   \n",
      "1                  Primary  ...                          0.0   \n",
      "2                      NaN  ...                          6.0   \n",
      "3                  Primary  ...                          1.0   \n",
      "4      no formal education  ...                         33.0   \n",
      "..                     ...  ...                          ...   \n",
      "143    no formal education  ...                          0.0   \n",
      "144                primary  ...                          2.0   \n",
      "145            high school  ...                          1.0   \n",
      "146            high school  ...                          0.0   \n",
      "147                primary  ...                          0.0   \n",
      "\n",
      "    Off-medications duration (to add all such durations over follow-up in days)  \\\n",
      "0                                                 22.0                            \n",
      "1                                                 30.0                            \n",
      "2                                                 58.0                            \n",
      "3                                                 20.0                            \n",
      "4                                                 65.0                            \n",
      "..                                                 ...                            \n",
      "143                                                0.0                            \n",
      "144                                              330.0                            \n",
      "145                                              180.0                            \n",
      "146                                              120.0                            \n",
      "147                                                0.0                            \n",
      "\n",
      "    Compliant to medications (Poor/Satisfactory/Good) (if off medications period is less than 7 days then it is considered as compliant {Poor-loss to follow up, maximum relapses,medication possession ratio < 0.9; Satisfactory- medication possession ratio 0.9 - 0.95, minimal relapse; Good- no relapse, medication possession ratio < 0.95}  \\\n",
      "0                                         Satisfactory                                                                                                                                                                                                                                                                                              \n",
      "1                                                 Poor                                                                                                                                                                                                                                                                                              \n",
      "2                                                 Good                                                                                                                                                                                                                                                                                              \n",
      "3                                                 Good                                                                                                                                                                                                                                                                                              \n",
      "4                                         Satisfactory                                                                                                                                                                                                                                                                                              \n",
      "..                                                 ...                                                                                                                                                                                                                                                                                              \n",
      "143                                               Good                                                                                                                                                                                                                                                                                              \n",
      "144                                               Poor                                                                                                                                                                                                                                                                                              \n",
      "145                                               Poor                                                                                                                                                                                                                                                                                              \n",
      "146                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
      "147                                       Satisfactory                                                                                                                                                                                                                                                                                              \n",
      "\n",
      "     mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
      "0                                                 1.66                                     \n",
      "1                                                 1.78                                     \n",
      "2                                                  NaN                                     \n",
      "3                                                    1                                     \n",
      "4                                                  6.6                                     \n",
      "..                                                 ...                                     \n",
      "143                                                2.1                                     \n",
      "144                                                3.8                                     \n",
      "145                                                4.3                                     \n",
      "146                                               1.21                                     \n",
      "147                                               2.15                                     \n",
      "\n",
      "    maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
      "0                                                395.0                                  \n",
      "1                                                240.0                                  \n",
      "2                                                  NaN                                  \n",
      "3                                                 90.0                                  \n",
      "4                                                480.0                                  \n",
      "..                                                 ...                                  \n",
      "143                                              648.0                                  \n",
      "144                                              113.0                                  \n",
      "145                                              170.0                                  \n",
      "146                                              390.0                                  \n",
      "147                                             1619.0                                  \n",
      "\n",
      "    total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
      "0                                                626.0                                                   \n",
      "1                                                330.0                                                   \n",
      "2                                               1320.0                                                   \n",
      "3                                                 90.0                                                   \n",
      "4                                               3495.0                                                   \n",
      "..                                                 ...                                                   \n",
      "143                                              648.0                                                   \n",
      "144                                              576.0                                                   \n",
      "145                                              384.0                                                   \n",
      "146                                              875.0                                                   \n",
      "147                                             1619.0                                                   \n",
      "\n",
      "    frequency of follow up at lgb (to write down follow-up dates)  \\\n",
      "0    24-06-2019, 29-07-2019, 09-09-2019, 21-10-2019...              \n",
      "1       19-12-2019, 01-02-2020, 20-03-2020, 22-06-2020              \n",
      "2    31-03-2014, 29-04-2014, 29-05-2014, 04-07-2014...              \n",
      "3                                22-06-2020,30-09-2020              \n",
      "4    29-04-2014, 29-05-2014, 04-07-2014, 25-08-14, ...              \n",
      "..                                                 ...              \n",
      "143  28-03-22, 13-07-22, 26-08-22, 11-10-22, 15-05-...              \n",
      "144   08-06-22, 26-08-22, 19-12-22, 23-01-23, 02-11-23              \n",
      "145                 28-08-2021, 15-07-2022, 17-08-2022              \n",
      "146  29-06-2020, 21-08-2020, 30-08-2020, 31-10-2020...              \n",
      "147  16-05-2019, 14-08-2019, 03-02-2020, 06-02-2020...              \n",
      "\n",
      "    total number of follow up at LGBRIMH Final (ignore for now)  \\\n",
      "0                                     12                    NaN   \n",
      "1                                      4                    NaN   \n",
      "2                                     69                    NaN   \n",
      "3                                      2                    NaN   \n",
      "4                                     71                    NaN   \n",
      "..                                   ...                    ...   \n",
      "143                                   10                    NaN   \n",
      "144                                    5                    NaN   \n",
      "145                                    3                    NaN   \n",
      "146                                   24                    NaN   \n",
      "147                                   25                    NaN   \n",
      "\n",
      "    Number of In patient cares  \n",
      "0                            0  \n",
      "1                            0  \n",
      "2                            0  \n",
      "3                            1  \n",
      "4                            0  \n",
      "..                         ...  \n",
      "143                          0  \n",
      "144                          0  \n",
      "145                          0  \n",
      "146                          0  \n",
      "147                          0  \n",
      "\n",
      "[148 rows x 274 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df2_loaded = pd.read_excel('df2_n.xlsx')\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(df2_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "f27dbf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['loss to follow-up', 'Continued', 'Changed d/t poor tolerance',\n",
       "       'Nil', 'Stopped', 'Reduced d/t resolution',\n",
       "       'Changed d/t non response', nan], dtype=object)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_loaded['Continued medication 1/stopped/changed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "1d69ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'loss to follow-up' : 4,\n",
    "    'Continued' : 3 , \n",
    "    'Changed d/t poor tolerance' :5,\n",
    "       'Nil' : 2, \n",
    "    'Stopped' : 6 , \n",
    "    'Reduced d/t resolution' : 7,\n",
    "       'Changed d/t non response' : 1, \n",
    "    np.nan : 0\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2_loaded['Continued medication 1/stopped/changed'] = df2_loaded['Continued medication 1/stopped/changed'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "682fd447",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i in df2_loaded['Continued medication 1/stopped/changed'] :\n",
    "    li.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "12014fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      4\n",
      "2      4\n",
      "3      3\n",
      "4      4\n",
      "5      3\n",
      "      ..\n",
      "163    3\n",
      "164    4\n",
      "186    4\n",
      "187    6\n",
      "191    4\n",
      "Name: Continued medication 1/stopped/changed, Length: 148, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'School Adjustment' is the column in df2 and values_to_insert is your list of values\n",
    "column_name = 'Continued medication 1/stopped/changed'\n",
    "values_to_insert = li  # Replace with your actual list of values\n",
    "\n",
    "# Check if the length of values_to_insert matches the number of rows in df2\n",
    "if len(values_to_insert) == len(df2):\n",
    "    df2[column_name] = values_to_insert\n",
    "    print(df2[column_name])\n",
    "else:\n",
    "    print(\"Length of values_to_insert does not match the number of rows in df2.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "a9853181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df2 is your DataFrame\n",
    "# Specify the file path and name for the Excel file\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Display a message indicating the file has been created\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "0d8c17ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([240, 180, 2686, 'Nil', 1819, 1530, 60, 45, 0, 1590, 2280, 143, 30,\n",
       "       10, 1906, 1614, 840, 7, 446, 111, 100, 3030, 300, 546, 789, 90,\n",
       "       150, 524, 120, 720, 40, 27, 15, 757, 414, 179, 238, 76, 2349, 22,\n",
       "       451, 2380, 3, 746, 311, 660, 1406, 1067, 109, 1414, 3838, 735,\n",
       "       4598, 1118, 736, 600, 252, 0.13, 122, 774, 110, 301, 89, 33, 389,\n",
       "       1207, 923, 960, 1044, 956, 14, 991, 331, 18, 1064, 151, 1086, 629,\n",
       "       4, 682, 1989, 50, 1565, 54, 296, 258, 123, 941, 846, 49, 2949,\n",
       "       1267, 198, 495, 648, 576, 70, 817, 1619], dtype=object)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Total duration of medication 2(in days) '].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "1bb9e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Total duration of medication 2(in days) '].replace({np.nan: 0, 'Nil': 0}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "41865284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['good', 'partial', 'nil', 'Nil', nan, 'no', 'Good', 'Partial',\n",
       "       'No'], dtype=object)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Response to medication 2 (Good/partial/no)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "c01fb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'good':3, 'partial':2, 'nil' : 1, 'Nil':1, np.nan:0, 'no':1, 'Good':3, 'Partial':2,\n",
    "       'No':1\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2['Response to medication 2 (Good/partial/no)'] = df2['Response to medication 2 (Good/partial/no)'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "f1f43e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96, 0.9, nan, 'Nil', 0.98, 1, 0.94, 0.47, 0.82, 0.99, 0.26, 0.93,\n",
       "       0.97, 0.33, 0.29, 0.17, 'x', 0.55, 0.95, 0.92, 0.44, 0.61, 0.72,\n",
       "       0.5, 0.91, 0.64, 0.84, 0.998, 0.83, 0.22, 0.42, 0.85], dtype=object)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Medication possession ratios 2(MPRs) in lgb;x-syrup'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "234780f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      0.96\n",
      "2       0.9\n",
      "3         0\n",
      "4         0\n",
      "5      0.98\n",
      "       ... \n",
      "163       x\n",
      "164    0.42\n",
      "186       1\n",
      "187    0.85\n",
      "191       1\n",
      "Name: Medication possession ratios 2(MPRs) in lgb;x-syrup, Length: 148, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'Total duration of medication 2(in days)' is the column in df2\n",
    "column_name = 'Medication possession ratios 2(MPRs) in lgb;x-syrup'\n",
    "\n",
    "# Replace np.nan and 'nil' with 0 in the specified column\n",
    "df2[column_name].replace({np.nan: 0, 'Nil': 0}, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "3c29ff6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Free', 'Both Free and Purchased', 'Purchased', 'Nil'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['cost of medication'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "8184ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'School adjustment' is a column in df2\n",
    "school_adjustment_mapping = {\n",
    "    'Free':0.33, 'Both Free and Purchased':0.66, 'Purchased':1, 'Nil':0\n",
    "}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "df2['cost of medication'] = df2['cost of medication'].map(school_adjustment_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "02082b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([390, 270, 570, 60, 480, 1770, 1460, 180, 1470, 30, 15, 900, nan,\n",
       "       780, 1290, 365, 'Nil', 0, 1065, 1020, 1095, 1539, 330, 540, 930,\n",
       "       81, 293, 300, 1530, 829, 90, 28, 150, 690, 56, 467, 466, 400, 134,\n",
       "       288, 234, 120, 40, 105, 386, 375, 236, 292, 2255, 210, 677, 1424,\n",
       "       451, 4340, 529, 453, 363, 1019, 133, 316, 135, 532, 650, 534, 803,\n",
       "       1092, 1361, 202, 2397, 557, 660, 502, 500, 700, 91, 170, 76, 239,\n",
       "       219, 100, 10, 422, 1817, 1177, 163, 84, 304, 311, 648, 228, 530,\n",
       "       205], dtype=object)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Maximum duration of symptom free period (in days)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "a4757f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Maximum duration of symptom free period (in days)'].replace({np.nan: 0, 'Nil': 0}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "4b21ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Max Duration of resolution of symptoms before recurrence/relapse (in days)'].replace({np.nan: 0, 'Nil': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "2ad77a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['No of relapses/exacerbations'].replace({np.nan: 0, 'Nil': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "d4a5cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Off-medications duration (to add all such durations over follow-up in days)'].replace({np.nan: 0, 'Nil': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "38ac121b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.66, 1.78, nan, 1, 6.6, 1.36, 1.28, 6, 2.25, 3, 9, 0.13, 1.24,\n",
       "       2.08, 3.3, 1.39, 1.02, 1.46, 1.9, 3.32, 1.77, 1.49, 0.71, 2.9, 1.7,\n",
       "       6.5, 1.63, 2, 3.8, 1.3, 2.54, 13.62, 5.66, 4, 2.5, 0.8, 0.74, 0.03,\n",
       "       1.69, 2.64, 6.11, 1.08, 1.06, 6.55, 1.95, 0.39, 1.31, 0.36, 1.05,\n",
       "       1.59, 32.03, 1.11, 4.151, 1.29, 1.52, 558, 3.03, 10.9, 1.17, 1.98,\n",
       "       1.83, 2.23, 2.1, 1.33, 5.8, 1.4, 3.04, 2.89, 0.82, 'so', 2.72, 1.5,\n",
       "       2.16, 3.01, 3.57, 1.38, 1.22, 1.94, 2.06, 0.5, 5, 3.16, 1.67, 4.12,\n",
       "       2.2, 0.3, 4.43, 1.26, 1.18, 3.86, 1.41, 0.93, 1.6, 1.32, 1.8, 1.12,\n",
       "       1.71, 2.26, 5.94, 2.17, 2.11, 0.64, 4.3, 1.21, 2.15], dtype=object)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "e0378b24",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [453], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m({np\u001b[38;5;241m.\u001b[39mnan: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNil\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mso\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "df2['mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)'].unique().replace({np.nan: 0, 'Nil': 0,'so':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "0e56aa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      1.66\n",
      "2      1.78\n",
      "3      0.00\n",
      "4      1.00\n",
      "5      6.60\n",
      "       ... \n",
      "163    2.10\n",
      "164    3.80\n",
      "186    4.30\n",
      "187    1.21\n",
      "191    2.15\n",
      "Name: mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups), Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)' is the column in df2\n",
    "column_name = 'mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)'\n",
    "\n",
    "# Replace np.nan, 'Nil', and 'so' with 0 in the specified column\n",
    "df2[column_name].replace({np.nan: 0, 'Nil': 0, 'so': 0}, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "c1a69d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['maximum period of compliance at lgb (in days) (longest streak of good compliance)'].replace({np.nan: 0, 'Nil': 0, 'so': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "da7c94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)'].replace({np.nan: 0, 'Nil': 0, 'so': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "6053f250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...  depressed                                 Combined_Axis_Text  \\\n",
      "1    ...          0  Nil Nil Nil Nil Nil Nil seizure disorder nan n...   \n",
      "2    ...          0  Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "3    ...          0  Nil Nil Nil Nil Nil Moderate IDD/GDD seizure d...   \n",
      "4    ...          0  ADHD Nil Nil Nil motor coordination disorder M...   \n",
      "5    ...          0  Nil Nil Nil Nil Nil nan seizure disorder Nil N...   \n",
      "..   ...        ...                                                ...   \n",
      "163  ...          0  ADHD Nil Nil Nil Nil Severe IDD/GDD seizure di...   \n",
      "164  ...          0  Psychosis NOS Nil Nil Nil Nil IDD Nil Nil Nil Nil   \n",
      "186  ...          0  BPAD in Mania with psycotic symptoms Nil Nil N...   \n",
      "187  ...          0  Depressive Disorder Nil Nil Nil Nil Average IQ...   \n",
      "191  ...          0  ADHD Nil Nil Nil Nil Mild IDD/GDD Seizure Diso...   \n",
      "\n",
      "                                Combined_Axis_Keywords  seizure  adhd  \\\n",
      "1    [nil, nil, nil, nil, nil, nil, seizure, disord...        1     0   \n",
      "2    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "3    [nil, nil, nil, nil, nil, moderate, seizure, d...        1     0   \n",
      "4    [adhd, nil, nil, nil, motor, coordination, dis...        0     1   \n",
      "5    [nil, nil, nil, nil, nil, nan, seizure, disord...        1     0   \n",
      "..                                                 ...      ...   ...   \n",
      "163  [adhd, nil, nil, nil, nil, severe, seizure, di...        1     1   \n",
      "164  [psychosis, nos, nil, nil, nil, nil, idd, nil,...        0     0   \n",
      "186  [bpad, mania, psycotic, symptoms, nil, nil, ni...        0     0   \n",
      "187  [depressive, disorder, nil, nil, nil, nil, ave...        0     0   \n",
      "191  [adhd, nil, nil, nil, nil, mild, seizure, diso...        1     1   \n",
      "\n",
      "     depression1  Continued medication 1/stopped/changed_scaled  \\\n",
      "1              0                                            NaN   \n",
      "2              0                                            NaN   \n",
      "3              0                                            NaN   \n",
      "4              0                                            NaN   \n",
      "5              0                                            NaN   \n",
      "..           ...                                            ...   \n",
      "163            0                                            NaN   \n",
      "164            0                                            NaN   \n",
      "186            0                                            NaN   \n",
      "187            1                                            NaN   \n",
      "191            0                                            NaN   \n",
      "\n",
      "     School Adjustment  \\\n",
      "1                 0.00   \n",
      "2                 0.66   \n",
      "3                 0.00   \n",
      "4                 1.00   \n",
      "5                 0.00   \n",
      "..                 ...   \n",
      "163               0.33   \n",
      "164               0.66   \n",
      "186               1.00   \n",
      "187               0.00   \n",
      "191               0.66   \n",
      "\n",
      "     If yes, after how many days from first presentation diagnosis changed (in days)  \\\n",
      "1                                                    0                                 \n",
      "2                                                    0                                 \n",
      "3                                                    0                                 \n",
      "4                                                    0                                 \n",
      "5                                                    0                                 \n",
      "..                                                 ...                                 \n",
      "163                                                  0                                 \n",
      "164                                                220                                 \n",
      "186                                                  0                                 \n",
      "187                                                  0                                 \n",
      "191                                                266                                 \n",
      "\n",
      "     Continued medication 1/stopped/changed  \n",
      "1                                         4  \n",
      "2                                         4  \n",
      "3                                         3  \n",
      "4                                         4  \n",
      "5                                         3  \n",
      "..                                      ...  \n",
      "163                                       3  \n",
      "164                                       4  \n",
      "186                                       4  \n",
      "187                                       6  \n",
      "191                                       4  \n",
      "\n",
      "[148 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['Keywords', 'Axis 1_1_Keywords', 'Axis 1_2_Keywords', 'Axis 1_3_Keywords', 'Axis 1_4_Keywords', 'Axis 2_Keywords', 'Axis 3_Keywords', 'Axis 4_1_Keywords', 'Axis 4_2_Keywords', 'Axis 4_3_Keywords', 'Axis 5_Keywords']\n",
    "\n",
    "# Drop the specified columns\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "ff42e5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...  anxious  hallucination  depressed  seizure  adhd  depression1  \\\n",
      "1    ...        0              0          0        1     0            0   \n",
      "2    ...        0              0          0        1     0            0   \n",
      "3    ...        0              0          0        1     0            0   \n",
      "4    ...        0              0          0        0     1            0   \n",
      "5    ...        0              0          0        1     0            0   \n",
      "..   ...      ...            ...        ...      ...   ...          ...   \n",
      "163  ...        0              0          0        1     1            0   \n",
      "164  ...        0              0          0        0     0            0   \n",
      "186  ...        0              0          0        0     0            0   \n",
      "187  ...        1              0          0        0     0            1   \n",
      "191  ...        0              0          0        1     1            0   \n",
      "\n",
      "     Continued medication 1/stopped/changed_scaled  School Adjustment  \\\n",
      "1                                              NaN               0.00   \n",
      "2                                              NaN               0.66   \n",
      "3                                              NaN               0.00   \n",
      "4                                              NaN               1.00   \n",
      "5                                              NaN               0.00   \n",
      "..                                             ...                ...   \n",
      "163                                            NaN               0.33   \n",
      "164                                            NaN               0.66   \n",
      "186                                            NaN               1.00   \n",
      "187                                            NaN               0.00   \n",
      "191                                            NaN               0.66   \n",
      "\n",
      "     If yes, after how many days from first presentation diagnosis changed (in days)  \\\n",
      "1                                                    0                                 \n",
      "2                                                    0                                 \n",
      "3                                                    0                                 \n",
      "4                                                    0                                 \n",
      "5                                                    0                                 \n",
      "..                                                 ...                                 \n",
      "163                                                  0                                 \n",
      "164                                                220                                 \n",
      "186                                                  0                                 \n",
      "187                                                  0                                 \n",
      "191                                                266                                 \n",
      "\n",
      "     Continued medication 1/stopped/changed  \n",
      "1                                         4  \n",
      "2                                         4  \n",
      "3                                         3  \n",
      "4                                         4  \n",
      "5                                         3  \n",
      "..                                      ...  \n",
      "163                                       3  \n",
      "164                                       4  \n",
      "186                                       4  \n",
      "187                                       6  \n",
      "191                                       4  \n",
      "\n",
      "[148 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['Combined_Axis_Text','Combined_Axis_Keywords']\n",
    "\n",
    "# Drop the specified columns\n",
    "df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "3c4e4713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df2 is your DataFrame\n",
    "# Specify the file path and name for the Excel file\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Display a message indicating the file has been created\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "9acc3d85",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Continued medication 1/stopped/changed_scaled '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Continued medication 1/stopped/changed_scaled '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [461], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf2_loaded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mContinued medication 1/stopped/changed_scaled \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Continued medication 1/stopped/changed_scaled '"
     ]
    }
   ],
   "source": [
    "df2_loaded['Continued medication 1/stopped/changed_scaled ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "2957b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
      "1                             8.0                   10.0        0.0  0.000000   \n",
      "2                            17.0                   18.0        0.0  0.000000   \n",
      "3                             7.0                   17.0        1.0  0.000000   \n",
      "4                            10.0                   10.0        1.0  0.333333   \n",
      "5                             8.0                   15.0        0.0  0.000000   \n",
      "..                            ...                    ...        ...       ...   \n",
      "163                           7.0                    9.0        1.0  0.333333   \n",
      "164                          16.0                   17.0        1.0  0.000000   \n",
      "186                          15.0                   15.0        1.0  0.000000   \n",
      "187                          15.0                   17.0        1.0  0.000000   \n",
      "191                           5.0                    8.0        1.0  0.333333   \n",
      "\n",
      "     Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
      "1                       0.0          0.5                           62.0   \n",
      "2                       0.4          0.5                           55.0   \n",
      "3                       0.0          0.5                          102.0   \n",
      "4                       0.4          0.5                           29.0   \n",
      "5                       0.0          0.5                          102.0   \n",
      "..                      ...          ...                            ...   \n",
      "163                     0.0          0.5                           57.0   \n",
      "164                     0.4          0.5                          110.0   \n",
      "186                     0.6          0.5                          326.0   \n",
      "187                     0.6          0.5                           37.0   \n",
      "191                     0.4          0.5                           63.0   \n",
      "\n",
      "     Socioeconomic status  Age at onset(in years)  \\\n",
      "1                    0.00                     8.0   \n",
      "2                    0.00                    17.0   \n",
      "3                    0.00                     5.5   \n",
      "4                    0.33                     0.0   \n",
      "5                    0.33                     5.5   \n",
      "..                    ...                     ...   \n",
      "163                  0.00                     0.0   \n",
      "164                  0.33                    16.0   \n",
      "186                  0.00                    15.0   \n",
      "187                  0.00                    15.0   \n",
      "191                  0.00                     4.0   \n",
      "\n",
      "     Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
      "1                                                150.0                            \n",
      "2                                                  3.0                            \n",
      "3                                                  0.0                            \n",
      "4                                                 10.0                            \n",
      "5                                                912.0                            \n",
      "..                                                 ...                            \n",
      "163                                             2555.0                            \n",
      "164                                               20.0                            \n",
      "186                                               75.0                            \n",
      "187                                              180.0                            \n",
      "191                                              540.0                            \n",
      "\n",
      "     ...  restless  anxious  hallucination  depressed  seizure  adhd  \\\n",
      "1    ...         0        0              0          0        1     0   \n",
      "2    ...         0        0              0          0        1     0   \n",
      "3    ...         0        0              0          0        1     0   \n",
      "4    ...         0        0              0          0        0     1   \n",
      "5    ...         0        0              0          0        1     0   \n",
      "..   ...       ...      ...            ...        ...      ...   ...   \n",
      "163  ...         1        0              0          0        1     1   \n",
      "164  ...         0        0              0          0        0     0   \n",
      "186  ...         0        0              0          0        0     0   \n",
      "187  ...         0        1              0          0        0     0   \n",
      "191  ...         0        0              0          0        1     1   \n",
      "\n",
      "     depression1  School Adjustment  \\\n",
      "1              0               0.00   \n",
      "2              0               0.66   \n",
      "3              0               0.00   \n",
      "4              0               1.00   \n",
      "5              0               0.00   \n",
      "..           ...                ...   \n",
      "163            0               0.33   \n",
      "164            0               0.66   \n",
      "186            0               1.00   \n",
      "187            1               0.00   \n",
      "191            0               0.66   \n",
      "\n",
      "     If yes, after how many days from first presentation diagnosis changed (in days)  \\\n",
      "1                                                    0                                 \n",
      "2                                                    0                                 \n",
      "3                                                    0                                 \n",
      "4                                                    0                                 \n",
      "5                                                    0                                 \n",
      "..                                                 ...                                 \n",
      "163                                                  0                                 \n",
      "164                                                220                                 \n",
      "186                                                  0                                 \n",
      "187                                                  0                                 \n",
      "191                                                266                                 \n",
      "\n",
      "     Continued medication 1/stopped/changed  \n",
      "1                                         4  \n",
      "2                                         4  \n",
      "3                                         3  \n",
      "4                                         4  \n",
      "5                                         3  \n",
      "..                                      ...  \n",
      "163                                       3  \n",
      "164                                       4  \n",
      "186                                       4  \n",
      "187                                       6  \n",
      "191                                       4  \n",
      "\n",
      "[148 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Continued medication 1/stopped/changed_scaled' is the column in df2\n",
    "column_to_drop = 'Continued medication 1/stopped/changed_scaled'\n",
    "\n",
    "# Drop the specified column\n",
    "df2.drop(columns=[column_to_drop], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "b954a63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values:\n",
      "Index(['Distance from LGBRIMH (in KM)', 'Time period between onset to first consultation at LGBRIMH (DUI) (in days)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with NaN values\n",
    "columns_with_nan = df2.columns[df2.isnull().any()]\n",
    "\n",
    "# Display the columns with NaN values\n",
    "print(\"Columns with NaN values:\")\n",
    "print(columns_with_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "da7fa5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       62.0\n",
       "2       55.0\n",
       "3      102.0\n",
       "4       29.0\n",
       "5      102.0\n",
       "       ...  \n",
       "163     57.0\n",
       "164    110.0\n",
       "186    326.0\n",
       "187     37.0\n",
       "191     63.0\n",
       "Name: Distance from LGBRIMH (in KM), Length: 148, dtype: float64"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Distance from LGBRIMH (in KM)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "e619bbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       62.0\n",
      "2       55.0\n",
      "3      102.0\n",
      "4       29.0\n",
      "5      102.0\n",
      "       ...  \n",
      "163     57.0\n",
      "164    110.0\n",
      "186    326.0\n",
      "187     37.0\n",
      "191     63.0\n",
      "Name: Distance from LGBRIMH (in KM), Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'Distance from LGBRIMH (in KM)' is the column in df2\n",
    "column_name = 'Distance from LGBRIMH (in KM)'\n",
    "\n",
    "# Replace NaN with 0 in the specified column\n",
    "df2[column_name].replace(np.nan, 0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "a87ee214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       150.0\n",
      "2         3.0\n",
      "3         0.0\n",
      "4        10.0\n",
      "5       912.0\n",
      "        ...  \n",
      "163    2555.0\n",
      "164      20.0\n",
      "186      75.0\n",
      "187     180.0\n",
      "191     540.0\n",
      "Name: Time period between onset to first consultation at LGBRIMH (DUI) (in days), Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'Distance from LGBRIMH (in KM)' is the column in df2\n",
    "column_name = 'Time period between onset to first consultation at LGBRIMH (DUI) (in days)'\n",
    "\n",
    "\n",
    "# Replace NaN with 0 in the specified column\n",
    "df2[column_name].replace(np.nan, 0, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "f2661eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values:\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with NaN values\n",
    "columns_with_nan = df2.columns[df2.isnull().any()]\n",
    "\n",
    "# Display the columns with NaN values\n",
    "print(\"Columns with NaN values:\")\n",
    "print(columns_with_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "f7fa1f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 148 entries, 1 to 191\n",
      "Data columns (total 62 columns):\n",
      " #   Column                                                                                                                                                                                                             Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                                                                                                             --------------  -----  \n",
      " 0   Age at presentation (in yrs)                                                                                                                                                                                       148 non-null    float64\n",
      " 1   Age at last follow up                                                                                                                                                                                              148 non-null    float64\n",
      " 2   Sex (m/f)                                                                                                                                                                                                          148 non-null    float64\n",
      " 3   Religion                                                                                                                                                                                                           148 non-null    float64\n",
      " 4   Max education attained                                                                                                                                                                                             148 non-null    float64\n",
      " 5   Rural/Urban                                                                                                                                                                                                        148 non-null    float64\n",
      " 6   Distance from LGBRIMH (in KM)                                                                                                                                                                                      148 non-null    float64\n",
      " 7   Socioeconomic status                                                                                                                                                                                               148 non-null    float64\n",
      " 8   Age at onset(in years)                                                                                                                                                                                             148 non-null    float64\n",
      " 9   Time period between onset to first consultation at LGBRIMH (DUI) (in days)                                                                                                                                         148 non-null    float64\n",
      " 10  Type of Family (Nuclear/Joint/single parent/orphan/ foster family                                                                                                                                                  148 non-null    float64\n",
      " 11  Family environment                                                                                                                                                                                                 148 non-null    float64\n",
      " 12  Academic performance                                                                                                                                                                                               148 non-null    float64\n",
      " 13  Change in doctor                                                                                                                                                                                                   148 non-null    float64\n",
      " 14  Past/Current medical conditions                                                                                                                                                                                    148 non-null    float64\n",
      " 15  weight (in Kg)                                                                                                                                                                                                     148 non-null    float64\n",
      " 16  systemic examination(abnormal/normal)                                                                                                                                                                              148 non-null    float64\n",
      " 17  Mental status examination/Behavioral Observation details (abnormal/normal)                                                                                                                                         148 non-null    float64\n",
      " 18  Follow up diagnosis changed or not (yes/no)                                                                                                                                                                        148 non-null    float64\n",
      " 19  significant psychosocial stressor                                                                                                                                                                                  148 non-null    float64\n",
      " 20  Avg dose of medication 1 (Mode value of medication) (in mg)                                                                                                                                                        148 non-null    float64\n",
      " 21  Maximum dose of medication 1 (in mg)                                                                                                                                                                               148 non-null    float64\n",
      " 22  Total duration of medication 1 (in days)                                                                                                                                                                           148 non-null    float64\n",
      " 23  Response to medication 1 (Good/partial/no)                                                                                                                                                                         148 non-null    float64\n",
      " 24  Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period)   148 non-null    float64\n",
      " 25  Total duration of medication 2(in days)                                                                                                                                                                            148 non-null    float64\n",
      " 26  Continued medication 2/stopped/changed                                                                                                                                                                             148 non-null    int64  \n",
      " 27  Response to medication 2 (Good/partial/no)                                                                                                                                                                         148 non-null    int64  \n",
      " 28  Medication possession ratios 2(MPRs) in lgb;x-syrup                                                                                                                                                                148 non-null    object \n",
      " 29  cost of medication                                                                                                                                                                                                 148 non-null    float64\n",
      " 30  Maximum duration of symptom free period (in days)                                                                                                                                                                  148 non-null    int64  \n",
      " 31  Max Duration of resolution of symptoms before recurrence/relapse (in days)                                                                                                                                         148 non-null    int64  \n",
      " 32  No of relapses/exacerbations                                                                                                                                                                                       148 non-null    float64\n",
      " 33  Off-medications duration (to add all such durations over follow-up in days)                                                                                                                                        148 non-null    int64  \n",
      " 34  Final                                                                                                                                                                                                              148 non-null    float64\n",
      " 35  mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)                                                                                                                                148 non-null    float64\n",
      " 36  maximum period of compliance at lgb (in days) (longest streak of good compliance)                                                                                                                                  148 non-null    float64\n",
      " 37  total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)                                                                                                                 148 non-null    int64  \n",
      " 38  total number of follow up at LGBRIMH                                                                                                                                                                               148 non-null    float64\n",
      " 39  Number of In patient cares                                                                                                                                                                                         148 non-null    float64\n",
      " 40  total_frequency                                                                                                                                                                                                    148 non-null    float64\n",
      " 41  total_days1                                                                                                                                                                                                        148 non-null    int64  \n",
      " 42  days/freq                                                                                                                                                                                                          148 non-null    float64\n",
      " 43  irritable                                                                                                                                                                                                          148 non-null    int64  \n",
      " 44  angry                                                                                                                                                                                                              148 non-null    int64  \n",
      " 45  abnormal                                                                                                                                                                                                           148 non-null    int64  \n",
      " 46  restlessness                                                                                                                                                                                                       148 non-null    int64  \n",
      " 47  jerky                                                                                                                                                                                                              148 non-null    int64  \n",
      " 48  low                                                                                                                                                                                                                148 non-null    int64  \n",
      " 49  outbursts                                                                                                                                                                                                          148 non-null    int64  \n",
      " 50  eye contact                                                                                                                                                                                                        148 non-null    int64  \n",
      " 51  poor                                                                                                                                                                                                               148 non-null    int64  \n",
      " 52  restless                                                                                                                                                                                                           148 non-null    int64  \n",
      " 53  anxious                                                                                                                                                                                                            148 non-null    int64  \n",
      " 54  hallucination                                                                                                                                                                                                      148 non-null    int64  \n",
      " 55  depressed                                                                                                                                                                                                          148 non-null    int64  \n",
      " 56  seizure                                                                                                                                                                                                            148 non-null    int64  \n",
      " 57  adhd                                                                                                                                                                                                               148 non-null    int64  \n",
      " 58  depression1                                                                                                                                                                                                        148 non-null    int64  \n",
      " 59  School Adjustment                                                                                                                                                                                                  148 non-null    float64\n",
      " 60  If yes, after how many days from first presentation diagnosis changed (in days)                                                                                                                                    148 non-null    object \n",
      " 61  Continued medication 1/stopped/changed                                                                                                                                                                             148 non-null    int64  \n",
      "dtypes: float64(36), int64(24), object(2)\n",
      "memory usage: 76.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "b7eb72d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      0.96\n",
      "2      0.90\n",
      "3      0.00\n",
      "4      0.00\n",
      "5      0.98\n",
      "       ... \n",
      "163    0.00\n",
      "164    0.42\n",
      "186    1.00\n",
      "187    0.85\n",
      "191    1.00\n",
      "Name: Medication possession ratios 2(MPRs) in lgb;x-syrup, Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "column_name = 'Medication possession ratios 2(MPRs) in lgb;x-syrup'\n",
    "\n",
    "df2[column_name] = df2[column_name].replace('x', 0)\n",
    "\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "3b95e0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "5        0\n",
      "      ... \n",
      "163      0\n",
      "164    220\n",
      "186      0\n",
      "187      0\n",
      "191    266\n",
      "Name: If yes, after how many days from first presentation diagnosis changed (in days), Length: 148, dtype: object\n"
     ]
    }
   ],
   "source": [
    "column_name = 'If yes, after how many days from first presentation diagnosis changed (in days)'\n",
    "\n",
    "df2[column_name].replace('Nil', 0, inplace=True)\n",
    "\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "b27cd0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 148 entries, 1 to 191\n",
      "Data columns (total 62 columns):\n",
      " #   Column                                                                                                                                                                                                             Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                                                                                                             --------------  -----  \n",
      " 0   Age at presentation (in yrs)                                                                                                                                                                                       148 non-null    float64\n",
      " 1   Age at last follow up                                                                                                                                                                                              148 non-null    float64\n",
      " 2   Sex (m/f)                                                                                                                                                                                                          148 non-null    float64\n",
      " 3   Religion                                                                                                                                                                                                           148 non-null    float64\n",
      " 4   Max education attained                                                                                                                                                                                             148 non-null    float64\n",
      " 5   Rural/Urban                                                                                                                                                                                                        148 non-null    float64\n",
      " 6   Distance from LGBRIMH (in KM)                                                                                                                                                                                      148 non-null    float64\n",
      " 7   Socioeconomic status                                                                                                                                                                                               148 non-null    float64\n",
      " 8   Age at onset(in years)                                                                                                                                                                                             148 non-null    float64\n",
      " 9   Time period between onset to first consultation at LGBRIMH (DUI) (in days)                                                                                                                                         148 non-null    float64\n",
      " 10  Type of Family (Nuclear/Joint/single parent/orphan/ foster family                                                                                                                                                  148 non-null    float64\n",
      " 11  Family environment                                                                                                                                                                                                 148 non-null    float64\n",
      " 12  Academic performance                                                                                                                                                                                               148 non-null    float64\n",
      " 13  Change in doctor                                                                                                                                                                                                   148 non-null    float64\n",
      " 14  Past/Current medical conditions                                                                                                                                                                                    148 non-null    float64\n",
      " 15  weight (in Kg)                                                                                                                                                                                                     148 non-null    float64\n",
      " 16  systemic examination(abnormal/normal)                                                                                                                                                                              148 non-null    float64\n",
      " 17  Mental status examination/Behavioral Observation details (abnormal/normal)                                                                                                                                         148 non-null    float64\n",
      " 18  Follow up diagnosis changed or not (yes/no)                                                                                                                                                                        148 non-null    float64\n",
      " 19  significant psychosocial stressor                                                                                                                                                                                  148 non-null    float64\n",
      " 20  Avg dose of medication 1 (Mode value of medication) (in mg)                                                                                                                                                        148 non-null    float64\n",
      " 21  Maximum dose of medication 1 (in mg)                                                                                                                                                                               148 non-null    float64\n",
      " 22  Total duration of medication 1 (in days)                                                                                                                                                                           148 non-null    float64\n",
      " 23  Response to medication 1 (Good/partial/no)                                                                                                                                                                         148 non-null    float64\n",
      " 24  Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period)   148 non-null    float64\n",
      " 25  Total duration of medication 2(in days)                                                                                                                                                                            148 non-null    float64\n",
      " 26  Continued medication 2/stopped/changed                                                                                                                                                                             148 non-null    int64  \n",
      " 27  Response to medication 2 (Good/partial/no)                                                                                                                                                                         148 non-null    int64  \n",
      " 28  Medication possession ratios 2(MPRs) in lgb;x-syrup                                                                                                                                                                148 non-null    float64\n",
      " 29  cost of medication                                                                                                                                                                                                 148 non-null    float64\n",
      " 30  Maximum duration of symptom free period (in days)                                                                                                                                                                  148 non-null    int64  \n",
      " 31  Max Duration of resolution of symptoms before recurrence/relapse (in days)                                                                                                                                         148 non-null    int64  \n",
      " 32  No of relapses/exacerbations                                                                                                                                                                                       148 non-null    float64\n",
      " 33  Off-medications duration (to add all such durations over follow-up in days)                                                                                                                                        148 non-null    int64  \n",
      " 34  Final                                                                                                                                                                                                              148 non-null    float64\n",
      " 35  mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)                                                                                                                                148 non-null    float64\n",
      " 36  maximum period of compliance at lgb (in days) (longest streak of good compliance)                                                                                                                                  148 non-null    float64\n",
      " 37  total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)                                                                                                                 148 non-null    int64  \n",
      " 38  total number of follow up at LGBRIMH                                                                                                                                                                               148 non-null    float64\n",
      " 39  Number of In patient cares                                                                                                                                                                                         148 non-null    float64\n",
      " 40  total_frequency                                                                                                                                                                                                    148 non-null    float64\n",
      " 41  total_days1                                                                                                                                                                                                        148 non-null    int64  \n",
      " 42  days/freq                                                                                                                                                                                                          148 non-null    float64\n",
      " 43  irritable                                                                                                                                                                                                          148 non-null    int64  \n",
      " 44  angry                                                                                                                                                                                                              148 non-null    int64  \n",
      " 45  abnormal                                                                                                                                                                                                           148 non-null    int64  \n",
      " 46  restlessness                                                                                                                                                                                                       148 non-null    int64  \n",
      " 47  jerky                                                                                                                                                                                                              148 non-null    int64  \n",
      " 48  low                                                                                                                                                                                                                148 non-null    int64  \n",
      " 49  outbursts                                                                                                                                                                                                          148 non-null    int64  \n",
      " 50  eye contact                                                                                                                                                                                                        148 non-null    int64  \n",
      " 51  poor                                                                                                                                                                                                               148 non-null    int64  \n",
      " 52  restless                                                                                                                                                                                                           148 non-null    int64  \n",
      " 53  anxious                                                                                                                                                                                                            148 non-null    int64  \n",
      " 54  hallucination                                                                                                                                                                                                      148 non-null    int64  \n",
      " 55  depressed                                                                                                                                                                                                          148 non-null    int64  \n",
      " 56  seizure                                                                                                                                                                                                            148 non-null    int64  \n",
      " 57  adhd                                                                                                                                                                                                               148 non-null    int64  \n",
      " 58  depression1                                                                                                                                                                                                        148 non-null    int64  \n",
      " 59  School Adjustment                                                                                                                                                                                                  148 non-null    float64\n",
      " 60  If yes, after how many days from first presentation diagnosis changed (in days)                                                                                                                                    148 non-null    object \n",
      " 61  Continued medication 1/stopped/changed                                                                                                                                                                             148 non-null    int64  \n",
      "dtypes: float64(37), int64(24), object(1)\n",
      "memory usage: 76.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "9a7470e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 365, 180, 720, 30, 1590, 1050, 1465, 1440, 409, 72, 163, 787,\n",
       "       280, 1752, 4518, 35, 523, 820, 480, 3453, 707, 5090, 299, 555, 141,\n",
       "       'NIl', 230, 43, 405, 425, 561, 4, 610, 788, 200, 14, 113, 668,\n",
       "       1774, 965, 1345, 2932, 235, 34, 218, 673, 220, 266], dtype=object)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['If yes, after how many days from first presentation diagnosis changed (in days)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "a949e717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "5        0\n",
      "      ... \n",
      "163      0\n",
      "164    220\n",
      "186      0\n",
      "187      0\n",
      "191    266\n",
      "Name: If yes, after how many days from first presentation diagnosis changed (in days), Length: 148, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_name = 'If yes, after how many days from first presentation diagnosis changed (in days)'\n",
    "\n",
    "df2[column_name].replace('NIl', 0, inplace=True)\n",
    "\n",
    "print(df2[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "d56e0cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 148 entries, 1 to 191\n",
      "Data columns (total 62 columns):\n",
      " #   Column                                                                                                                                                                                                             Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                                                                                                             --------------  -----  \n",
      " 0   Age at presentation (in yrs)                                                                                                                                                                                       148 non-null    float64\n",
      " 1   Age at last follow up                                                                                                                                                                                              148 non-null    float64\n",
      " 2   Sex (m/f)                                                                                                                                                                                                          148 non-null    float64\n",
      " 3   Religion                                                                                                                                                                                                           148 non-null    float64\n",
      " 4   Max education attained                                                                                                                                                                                             148 non-null    float64\n",
      " 5   Rural/Urban                                                                                                                                                                                                        148 non-null    float64\n",
      " 6   Distance from LGBRIMH (in KM)                                                                                                                                                                                      148 non-null    float64\n",
      " 7   Socioeconomic status                                                                                                                                                                                               148 non-null    float64\n",
      " 8   Age at onset(in years)                                                                                                                                                                                             148 non-null    float64\n",
      " 9   Time period between onset to first consultation at LGBRIMH (DUI) (in days)                                                                                                                                         148 non-null    float64\n",
      " 10  Type of Family (Nuclear/Joint/single parent/orphan/ foster family                                                                                                                                                  148 non-null    float64\n",
      " 11  Family environment                                                                                                                                                                                                 148 non-null    float64\n",
      " 12  Academic performance                                                                                                                                                                                               148 non-null    float64\n",
      " 13  Change in doctor                                                                                                                                                                                                   148 non-null    float64\n",
      " 14  Past/Current medical conditions                                                                                                                                                                                    148 non-null    float64\n",
      " 15  weight (in Kg)                                                                                                                                                                                                     148 non-null    float64\n",
      " 16  systemic examination(abnormal/normal)                                                                                                                                                                              148 non-null    float64\n",
      " 17  Mental status examination/Behavioral Observation details (abnormal/normal)                                                                                                                                         148 non-null    float64\n",
      " 18  Follow up diagnosis changed or not (yes/no)                                                                                                                                                                        148 non-null    float64\n",
      " 19  significant psychosocial stressor                                                                                                                                                                                  148 non-null    float64\n",
      " 20  Avg dose of medication 1 (Mode value of medication) (in mg)                                                                                                                                                        148 non-null    float64\n",
      " 21  Maximum dose of medication 1 (in mg)                                                                                                                                                                               148 non-null    float64\n",
      " 22  Total duration of medication 1 (in days)                                                                                                                                                                           148 non-null    float64\n",
      " 23  Response to medication 1 (Good/partial/no)                                                                                                                                                                         148 non-null    float64\n",
      " 24  Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period)   148 non-null    float64\n",
      " 25  Total duration of medication 2(in days)                                                                                                                                                                            148 non-null    float64\n",
      " 26  Continued medication 2/stopped/changed                                                                                                                                                                             148 non-null    int64  \n",
      " 27  Response to medication 2 (Good/partial/no)                                                                                                                                                                         148 non-null    int64  \n",
      " 28  Medication possession ratios 2(MPRs) in lgb;x-syrup                                                                                                                                                                148 non-null    float64\n",
      " 29  cost of medication                                                                                                                                                                                                 148 non-null    float64\n",
      " 30  Maximum duration of symptom free period (in days)                                                                                                                                                                  148 non-null    int64  \n",
      " 31  Max Duration of resolution of symptoms before recurrence/relapse (in days)                                                                                                                                         148 non-null    int64  \n",
      " 32  No of relapses/exacerbations                                                                                                                                                                                       148 non-null    float64\n",
      " 33  Off-medications duration (to add all such durations over follow-up in days)                                                                                                                                        148 non-null    int64  \n",
      " 34  Final                                                                                                                                                                                                              148 non-null    float64\n",
      " 35  mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)                                                                                                                                148 non-null    float64\n",
      " 36  maximum period of compliance at lgb (in days) (longest streak of good compliance)                                                                                                                                  148 non-null    float64\n",
      " 37  total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)                                                                                                                 148 non-null    int64  \n",
      " 38  total number of follow up at LGBRIMH                                                                                                                                                                               148 non-null    float64\n",
      " 39  Number of In patient cares                                                                                                                                                                                         148 non-null    float64\n",
      " 40  total_frequency                                                                                                                                                                                                    148 non-null    float64\n",
      " 41  total_days1                                                                                                                                                                                                        148 non-null    int64  \n",
      " 42  days/freq                                                                                                                                                                                                          148 non-null    float64\n",
      " 43  irritable                                                                                                                                                                                                          148 non-null    int64  \n",
      " 44  angry                                                                                                                                                                                                              148 non-null    int64  \n",
      " 45  abnormal                                                                                                                                                                                                           148 non-null    int64  \n",
      " 46  restlessness                                                                                                                                                                                                       148 non-null    int64  \n",
      " 47  jerky                                                                                                                                                                                                              148 non-null    int64  \n",
      " 48  low                                                                                                                                                                                                                148 non-null    int64  \n",
      " 49  outbursts                                                                                                                                                                                                          148 non-null    int64  \n",
      " 50  eye contact                                                                                                                                                                                                        148 non-null    int64  \n",
      " 51  poor                                                                                                                                                                                                               148 non-null    int64  \n",
      " 52  restless                                                                                                                                                                                                           148 non-null    int64  \n",
      " 53  anxious                                                                                                                                                                                                            148 non-null    int64  \n",
      " 54  hallucination                                                                                                                                                                                                      148 non-null    int64  \n",
      " 55  depressed                                                                                                                                                                                                          148 non-null    int64  \n",
      " 56  seizure                                                                                                                                                                                                            148 non-null    int64  \n",
      " 57  adhd                                                                                                                                                                                                               148 non-null    int64  \n",
      " 58  depression1                                                                                                                                                                                                        148 non-null    int64  \n",
      " 59  School Adjustment                                                                                                                                                                                                  148 non-null    float64\n",
      " 60  If yes, after how many days from first presentation diagnosis changed (in days)                                                                                                                                    148 non-null    int64  \n",
      " 61  Continued medication 1/stopped/changed                                                                                                                                                                             148 non-null    int64  \n",
      "dtypes: float64(37), int64(25)\n",
      "memory usage: 76.9 KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "bb892b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "0ec20049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "1af328d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['Final'] = df3['Final']*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "1e5dd739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age at presentation (in yrs)                                                      -0.090322\n",
      "Age at last follow up                                                              0.006969\n",
      "Sex (m/f)                                                                         -0.071062\n",
      "Religion                                                                           0.049126\n",
      "Max education attained                                                             0.049811\n",
      "                                                                                     ...   \n",
      "adhd                                                                               0.083695\n",
      "depression1                                                                        0.149854\n",
      "School Adjustment                                                                  0.130494\n",
      "If yes, after how many days from first presentation diagnosis changed (in days)   -0.000714\n",
      "Continued medication 1/stopped/changed                                            -0.088775\n",
      "Name: Final, Length: 62, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df3' is your DataFrame\n",
    "# Drop rows with NaN values in the target column\n",
    "df3.dropna(subset=['Final'], inplace=True)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df3.corr()\n",
    "\n",
    "# Extract the correlation of each column with 'Final'\n",
    "correlation_with_final = correlation_matrix['Final']\n",
    "\n",
    "# Display the correlation values\n",
    "print(correlation_with_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "3fb5ceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final: +1.0000\n",
      "maximum period of compliance at lgb (in days) (longest streak of good compliance): +0.2917\n",
      "Maximum duration of symptom free period (in days): +0.2891\n",
      "total number of follow up at LGBRIMH: +0.2839\n",
      "total_frequency: +0.2769\n",
      "Max Duration of resolution of symptoms before recurrence/relapse (in days): +0.2761\n",
      "days/freq: -0.2361\n",
      "total duration of medication treatment at LGB(in days) (from first consultation to last follow-up): +0.2026\n",
      "Total duration of medication 1 (in days) : +0.1958\n",
      "Continued medication 2/stopped/changed: +0.1940\n",
      "depression1: +0.1499\n",
      "School Adjustment: +0.1305\n",
      "outbursts: -0.1187\n",
      "Total duration of medication 2(in days) : +0.1138\n",
      "Follow up diagnosis changed or not (yes/no): +0.1069\n",
      "Rural/Urban: +0.0998\n",
      "Type of Family (Nuclear/Joint/single parent/orphan/ foster family: +0.0951\n",
      "depressed: +0.0936\n",
      "Distance from LGBRIMH (in KM): -0.0908\n",
      "Age at onset(in years): -0.0907\n",
      "Age at presentation (in yrs): -0.0903\n",
      "Continued medication 1/stopped/changed: -0.0888\n",
      "low: +0.0855\n",
      "Off-medications duration (to add all such durations over follow-up in days): -0.0840\n",
      "adhd: +0.0837\n",
      "Number of In patient cares: +0.0825\n",
      "Past/Current medical conditions: +0.0821\n",
      "Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) : +0.0820\n",
      "mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups): +0.0797\n",
      "systemic examination(abnormal/normal): +0.0747\n",
      "Medication possession ratios 2(MPRs) in lgb;x-syrup: -0.0726\n",
      "total_days1: +0.0720\n",
      "Sex (m/f): -0.0711\n",
      "No of relapses/exacerbations: +0.0704\n",
      "Maximum dose of medication 1 (in mg): +0.0671\n",
      "irritable: +0.0638\n",
      "seizure: +0.0619\n",
      "hallucination: +0.0566\n",
      "Max education attained: +0.0498\n",
      "Religion: +0.0491\n",
      "restlessness: +0.0486\n",
      "Response to medication 2 (Good/partial/no): -0.0463\n",
      "Mental status examination/Behavioral Observation details (abnormal/normal): -0.0453\n",
      "Avg dose of medication 1 (Mode value of medication) (in mg): +0.0438\n",
      "significant psychosocial stressor: -0.0391\n",
      "Socioeconomic status: +0.0377\n",
      "cost of medication: +0.0351\n",
      "Family environment: -0.0341\n",
      "abnormal: +0.0318\n",
      "jerky: +0.0292\n",
      "weight (in Kg): +0.0261\n",
      "Response to medication 1 (Good/partial/no): +0.0238\n",
      "Academic performance: +0.0227\n",
      "Change in doctor: +0.0187\n",
      "Time period between onset to first consultation at LGBRIMH (DUI) (in days): +0.0160\n",
      "anxious: +0.0102\n",
      "angry: -0.0081\n",
      "eye contact: -0.0072\n",
      "Age at last follow up: +0.0070\n",
      "poor: -0.0046\n",
      "restless: +0.0015\n",
      "If yes, after how many days from first presentation diagnosis changed (in days): -0.0007\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df3' is your DataFrame\n",
    "# Drop rows with NaN values in the target column\n",
    "df3.dropna(subset=['Final'], inplace=True)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df3.corr()\n",
    "\n",
    "# Extract the correlation of each column with 'Final'\n",
    "correlation_with_final = correlation_matrix['Final']\n",
    "\n",
    "# Sort the columns based on the absolute correlation values\n",
    "sorted_correlation = correlation_with_final.abs().sort_values(ascending=False)\n",
    "\n",
    "# Display the columns and their corresponding correlation values with proper signs\n",
    "for column in sorted_correlation.index:\n",
    "    correlation_value = correlation_with_final.loc[column]\n",
    "    print(f\"{column}: {correlation_value:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "95b10931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df3' is your DataFrame\n",
    "# Drop rows with NaN values in the target column\n",
    "df3.dropna(subset=['Final'], inplace=True)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df3.corr()\n",
    "\n",
    "# Extract the correlation of each column with 'Final'\n",
    "correlation_with_final = correlation_matrix['Final']\n",
    "\n",
    "# Sort the columns based on the absolute correlation values\n",
    "sorted_correlation = correlation_with_final.abs().sort_values(ascending=False)\n",
    "\n",
    "# Create a DataFrame to store results\n",
    "result_df = pd.DataFrame({\n",
    "    'Sr. No.': range(1, len(sorted_correlation) + 1),\n",
    "    'Column Name': sorted_correlation.index,\n",
    "    'Correlation Score': correlation_with_final.loc[sorted_correlation.index].values\n",
    "})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "result_df.to_excel('correlation_results.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "6cfa3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['depression2'] = df2['depressed'] + df2['depression1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "86b5401d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'df2_data.xlsx' created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "excel_file_path = 'df2_data.xlsx'\n",
    "\n",
    "\n",
    "df2.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Excel file '{excel_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "8777cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df3.dropna(subset=['Final'], inplace=True)\n",
    "\n",
    "\n",
    "correlation_matrix = df3.corr()\n",
    "\n",
    "correlation_with_final = correlation_matrix['Final']\n",
    "\n",
    "\n",
    "sorted_correlation = correlation_with_final.abs().sort_values(ascending=False)\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'Sr. No.': range(1, len(sorted_correlation) + 1),\n",
    "    'Column Name': sorted_correlation.index,\n",
    "    'Correlation Score': correlation_with_final.loc[sorted_correlation.index].values\n",
    "})\n",
    "\n",
    "result_df.to_excel('correlation_results1.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "60217ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df2 = df2.drop(columns=['depression1', 'depressed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "775307a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = df2.drop(columns=['Final'])\n",
    "\n",
    "y = df2['Final']\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "rf_classifier.fit(X, y)\n",
    "\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "similarity_df = pd.DataFrame({'Column Name': X.columns, 'Value': feature_importances})\n",
    "\n",
    "similarity_df = similarity_df.sort_values(by='Value', ascending=False).reset_index(drop=True)\n",
    "\n",
    "similarity_df['Sr No.'] = similarity_df.index + 1\n",
    "\n",
    "similarity_df = similarity_df[['Sr No.', 'Column Name', 'Value']]\n",
    "\n",
    "similarity_df.to_excel('similarity.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "6db58e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X = df2.drop(columns=['Final'])\n",
    "\n",
    "y = df2['Final']\n",
    "\n",
    "mutual_info_scores = mutual_info_classif(X, y)\n",
    "\n",
    "mutual_info_df = pd.DataFrame({'Column Name': X.columns, 'Mutual Information Score': mutual_info_scores})\n",
    "\n",
    "mutual_info_df = mutual_info_df.sort_values(by='Mutual Information Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "mutual_info_df['Sr No.'] = mutual_info_df.index + 1\n",
    "\n",
    "mutual_info_df = mutual_info_df[['Sr No.', 'Column Name', 'Mutual Information Score']]\n",
    "\n",
    "mutual_info_df.to_excel('mutual_information_scores.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "dd9a5d80",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sr No.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sr No.'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [513], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(merged_df, correlation_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn Name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate average rank\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Rank\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSr No._similarity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSr No._mutual_info\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSr No.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Sort by average rank in ascending order\u001b[39;00m\n\u001b[0;32m     16\u001b[0m final_ranking_df \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Rank\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sr No.'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "similarity_df = pd.read_excel('similarity.xlsx')\n",
    "mutual_info_df = pd.read_excel('mutual_information_scores.xlsx')\n",
    "correlation_df = pd.read_excel('correlation_results1.xlsx')\n",
    "\n",
    "merged_df = pd.merge(similarity_df, mutual_info_df, on='Column Name', suffixes=('_similarity', '_mutual_info'))\n",
    "merged_df = pd.merge(merged_df, correlation_df, on='Column Name')\n",
    "\n",
    "merged_df['Average Rank'] = (merged_df['Sr No._similarity'] + merged_df['Sr No._mutual_info'] + merged_df['Sr No.']) / 3\n",
    "\n",
    "final_ranking_df = merged_df.sort_values(by='Average Rank').reset_index(drop=True)\n",
    "\n",
    "final_ranking_df = final_ranking_df[['Column Name', 'Average Rank']]\n",
    "\n",
    "final_ranking_df.to_excel('finalranking.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "51b3533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "similarity_df = pd.read_excel('similarity.xlsx')\n",
    "mutual_info_df = pd.read_excel('mutual_information_scores.xlsx')\n",
    "correlation_df = pd.read_excel('correlation_results1.xlsx')\n",
    "\n",
    "merged_df = pd.merge(similarity_df, mutual_info_df, on='Column Name', suffixes=('_similarity', '_mutual_info'))\n",
    "merged_df = pd.merge(merged_df, correlation_df, on='Column Name')\n",
    "\n",
    "merged_df['Average Rank'] = (merged_df.index + merged_df.index + merged_df.index) / 3\n",
    "\n",
    "final_ranking_df = merged_df.sort_values(by='Average Rank').reset_index(drop=True)\n",
    "\n",
    "final_ranking_df = final_ranking_df[['Column Name', 'Average Rank']]\n",
    "\n",
    "final_ranking_df.to_excel('finalranking.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "dd8fac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "similarity_df = pd.read_excel('similarity.xlsx')\n",
    "mutual_info_df = pd.read_excel('mutual_information_scores.xlsx')\n",
    "correlation_df = pd.read_excel('correlation_results1.xlsx')\n",
    "\n",
    "merged_df = pd.merge(similarity_df, mutual_info_df, on='Column Name', suffixes=('_similarity', '_mutual_info'))\n",
    "merged_df = pd.merge(merged_df, correlation_df, on='Column Name')\n",
    "\n",
    "merged_df.to_excel('merged_results.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "e7731511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No._similarity</th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Value</th>\n",
       "      <th>Sr No._mutual_info</th>\n",
       "      <th>Mutual Information Score</th>\n",
       "      <th>Sr. No.</th>\n",
       "      <th>Correlation Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Off-medications duration (to add all such dura...</td>\n",
       "      <td>0.056537</td>\n",
       "      <td>2</td>\n",
       "      <td>0.089496</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.084005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Maximum duration of symptom free period (in days)</td>\n",
       "      <td>0.051824</td>\n",
       "      <td>18</td>\n",
       "      <td>0.029481</td>\n",
       "      <td>3</td>\n",
       "      <td>0.289070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>total_frequency</td>\n",
       "      <td>0.045023</td>\n",
       "      <td>10</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>5</td>\n",
       "      <td>0.276919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>total number of follow up at LGBRIMH</td>\n",
       "      <td>0.042317</td>\n",
       "      <td>7</td>\n",
       "      <td>0.068447</td>\n",
       "      <td>4</td>\n",
       "      <td>0.283869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>maximum period of compliance at lgb (in days) ...</td>\n",
       "      <td>0.042182</td>\n",
       "      <td>4</td>\n",
       "      <td>0.081424</td>\n",
       "      <td>2</td>\n",
       "      <td>0.291744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>mean gap ratio at lgb (total no of months of f...</td>\n",
       "      <td>0.041425</td>\n",
       "      <td>5</td>\n",
       "      <td>0.072944</td>\n",
       "      <td>30</td>\n",
       "      <td>0.079685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>total duration of medication treatment at LGB(...</td>\n",
       "      <td>0.036004</td>\n",
       "      <td>12</td>\n",
       "      <td>0.054573</td>\n",
       "      <td>8</td>\n",
       "      <td>0.202563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>days/freq</td>\n",
       "      <td>0.035563</td>\n",
       "      <td>11</td>\n",
       "      <td>0.058237</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.236128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Medication possession ratios 1(MPRs) in lgb;x-...</td>\n",
       "      <td>0.033481</td>\n",
       "      <td>9</td>\n",
       "      <td>0.066494</td>\n",
       "      <td>29</td>\n",
       "      <td>0.082006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Max Duration of resolution of symptoms before ...</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.276085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Total duration of medication 2(in days)</td>\n",
       "      <td>0.030494</td>\n",
       "      <td>8</td>\n",
       "      <td>0.066954</td>\n",
       "      <td>15</td>\n",
       "      <td>0.113820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Age at presentation (in yrs)</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>25</td>\n",
       "      <td>0.019688</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.090322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Total duration of medication 1 (in days)</td>\n",
       "      <td>0.027204</td>\n",
       "      <td>29</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>9</td>\n",
       "      <td>0.195820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>total_days1</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>15</td>\n",
       "      <td>0.043786</td>\n",
       "      <td>33</td>\n",
       "      <td>0.072007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Maximum dose of medication 1 (in mg)</td>\n",
       "      <td>0.026263</td>\n",
       "      <td>31</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>36</td>\n",
       "      <td>0.067057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Time period between onset to first consultatio...</td>\n",
       "      <td>0.025792</td>\n",
       "      <td>24</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>56</td>\n",
       "      <td>0.015991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Continued medication 2/stopped/changed</td>\n",
       "      <td>0.025246</td>\n",
       "      <td>34</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>10</td>\n",
       "      <td>0.193964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>No of relapses/exacerbations</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>17</td>\n",
       "      <td>0.033168</td>\n",
       "      <td>35</td>\n",
       "      <td>0.070423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Distance from LGBRIMH (in KM)</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.090810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Age at last follow up</td>\n",
       "      <td>0.021446</td>\n",
       "      <td>6</td>\n",
       "      <td>0.068525</td>\n",
       "      <td>60</td>\n",
       "      <td>0.006969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>weight (in Kg)</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>21</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>52</td>\n",
       "      <td>0.026139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Age at onset(in years)</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>37</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.090728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Avg dose of medication 1 (Mode value of medica...</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45</td>\n",
       "      <td>0.043787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Medication possession ratios 2(MPRs) in lgb;x-...</td>\n",
       "      <td>0.019254</td>\n",
       "      <td>30</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.072624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Continued medication 1/stopped/changed</td>\n",
       "      <td>0.017281</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.088775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>School Adjustment</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>22</td>\n",
       "      <td>0.024658</td>\n",
       "      <td>13</td>\n",
       "      <td>0.130494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Response to medication 2 (Good/partial/no)</td>\n",
       "      <td>0.015436</td>\n",
       "      <td>35</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.046339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Family environment</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>16</td>\n",
       "      <td>0.036636</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.034065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>If yes, after how many days from first present...</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>26</td>\n",
       "      <td>0.019280</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Response to medication 1 (Good/partial/no)</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>14</td>\n",
       "      <td>0.049599</td>\n",
       "      <td>53</td>\n",
       "      <td>0.023813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Academic performance</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>0.022744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Max education attained</td>\n",
       "      <td>0.009767</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>0.049811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Mental status examination/Behavioral Observati...</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>33</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.045258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>systemic examination(abnormal/normal)</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>31</td>\n",
       "      <td>0.074685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>Type of Family (Nuclear/Joint/single parent/or...</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.095081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>jerky</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>27</td>\n",
       "      <td>0.017063</td>\n",
       "      <td>51</td>\n",
       "      <td>0.029180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>significant psychosocial stressor</td>\n",
       "      <td>0.006442</td>\n",
       "      <td>23</td>\n",
       "      <td>0.023740</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.039125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.031793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>Rural/Urban</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>28</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>17</td>\n",
       "      <td>0.099830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>Sex (m/f)</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.071062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>Socioeconomic status</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.037702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>cost of medication</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>0.035124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>Past/Current medical conditions</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>0.082140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>Religion</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.049126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>low</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.085507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>restless</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>32</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>irritable</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "      <td>0.063836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>seizure</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>0.061944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>poor</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61</td>\n",
       "      <td>-0.004646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>depression2</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.154245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>Change in doctor</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>3</td>\n",
       "      <td>0.084568</td>\n",
       "      <td>55</td>\n",
       "      <td>0.018691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>adhd</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>19</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>26</td>\n",
       "      <td>0.083695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>Number of In patient cares</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>36</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>27</td>\n",
       "      <td>0.082455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>restlessness</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.048583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>eye contact</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59</td>\n",
       "      <td>-0.007223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.008080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>Follow up diagnosis changed or not (yes/no)</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>20</td>\n",
       "      <td>0.027593</td>\n",
       "      <td>16</td>\n",
       "      <td>0.106881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>anxious</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103339</td>\n",
       "      <td>57</td>\n",
       "      <td>0.010158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>outbursts</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>13</td>\n",
       "      <td>0.050675</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.118693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>0.056554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sr No._similarity                                        Column Name  \\\n",
       "0                   1  Off-medications duration (to add all such dura...   \n",
       "1                   2  Maximum duration of symptom free period (in days)   \n",
       "2                   3                                    total_frequency   \n",
       "3                   4               total number of follow up at LGBRIMH   \n",
       "4                   5  maximum period of compliance at lgb (in days) ...   \n",
       "5                   6  mean gap ratio at lgb (total no of months of f...   \n",
       "6                   7  total duration of medication treatment at LGB(...   \n",
       "7                   8                                          days/freq   \n",
       "8                   9  Medication possession ratios 1(MPRs) in lgb;x-...   \n",
       "9                  10  Max Duration of resolution of symptoms before ...   \n",
       "10                 11           Total duration of medication 2(in days)    \n",
       "11                 12                       Age at presentation (in yrs)   \n",
       "12                 13          Total duration of medication 1 (in days)    \n",
       "13                 14                                        total_days1   \n",
       "14                 15               Maximum dose of medication 1 (in mg)   \n",
       "15                 16  Time period between onset to first consultatio...   \n",
       "16                 17             Continued medication 2/stopped/changed   \n",
       "17                 18                       No of relapses/exacerbations   \n",
       "18                 19                      Distance from LGBRIMH (in KM)   \n",
       "19                 20                              Age at last follow up   \n",
       "20                 21                                     weight (in Kg)   \n",
       "21                 22                             Age at onset(in years)   \n",
       "22                 23  Avg dose of medication 1 (Mode value of medica...   \n",
       "23                 24  Medication possession ratios 2(MPRs) in lgb;x-...   \n",
       "24                 25             Continued medication 1/stopped/changed   \n",
       "25                 26                                  School Adjustment   \n",
       "26                 27         Response to medication 2 (Good/partial/no)   \n",
       "27                 28                                 Family environment   \n",
       "28                 29  If yes, after how many days from first present...   \n",
       "29                 30         Response to medication 1 (Good/partial/no)   \n",
       "30                 31                               Academic performance   \n",
       "31                 32                             Max education attained   \n",
       "32                 33  Mental status examination/Behavioral Observati...   \n",
       "33                 34              systemic examination(abnormal/normal)   \n",
       "34                 35  Type of Family (Nuclear/Joint/single parent/or...   \n",
       "35                 36                                              jerky   \n",
       "36                 37                  significant psychosocial stressor   \n",
       "37                 38                                           abnormal   \n",
       "38                 39                                        Rural/Urban   \n",
       "39                 40                                          Sex (m/f)   \n",
       "40                 41                               Socioeconomic status   \n",
       "41                 42                                 cost of medication   \n",
       "42                 43                    Past/Current medical conditions   \n",
       "43                 44                                           Religion   \n",
       "44                 45                                                low   \n",
       "45                 46                                           restless   \n",
       "46                 47                                          irritable   \n",
       "47                 48                                            seizure   \n",
       "48                 49                                               poor   \n",
       "49                 50                                        depression2   \n",
       "50                 51                                   Change in doctor   \n",
       "51                 52                                               adhd   \n",
       "52                 53                         Number of In patient cares   \n",
       "53                 54                                       restlessness   \n",
       "54                 55                                        eye contact   \n",
       "55                 56                                              angry   \n",
       "56                 57        Follow up diagnosis changed or not (yes/no)   \n",
       "57                 58                                            anxious   \n",
       "58                 59                                          outbursts   \n",
       "59                 60                                      hallucination   \n",
       "\n",
       "       Value  Sr No._mutual_info  Mutual Information Score  Sr. No.  \\\n",
       "0   0.056537                   2                  0.089496       25   \n",
       "1   0.051824                  18                  0.029481        3   \n",
       "2   0.045023                  10                  0.061889        5   \n",
       "3   0.042317                   7                  0.068447        4   \n",
       "4   0.042182                   4                  0.081424        2   \n",
       "5   0.041425                   5                  0.072944       30   \n",
       "6   0.036004                  12                  0.054573        8   \n",
       "7   0.035563                  11                  0.058237        7   \n",
       "8   0.033481                   9                  0.066494       29   \n",
       "9   0.031562                  58                  0.000000        6   \n",
       "10  0.030494                   8                  0.066954       15   \n",
       "11  0.029349                  25                  0.019688       22   \n",
       "12  0.027204                  29                  0.015687        9   \n",
       "13  0.026826                  15                  0.043786       33   \n",
       "14  0.026263                  31                  0.009807       36   \n",
       "15  0.025792                  24                  0.020264       56   \n",
       "16  0.025246                  34                  0.004965       10   \n",
       "17  0.024583                  17                  0.033168       35   \n",
       "18  0.024215                  52                  0.000000       20   \n",
       "19  0.021446                   6                  0.068525       60   \n",
       "20  0.021375                  21                  0.025449       52   \n",
       "21  0.019907                  37                  0.001206       21   \n",
       "22  0.019759                  57                  0.000000       45   \n",
       "23  0.019254                  30                  0.010382       32   \n",
       "24  0.017281                  41                  0.000000       23   \n",
       "25  0.015758                  22                  0.024658       13   \n",
       "26  0.015436                  35                  0.003966       43   \n",
       "27  0.014977                  16                  0.036636       49   \n",
       "28  0.013829                  26                  0.019280       63   \n",
       "29  0.012964                  14                  0.049599       53   \n",
       "30  0.012228                  55                  0.000000       54   \n",
       "31  0.009767                  42                  0.000000       40   \n",
       "32  0.007691                  33                  0.005975       44   \n",
       "33  0.007265                  38                  0.000082       31   \n",
       "34  0.006717                  54                  0.000000       18   \n",
       "35  0.006489                  27                  0.017063       51   \n",
       "36  0.006442                  23                  0.023740       46   \n",
       "37  0.006365                  50                  0.000000       50   \n",
       "38  0.005909                  28                  0.016799       17   \n",
       "39  0.005870                  46                  0.000000       34   \n",
       "40  0.005787                  53                  0.000000       47   \n",
       "41  0.005619                  59                  0.000000       48   \n",
       "42  0.005595                  56                  0.000000       28   \n",
       "43  0.004949                  45                  0.000000       41   \n",
       "44  0.004857                  44                  0.000000       24   \n",
       "45  0.004771                  32                  0.006923       62   \n",
       "46  0.004382                  48                  0.000000       37   \n",
       "47  0.004197                  47                  0.000000       38   \n",
       "48  0.004063                  40                  0.000000       61   \n",
       "49  0.003991                  60                  0.000000       11   \n",
       "50  0.003817                   3                  0.084568       55   \n",
       "51  0.003714                  19                  0.028621       26   \n",
       "52  0.003239                  36                  0.003562       27   \n",
       "53  0.003070                  49                  0.000000       42   \n",
       "54  0.003043                  39                  0.000000       59   \n",
       "55  0.003038                  51                  0.000000       58   \n",
       "56  0.003031                  20                  0.027593       16   \n",
       "57  0.002747                   1                  0.103339       57   \n",
       "58  0.002204                  13                  0.050675       14   \n",
       "59  0.001268                  43                  0.000000       39   \n",
       "\n",
       "    Correlation Score  \n",
       "0           -0.084005  \n",
       "1            0.289070  \n",
       "2            0.276919  \n",
       "3            0.283869  \n",
       "4            0.291744  \n",
       "5            0.079685  \n",
       "6            0.202563  \n",
       "7           -0.236128  \n",
       "8            0.082006  \n",
       "9            0.276085  \n",
       "10           0.113820  \n",
       "11          -0.090322  \n",
       "12           0.195820  \n",
       "13           0.072007  \n",
       "14           0.067057  \n",
       "15           0.015991  \n",
       "16           0.193964  \n",
       "17           0.070423  \n",
       "18          -0.090810  \n",
       "19           0.006969  \n",
       "20           0.026139  \n",
       "21          -0.090728  \n",
       "22           0.043787  \n",
       "23          -0.072624  \n",
       "24          -0.088775  \n",
       "25           0.130494  \n",
       "26          -0.046339  \n",
       "27          -0.034065  \n",
       "28          -0.000714  \n",
       "29           0.023813  \n",
       "30           0.022744  \n",
       "31           0.049811  \n",
       "32          -0.045258  \n",
       "33           0.074685  \n",
       "34           0.095081  \n",
       "35           0.029180  \n",
       "36          -0.039125  \n",
       "37           0.031793  \n",
       "38           0.099830  \n",
       "39          -0.071062  \n",
       "40           0.037702  \n",
       "41           0.035124  \n",
       "42           0.082140  \n",
       "43           0.049126  \n",
       "44           0.085507  \n",
       "45           0.001452  \n",
       "46           0.063836  \n",
       "47           0.061944  \n",
       "48          -0.004646  \n",
       "49           0.154245  \n",
       "50           0.018691  \n",
       "51           0.083695  \n",
       "52           0.082455  \n",
       "53           0.048583  \n",
       "54          -0.007223  \n",
       "55          -0.008080  \n",
       "56           0.106881  \n",
       "57           0.010158  \n",
       "58          -0.118693  \n",
       "59           0.056554  "
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "76ec08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Average Rank'] = (merged_df['Sr No._similarity'] + merged_df['Sr No._mutual_info'] + merged_df['Sr. No.']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "9d55a213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No._similarity</th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Value</th>\n",
       "      <th>Sr No._mutual_info</th>\n",
       "      <th>Mutual Information Score</th>\n",
       "      <th>Sr. No.</th>\n",
       "      <th>Correlation Score</th>\n",
       "      <th>Average Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Off-medications duration (to add all such dura...</td>\n",
       "      <td>0.056537</td>\n",
       "      <td>2</td>\n",
       "      <td>0.089496</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.084005</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Maximum duration of symptom free period (in days)</td>\n",
       "      <td>0.051824</td>\n",
       "      <td>18</td>\n",
       "      <td>0.029481</td>\n",
       "      <td>3</td>\n",
       "      <td>0.289070</td>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>total_frequency</td>\n",
       "      <td>0.045023</td>\n",
       "      <td>10</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>5</td>\n",
       "      <td>0.276919</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>total number of follow up at LGBRIMH</td>\n",
       "      <td>0.042317</td>\n",
       "      <td>7</td>\n",
       "      <td>0.068447</td>\n",
       "      <td>4</td>\n",
       "      <td>0.283869</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>maximum period of compliance at lgb (in days) ...</td>\n",
       "      <td>0.042182</td>\n",
       "      <td>4</td>\n",
       "      <td>0.081424</td>\n",
       "      <td>2</td>\n",
       "      <td>0.291744</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>mean gap ratio at lgb (total no of months of f...</td>\n",
       "      <td>0.041425</td>\n",
       "      <td>5</td>\n",
       "      <td>0.072944</td>\n",
       "      <td>30</td>\n",
       "      <td>0.079685</td>\n",
       "      <td>13.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>total duration of medication treatment at LGB(...</td>\n",
       "      <td>0.036004</td>\n",
       "      <td>12</td>\n",
       "      <td>0.054573</td>\n",
       "      <td>8</td>\n",
       "      <td>0.202563</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>days/freq</td>\n",
       "      <td>0.035563</td>\n",
       "      <td>11</td>\n",
       "      <td>0.058237</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.236128</td>\n",
       "      <td>8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Medication possession ratios 1(MPRs) in lgb;x-...</td>\n",
       "      <td>0.033481</td>\n",
       "      <td>9</td>\n",
       "      <td>0.066494</td>\n",
       "      <td>29</td>\n",
       "      <td>0.082006</td>\n",
       "      <td>15.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Max Duration of resolution of symptoms before ...</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.276085</td>\n",
       "      <td>24.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Total duration of medication 2(in days)</td>\n",
       "      <td>0.030494</td>\n",
       "      <td>8</td>\n",
       "      <td>0.066954</td>\n",
       "      <td>15</td>\n",
       "      <td>0.113820</td>\n",
       "      <td>11.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Age at presentation (in yrs)</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>25</td>\n",
       "      <td>0.019688</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.090322</td>\n",
       "      <td>19.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Total duration of medication 1 (in days)</td>\n",
       "      <td>0.027204</td>\n",
       "      <td>29</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>9</td>\n",
       "      <td>0.195820</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>total_days1</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>15</td>\n",
       "      <td>0.043786</td>\n",
       "      <td>33</td>\n",
       "      <td>0.072007</td>\n",
       "      <td>20.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Maximum dose of medication 1 (in mg)</td>\n",
       "      <td>0.026263</td>\n",
       "      <td>31</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>36</td>\n",
       "      <td>0.067057</td>\n",
       "      <td>27.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Time period between onset to first consultatio...</td>\n",
       "      <td>0.025792</td>\n",
       "      <td>24</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>56</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Continued medication 2/stopped/changed</td>\n",
       "      <td>0.025246</td>\n",
       "      <td>34</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>10</td>\n",
       "      <td>0.193964</td>\n",
       "      <td>20.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>No of relapses/exacerbations</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>17</td>\n",
       "      <td>0.033168</td>\n",
       "      <td>35</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>23.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Distance from LGBRIMH (in KM)</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.090810</td>\n",
       "      <td>30.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Age at last follow up</td>\n",
       "      <td>0.021446</td>\n",
       "      <td>6</td>\n",
       "      <td>0.068525</td>\n",
       "      <td>60</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>28.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>weight (in Kg)</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>21</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>52</td>\n",
       "      <td>0.026139</td>\n",
       "      <td>31.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Age at onset(in years)</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>37</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.090728</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Avg dose of medication 1 (Mode value of medica...</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45</td>\n",
       "      <td>0.043787</td>\n",
       "      <td>41.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Medication possession ratios 2(MPRs) in lgb;x-...</td>\n",
       "      <td>0.019254</td>\n",
       "      <td>30</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.072624</td>\n",
       "      <td>28.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Continued medication 1/stopped/changed</td>\n",
       "      <td>0.017281</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.088775</td>\n",
       "      <td>29.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>School Adjustment</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>22</td>\n",
       "      <td>0.024658</td>\n",
       "      <td>13</td>\n",
       "      <td>0.130494</td>\n",
       "      <td>20.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Response to medication 2 (Good/partial/no)</td>\n",
       "      <td>0.015436</td>\n",
       "      <td>35</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.046339</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Family environment</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>16</td>\n",
       "      <td>0.036636</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.034065</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>If yes, after how many days from first present...</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>26</td>\n",
       "      <td>0.019280</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>39.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Response to medication 1 (Good/partial/no)</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>14</td>\n",
       "      <td>0.049599</td>\n",
       "      <td>53</td>\n",
       "      <td>0.023813</td>\n",
       "      <td>32.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Academic performance</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>0.022744</td>\n",
       "      <td>46.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Max education attained</td>\n",
       "      <td>0.009767</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>0.049811</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Mental status examination/Behavioral Observati...</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>33</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.045258</td>\n",
       "      <td>36.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>systemic examination(abnormal/normal)</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>31</td>\n",
       "      <td>0.074685</td>\n",
       "      <td>34.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>Type of Family (Nuclear/Joint/single parent/or...</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.095081</td>\n",
       "      <td>35.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>jerky</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>27</td>\n",
       "      <td>0.017063</td>\n",
       "      <td>51</td>\n",
       "      <td>0.029180</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>significant psychosocial stressor</td>\n",
       "      <td>0.006442</td>\n",
       "      <td>23</td>\n",
       "      <td>0.023740</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.039125</td>\n",
       "      <td>35.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.031793</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>Rural/Urban</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>28</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>17</td>\n",
       "      <td>0.099830</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>Sex (m/f)</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.071062</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>Socioeconomic status</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.037702</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>cost of medication</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>0.035124</td>\n",
       "      <td>49.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>Past/Current medical conditions</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>0.082140</td>\n",
       "      <td>42.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>Religion</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.049126</td>\n",
       "      <td>43.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>low</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.085507</td>\n",
       "      <td>37.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>restless</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>32</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>46.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>irritable</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "      <td>0.063836</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>seizure</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>0.061944</td>\n",
       "      <td>44.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>poor</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61</td>\n",
       "      <td>-0.004646</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>depression2</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.154245</td>\n",
       "      <td>40.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>Change in doctor</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>3</td>\n",
       "      <td>0.084568</td>\n",
       "      <td>55</td>\n",
       "      <td>0.018691</td>\n",
       "      <td>36.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>adhd</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>19</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>26</td>\n",
       "      <td>0.083695</td>\n",
       "      <td>32.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>Number of In patient cares</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>36</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>27</td>\n",
       "      <td>0.082455</td>\n",
       "      <td>38.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>restlessness</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.048583</td>\n",
       "      <td>48.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>eye contact</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59</td>\n",
       "      <td>-0.007223</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.008080</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>Follow up diagnosis changed or not (yes/no)</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>20</td>\n",
       "      <td>0.027593</td>\n",
       "      <td>16</td>\n",
       "      <td>0.106881</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>anxious</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103339</td>\n",
       "      <td>57</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>38.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>outbursts</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>13</td>\n",
       "      <td>0.050675</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.118693</td>\n",
       "      <td>28.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>0.056554</td>\n",
       "      <td>47.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sr No._similarity                                        Column Name  \\\n",
       "0                   1  Off-medications duration (to add all such dura...   \n",
       "1                   2  Maximum duration of symptom free period (in days)   \n",
       "2                   3                                    total_frequency   \n",
       "3                   4               total number of follow up at LGBRIMH   \n",
       "4                   5  maximum period of compliance at lgb (in days) ...   \n",
       "5                   6  mean gap ratio at lgb (total no of months of f...   \n",
       "6                   7  total duration of medication treatment at LGB(...   \n",
       "7                   8                                          days/freq   \n",
       "8                   9  Medication possession ratios 1(MPRs) in lgb;x-...   \n",
       "9                  10  Max Duration of resolution of symptoms before ...   \n",
       "10                 11           Total duration of medication 2(in days)    \n",
       "11                 12                       Age at presentation (in yrs)   \n",
       "12                 13          Total duration of medication 1 (in days)    \n",
       "13                 14                                        total_days1   \n",
       "14                 15               Maximum dose of medication 1 (in mg)   \n",
       "15                 16  Time period between onset to first consultatio...   \n",
       "16                 17             Continued medication 2/stopped/changed   \n",
       "17                 18                       No of relapses/exacerbations   \n",
       "18                 19                      Distance from LGBRIMH (in KM)   \n",
       "19                 20                              Age at last follow up   \n",
       "20                 21                                     weight (in Kg)   \n",
       "21                 22                             Age at onset(in years)   \n",
       "22                 23  Avg dose of medication 1 (Mode value of medica...   \n",
       "23                 24  Medication possession ratios 2(MPRs) in lgb;x-...   \n",
       "24                 25             Continued medication 1/stopped/changed   \n",
       "25                 26                                  School Adjustment   \n",
       "26                 27         Response to medication 2 (Good/partial/no)   \n",
       "27                 28                                 Family environment   \n",
       "28                 29  If yes, after how many days from first present...   \n",
       "29                 30         Response to medication 1 (Good/partial/no)   \n",
       "30                 31                               Academic performance   \n",
       "31                 32                             Max education attained   \n",
       "32                 33  Mental status examination/Behavioral Observati...   \n",
       "33                 34              systemic examination(abnormal/normal)   \n",
       "34                 35  Type of Family (Nuclear/Joint/single parent/or...   \n",
       "35                 36                                              jerky   \n",
       "36                 37                  significant psychosocial stressor   \n",
       "37                 38                                           abnormal   \n",
       "38                 39                                        Rural/Urban   \n",
       "39                 40                                          Sex (m/f)   \n",
       "40                 41                               Socioeconomic status   \n",
       "41                 42                                 cost of medication   \n",
       "42                 43                    Past/Current medical conditions   \n",
       "43                 44                                           Religion   \n",
       "44                 45                                                low   \n",
       "45                 46                                           restless   \n",
       "46                 47                                          irritable   \n",
       "47                 48                                            seizure   \n",
       "48                 49                                               poor   \n",
       "49                 50                                        depression2   \n",
       "50                 51                                   Change in doctor   \n",
       "51                 52                                               adhd   \n",
       "52                 53                         Number of In patient cares   \n",
       "53                 54                                       restlessness   \n",
       "54                 55                                        eye contact   \n",
       "55                 56                                              angry   \n",
       "56                 57        Follow up diagnosis changed or not (yes/no)   \n",
       "57                 58                                            anxious   \n",
       "58                 59                                          outbursts   \n",
       "59                 60                                      hallucination   \n",
       "\n",
       "       Value  Sr No._mutual_info  Mutual Information Score  Sr. No.  \\\n",
       "0   0.056537                   2                  0.089496       25   \n",
       "1   0.051824                  18                  0.029481        3   \n",
       "2   0.045023                  10                  0.061889        5   \n",
       "3   0.042317                   7                  0.068447        4   \n",
       "4   0.042182                   4                  0.081424        2   \n",
       "5   0.041425                   5                  0.072944       30   \n",
       "6   0.036004                  12                  0.054573        8   \n",
       "7   0.035563                  11                  0.058237        7   \n",
       "8   0.033481                   9                  0.066494       29   \n",
       "9   0.031562                  58                  0.000000        6   \n",
       "10  0.030494                   8                  0.066954       15   \n",
       "11  0.029349                  25                  0.019688       22   \n",
       "12  0.027204                  29                  0.015687        9   \n",
       "13  0.026826                  15                  0.043786       33   \n",
       "14  0.026263                  31                  0.009807       36   \n",
       "15  0.025792                  24                  0.020264       56   \n",
       "16  0.025246                  34                  0.004965       10   \n",
       "17  0.024583                  17                  0.033168       35   \n",
       "18  0.024215                  52                  0.000000       20   \n",
       "19  0.021446                   6                  0.068525       60   \n",
       "20  0.021375                  21                  0.025449       52   \n",
       "21  0.019907                  37                  0.001206       21   \n",
       "22  0.019759                  57                  0.000000       45   \n",
       "23  0.019254                  30                  0.010382       32   \n",
       "24  0.017281                  41                  0.000000       23   \n",
       "25  0.015758                  22                  0.024658       13   \n",
       "26  0.015436                  35                  0.003966       43   \n",
       "27  0.014977                  16                  0.036636       49   \n",
       "28  0.013829                  26                  0.019280       63   \n",
       "29  0.012964                  14                  0.049599       53   \n",
       "30  0.012228                  55                  0.000000       54   \n",
       "31  0.009767                  42                  0.000000       40   \n",
       "32  0.007691                  33                  0.005975       44   \n",
       "33  0.007265                  38                  0.000082       31   \n",
       "34  0.006717                  54                  0.000000       18   \n",
       "35  0.006489                  27                  0.017063       51   \n",
       "36  0.006442                  23                  0.023740       46   \n",
       "37  0.006365                  50                  0.000000       50   \n",
       "38  0.005909                  28                  0.016799       17   \n",
       "39  0.005870                  46                  0.000000       34   \n",
       "40  0.005787                  53                  0.000000       47   \n",
       "41  0.005619                  59                  0.000000       48   \n",
       "42  0.005595                  56                  0.000000       28   \n",
       "43  0.004949                  45                  0.000000       41   \n",
       "44  0.004857                  44                  0.000000       24   \n",
       "45  0.004771                  32                  0.006923       62   \n",
       "46  0.004382                  48                  0.000000       37   \n",
       "47  0.004197                  47                  0.000000       38   \n",
       "48  0.004063                  40                  0.000000       61   \n",
       "49  0.003991                  60                  0.000000       11   \n",
       "50  0.003817                   3                  0.084568       55   \n",
       "51  0.003714                  19                  0.028621       26   \n",
       "52  0.003239                  36                  0.003562       27   \n",
       "53  0.003070                  49                  0.000000       42   \n",
       "54  0.003043                  39                  0.000000       59   \n",
       "55  0.003038                  51                  0.000000       58   \n",
       "56  0.003031                  20                  0.027593       16   \n",
       "57  0.002747                   1                  0.103339       57   \n",
       "58  0.002204                  13                  0.050675       14   \n",
       "59  0.001268                  43                  0.000000       39   \n",
       "\n",
       "    Correlation Score  Average Rank  \n",
       "0           -0.084005      9.333333  \n",
       "1            0.289070      7.666667  \n",
       "2            0.276919      6.000000  \n",
       "3            0.283869      5.000000  \n",
       "4            0.291744      3.666667  \n",
       "5            0.079685     13.666667  \n",
       "6            0.202563      9.000000  \n",
       "7           -0.236128      8.666667  \n",
       "8            0.082006     15.666667  \n",
       "9            0.276085     24.666667  \n",
       "10           0.113820     11.333333  \n",
       "11          -0.090322     19.666667  \n",
       "12           0.195820     17.000000  \n",
       "13           0.072007     20.666667  \n",
       "14           0.067057     27.333333  \n",
       "15           0.015991     32.000000  \n",
       "16           0.193964     20.333333  \n",
       "17           0.070423     23.333333  \n",
       "18          -0.090810     30.333333  \n",
       "19           0.006969     28.666667  \n",
       "20           0.026139     31.333333  \n",
       "21          -0.090728     26.666667  \n",
       "22           0.043787     41.666667  \n",
       "23          -0.072624     28.666667  \n",
       "24          -0.088775     29.666667  \n",
       "25           0.130494     20.333333  \n",
       "26          -0.046339     35.000000  \n",
       "27          -0.034065     31.000000  \n",
       "28          -0.000714     39.333333  \n",
       "29           0.023813     32.333333  \n",
       "30           0.022744     46.666667  \n",
       "31           0.049811     38.000000  \n",
       "32          -0.045258     36.666667  \n",
       "33           0.074685     34.333333  \n",
       "34           0.095081     35.666667  \n",
       "35           0.029180     38.000000  \n",
       "36          -0.039125     35.333333  \n",
       "37           0.031793     46.000000  \n",
       "38           0.099830     28.000000  \n",
       "39          -0.071062     40.000000  \n",
       "40           0.037702     47.000000  \n",
       "41           0.035124     49.666667  \n",
       "42           0.082140     42.333333  \n",
       "43           0.049126     43.333333  \n",
       "44           0.085507     37.666667  \n",
       "45           0.001452     46.666667  \n",
       "46           0.063836     44.000000  \n",
       "47           0.061944     44.333333  \n",
       "48          -0.004646     50.000000  \n",
       "49           0.154245     40.333333  \n",
       "50           0.018691     36.333333  \n",
       "51           0.083695     32.333333  \n",
       "52           0.082455     38.666667  \n",
       "53           0.048583     48.333333  \n",
       "54          -0.007223     51.000000  \n",
       "55          -0.008080     55.000000  \n",
       "56           0.106881     31.000000  \n",
       "57           0.010158     38.666667  \n",
       "58          -0.118693     28.666667  \n",
       "59           0.056554     47.333333  "
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "86f437e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sorted_df = merged_df.sort_values(by='Average Rank')\n",
    "\n",
    "# Save sorted DataFrame to Excel\n",
    "sorted_df.to_excel('sorted_merged_results.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "263c4b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No._similarity</th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Value</th>\n",
       "      <th>Sr No._mutual_info</th>\n",
       "      <th>Mutual Information Score</th>\n",
       "      <th>Sr. No.</th>\n",
       "      <th>Correlation Score</th>\n",
       "      <th>Average Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>maximum period of compliance at lgb (in days) ...</td>\n",
       "      <td>0.042182</td>\n",
       "      <td>4</td>\n",
       "      <td>0.081424</td>\n",
       "      <td>2</td>\n",
       "      <td>0.291744</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>total number of follow up at LGBRIMH</td>\n",
       "      <td>0.042317</td>\n",
       "      <td>7</td>\n",
       "      <td>0.068447</td>\n",
       "      <td>4</td>\n",
       "      <td>0.283869</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>total_frequency</td>\n",
       "      <td>0.045023</td>\n",
       "      <td>10</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>5</td>\n",
       "      <td>0.276919</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Maximum duration of symptom free period (in days)</td>\n",
       "      <td>0.051824</td>\n",
       "      <td>18</td>\n",
       "      <td>0.029481</td>\n",
       "      <td>3</td>\n",
       "      <td>0.289070</td>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>days/freq</td>\n",
       "      <td>0.035563</td>\n",
       "      <td>11</td>\n",
       "      <td>0.058237</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.236128</td>\n",
       "      <td>8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>total duration of medication treatment at LGB(...</td>\n",
       "      <td>0.036004</td>\n",
       "      <td>12</td>\n",
       "      <td>0.054573</td>\n",
       "      <td>8</td>\n",
       "      <td>0.202563</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Off-medications duration (to add all such dura...</td>\n",
       "      <td>0.056537</td>\n",
       "      <td>2</td>\n",
       "      <td>0.089496</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.084005</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Total duration of medication 2(in days)</td>\n",
       "      <td>0.030494</td>\n",
       "      <td>8</td>\n",
       "      <td>0.066954</td>\n",
       "      <td>15</td>\n",
       "      <td>0.113820</td>\n",
       "      <td>11.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>mean gap ratio at lgb (total no of months of f...</td>\n",
       "      <td>0.041425</td>\n",
       "      <td>5</td>\n",
       "      <td>0.072944</td>\n",
       "      <td>30</td>\n",
       "      <td>0.079685</td>\n",
       "      <td>13.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Medication possession ratios 1(MPRs) in lgb;x-...</td>\n",
       "      <td>0.033481</td>\n",
       "      <td>9</td>\n",
       "      <td>0.066494</td>\n",
       "      <td>29</td>\n",
       "      <td>0.082006</td>\n",
       "      <td>15.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Total duration of medication 1 (in days)</td>\n",
       "      <td>0.027204</td>\n",
       "      <td>29</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>9</td>\n",
       "      <td>0.195820</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Age at presentation (in yrs)</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>25</td>\n",
       "      <td>0.019688</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.090322</td>\n",
       "      <td>19.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Continued medication 2/stopped/changed</td>\n",
       "      <td>0.025246</td>\n",
       "      <td>34</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>10</td>\n",
       "      <td>0.193964</td>\n",
       "      <td>20.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>School Adjustment</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>22</td>\n",
       "      <td>0.024658</td>\n",
       "      <td>13</td>\n",
       "      <td>0.130494</td>\n",
       "      <td>20.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>total_days1</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>15</td>\n",
       "      <td>0.043786</td>\n",
       "      <td>33</td>\n",
       "      <td>0.072007</td>\n",
       "      <td>20.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>No of relapses/exacerbations</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>17</td>\n",
       "      <td>0.033168</td>\n",
       "      <td>35</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>23.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Max Duration of resolution of symptoms before ...</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.276085</td>\n",
       "      <td>24.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Age at onset(in years)</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>37</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.090728</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Maximum dose of medication 1 (in mg)</td>\n",
       "      <td>0.026263</td>\n",
       "      <td>31</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>36</td>\n",
       "      <td>0.067057</td>\n",
       "      <td>27.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>Rural/Urban</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>28</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>17</td>\n",
       "      <td>0.099830</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Age at last follow up</td>\n",
       "      <td>0.021446</td>\n",
       "      <td>6</td>\n",
       "      <td>0.068525</td>\n",
       "      <td>60</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>28.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Medication possession ratios 2(MPRs) in lgb;x-...</td>\n",
       "      <td>0.019254</td>\n",
       "      <td>30</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.072624</td>\n",
       "      <td>28.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>outbursts</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>13</td>\n",
       "      <td>0.050675</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.118693</td>\n",
       "      <td>28.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Continued medication 1/stopped/changed</td>\n",
       "      <td>0.017281</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.088775</td>\n",
       "      <td>29.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Distance from LGBRIMH (in KM)</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.090810</td>\n",
       "      <td>30.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>Follow up diagnosis changed or not (yes/no)</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>20</td>\n",
       "      <td>0.027593</td>\n",
       "      <td>16</td>\n",
       "      <td>0.106881</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Family environment</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>16</td>\n",
       "      <td>0.036636</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.034065</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>weight (in Kg)</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>21</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>52</td>\n",
       "      <td>0.026139</td>\n",
       "      <td>31.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Time period between onset to first consultatio...</td>\n",
       "      <td>0.025792</td>\n",
       "      <td>24</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>56</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>adhd</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>19</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>26</td>\n",
       "      <td>0.083695</td>\n",
       "      <td>32.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Response to medication 1 (Good/partial/no)</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>14</td>\n",
       "      <td>0.049599</td>\n",
       "      <td>53</td>\n",
       "      <td>0.023813</td>\n",
       "      <td>32.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>systemic examination(abnormal/normal)</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>31</td>\n",
       "      <td>0.074685</td>\n",
       "      <td>34.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Response to medication 2 (Good/partial/no)</td>\n",
       "      <td>0.015436</td>\n",
       "      <td>35</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.046339</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>significant psychosocial stressor</td>\n",
       "      <td>0.006442</td>\n",
       "      <td>23</td>\n",
       "      <td>0.023740</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.039125</td>\n",
       "      <td>35.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>Type of Family (Nuclear/Joint/single parent/or...</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.095081</td>\n",
       "      <td>35.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>Change in doctor</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>3</td>\n",
       "      <td>0.084568</td>\n",
       "      <td>55</td>\n",
       "      <td>0.018691</td>\n",
       "      <td>36.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Mental status examination/Behavioral Observati...</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>33</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.045258</td>\n",
       "      <td>36.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>low</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.085507</td>\n",
       "      <td>37.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Max education attained</td>\n",
       "      <td>0.009767</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>0.049811</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>jerky</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>27</td>\n",
       "      <td>0.017063</td>\n",
       "      <td>51</td>\n",
       "      <td>0.029180</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>Number of In patient cares</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>36</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>27</td>\n",
       "      <td>0.082455</td>\n",
       "      <td>38.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>anxious</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103339</td>\n",
       "      <td>57</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>38.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>If yes, after how many days from first present...</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>26</td>\n",
       "      <td>0.019280</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>39.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>Sex (m/f)</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.071062</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>depression2</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.154245</td>\n",
       "      <td>40.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Avg dose of medication 1 (Mode value of medica...</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45</td>\n",
       "      <td>0.043787</td>\n",
       "      <td>41.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>Past/Current medical conditions</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>0.082140</td>\n",
       "      <td>42.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>Religion</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.049126</td>\n",
       "      <td>43.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>irritable</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "      <td>0.063836</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>seizure</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>0.061944</td>\n",
       "      <td>44.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.031793</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>restless</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>32</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>46.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Academic performance</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>0.022744</td>\n",
       "      <td>46.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>Socioeconomic status</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.037702</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>0.056554</td>\n",
       "      <td>47.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>restlessness</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.048583</td>\n",
       "      <td>48.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>cost of medication</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>0.035124</td>\n",
       "      <td>49.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>poor</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61</td>\n",
       "      <td>-0.004646</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>eye contact</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59</td>\n",
       "      <td>-0.007223</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.008080</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sr No._similarity                                        Column Name  \\\n",
       "4                   5  maximum period of compliance at lgb (in days) ...   \n",
       "3                   4               total number of follow up at LGBRIMH   \n",
       "2                   3                                    total_frequency   \n",
       "1                   2  Maximum duration of symptom free period (in days)   \n",
       "7                   8                                          days/freq   \n",
       "6                   7  total duration of medication treatment at LGB(...   \n",
       "0                   1  Off-medications duration (to add all such dura...   \n",
       "10                 11           Total duration of medication 2(in days)    \n",
       "5                   6  mean gap ratio at lgb (total no of months of f...   \n",
       "8                   9  Medication possession ratios 1(MPRs) in lgb;x-...   \n",
       "12                 13          Total duration of medication 1 (in days)    \n",
       "11                 12                       Age at presentation (in yrs)   \n",
       "16                 17             Continued medication 2/stopped/changed   \n",
       "25                 26                                  School Adjustment   \n",
       "13                 14                                        total_days1   \n",
       "17                 18                       No of relapses/exacerbations   \n",
       "9                  10  Max Duration of resolution of symptoms before ...   \n",
       "21                 22                             Age at onset(in years)   \n",
       "14                 15               Maximum dose of medication 1 (in mg)   \n",
       "38                 39                                        Rural/Urban   \n",
       "19                 20                              Age at last follow up   \n",
       "23                 24  Medication possession ratios 2(MPRs) in lgb;x-...   \n",
       "58                 59                                          outbursts   \n",
       "24                 25             Continued medication 1/stopped/changed   \n",
       "18                 19                      Distance from LGBRIMH (in KM)   \n",
       "56                 57        Follow up diagnosis changed or not (yes/no)   \n",
       "27                 28                                 Family environment   \n",
       "20                 21                                     weight (in Kg)   \n",
       "15                 16  Time period between onset to first consultatio...   \n",
       "51                 52                                               adhd   \n",
       "29                 30         Response to medication 1 (Good/partial/no)   \n",
       "33                 34              systemic examination(abnormal/normal)   \n",
       "26                 27         Response to medication 2 (Good/partial/no)   \n",
       "36                 37                  significant psychosocial stressor   \n",
       "34                 35  Type of Family (Nuclear/Joint/single parent/or...   \n",
       "50                 51                                   Change in doctor   \n",
       "32                 33  Mental status examination/Behavioral Observati...   \n",
       "44                 45                                                low   \n",
       "31                 32                             Max education attained   \n",
       "35                 36                                              jerky   \n",
       "52                 53                         Number of In patient cares   \n",
       "57                 58                                            anxious   \n",
       "28                 29  If yes, after how many days from first present...   \n",
       "39                 40                                          Sex (m/f)   \n",
       "49                 50                                        depression2   \n",
       "22                 23  Avg dose of medication 1 (Mode value of medica...   \n",
       "42                 43                    Past/Current medical conditions   \n",
       "43                 44                                           Religion   \n",
       "46                 47                                          irritable   \n",
       "47                 48                                            seizure   \n",
       "37                 38                                           abnormal   \n",
       "45                 46                                           restless   \n",
       "30                 31                               Academic performance   \n",
       "40                 41                               Socioeconomic status   \n",
       "59                 60                                      hallucination   \n",
       "53                 54                                       restlessness   \n",
       "41                 42                                 cost of medication   \n",
       "48                 49                                               poor   \n",
       "54                 55                                        eye contact   \n",
       "55                 56                                              angry   \n",
       "\n",
       "       Value  Sr No._mutual_info  Mutual Information Score  Sr. No.  \\\n",
       "4   0.042182                   4                  0.081424        2   \n",
       "3   0.042317                   7                  0.068447        4   \n",
       "2   0.045023                  10                  0.061889        5   \n",
       "1   0.051824                  18                  0.029481        3   \n",
       "7   0.035563                  11                  0.058237        7   \n",
       "6   0.036004                  12                  0.054573        8   \n",
       "0   0.056537                   2                  0.089496       25   \n",
       "10  0.030494                   8                  0.066954       15   \n",
       "5   0.041425                   5                  0.072944       30   \n",
       "8   0.033481                   9                  0.066494       29   \n",
       "12  0.027204                  29                  0.015687        9   \n",
       "11  0.029349                  25                  0.019688       22   \n",
       "16  0.025246                  34                  0.004965       10   \n",
       "25  0.015758                  22                  0.024658       13   \n",
       "13  0.026826                  15                  0.043786       33   \n",
       "17  0.024583                  17                  0.033168       35   \n",
       "9   0.031562                  58                  0.000000        6   \n",
       "21  0.019907                  37                  0.001206       21   \n",
       "14  0.026263                  31                  0.009807       36   \n",
       "38  0.005909                  28                  0.016799       17   \n",
       "19  0.021446                   6                  0.068525       60   \n",
       "23  0.019254                  30                  0.010382       32   \n",
       "58  0.002204                  13                  0.050675       14   \n",
       "24  0.017281                  41                  0.000000       23   \n",
       "18  0.024215                  52                  0.000000       20   \n",
       "56  0.003031                  20                  0.027593       16   \n",
       "27  0.014977                  16                  0.036636       49   \n",
       "20  0.021375                  21                  0.025449       52   \n",
       "15  0.025792                  24                  0.020264       56   \n",
       "51  0.003714                  19                  0.028621       26   \n",
       "29  0.012964                  14                  0.049599       53   \n",
       "33  0.007265                  38                  0.000082       31   \n",
       "26  0.015436                  35                  0.003966       43   \n",
       "36  0.006442                  23                  0.023740       46   \n",
       "34  0.006717                  54                  0.000000       18   \n",
       "50  0.003817                   3                  0.084568       55   \n",
       "32  0.007691                  33                  0.005975       44   \n",
       "44  0.004857                  44                  0.000000       24   \n",
       "31  0.009767                  42                  0.000000       40   \n",
       "35  0.006489                  27                  0.017063       51   \n",
       "52  0.003239                  36                  0.003562       27   \n",
       "57  0.002747                   1                  0.103339       57   \n",
       "28  0.013829                  26                  0.019280       63   \n",
       "39  0.005870                  46                  0.000000       34   \n",
       "49  0.003991                  60                  0.000000       11   \n",
       "22  0.019759                  57                  0.000000       45   \n",
       "42  0.005595                  56                  0.000000       28   \n",
       "43  0.004949                  45                  0.000000       41   \n",
       "46  0.004382                  48                  0.000000       37   \n",
       "47  0.004197                  47                  0.000000       38   \n",
       "37  0.006365                  50                  0.000000       50   \n",
       "45  0.004771                  32                  0.006923       62   \n",
       "30  0.012228                  55                  0.000000       54   \n",
       "40  0.005787                  53                  0.000000       47   \n",
       "59  0.001268                  43                  0.000000       39   \n",
       "53  0.003070                  49                  0.000000       42   \n",
       "41  0.005619                  59                  0.000000       48   \n",
       "48  0.004063                  40                  0.000000       61   \n",
       "54  0.003043                  39                  0.000000       59   \n",
       "55  0.003038                  51                  0.000000       58   \n",
       "\n",
       "    Correlation Score  Average Rank  \n",
       "4            0.291744      3.666667  \n",
       "3            0.283869      5.000000  \n",
       "2            0.276919      6.000000  \n",
       "1            0.289070      7.666667  \n",
       "7           -0.236128      8.666667  \n",
       "6            0.202563      9.000000  \n",
       "0           -0.084005      9.333333  \n",
       "10           0.113820     11.333333  \n",
       "5            0.079685     13.666667  \n",
       "8            0.082006     15.666667  \n",
       "12           0.195820     17.000000  \n",
       "11          -0.090322     19.666667  \n",
       "16           0.193964     20.333333  \n",
       "25           0.130494     20.333333  \n",
       "13           0.072007     20.666667  \n",
       "17           0.070423     23.333333  \n",
       "9            0.276085     24.666667  \n",
       "21          -0.090728     26.666667  \n",
       "14           0.067057     27.333333  \n",
       "38           0.099830     28.000000  \n",
       "19           0.006969     28.666667  \n",
       "23          -0.072624     28.666667  \n",
       "58          -0.118693     28.666667  \n",
       "24          -0.088775     29.666667  \n",
       "18          -0.090810     30.333333  \n",
       "56           0.106881     31.000000  \n",
       "27          -0.034065     31.000000  \n",
       "20           0.026139     31.333333  \n",
       "15           0.015991     32.000000  \n",
       "51           0.083695     32.333333  \n",
       "29           0.023813     32.333333  \n",
       "33           0.074685     34.333333  \n",
       "26          -0.046339     35.000000  \n",
       "36          -0.039125     35.333333  \n",
       "34           0.095081     35.666667  \n",
       "50           0.018691     36.333333  \n",
       "32          -0.045258     36.666667  \n",
       "44           0.085507     37.666667  \n",
       "31           0.049811     38.000000  \n",
       "35           0.029180     38.000000  \n",
       "52           0.082455     38.666667  \n",
       "57           0.010158     38.666667  \n",
       "28          -0.000714     39.333333  \n",
       "39          -0.071062     40.000000  \n",
       "49           0.154245     40.333333  \n",
       "22           0.043787     41.666667  \n",
       "42           0.082140     42.333333  \n",
       "43           0.049126     43.333333  \n",
       "46           0.063836     44.000000  \n",
       "47           0.061944     44.333333  \n",
       "37           0.031793     46.000000  \n",
       "45           0.001452     46.666667  \n",
       "30           0.022744     46.666667  \n",
       "40           0.037702     47.000000  \n",
       "59           0.056554     47.333333  \n",
       "53           0.048583     48.333333  \n",
       "41           0.035124     49.666667  \n",
       "48          -0.004646     50.000000  \n",
       "54          -0.007223     51.000000  \n",
       "55          -0.008080     55.000000  "
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "cec13d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "3565db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the sorted DataFrame\n",
    "sorted_df = pd.read_excel('sorted_merged_results.xlsx')\n",
    "\n",
    "# Extract the first 10 features\n",
    "selected_features = sorted_df['Column Name'].tolist()[:10]\n",
    "\n",
    "# Select only the first 10 columns in df4 based on the selected features\n",
    "df4 = df4[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "495ee8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_18628\\2762611607.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['Final'] = df3['Final']\n"
     ]
    }
   ],
   "source": [
    "df4['Final'] = df3['Final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "3d747ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>total_frequency</th>\n",
       "      <th>Maximum duration of symptom free period (in days)</th>\n",
       "      <th>days/freq</th>\n",
       "      <th>total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)</th>\n",
       "      <th>Off-medications duration (to add all such durations over follow-up in days)</th>\n",
       "      <th>Total duration of medication 2(in days)</th>\n",
       "      <th>mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)</th>\n",
       "      <th>Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period)</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>395.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>390</td>\n",
       "      <td>48.083333</td>\n",
       "      <td>626</td>\n",
       "      <td>22</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>270</td>\n",
       "      <td>886.750000</td>\n",
       "      <td>330</td>\n",
       "      <td>30</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>570</td>\n",
       "      <td>52.940299</td>\n",
       "      <td>1320</td>\n",
       "      <td>58</td>\n",
       "      <td>2686.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>480.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>480</td>\n",
       "      <td>54.342857</td>\n",
       "      <td>3495</td>\n",
       "      <td>65</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>648.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>648</td>\n",
       "      <td>61.600000</td>\n",
       "      <td>648</td>\n",
       "      <td>0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>113.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>228</td>\n",
       "      <td>102.400000</td>\n",
       "      <td>576</td>\n",
       "      <td>330</td>\n",
       "      <td>576.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>384</td>\n",
       "      <td>180</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>390.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>530</td>\n",
       "      <td>39.545455</td>\n",
       "      <td>875</td>\n",
       "      <td>120</td>\n",
       "      <td>817.0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1619.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>205</td>\n",
       "      <td>61.680000</td>\n",
       "      <td>1619</td>\n",
       "      <td>0</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "1                                                395.0                                   \n",
       "2                                                240.0                                   \n",
       "3                                                  0.0                                   \n",
       "4                                                 90.0                                   \n",
       "5                                                480.0                                   \n",
       "..                                                 ...                                   \n",
       "163                                              648.0                                   \n",
       "164                                              113.0                                   \n",
       "186                                              170.0                                   \n",
       "187                                              390.0                                   \n",
       "191                                             1619.0                                   \n",
       "\n",
       "     total number of follow up at LGBRIMH  total_frequency  \\\n",
       "1                                    12.0             12.0   \n",
       "2                                     4.0              4.0   \n",
       "3                                    69.0             67.0   \n",
       "4                                     2.0              2.0   \n",
       "5                                    71.0             70.0   \n",
       "..                                    ...              ...   \n",
       "163                                  10.0             10.0   \n",
       "164                                   5.0              5.0   \n",
       "186                                   3.0              3.0   \n",
       "187                                  24.0             22.0   \n",
       "191                                  25.0             25.0   \n",
       "\n",
       "     Maximum duration of symptom free period (in days)   days/freq  \\\n",
       "1                                                  390   48.083333   \n",
       "2                                                  270  886.750000   \n",
       "3                                                  570   52.940299   \n",
       "4                                                   60   50.000000   \n",
       "5                                                  480   54.342857   \n",
       "..                                                 ...         ...   \n",
       "163                                                648   61.600000   \n",
       "164                                                228  102.400000   \n",
       "186                                                 30  118.000000   \n",
       "187                                                530   39.545455   \n",
       "191                                                205   61.680000   \n",
       "\n",
       "     total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)  \\\n",
       "1                                                  626                                                    \n",
       "2                                                  330                                                    \n",
       "3                                                 1320                                                    \n",
       "4                                                   90                                                    \n",
       "5                                                 3495                                                    \n",
       "..                                                 ...                                                    \n",
       "163                                                648                                                    \n",
       "164                                                576                                                    \n",
       "186                                                384                                                    \n",
       "187                                                875                                                    \n",
       "191                                               1619                                                    \n",
       "\n",
       "     Off-medications duration (to add all such durations over follow-up in days)  \\\n",
       "1                                                   22                             \n",
       "2                                                   30                             \n",
       "3                                                   58                             \n",
       "4                                                   20                             \n",
       "5                                                   65                             \n",
       "..                                                 ...                             \n",
       "163                                                  0                             \n",
       "164                                                330                             \n",
       "186                                                180                             \n",
       "187                                                120                             \n",
       "191                                                  0                             \n",
       "\n",
       "     Total duration of medication 2(in days)   \\\n",
       "1                                       240.0   \n",
       "2                                       180.0   \n",
       "3                                      2686.0   \n",
       "4                                         0.0   \n",
       "5                                      1819.0   \n",
       "..                                        ...   \n",
       "163                                     648.0   \n",
       "164                                     576.0   \n",
       "186                                      70.0   \n",
       "187                                     817.0   \n",
       "191                                    1619.0   \n",
       "\n",
       "     mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)  \\\n",
       "1                                                 1.66                                     \n",
       "2                                                 1.78                                     \n",
       "3                                                 0.00                                     \n",
       "4                                                 1.00                                     \n",
       "5                                                 6.60                                     \n",
       "..                                                 ...                                     \n",
       "163                                               2.10                                     \n",
       "164                                               3.80                                     \n",
       "186                                               4.30                                     \n",
       "187                                               1.21                                     \n",
       "191                                               2.15                                     \n",
       "\n",
       "     Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period)   \\\n",
       "1                                                 0.96                                                                                                                                                                   \n",
       "2                                                 0.90                                                                                                                                                                   \n",
       "3                                                 0.00                                                                                                                                                                   \n",
       "4                                                 0.30                                                                                                                                                                   \n",
       "5                                                 0.98                                                                                                                                                                   \n",
       "..                                                 ...                                                                                                                                                                   \n",
       "163                                               1.00                                                                                                                                                                   \n",
       "164                                               0.42                                                                                                                                                                   \n",
       "186                                               1.00                                                                                                                                                                   \n",
       "187                                               1.00                                                                                                                                                                   \n",
       "191                                               0.00                                                                                                                                                                   \n",
       "\n",
       "     Final  \n",
       "1      1.0  \n",
       "2      0.0  \n",
       "3      2.0  \n",
       "4      2.0  \n",
       "5      1.0  \n",
       "..     ...  \n",
       "163    2.0  \n",
       "164    0.0  \n",
       "186    0.0  \n",
       "187    1.0  \n",
       "191    1.0  \n",
       "\n",
       "[148 rows x 11 columns]"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "a880966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "b7177caa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)', 'Off-medications duration (to add all such durations over follow-up in days)', 'Total duration of medication 2(in days) ', 'mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)', 'Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) ', 'Total duration of medication 1 (in days) ', 'Age at presentation (in yrs)', 'Continued medication 2/stopped/changed', 'School Adjustment', 'total_days1', 'No of relapses/exacerbations', 'Max Duration of resolution of symptoms before recurrence/relapse (in days)', 'Age at onset(in years)', 'Maximum dose of medication 1 (in mg)', 'Rural/Urban', 'Age at last follow up', 'Medication possession ratios 2(MPRs) in lgb;x-syrup', 'outbursts', 'Continued medication 1/stopped/changed', 'Distance from LGBRIMH (in KM)', 'Follow up diagnosis changed or not (yes/no)', 'Family environment', 'weight (in Kg)', 'Time period between onset to first consultation at LGBRIMH (DUI) (in days)', 'adhd'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [547], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m sorted_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()[:\u001b[38;5;241m30\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Select only the first 10 columns in df4 based on the selected features\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df4\u001b[38;5;241m=\u001b[39m \u001b[43mdf4\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3810\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3809\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3810\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3812\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6111\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6109\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6113\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6115\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6174\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6173\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6174\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['total duration of medication treatment at LGB(in days) (from first consultation to last follow-up)', 'Off-medications duration (to add all such durations over follow-up in days)', 'Total duration of medication 2(in days) ', 'mean gap ratio at lgb (total no of months of follow-up divided by no of follow-ups)', 'Medication possession ratios 1(MPRs) in lgb;x-syrup (total number of days when medications were taken divided by summation of total number of days when medications were taken with total off medication period) ', 'Total duration of medication 1 (in days) ', 'Age at presentation (in yrs)', 'Continued medication 2/stopped/changed', 'School Adjustment', 'total_days1', 'No of relapses/exacerbations', 'Max Duration of resolution of symptoms before recurrence/relapse (in days)', 'Age at onset(in years)', 'Maximum dose of medication 1 (in mg)', 'Rural/Urban', 'Age at last follow up', 'Medication possession ratios 2(MPRs) in lgb;x-syrup', 'outbursts', 'Continued medication 1/stopped/changed', 'Distance from LGBRIMH (in KM)', 'Follow up diagnosis changed or not (yes/no)', 'Family environment', 'weight (in Kg)', 'Time period between onset to first consultation at LGBRIMH (DUI) (in days)', 'adhd'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sorted_df = pd.read_excel('sorted_merged_results.xlsx')\n",
    "selected_features = sorted_df['Column Name'].tolist()[:30]\n",
    "df4= df4[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "88e50d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maximum period of compliance at lgb (in days) (longest streak of good compliance)</th>\n",
       "      <th>total number of follow up at LGBRIMH</th>\n",
       "      <th>total_frequency</th>\n",
       "      <th>Maximum duration of symptom free period (in days)</th>\n",
       "      <th>days/freq</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>395.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>390</td>\n",
       "      <td>48.083333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>270</td>\n",
       "      <td>886.750000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>570</td>\n",
       "      <td>52.940299</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>480.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>480</td>\n",
       "      <td>54.342857</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>648.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>648</td>\n",
       "      <td>61.600000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>113.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>228</td>\n",
       "      <td>102.400000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>390.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>530</td>\n",
       "      <td>39.545455</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1619.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>205</td>\n",
       "      <td>61.680000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     maximum period of compliance at lgb (in days) (longest streak of good compliance)  \\\n",
       "1                                                395.0                                   \n",
       "2                                                240.0                                   \n",
       "3                                                  0.0                                   \n",
       "4                                                 90.0                                   \n",
       "5                                                480.0                                   \n",
       "..                                                 ...                                   \n",
       "163                                              648.0                                   \n",
       "164                                              113.0                                   \n",
       "186                                              170.0                                   \n",
       "187                                              390.0                                   \n",
       "191                                             1619.0                                   \n",
       "\n",
       "     total number of follow up at LGBRIMH  total_frequency  \\\n",
       "1                                    12.0             12.0   \n",
       "2                                     4.0              4.0   \n",
       "3                                    69.0             67.0   \n",
       "4                                     2.0              2.0   \n",
       "5                                    71.0             70.0   \n",
       "..                                    ...              ...   \n",
       "163                                  10.0             10.0   \n",
       "164                                   5.0              5.0   \n",
       "186                                   3.0              3.0   \n",
       "187                                  24.0             22.0   \n",
       "191                                  25.0             25.0   \n",
       "\n",
       "     Maximum duration of symptom free period (in days)   days/freq  Final  \n",
       "1                                                  390   48.083333    1.0  \n",
       "2                                                  270  886.750000    0.0  \n",
       "3                                                  570   52.940299    2.0  \n",
       "4                                                   60   50.000000    2.0  \n",
       "5                                                  480   54.342857    1.0  \n",
       "..                                                 ...         ...    ...  \n",
       "163                                                648   61.600000    2.0  \n",
       "164                                                228  102.400000    0.0  \n",
       "186                                                 30  118.000000    0.0  \n",
       "187                                                530   39.545455    1.0  \n",
       "191                                                205   61.680000    1.0  \n",
       "\n",
       "[148 rows x 6 columns]"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "225ccdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_18628\\2762611607.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['Final'] = df3['Final']\n"
     ]
    }
   ],
   "source": [
    "df4['Final'] = df3['Final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "54719688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "baad2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sorted_df = pd.read_excel('sorted_merged_results.xlsx')\n",
    "selected_features = sorted_df['Column Name'].tolist()[:50]\n",
    "df4= df4[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "fb55ef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_18628\\2762611607.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['Final'] = df3['Final']\n"
     ]
    }
   ],
   "source": [
    "df4['Final'] = df3['Final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd6c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
