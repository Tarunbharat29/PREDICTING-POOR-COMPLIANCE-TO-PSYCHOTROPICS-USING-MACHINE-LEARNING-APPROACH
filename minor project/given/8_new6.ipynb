{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "407f2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('df2_data.xlsx')\n",
    "df.to_csv('df2_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "028827b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at presentation (in yrs)</th>\n",
       "      <th>Age at last follow up</th>\n",
       "      <th>Sex (m/f)</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Max education attained</th>\n",
       "      <th>Rural/Urban</th>\n",
       "      <th>Distance from LGBRIMH (in KM)</th>\n",
       "      <th>Socioeconomic status</th>\n",
       "      <th>Age at onset(in years)</th>\n",
       "      <th>Time period between onset to first consultation at LGBRIMH (DUI) (in days)</th>\n",
       "      <th>...</th>\n",
       "      <th>anxious</th>\n",
       "      <th>hallucination</th>\n",
       "      <th>depressed</th>\n",
       "      <th>seizure</th>\n",
       "      <th>adhd</th>\n",
       "      <th>depression1</th>\n",
       "      <th>School Adjustment</th>\n",
       "      <th>If yes, after how many days from first presentation diagnosis changed (in days)</th>\n",
       "      <th>Continued medication 1/stopped/changed</th>\n",
       "      <th>depression2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>5.5</td>\n",
       "      <td>912</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age at presentation (in yrs)  Age at last follow up  Sex (m/f)  Religion  \\\n",
       "0                           8.0                   10.0          0  0.000000   \n",
       "1                          17.0                   18.0          0  0.000000   \n",
       "2                           7.0                   17.0          1  0.000000   \n",
       "3                          10.0                   10.0          1  0.333333   \n",
       "4                           8.0                   15.0          0  0.000000   \n",
       "\n",
       "   Max education attained  Rural/Urban  Distance from LGBRIMH (in KM)  \\\n",
       "0                     0.0          0.5                           62.0   \n",
       "1                     0.4          0.5                           55.0   \n",
       "2                     0.0          0.5                          102.0   \n",
       "3                     0.4          0.5                           29.0   \n",
       "4                     0.0          0.5                          102.0   \n",
       "\n",
       "   Socioeconomic status  Age at onset(in years)  \\\n",
       "0                  0.00                     8.0   \n",
       "1                  0.00                    17.0   \n",
       "2                  0.00                     5.5   \n",
       "3                  0.33                     0.0   \n",
       "4                  0.33                     5.5   \n",
       "\n",
       "   Time period between onset to first consultation at LGBRIMH (DUI) (in days)  \\\n",
       "0                                                150                            \n",
       "1                                                  3                            \n",
       "2                                                  0                            \n",
       "3                                                 10                            \n",
       "4                                                912                            \n",
       "\n",
       "   ...  anxious  hallucination  depressed  seizure  adhd  depression1  \\\n",
       "0  ...        0              0          0        1     0            0   \n",
       "1  ...        0              0          0        1     0            0   \n",
       "2  ...        0              0          0        1     0            0   \n",
       "3  ...        0              0          0        0     1            0   \n",
       "4  ...        0              0          0        1     0            0   \n",
       "\n",
       "   School Adjustment  \\\n",
       "0               0.00   \n",
       "1               0.66   \n",
       "2               0.00   \n",
       "3               1.00   \n",
       "4               0.00   \n",
       "\n",
       "   If yes, after how many days from first presentation diagnosis changed (in days)  \\\n",
       "0                                                  0                                 \n",
       "1                                                  0                                 \n",
       "2                                                  0                                 \n",
       "3                                                  0                                 \n",
       "4                                                  0                                 \n",
       "\n",
       "   Continued medication 1/stopped/changed  depression2  \n",
       "0                                       4            0  \n",
       "1                                       4            0  \n",
       "2                                       3            0  \n",
       "3                                       4            0  \n",
       "4                                       3            0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('df2_data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44609298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4243cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sorted_df = pd.read_excel('rank2.xlsx')\n",
    "selected_features = sorted_df['Column Name'].tolist()[:30]\n",
    "df4 = df4[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b71c4527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9088\\4197094083.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['Final'] = df['Final']\n"
     ]
    }
   ],
   "source": [
    "df4['Final'] = df['Final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d49ae7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExplainerError",
     "evalue": "Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 0.450000, while the model output was 0.437500. If this difference is acceptable you can set check_additivity=False to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExplainerError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Explain the model predictions using SHAP\u001b[39;00m\n\u001b[0;32m     20\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(model, X_train)\n\u001b[1;32m---> 21\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Initialize lists to store results\u001b[39;00m\n\u001b[0;32m     24\u001b[0m results_shap \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_tree.py:510\u001b[0m, in \u001b[0;36mTreeExplainer.shap_values\u001b[1;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[0;32m    508\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_shap_output(phi, flat_output)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_additivity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 510\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_additivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# This statements handles the case of multiple outputs\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m# e.g. a multi-class classification problem, multi-target regression problem\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# in this case the output shape corresponds to [num_samples, num_features, num_outputs]\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_tree.py:678\u001b[0m, in \u001b[0;36mTreeExplainer.assert_additivity\u001b[1;34m(self, phi, model_output)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(phi, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(phi)):\n\u001b[1;32m--> 678\u001b[0m         \u001b[43mcheck_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_value\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    680\u001b[0m     check_sum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m+\u001b[39m phi\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), model_output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_tree.py:674\u001b[0m, in \u001b[0;36mTreeExplainer.assert_additivity.<locals>.check_sum\u001b[1;34m(sum_val, model_output)\u001b[0m\n\u001b[0;32m    670\u001b[0m     err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Consider retrying with the feature_perturbation=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterventional\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m option.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This check failed because for one of the samples the sum of the SHAP values\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    672\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msum_val[ind]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, while the model output was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_output[ind]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If this\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    673\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m difference is acceptable you can set check_additivity=False to disable this check.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 674\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ExplainerError(err_msg)\n",
      "\u001b[1;31mExplainerError\u001b[0m: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 0.450000, while the model output was 0.437500. If this difference is acceptable you can set check_additivity=False to disable this check."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier\n",
    "import shap\n",
    "\n",
    "X = df4.drop('Final', axis=1)\n",
    "y = df4['Final']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=80, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "results_shap = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    shap_instance = shap_values[i]\n",
    "    \n",
    "    feature_importance = pd.DataFrame(abs(shap_instance).mean(axis=0), index=X_train.columns, columns=['Weight'])\n",
    "    feature_importance.reset_index(inplace=True)\n",
    "    feature_importance.rename(columns={'index': 'Feature'}, inplace=True)\n",
    "    \n",
    "    results_shap.append(feature_importance)\n",
    "    print('Instance:', i)\n",
    "    print('Original prediction probabilities:', model.predict_proba(X_test.iloc[[i]])[0])\n",
    "    print('SHAP explanation for the prediction:')\n",
    "    print(feature_importance)\n",
    "    print('\\n')\n",
    "\n",
    "df_results_shap = pd.concat(results_shap)\n",
    "final_table_shap = df_results_shap.groupby('Feature').agg({'Weight': 'mean'}).reset_index()\n",
    "final_table_shap['Rank'] = final_table_shap['Weight'].rank(ascending=False)\n",
    "\n",
    "print('Final Table (SHAP):')\n",
    "print(final_table_shap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f09620",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TreeExplainer.__init__() got an unexpected keyword argument 'check_additivity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Explain the model predictions using SHAP\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Disable additivity check\u001b[39;00m\n\u001b[0;32m      7\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_explainer.py:188\u001b[0m, in \u001b[0;36mExplainer.__init__\u001b[1;34m(self, model, masker, link, algorithm, output_names, feature_names, linearize_link, seed, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m explainers\u001b[38;5;241m.\u001b[39mTreeExplainer\n\u001b[1;32m--> 188\u001b[0m     explainers\u001b[38;5;241m.\u001b[39mTreeExplainer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker, link\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlink, feature_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, linearize_link\u001b[38;5;241m=\u001b[39mlinearize_link, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditive\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m explainers\u001b[38;5;241m.\u001b[39mAdditiveExplainer\n",
      "\u001b[1;31mTypeError\u001b[0m: TreeExplainer.__init__() got an unexpected keyword argument 'check_additivity'"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=80, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = shap.Explainer(model, X_train, check_additivity=False)  # Disable additivity check\n",
    "shap_values = explainer.shap_values(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b92a2bfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExplainerError",
     "evalue": "Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 0.090100, while the model output was 0.100000. If this difference is acceptable you can set check_additivity=False to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExplainerError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(rf_classifier, features)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Calculate SHAP values for all instances\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Create a dictionary to store the importance of each feature for each class\u001b[39;00m\n\u001b[0;32m     21\u001b[0m feature_importance_per_class \u001b[38;5;241m=\u001b[39m {class_label: {} \u001b[38;5;28;01mfor\u001b[39;00m class_label \u001b[38;5;129;01min\u001b[39;00m target\u001b[38;5;241m.\u001b[39munique()}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_tree.py:510\u001b[0m, in \u001b[0;36mTreeExplainer.shap_values\u001b[1;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[0;32m    508\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_shap_output(phi, flat_output)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_additivity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 510\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_additivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# This statements handles the case of multiple outputs\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m# e.g. a multi-class classification problem, multi-target regression problem\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# in this case the output shape corresponds to [num_samples, num_features, num_outputs]\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_tree.py:678\u001b[0m, in \u001b[0;36mTreeExplainer.assert_additivity\u001b[1;34m(self, phi, model_output)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(phi, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(phi)):\n\u001b[1;32m--> 678\u001b[0m         \u001b[43mcheck_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_value\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    680\u001b[0m     check_sum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m+\u001b[39m phi\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), model_output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_tree.py:674\u001b[0m, in \u001b[0;36mTreeExplainer.assert_additivity.<locals>.check_sum\u001b[1;34m(sum_val, model_output)\u001b[0m\n\u001b[0;32m    670\u001b[0m     err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Consider retrying with the feature_perturbation=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterventional\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m option.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This check failed because for one of the samples the sum of the SHAP values\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    672\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msum_val[ind]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, while the model output was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_output[ind]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If this\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    673\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m difference is acceptable you can set check_additivity=False to disable this check.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 674\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ExplainerError(err_msg)\n",
      "\u001b[1;31mExplainerError\u001b[0m: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 0.090100, while the model output was 0.100000. If this difference is acceptable you can set check_additivity=False to disable this check."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "features = df4.drop(columns=['Final'])  # Features (independent variables)\n",
    "target = df4['Final']  # Target variable\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(features, target)\n",
    "\n",
    "explainer = shap.Explainer(rf_classifier, features)\n",
    "\n",
    "shap_values = explainer.shap_values(features)\n",
    "feature_importance_per_class = {class_label: {} for class_label in target.unique()}\n",
    "\n",
    "for class_label in target.unique():\n",
    "    class_indices = target[target == class_label].index\n",
    "    for idx in class_indices:\n",
    "        instance_shap_values = shap_values[idx]\n",
    "        for feature, weight in zip(features.columns, instance_shap_values):\n",
    "            if feature not in feature_importance_per_class[class_label]:\n",
    "                feature_importance_per_class[class_label][feature] = []\n",
    "            feature_importance_per_class[class_label][feature].append(weight)\n",
    "\n",
    "average_feature_importance_per_class = {class_label: {feature: sum(weights) / len(weights) for feature, weights in importance.items()} for class_label, importance in feature_importance_per_class.items()}\n",
    "\n",
    "top_features_per_class = {class_label: sorted(importance.keys(), key=lambda x: abs(importance[x]).mean(), reverse=True)[:10] for class_label, importance in average_feature_importance_per_class.items()}\n",
    "\n",
    "for class_label, top_features in top_features_per_class.items():\n",
    "    print(f\"Top 10 features for class {class_label}: {top_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee0f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
